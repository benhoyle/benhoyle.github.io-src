{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim2Title\n",
    "\n",
    "This notebook looks at trying to implement the recursive model A described here - https://machinelearningmastery.com/encoder-decoder-models-text-summarization-keras/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "\n",
    "First we need a source of say ~ 10,000 titles and claims. We'll concentrate on G06 as crossing the streams of chemistry and computing results in some funky chimeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# imports\n",
    "import os, pickle\n",
    "from keras.preprocessing import text\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "50000 claims and titles loaded\n"
     ]
    }
   ],
   "source": [
    "# Get the claim 1 and classificationt text\n",
    "\n",
    "PIK = \"claim_and_title_50k.data\"\n",
    "\n",
    "if os.path.isfile(PIK):\n",
    "    with open(PIK, \"rb\") as f:\n",
    "        print(\"Loading data\")\n",
    "        data = pickle.load(f)\n",
    "        print(\"{0} claims and titles loaded\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n1. A method comprising:\\nreceiving a first e-mail message;\\ndetermining whether the received first e-mail message is related to another e-mail message in a mailbox;\\nwhen, based on the determining, the first e-mail message is not related another e-mail message, displaying a first entry associated with the first e-mail message in a mailbox display; and\\nwhen, based on the determining, the first e-mail message is related to a second e-mail message, generating an e-mail thread, the e-mail thread associating the first e-mail message and the second e-mail message, the e-mail thread having a thread header including information derived from attributes of at least one of the first or second e-mail messages, and displaying the thread header in the mailbox display as a thread header entry in place of separate mailbox entries for the first e-mail message and the second e-mail message.\\n\\n',\n",
       " '\\tThreaded presentation of electronic mail\\n')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Look at Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest claim is 17017 characters long.\n"
     ]
    }
   ],
   "source": [
    "length = max([len(d[0]) for d in data])\n",
    "print(\"Our longest claim is {0} characters long.\".format(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest title is 417 characters long.\n"
     ]
    }
   ],
   "source": [
    "length = max([len(d[1]) for d in data])\n",
    "print(\"Our longest title is {0} characters long.\".format(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Titles"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with a limited vocabulary in words on both the input and output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting vocabulary lengths\n",
    "X_vocab_len = 5000\n",
    "y_vocab_len = 2500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Adding start and stop tokens to output\n"
     ]
    }
   ],
   "source": [
    "# lower = true doesn't seem to work at the character level\n",
    "# We were filtering out our \\t and \\n characters! - use words instead of \\t and \\n\n",
    "print(\"\\n\\nAdding start and stop tokens to output\")\n",
    "data = [(c, \"startseq {0} stopseq\".format(t)) for c, t in data]\n",
    "\n",
    "t_title = text.Tokenizer(num_words=y_vocab_len, lower=True)\n",
    "Y_texts = [d[1] for d in data]\n",
    "t_title.fit_on_texts(Y_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['startseq \\tOperating a storage server on a virtual machine\\n stopseq',\n",
       " 'startseq \\tThreaded presentation of electronic mail\\n stopseq',\n",
       " 'startseq \\tMethod and apparatus for communicating during automated data processing\\n stopseq',\n",
       " 'startseq \\tTelemetry data analysis using multivariate sequential probability ratio test\\n stopseq',\n",
       " 'startseq \\tMethod and a system for integrating data from a source to a destination\\n stopseq']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_texts[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our output sequences (titles) have a vocabulary of 13465 words\n"
     ]
    }
   ],
   "source": [
    "print(\"Our output sequences (titles) have a vocabulary of {0} words\".format(max([v for k, v in t_title.word_index.items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So limiting to 2500 is fairly restrictive - about 1/5 of the total in just our small sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_seqs = t_title.texts_to_sequences(Y_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[1, 115, 7, 27, 72, 25, 7, 48, 84, 2]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_seqs[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing Claims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_claim = text.Tokenizer(\n",
    "                num_words=X_vocab_len, \n",
    "                filters='1.:;\\n',\n",
    "                lower=True,\n",
    "                split=\" \",\n",
    "                char_level=False\n",
    ")\n",
    "X_texts = [d[0] for d in data]\n",
    "t_claim.fit_on_texts(X_texts)\n",
    "X_seqs = t_claim.texts_to_sequences(X_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input sequences (claims) have a vocabulary of 69693 words\n"
     ]
    }
   ],
   "source": [
    "print(\"Our input sequences (claims) have a vocabulary of {0} words\".format(max([v for k, v in t_claim.word_index.items()])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. A virtualized clustered storage server system, comprising:\n",
      "at least one host computer having a host operating system; and\n",
      "a plurality of virtual computers operating on the at least one host computer, each of the plurality of virtual computers having one or more virtualization components and a guest operating system, said guest operating system being hosted by said host operating system of the at least one host computer,\n",
      "wherein each virtual computer of the plurality of virtual computers comprises a storage server system instance, including said guest operating system and at least one facility including at least one simulated storage device for storing data of at least one virtual volume,\n",
      "wherein the at least one host computer is to receive commands for manipulating data of a specified virtual volume, wherein each command is directed to a specified storage server system instance, and wherein the at least one host computer routes each of the commands to the respective specified storage server system instance through a virtual interface of the one or more virtualization components of the virtual computer,\n",
      "wherein each storage server system instance is to transmit, in response to receipt of a routed command to manipulate data of a specified virtual volume of a different storage server instance, a request to manipulate the data of the specified virtual volume to the different storage server instance using one or more emulated cluster network adapters, and manipulate said data of said specified virtual volume stored on the simulated storage device in accordance with the command, and\n",
      "wherein said at least one facility of each storage server system instance is mapped onto at least one corresponding facility of the host operating system via the one or more virtualization components of the virtual computer.\n",
      "\n",
      " [2, 2573, 3851, 41, 70, 88, 25, 14, 24, 8, 196, 39, 59, 2, 196, 182, 34, 5, 2, 22, 3, 97, 968, 182, 18, 1, 14, 24, 8, 196, 265, 29, 3, 1, 22, 3, 97, 968, 59, 8, 20, 30, 2030, 320, 5, 2, 1521, 182, 88, 16, 1521, 182, 34, 45, 1802, 15, 16, 196, 182, 34, 3, 1, 14, 24, 8, 196, 265, 17, 29, 97, 39, 3, 1, 22, 3, 97, 968, 73, 2, 41, 70, 34, 2922, 53, 16, 1521, 182, 34, 5, 14, 24, 8, 1317, 53, 14, 24, 8, 1452, 41, 28, 9, 105, 10, 3, 14, 24, 8, 97, 1960, 17, 1, 14, 24, 8, 196, 39, 13, 4, 155, 700, 9, 3578, 10, 3, 2, 294, 97, 1960, 17, 29, 206, 13, 1190, 4, 2, 294, 41, 70, 34, 2922, 5, 17, 1, 14, 24, 8, 196, 39, 3094, 29, 3, 1, 700, 4, 1, 93, 294, 41, 70, 34, 417, 167, 2, 97, 81, 3, 1, 8, 20, 30, 2030, 320, 3, 1, 97, 265, 17, 29, 41, 70, 34, 417, 13, 4, 3458, 6, 68, 4, 967, 3, 2, 4174, 206, 4, 10, 3, 2, 294, 97, 364, 3, 2, 111, 41, 70, 2922, 2, 63, 4, 1, 10, 3, 1, 294, 97, 364, 4, 1, 111, 41, 70, 417, 48, 8, 20, 30, 3657, 524, 58, 5, 16, 10, 3, 16, 294, 97, 364, 77, 18, 1, 1452, 41, 28, 6, 335, 19, 1, 1523, 5, 17, 16, 14, 24, 8, 1317, 3, 29, 41, 70, 34, 417, 13, 1320, 991, 14, 24, 8, 52, 1317, 3, 1, 196, 182, 34, 98, 1, 8, 20, 30, 2030, 320, 3, 1, 97, 39]\n"
     ]
    }
   ],
   "source": [
    "print(X_texts[0], X_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "startseq \tOperating a storage server on a virtual machine\n",
      " stopseq [1, 115, 7, 27, 72, 25, 7, 48, 84, 2]\n"
     ]
    }
   ],
   "source": [
    "print(Y_texts[0], Y_seqs[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our sequence length distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest sequence is 2386 tokens long.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c7d26af28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X_length = [len(x) for x in X_seqs]\n",
    "max_length = max(X_length)\n",
    "print(\"Our longest sequence is {0} tokens long.\".format(max_length))\n",
    "\n",
    "bins = np.linspace(0, max_length, 200)\n",
    "plt.hist(X_length, bins)\n",
    "plt.title('Claim 1 - Sequence Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvNQv5yAAAIABJREFUeJzt3XmYXVWd7vHvS8IgYwIpY0wCQYlygaYZiumCiIAIkWtoGxQaJWC8keeC4oVWgxM40BdURFREg4yKDNogaUAhzSA2MlUghFkigyQdSAJhkkGDv/vHWifZKWo4u+pMder9PM95zt5r7732Wqeqzq/WWnuvrYjAzMysWms0uwBmZja0OHCYmVkpDhxmZlaKA4eZmZXiwGFmZqU4cJiZWSkOHFZzkk6W9PMq9/2xpK/Uu0w2NEkKSVs0uxy2OgcOGxBJ/yKpS9LLkhZL+o2kPcrmExFHR8Q3alSm90m6SdILkp6oQX57SPpDzu85SbdK2qkGRW15zfjClnSzpE828pw2MA4cVpqk44HvAf8GjAU2BX4ETG1muYC/AOcBnxtsRpI2BK4GfgBsDIwHvga8Pti8zYY6Bw4rRdJGwNeBYyLiioj4S0T8LSL+IyJ6/MKW9EtJT+f/3G+RtHVh2wWSvpmX95K0UNLnJS3JLZmDJE2R9Mf8X/8XeytbRNwZET8DHqtBVd+V87wkIt6IiFcj4vqImF8o+yckPSRpuaTrJG1W2PZ+SQ/nOv9Q0u8q/01378qTNCn/hz8yr28k6dxc/0WSvilpRN52pKT/kvSdfN7HJR1QyGtjSedL+u+8/deFbQdKmifp+dyS2nYgH0w/9Q5JR0t6NJ/nLEnK20ZIOl3SslzuYyv1lnQK8B7gh7kV+8PCKfftKT9rHgcOK2s3YB3gyhLH/AaYDLwVuBu4uI9935bzHw98FTgH+BiwI+mL5SuSNi9f7NL+CLwh6UJJB0gaXdwoaSrwReDDQAfwe+CSvG0McAXwZWAM8Cdg9xLnvgBYAWwBbA/sBxS7cHYBHsl5fws4t/Bl+jNgXWBr0ud9Ri7T9qTW2KeATYCfALMlrV2iXH3Wu+BAYCdgW+AjwAdy+v8GDgC2A3YADqocEBFfynkdGxHrR8SxVeRnzRIRfvlV9Qs4HHi6n31OBn7ey7ZRQAAb5fULgG/m5b2AV4EReX2DvO8uhePnAgf1c/59gSdqUNf/kcu3kPRFPhsYm7f9Bphe2HcN4BVgM+AI4PbCNuU8PtnT5wNMyvUcSer6ex14S2H7YcBNeflIYEFh27r52LcB44C/A6N7qMvZwDe6pT0CvLeXugewRQ/pvda7cNwehe2XAzPz8o3Ap7r9nAIYmddvrnxG3crRY35+Ne/lFoeV9SwwptKt0p/cPXGqpD9JehF4Im8a01v+EfFGXn41vz9T2P4qsH7JMvdUrh/nLpGXe+v+ioiHIuLIiJgAbAO8nTS2AylAnJm7T54HniMFiPF5v6cK+URxvR+bAWsCiwt5/4TUeqh4upD3K3lxfWAi8FxELO8l3xMqeeZ8J+ayltFXvd9UPlJQqfy8VvtcqP4z6S0/a5Kq/vjNCm4j/Ud8EPCrKvb/F9Kg+b6koLERsJz0ZdM0EXE0cHSJ/R+WdAGpqwfSl94pEfGmbjdJk0lfypV1FddJg/jrFtbfVlh+ivT5jomIFdWWr3DsxpJGRcTzPWw7JSJOKZlnT+fosd5VWAxMKKxP7LbdU3UPEW5xWCkR8QJp7OGsPHC9rqQ18zjAt3o4ZAPSF+GzpC/Lf6tX2SStIWkd0n/skrSOpLUGmNeWkk6QNCGvTyR1Gd2ed/kxcGJloD8PaB+St10DbC3pw7ll9hlWDw7zgD0lbap0scGJlQ0RsRi4Hjhd0oa5Tu+U9N7+ypyP/Q3wI0mj889lz7z5HOBoSbsoWU/SByVt0EeWa+XPsPIa0U+9+3M5cJyk8ZJGAV/otv0Z4B1V5mVN5MBhpUXE6cDxpMHfpaT/Qo8Fft3D7hcBTwKLgAdZ9cVbD3uSurKuJV0i/CrpS3ggXiINQt8h6S+kct8PnAAQEVcCpwGX5i64+0kDv0TEMuAQ4FRSwJwM3FrJOCLmAJcB80ljNld3O/cRwFqkz2s5qWU3rspyfxz4G/AwsAT4bD5nF2lw+oc5zwWk8ZK+PED6DCuvo/qqdxXOIf085gP3kH5OK4BK1+SZwMH5aq3vV5mnNYHygJOZ1ZGkm0kD4j9tdllaRb6M+McRsVm/O1tLcYvDzBpC0luU7skZKWk8cBLlLuu2FuHAYWaNItLd98tJXVUPkcbLbIhxV5WZmZXiFoeZmZVSt/s4JJ1HmipgSURs023bCcB3gI6IWJavcz8TmEK6wefIiLg77zuNdPUOpDuML+zv3GPGjIlJkybVrC5mZsPB3Llzl0VER3/71fMGwAtIl/5dVEzM18PvB/y5kHwA6ZLFyaRLIM8GdpG0MWkArZN0c9BcSbN7uTN2pUmTJtHV1VWjapiZDQ+Snqxmv7p1VUXELaTpCLo7A/g8q98lOhW4KJLbgVGSxpEmM5sTEZVpFOYA+9erzGZm1r+GjnHkmTUXRcS93TaNZ/V5axbmtN7Se8p7htKDhbqWLl1aw1KbmVlRwwKHpHVJ0zHX5fK7iJgVEZ0R0dnR0W8XnZmZDVAjWxzvBDYH7lV6rOcE4G5JbyNNR1Gc8GxCTust3czMmqRhgSMi7ouIt0bEpIiYROp22iEiniY95+CIPPnarsALecK264D98oRto0mD6tc1qsxmZvZmdQscki4hTcH9bqXHgU7vY/drSY/7XECaCO3/AETEc8A3gLvy6+s5zczMmqQt7xzv7OwMX45rZlaOpLkR0dnffr5z3MzMSnHgMDOzUvzoWKurSTOvWbn8xKkfbGJJzKxW3OIwM7NS3OKwhnHrw6w9uMVhZmaluMVhLcWtErPW5xaHmZmV4sBhZmaluKvKmsJdUmZDlwOHtSwHF7PW5K4qMzMrxS0OG3LcEjFrLrc4zMysFAcOMzMrxV1V1nTFrqdGn89dXWblucVhZmaluMVhQ0KjWyVm1ju3OMzMrBQHDjMzK8VdVVYTrTDg3AplMBsOHDhsQDzmYDZ81a2rStJ5kpZIur+Q9m1JD0uaL+lKSaMK206UtEDSI5I+UEjfP6ctkDSzXuU1M7Pq1HOM4wJg/25pc4BtImJb4I/AiQCStgIOBbbOx/xI0ghJI4CzgAOArYDD8r5mZtYkdQscEXEL8Fy3tOsjYkVevR2YkJenApdGxOsR8TiwANg5vxZExGMR8Vfg0ryvmZk1STPHOD4BXJaXx5MCScXCnAbwVLf0XXrKTNIMYAbApptuWtOCWjke/zBrb025HFfSl4AVwMW1yjMiZkVEZ0R0dnR01CpbMzPrpuEtDklHAgcC+0RE5ORFwMTCbhNyGn2km5lZEzS0xSFpf+DzwIci4pXCptnAoZLWlrQ5MBm4E7gLmCxpc0lrkQbQZzeyzGZmtrq6tTgkXQLsBYyRtBA4iXQV1drAHEkAt0fE0RHxgKTLgQdJXVjHRMQbOZ9jgeuAEcB5EfFAvcpsZmb9q1vgiIjDekg+t4/9TwFO6SH9WuDaGhbNzMwGwXNVmZlZKQ4cZmZWiueqsqq14v0ZvZXJEx6a1Y9bHGZmVooDh5mZleLAYWZmpXiMw/rUiuMaZtZcbnGYmVkpDhxmZlaKA4eZmZXiMQ5rex6nMasttzjMzKwUBw4zMyvFgcPMzEpx4DAzs1IcOMzMrBRfVWXDmmfRNSvPLQ4zMyvFgcPMzEpx4DAzs1I8xmGWebzDrDp1a3FIOk/SEkn3F9I2ljRH0qP5fXROl6TvS1ogab6kHQrHTMv7PyppWr3Ka2Zm1alnV9UFwP7d0mYCN0TEZOCGvA5wADA5v2YAZ0MKNMBJwC7AzsBJlWBjZmbNUbfAERG3AM91S54KXJiXLwQOKqRfFMntwChJ44APAHMi4rmIWA7M4c3ByMzMGqjRg+NjI2JxXn4aGJuXxwNPFfZbmNN6S38TSTMkdUnqWrp0aW1LbWZmKzVtcDwiQlLUML9ZwCyAzs7OmuXbzjwYbGYD0egWxzO5C4r8viSnLwImFvabkNN6SzczsyZpdOCYDVSujJoGXFVIPyJfXbUr8ELu0roO2E/S6Dwovl9OMzOzJqlbV5WkS4C9gDGSFpKujjoVuFzSdOBJ4CN592uBKcAC4BXgKICIeE7SN4C78n5fj4juA+5WY35inpn1pW6BIyIO62XTPj3sG8AxveRzHnBeDYtmZmaD4DvHDXArw8yq57mqzMysFAcOMzMrxV1VZv3w/S5mq3OLw8zMSnHgMDOzUhw4zMysFI9xmPXAlyeb9a7fFoek9SStkZffJelDktasf9HMzKwVVdNVdQuwjqTxwPXAx0kPaTIzs2Gomq4qRcQreX6pH0XEtyTNq3fBzFqRL801qzJwSNoNOByYntNG1K9IZkODg4gNV9V0VX0WOBG4MiIekPQO4Kb6FsvMzFpVvy2OiPgd8LvC+mPAZ+pZKDMza139Bg5JncAXgUnF/SNi2/oVy8zMWlU1YxwXA58D7gP+Xt/imJlZq6smcCyNiNl1L4mZmQ0J1QSOkyT9FLgBeL2SGBFX1K1UZmbWsqoJHEcBWwJrsqqrKgAHDjOzYaiawLFTRLy77iUxM7MhoZrA8QdJW0XEg3UvjdkQ5ZsBbTipJnDsCsyT9DhpjENA+HJcM7PhqZrAsX+tTyrp/wKfJI2V3EcaRxkHXApsAswFPh4Rf5W0NnARsCPwLPDRiHii1mUaLjxduJkNVq9TjkjaMC++1MtrQPIsu58BOiNiG9K8V4cCpwFnRMQWwHJWzYs1HVie08/I+5mZWZP0NVfVL/L7XKArv88trA/GSOAtkkYC6wKLgb2BX+XtFwIH5eWpeZ28fR9JGuT5zcxsgHrtqoqIA/P75rU8YUQskvQd4M/Aq6RnfMwFno+IFXm3hcD4vDweeCofu0LSC6TurGXFfCXNAGYAbLrpprUsspmZFVT1zHFJoyXtLGnPymugJ5Q0mtSK2Bx4O7AeNRhHiYhZEdEZEZ0dHR2Dzc7MzHpRzSSHnwSOAyYA80hXWd1G6loaiH2BxyNiac7/CmB3YJSkkbnVMQFYlPdfBEwEFuaurY1Ig+RmZtYE1bQ4jgN2Ap6MiPcB2wPPD+KcfwZ2lbRuHqvYB3iQ9IyPg/M+04Cr8vLsvE7efmNExCDOb1ZXk2Zes/Jl1o6qCRyvRcRrAJLWjoiHgQHfSR4Rd5AGue8mXYq7BjAL+AJwvKQFpDGMc/Mh5wKb5PTjgZkDPbeZmQ1eNfdxLJQ0Cvg1MEfScuDJwZw0Ik4CTuqW/Biwcw/7vgYcMpjzmZlZ7VTzBMB/yosnS7qJNMbw27qWyszMWlavgUPSxj0k35ff1weeq0uJzMyspfXV4phLmhKkeLNdZT2Ad9SxXGZm1qL6ugGwpjf+mZlZe+j3qipJ/yRpo8L6KEkH9XWMmZm1r2ouxz0pIl6orETE87z5iigzMxsmqrkct6fgUs1xZsOeH/Bk7aiaANAl6bvAWXn9GNLAuQ0RvoPZzGqpmsDxaeArwGWkq6nmkIKHmZXg1oe1i2puAPwLnubDzMyyqqZVNzMzq3DgMDOzUvqacuS0iPiCpEMi4peNLJTZcNL94gWPf1ir62uMY4qkmcCJgAOHWQ35SjcbyvoKHL8FlgPrS3qRVXNUCYiI2LAB5TMzsxbT6xhHRHwuIkYB10TEhhGxQfG9gWU0M7MWUs3luFMljSU9Phbgjsrzws3MbPipZpLDQ4A7SU/h+whwp6SD+z7KzMzaVTV3jn8Z2CkilgBI6gD+k/TccDMzG2aquY9jjUrQyJ6t8jgzM2tD1bQ4fivpOuCSvP5R4Nr6FcnMzFpZNYPjn5P0YWCPnDQrIq6sb7HMzKxVVfVcjYi4AriiVieVNAr4KbAN6d6QTwCPkGbgnQQ8AXwkIpZLEnAmMAV4BTgyIu6uVVnalW8wM7N6adZYxZnAbyNiS+AfgYdIM/DeEBGTgRtYNSPvAcDk/JoBnN344po1zqSZ16x8mbWihgeO/PzyPYFzASLir/lxtFOBC/NuFwKV55pPBS6K5HZglKRxDS62mZllzWhxbA4sBc6XdI+kn0paDxgbEYvzPk8DY/PyeOCpwvELc9pqJM2Q1CWpa+lS359oZlYvAwockk4exDlHAjsAZ0fE9sCbHhQVEUEa+6haRMyKiM6I6Ozo6BhE8czMrC8DbXEM5pnjC4GFEXFHXv8VKZA8U+mCyu+Ve0cWARMLx0/IaWZm1gQDChwR8R8DPWFEPA08JendOWkf4EFgNjAtp00DrsrLs4EjlOwKvFDo0jIzswbr93JcSROAH5Du4wjg98BxEbFwEOf9NHCxpLWAx4CjSEHscknTgSdJ82JButlwCrCAdDnuUYM4r5mZDVI193GcD/yCNMkhwMdy2vsHetKImAd09rBpnx72DeCYgZ7LzMxqq5quqo6IOD8iVuTXBYBHn83MhqlqAsezkj4maUR+fYw00aGZmQ1D1QSOT5DGG54GFgMH43EGM7Nhq5pJDp8EPtSAspiZ2RDQa+CQ9NU+jouI+EYdymNmBcX5qp449YNNLInZKn21OP7SQ9p6wHRgE8CBw6yBepv00AHFGq3XwBERp1eWJW0AHEca27gUOL2348zMrL31OcYhaWPgeOBw0oy1O0TE8kYUzMzMWlNfYxzfBj4MzAL+ISJeblipbED8/AYza4S+Lsc9AXg78GXgvyW9mF8vSXqxMcUzM7NW09cYR7OeDmhmJfjKK2s0BwczMyvFgcPMzEqpZnZcMxvi3J1lteQWh5mZleLAYWZmpbiryqxN+b4eqxe3OMzMrBQHDjMzK8VdVWZtxN1T1ghucZiZWSlNCxz5+eX3SLo6r28u6Q5JCyRdJmmtnL52Xl+Qt09qVpnNzKy5XVXHAQ8BG+b104AzIuJSST8mPTDq7Py+PCK2kHRo3u+jzShwK3LXhJk1WlNaHJImAB8EfprXBewN/CrvciFwUF6emtfJ2/fJ+5uZWRM0q6vqe8Dngb/n9U2A5yNiRV5fCIzPy+OBpwDy9hfy/quRNENSl6SupUuX1rPsZmbDWsMDh6QDgSURMbeW+UbErIjojIjOjo6OWmZtZmYFzRjj2B34kKQpwDqkMY4zgVGSRuZWxQRgUd5/ETARWChpJLAR8Gzji21mZtCEFkdEnBgREyJiEnAocGNEHA7cBBycd5sGXJWXZ+d18vYbIyIaWGQzMytopRsAvwBcKumbwD3AuTn9XOBnkhYAz5GCjZkNkKdYt8FqauCIiJuBm/PyY8DOPezzGnBIQwtmZma98p3jZmZWSit1VVmVfNOf1Yq7rWwg3OIwM7NSHDjMzKwUBw4zMyvFYxxmBni8w6rnFoeZmZXiFoeZvYlbH9YXtzjMzKwUBw4zMyvFgcPMzErxGIeZ9an7TAUe8zC3OMzMrBQHDjMzK8VdVWZWii/VNQeOIcIz4ppZq3BXlZmZleLAYWZmpbiryswGzOMdw5NbHGZmVooDh5mZleKuKjOrCXdbDR8Nb3FImijpJkkPSnpA0nE5fWNJcyQ9mt9H53RJ+r6kBZLmS9qh0WU2M7NVmtHiWAGcEBF3S9oAmCtpDnAkcENEnCppJjAT+AJwADA5v3YBzs7vZtaiemt9uFXSHhoeOCJiMbA4L78k6SFgPDAV2CvvdiFwMylwTAUuiogAbpc0StK4nI+ZtTjfvNp+mjo4LmkSsD1wBzC2EAyeBsbm5fHAU4XDFua07nnNkNQlqWvp0qV1K7OZ2XDXtMFxSesD/w58NiJelLRyW0SEpCiTX0TMAmYBdHZ2ljq2Ffm/NGt37rYauprS4pC0JiloXBwRV+TkZySNy9vHAUty+iJgYuHwCTnNzMyaoOEtDqWmxbnAQxHx3cKm2cA04NT8flUh/VhJl5IGxV/w+IZZe3HrY2hpRlfV7sDHgfskzctpXyQFjMslTQeeBD6St10LTAEWAK8ARzW2uGZmVtSMq6r+C1Avm/fpYf8AjqlroczMrGqecsTMzErxlCNm1lLK3jzo8ZHGc+Aws5bly9JbkwNHC/EfiZkNBQ4cZta23I1VHx4cNzOzUtziMLO24e7exnDgMLMhxwGiudxVZWZmpbjFYWbDjgfNB8eBo8nc5DZrjGr+1hxQquPAYWbWDweU1TlwmNmw1ltLxC2U3nlw3MzMSnGLw8yshLLjku3YKnGLw8zMSnGLowl8JZVZe2v3v3EHDjOzGig7mA69P1ekt31ahQOHmVmTDNXxEgcOM7MhqJlBRBHR0BM2QmdnZ3R1dTW7GKtp9z5PM2sNgwkikuZGRGd/+/mqKjMzK2XIBA5J+0t6RNICSTObXR4zs+FqSIxxSBoBnAW8H1gI3CVpdkQ82NyS9c3dU2bWjoZE4AB2BhZExGMAki4FpgItFzgcLMys3Q2VwDEeeKqwvhDYpbiDpBnAjLz6sqRHBnG+McCyQRw/FA23Og+3+oLrPCzotEHVebNqdhoqgaNfETELmFWLvCR1VXNlQTsZbnUebvUF13m4aESdh8rg+CJgYmF9Qk4zM7MGGyqB4y5gsqTNJa0FHArMbnKZzMyGpSHRVRURKyQdC1wHjADOi4gH6njKmnR5DTHDrc7Drb7gOg8Xda9zW945bmZm9TNUuqrMzKxFOHCYmVkpDhwF7TqtiaTzJC2RdH8hbWNJcyQ9mt9H53RJ+n7+DOZL2qF5JR84SRMl3STpQUkPSDoup7dtvSWtI+lOSffmOn8tp28u6Y5ct8vyBSZIWjuvL8jbJzWz/AMlaYSkeyRdndfbvb5PSLpP0jxJXTmtob/XDhxZYVqTA4CtgMMkbdXcUtXMBcD+3dJmAjdExGTghrwOqf6T82sGcHaDylhrK4ATImIrYFfgmPzzbOd6vw7sHRH/CGwH7C9pV+A04IyI2AJYDkzP+08Hluf0M/J+Q9FxwEOF9XavL8D7ImK7wv0ajf29jgi/0gUCuwHXFdZPBE5sdrlqWL9JwP2F9UeAcXl5HPBIXv4JcFhP+w3lF3AVaa6zYVFvYF3gbtIMC8uAkTl95e856SrF3fLyyLyfml32kvWcQPqi3Bu4GlA71zeX/QlgTLe0hv5eu8WxSk/TmoxvUlkaYWxELM7LTwNj83LbfQ65S2J74A7avN6522YesASYA/wJeD4iVuRdivVaWee8/QVgk8aWeNC+B3we+Hte34T2ri9AANdLmpunWoIG/14Pifs4rL4iIiS15XXZktYH/h34bES8KGnltnasd0S8AWwnaRRwJbBlk4tUN5IOBJZExFxJezW7PA20R0QskvRWYI6kh4sbG/F77RbHKsNtWpNnJI0DyO9LcnrbfA6S1iQFjYsj4oqc3Pb1BoiI54GbSF01oyRV/kks1mtlnfP2jYBnG1zUwdgd+JCkJ4BLSd1VZ9K+9QUgIhbl9yWkfw52psG/1w4cqwy3aU1mA9Py8jTSGEAl/Yh8NcauwAuFJvCQodS0OBd4KCK+W9jUtvWW1JFbGkh6C2lM5yFSADk479a9zpXP4mDgxsgd4UNBRJwYERMiYhLp7/XGiDicNq0vgKT1JG1QWQb2A+6n0b/XzR7oaaUXMAX4I6lf+EvNLk8N63UJsBj4G6mPczqpb/cG4FHgP4GN874iXV32J+A+oLPZ5R9gnfcg9QXPB+bl15R2rjewLXBPrvP9wFdz+juAO4EFwC+BtXP6Onl9Qd7+jmbXYRB13wu4ut3rm+t2b349UPmeavTvtaccMTOzUtxVZWZmpThwmJlZKQ4cZmZWigOHmZmV4sBhZmalOHBYU0j6Up7BdX6e5XOXZpdpMCRdIOng/vcccP7bSZpSWD9Z0r9WcZwk3ShpwzqWba/KzLS9bO+Q9Nt6nd8az4HDGk7SbsCBwA4RsS2wL6vPp2Nvth3pPpSypgD3RsSLtSpInkm6ahGxFFgsafdalcGay4HDmmEcsCwiXgeIiGUR8d8AknaU9Ls8gdt1hWkUdlR6zsS9kr6t/GwRSUdK+mElY0lXV+YtkrSfpNsk3S3pl3neqsrzDL6W0++TtGVOX1/S+TltvqR/7iufakj6nKS7cn6V52NMkvSQpHNyq+v6fKc3knYqtMK+Len+PJPB14GP5vSP5uy3knSzpMckfaaXIhxOvos4l+UzefkMSTfm5b0lXZyXD8v1v1/SymnHJb0s6XRJ9wK7KT275mFJdwMfLuz33lzGeUrPyNggb/p1Lou1AQcOa4brgYmS/ijpR5LeCyvnlvoBcHBE7AicB5ySjzkf+HSkZ030S9IY4MvAvhGxA9AFHF/YZVlOPxuodPl8hTQlwz/kltCNVeTTVxn2Iz0HYWdSi2FHSXvmzZOBsyJia+B54J8L9fxURGwHvAEQEX8FvgpcFukZDJflfbcEPpDzPyl/ft3tDszNy78H3pOXO4H18zHvAW6R9HbSMyr2zuXdSdJBef/1gDvy598FnAP8L2BH4G2F8/0rcEwu/3uAV3N6V+HcNsQ5cFjDRcTLpC+cGcBS4DJJRwLvBrYhzfg5j/SFPSHPvzQqIm7JWfysitPsSnog1605r2nAZoXtlUkP55KeVQKpy+ysQjmXV5FPX/bLr3tIz8bYkhQwAB6PiHnFMuR6bhARt+X0X/ST/zUR8XpELCNNaje2h302joiXCufZMY93vA7cRgog7yEFlZ2AmyNiaaRpxy8GKoHuDdKEkeR6PB4Rj0aaeuLnhfPdCnw3t2xGxarpzZcAb++nPjZEeFp1a4pI03/fDNws6T7SF/Jc4IGI2K24b/5C7c0KVv8HaJ3KYcCciDisl+Nez+9v0PffQX/59EXA/4uIn6yWmJ4P8noh6Q3gLQPIv3sePdVjhaQ1IuLvEfE3SY8DRwJ/IM1p9T5gC9JkiJN7OL7itfwz61NEnCrpGtLYyq2SPhARD5N+Lq/2fbQNFW5xWMNJerek4pfUdsCTpKeTdeTBcyStKWnrSFOEPy9pj7x/sa/8CdLzJ9aQNJHUbQNwO7C7pC1yXutJelc/RZsDHFMo5+gB5lNxHfCJwtjKeKVnKPQo1/MlrbrC7NDC5peADd4yoqlNAAABcUlEQVR8VL8eIU2MV/F7UnfSLXn5aOCe3HK4E3ivpDF5APww4Hc95PkwqYX0zry+MqhKemdE3BcRp5FmnK48D+RdpIkXrQ04cFgzrA9cKOlBSfNJXUEn5778g4HT8iDsPOB/5mOOAs7K3UUq5HUr8DjwIPB9UpdQ5UqeI4FL8jluo/+HGn0TGJ0Hhu8lPde5TD4/kbQwv26LiOtJ3U235VbVr+j/y386cE6u53qkp9RBmip8q26D49W4hjRzbMXvSRcn3BYRzwCv5TQiTbc9M5/rXmBuRFxFNxHxGqmb8Zo8OL6ksPmz+fObT5qN+Tc5/X25LNYGPDuuDTm5q+fqiNimyUWpOUnr5zEgJM0kPR/6uEHkNw64KCLeX6syDrActwBT87iRDXEe4zBrLR+UdCLpb/NJUmtnwCJicb7sd8Na3stRhqQO4LsOGu3DLQ4zMyvFYxxmZlaKA4eZmZXiwGFmZqU4cJiZWSkOHGZmVsr/B1RIGx2odPSoAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c7baa4828>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's zoom in on 0 to 500\n",
    "bins = np.linspace(0, 500, 100)\n",
    "plt.hist(X_length, bins)\n",
    "plt.title('Claim 1 - Sequence Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit our sequence length to 300 on our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest sequence is 60 words long.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f6c7d132e10>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_length = [len(y) for y in Y_seqs]\n",
    "max_y_length = max(Y_length)\n",
    "print(\"Our longest sequence is {0} words long.\".format(max_y_length))\n",
    "\n",
    "bins = np.linspace(0, max_y_length, 100)\n",
    "plt.hist(Y_length, bins)\n",
    "plt.title('Title - Sequence Length')\n",
    "plt.ylabel('No. of samples');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit to 20 words on our output.  \n",
    "\n",
    "So we can pad our input and output sequences, limiting to 300 on the input and 20 on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting maximum sequence lengths\n",
    "X_max_len = 300\n",
    "y_max_len = 20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We want to reverse our X_seqs - so our preamble comes last and so is more influential\n",
    "X = pad_sequences(X_seqs, maxlen=X_max_len, truncating='post')\n",
    "# We don't want to reverse our output\n",
    "Y = pad_sequences(Y_seqs, maxlen=y_max_len, padding='post', truncating='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X data has shape (50000, 300) and our Y data has shape (50000, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our X data has shape {0} and our Y data has shape {1}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[   0    0    0    0    0    0    0    0    0    0    0    0    0    0\n",
      "    0    2 2573 3851   41   70   88   25   14   24    8  196   39   59\n",
      "    2  196  182   34    5    2   22    3   97  968  182   18    1   14\n",
      "   24    8  196  265   29    3    1   22    3   97  968   59    8   20\n",
      "   30 2030  320    5    2 1521  182   88   16 1521  182   34   45 1802\n",
      "   15   16  196  182   34    3    1   14   24    8  196  265   17   29\n",
      "   97   39    3    1   22    3   97  968   73    2   41   70   34 2922\n",
      "   53   16 1521  182   34    5   14   24    8 1317   53   14   24    8\n",
      " 1452   41   28    9  105   10    3   14   24    8   97 1960   17    1\n",
      "   14   24    8  196   39   13    4  155  700    9 3578   10    3    2\n",
      "  294   97 1960   17   29  206   13 1190    4    2  294   41   70   34\n",
      " 2922    5   17    1   14   24    8  196   39 3094   29    3    1  700\n",
      "    4    1   93  294   41   70   34  417  167    2   97   81    3    1\n",
      "    8   20   30 2030  320    3    1   97  265   17   29   41   70   34\n",
      "  417   13    4 3458    6   68    4  967    3    2 4174  206    4   10\n",
      "    3    2  294   97  364    3    2  111   41   70 2922    2   63    4\n",
      "    1   10    3    1  294   97  364    4    1  111   41   70  417   48\n",
      "    8   20   30 3657  524   58    5   16   10    3   16  294   97  364\n",
      "   77   18    1 1452   41   28    6  335   19    1 1523    5   17   16\n",
      "   14   24    8 1317    3   29   41   70   34  417   13 1320  991   14\n",
      "   24    8   52 1317    3    1  196  182   34   98    1    8   20   30\n",
      " 2030  320    3    1   97   39] [  1 115   7  27  72  25   7  48  84   2   0   0   0   0   0   0   0   0\n",
      "   0   0]\n"
     ]
    }
   ],
   "source": [
    "print(X[0], Y[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could maybe share the embedding layer as per here? https://stackoverflow.com/questions/42122168/keras-how-to-construct-a-shared-embedding-layer-for-each-input-neuron\n",
    "\n",
    "The model by Oswaldo Ludwig shares the embedding layer. We can also look at using a pre-trained embedding layer.\n",
    "\n",
    "See also here: http://www.orbifold.net/default/2017/01/10/embedding-and-tokenizer-in-keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import concatenate\n",
    "\n",
    "# source text input model\n",
    "inputs1 = Input(shape=(X_max_len,))\n",
    "am1 = Embedding(X_vocab_len, 128)(inputs1)\n",
    "am2 = LSTM(128)(am1)\n",
    "# summary input model\n",
    "inputs2 = Input(shape=(y_max_len,))\n",
    "sm1 = Embedding(y_vocab_len, 128)(inputs2)\n",
    "sm2 = LSTM(128)(sm1)\n",
    "# decoder output model\n",
    "decoder1 = concatenate([am2, sm2])\n",
    "outputs = Dense(y_vocab_len, activation='softmax')(decoder1)\n",
    "# tie it together [article, summary] [word]\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 20)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 128)     640000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 20, 128)      320000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          131584      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          131584      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2500)         642500      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,865,668\n",
      "Trainable params: 1,865,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To reduce the number of parameters we can probably share embeddings between the two inputs. But this would require a larger dense layer on the output.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the one-hot vector takes a lot of memory we need to iterate the training in batches (as per here and other examples - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 1th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 6.7545\n",
      "[INFO] Training model: epoch 1th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.3911\n",
      "[INFO] Training model: epoch 1th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.1002\n",
      "[INFO] Training model: epoch 1th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.0144\n",
      "[INFO] Training model: epoch 1th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.9499\n",
      "[INFO] Training model: epoch 1th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.8704\n",
      "[INFO] Training model: epoch 1th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.7579\n",
      "[INFO] Training model: epoch 1th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.6246\n",
      "[INFO] Training model: epoch 1th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.5086\n",
      "[INFO] Training model: epoch 1th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.4338\n",
      "[INFO] Training model: epoch 1th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3895\n",
      "[INFO] Training model: epoch 1th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3620\n",
      "[INFO] Training model: epoch 1th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3386\n",
      "[INFO] Training model: epoch 1th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3133\n",
      "[INFO] Training model: epoch 1th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2910\n",
      "[INFO] Training model: epoch 1th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 2.2637\n",
      "[INFO] Training model: epoch 1th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2320\n",
      "[INFO] Training model: epoch 1th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1966\n",
      "[INFO] Training model: epoch 1th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1643\n",
      "[INFO] Training model: epoch 1th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1287\n",
      "[INFO] Training model: epoch 1th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0962\n",
      "[INFO] Training model: epoch 1th 2100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0629\n",
      "[INFO] Training model: epoch 1th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0297\n",
      "[INFO] Training model: epoch 1th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0008\n",
      "[INFO] Training model: epoch 1th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9688\n",
      "[INFO] Training model: epoch 1th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9382\n",
      "[INFO] Training model: epoch 1th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9096\n",
      "[INFO] Training model: epoch 1th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8800\n",
      "[INFO] Training model: epoch 1th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8485\n",
      "[INFO] Training model: epoch 1th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8213\n",
      "[INFO] Training model: epoch 1th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7916\n",
      "[INFO] Training model: epoch 1th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.7648\n",
      "[INFO] Training model: epoch 1th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7375\n",
      "[INFO] Training model: epoch 1th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.7070\n",
      "[INFO] Training model: epoch 1th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6786\n",
      "[INFO] Training model: epoch 1th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6553\n",
      "[INFO] Training model: epoch 1th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6243\n",
      "[INFO] Training model: epoch 1th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5973\n",
      "[INFO] Training model: epoch 1th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5662\n",
      "[INFO] Training model: epoch 1th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5398\n",
      "[INFO] Training model: epoch 1th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5074\n",
      "[INFO] Training model: epoch 1th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.4776\n",
      "[INFO] Training model: epoch 1th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.4469\n",
      "[INFO] Training model: epoch 1th 4300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.4144\n",
      "[INFO] Training model: epoch 1th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.3827\n",
      "[INFO] Training model: epoch 1th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.3515\n",
      "[INFO] Training model: epoch 1th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.3213\n",
      "[INFO] Training model: epoch 1th 4700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2865\n",
      "[INFO] Training model: epoch 1th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2569\n",
      "[INFO] Training model: epoch 1th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.2243\n",
      "[INFO] Training model: epoch 1th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1942\n",
      "[INFO] Training model: epoch 1th 5100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.1615\n",
      "[INFO] Training model: epoch 1th 5200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1316\n",
      "[INFO] Training model: epoch 1th 5300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1022\n",
      "[INFO] Training model: epoch 1th 5400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0701\n",
      "[INFO] Training model: epoch 1th 5500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0401\n",
      "[INFO] Training model: epoch 1th 5600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0085\n",
      "[INFO] Training model: epoch 1th 5700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9800\n",
      "[INFO] Training model: epoch 1th 5800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9521\n",
      "[INFO] Training model: epoch 1th 5900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9232\n",
      "[INFO] Training model: epoch 1th 6000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8933\n",
      "[INFO] Training model: epoch 1th 6100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8655\n",
      "[INFO] Training model: epoch 1th 6200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8398\n",
      "[INFO] Training model: epoch 1th 6300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8130\n",
      "[INFO] Training model: epoch 1th 6400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7876\n",
      "[INFO] Training model: epoch 1th 6500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7625\n",
      "[INFO] Training model: epoch 1th 6600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7380\n",
      "[INFO] Training model: epoch 1th 6700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.7153\n",
      "[INFO] Training model: epoch 1th 6800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6896\n",
      "[INFO] Training model: epoch 1th 6900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6681\n",
      "[INFO] Training model: epoch 1th 7000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6473\n",
      "[INFO] Training model: epoch 1th 7100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6243\n",
      "[INFO] Training model: epoch 1th 7200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6047\n",
      "[INFO] Training model: epoch 1th 7300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5855\n",
      "[INFO] Training model: epoch 1th 7400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5670\n",
      "[INFO] Training model: epoch 1th 7500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5478\n",
      "[INFO] Training model: epoch 1th 7600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5296\n",
      "[INFO] Training model: epoch 1th 7700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5129\n",
      "[INFO] Training model: epoch 1th 7800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4964\n",
      "[INFO] Training model: epoch 1th 7900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4810\n",
      "[INFO] Training model: epoch 1th 8000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4655\n",
      "[INFO] Training model: epoch 1th 8100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4547\n",
      "[INFO] Training model: epoch 1th 8200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4478\n",
      "[INFO] Training model: epoch 1th 8300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.4263\n",
      "[INFO] Training model: epoch 1th 8400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4103\n",
      "[INFO] Training model: epoch 1th 8500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3970\n",
      "[INFO] Training model: epoch 1th 8600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3852\n",
      "[INFO] Training model: epoch 1th 8700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3725\n",
      "[INFO] Training model: epoch 1th 8800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3627\n",
      "[INFO] Training model: epoch 1th 8900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3511\n",
      "[INFO] Training model: epoch 1th 9000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3406\n",
      "[INFO] Training model: epoch 1th 9100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3303\n",
      "[INFO] Training model: epoch 1th 9200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3213\n",
      "[INFO] Training model: epoch 1th 9300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3121\n",
      "[INFO] Training model: epoch 1th 9400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3047\n",
      "[INFO] Training model: epoch 1th 9500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2955\n",
      "[INFO] Training model: epoch 1th 9600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2868\n",
      "[INFO] Training model: epoch 1th 9700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2780\n",
      "[INFO] Training model: epoch 1th 9800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2715\n",
      "[INFO] Training model: epoch 1th 9900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2639\n",
      "[INFO] Training model: epoch 1th 10000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2565\n",
      "[INFO] Training model: epoch 1th 10100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2506\n",
      "[INFO] Training model: epoch 1th 10200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2431\n",
      "[INFO] Training model: epoch 1th 10300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2360\n",
      "[INFO] Training model: epoch 1th 10400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2303\n",
      "[INFO] Training model: epoch 1th 10500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2242\n",
      "[INFO] Training model: epoch 1th 10600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2184\n",
      "[INFO] Training model: epoch 1th 10700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2138\n",
      "[INFO] Training model: epoch 1th 10800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2077\n",
      "[INFO] Training model: epoch 1th 10900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2017\n",
      "[INFO] Training model: epoch 1th 11000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1966\n",
      "[INFO] Training model: epoch 1th 11100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1928\n",
      "[INFO] Training model: epoch 1th 11200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1882\n",
      "[INFO] Training model: epoch 1th 11300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1840\n",
      "[INFO] Training model: epoch 1th 11400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1793\n",
      "[INFO] Training model: epoch 1th 11500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1750\n",
      "[INFO] Training model: epoch 1th 11600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1712\n",
      "[INFO] Training model: epoch 1th 11700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1656\n",
      "[INFO] Training model: epoch 1th 11800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1626\n",
      "[INFO] Training model: epoch 1th 11900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1587\n",
      "[INFO] Training model: epoch 1th 12000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1552\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 1th 12100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1521\n",
      "[INFO] Training model: epoch 1th 12200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1485\n",
      "[INFO] Training model: epoch 1th 12300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1455\n",
      "[INFO] Training model: epoch 1th 12400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1417\n",
      "[INFO] Training model: epoch 1th 12500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1385\n",
      "[INFO] Training model: epoch 1th 12600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1356\n",
      "[INFO] Training model: epoch 1th 12700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1324\n",
      "[INFO] Training model: epoch 1th 12800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1298\n",
      "[INFO] Training model: epoch 1th 12900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1263\n",
      "[INFO] Training model: epoch 1th 13000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1249\n",
      "[INFO] Training model: epoch 1th 13100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1215\n",
      "[INFO] Training model: epoch 1th 13200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1191\n",
      "[INFO] Training model: epoch 1th 13300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1169\n",
      "[INFO] Training model: epoch 1th 13400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1146\n",
      "[INFO] Training model: epoch 1th 13500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1117\n",
      "[INFO] Training model: epoch 1th 13600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1092\n",
      "[INFO] Training model: epoch 1th 13700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1066\n",
      "[INFO] Training model: epoch 1th 13800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1046\n",
      "[INFO] Training model: epoch 1th 13900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1021\n",
      "[INFO] Training model: epoch 1th 14000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1000\n",
      "[INFO] Training model: epoch 1th 14100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0983\n",
      "[INFO] Training model: epoch 1th 14200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0963\n",
      "[INFO] Training model: epoch 1th 14300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0942\n",
      "[INFO] Training model: epoch 1th 14400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0926\n",
      "[INFO] Training model: epoch 1th 14500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0907\n",
      "[INFO] Training model: epoch 1th 14600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0889\n",
      "[INFO] Training model: epoch 1th 14700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0870\n",
      "[INFO] Training model: epoch 1th 14800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0854\n",
      "[INFO] Training model: epoch 1th 14900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0838\n",
      "[INFO] Training model: epoch 1th 15000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0817\n",
      "[INFO] Training model: epoch 1th 15100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0808\n",
      "[INFO] Training model: epoch 1th 15200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0790\n",
      "[INFO] Training model: epoch 1th 15300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0774\n",
      "[INFO] Training model: epoch 1th 15400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0759\n",
      "[INFO] Training model: epoch 1th 15500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0742\n",
      "[INFO] Training model: epoch 1th 15600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0729\n",
      "[INFO] Training model: epoch 1th 15700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0712\n",
      "[INFO] Training model: epoch 1th 15800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0699\n",
      "[INFO] Training model: epoch 1th 15900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0684\n",
      "[INFO] Training model: epoch 1th 16000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0672\n",
      "[INFO] Training model: epoch 1th 16100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0662\n",
      "[INFO] Training model: epoch 1th 16200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0647\n",
      "[INFO] Training model: epoch 1th 16300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0634\n",
      "[INFO] Training model: epoch 1th 16400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0624\n",
      "[INFO] Training model: epoch 1th 16500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0613\n",
      "[INFO] Training model: epoch 1th 16600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0600\n",
      "[INFO] Training model: epoch 1th 16700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0592\n",
      "[INFO] Training model: epoch 1th 16800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0578\n",
      "[INFO] Training model: epoch 1th 16900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0569\n",
      "[INFO] Training model: epoch 1th 17000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0559\n",
      "[INFO] Training model: epoch 1th 17100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0549\n",
      "[INFO] Training model: epoch 1th 17200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0541\n",
      "[INFO] Training model: epoch 1th 17300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0531\n",
      "[INFO] Training model: epoch 1th 17400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0517\n",
      "[INFO] Training model: epoch 1th 17500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0508\n",
      "[INFO] Training model: epoch 1th 17600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0498\n",
      "[INFO] Training model: epoch 1th 17700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0491\n",
      "[INFO] Training model: epoch 1th 17800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0483\n",
      "[INFO] Training model: epoch 1th 17900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0474\n",
      "[INFO] Training model: epoch 1th 18000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0465\n",
      "[INFO] Training model: epoch 1th 18100/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0460\n",
      "[INFO] Training model: epoch 1th 18200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0450\n",
      "[INFO] Training model: epoch 1th 18300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0440\n",
      "[INFO] Training model: epoch 1th 18400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0435\n",
      "[INFO] Training model: epoch 1th 18500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0426\n",
      "[INFO] Training model: epoch 1th 18600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0421\n",
      "[INFO] Training model: epoch 1th 18700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0414\n",
      "[INFO] Training model: epoch 1th 18800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0405\n",
      "[INFO] Training model: epoch 1th 18900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0401\n",
      "[INFO] Training model: epoch 1th 19000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0392\n",
      "[INFO] Training model: epoch 1th 19100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0385\n",
      "[INFO] Training model: epoch 1th 19200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0378\n",
      "[INFO] Training model: epoch 1th 19300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0372\n",
      "[INFO] Training model: epoch 1th 19400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0366\n",
      "[INFO] Training model: epoch 1th 19500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0360\n",
      "[INFO] Training model: epoch 1th 19600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0354\n",
      "[INFO] Training model: epoch 1th 19700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
      "[INFO] Training model: epoch 1th 19800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 1th 19900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 1th 20000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 1th 20100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0327\n",
      "[INFO] Training model: epoch 1th 20200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0323\n",
      "[INFO] Training model: epoch 1th 20300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0317\n",
      "[INFO] Training model: epoch 1th 20400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0311\n",
      "[INFO] Training model: epoch 1th 20500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0307\n",
      "[INFO] Training model: epoch 1th 20600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0304\n",
      "[INFO] Training model: epoch 1th 20700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0298\n",
      "[INFO] Training model: epoch 1th 20800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0293\n",
      "[INFO] Training model: epoch 1th 20900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0288\n",
      "[INFO] Training model: epoch 1th 21000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0286\n",
      "[INFO] Training model: epoch 1th 21100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0281\n",
      "[INFO] Training model: epoch 1th 21200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0274\n",
      "[INFO] Training model: epoch 1th 21300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0270\n",
      "[INFO] Training model: epoch 1th 21400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0267\n",
      "[INFO] Training model: epoch 1th 21500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0262\n",
      "[INFO] Training model: epoch 1th 21600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0259\n",
      "[INFO] Training model: epoch 1th 21700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0255\n",
      "[INFO] Training model: epoch 1th 21800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0252\n",
      "[INFO] Training model: epoch 1th 21900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0248\n",
      "[INFO] Training model: epoch 1th 22000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0245\n",
      "[INFO] Training model: epoch 1th 22100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0240\n",
      "[INFO] Training model: epoch 1th 22200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0236\n",
      "[INFO] Training model: epoch 1th 22300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0233\n",
      "[INFO] Training model: epoch 1th 22400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0230\n",
      "[INFO] Training model: epoch 1th 22500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0228\n",
      "[INFO] Training model: epoch 1th 22600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0222\n",
      "[INFO] Training model: epoch 1th 22700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0220\n",
      "[INFO] Training model: epoch 1th 22800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0218\n",
      "[INFO] Training model: epoch 1th 22900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0214\n",
      "[INFO] Training model: epoch 1th 23000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0210\n",
      "[INFO] Training model: epoch 1th 23100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0208\n",
      "[INFO] Training model: epoch 1th 23200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0205\n",
      "[INFO] Training model: epoch 1th 23300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0203\n",
      "[INFO] Training model: epoch 1th 23400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0200\n",
      "[INFO] Training model: epoch 1th 23500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0197\n",
      "[INFO] Training model: epoch 1th 23600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0194\n",
      "[INFO] Training model: epoch 1th 23700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0191\n",
      "[INFO] Training model: epoch 1th 23800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0188\n",
      "[INFO] Training model: epoch 1th 23900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0186\n",
      "[INFO] Training model: epoch 1th 24000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0183\n",
      "[INFO] Training model: epoch 1th 24100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0181\n",
      "[INFO] Training model: epoch 1th 24200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0178\n",
      "[INFO] Training model: epoch 1th 24300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0176\n",
      "[INFO] Training model: epoch 1th 24400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0173\n",
      "[INFO] Training model: epoch 1th 24500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0171\n",
      "[INFO] Training model: epoch 1th 24600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0169\n",
      "[INFO] Training model: epoch 1th 24700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0167\n",
      "[INFO] Training model: epoch 1th 24800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0164\n",
      "[INFO] Training model: epoch 1th 24900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0162\n",
      "[INFO] Training model: epoch 1th 25000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0160\n",
      "[INFO] Training model: epoch 1th 25100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0158\n",
      "[INFO] Training model: epoch 1th 25200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0156\n",
      "[INFO] Training model: epoch 1th 25300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0154\n",
      "[INFO] Training model: epoch 1th 25400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0153\n",
      "[INFO] Training model: epoch 1th 25500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0150\n",
      "[INFO] Training model: epoch 1th 25600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0148\n",
      "[INFO] Training model: epoch 1th 25700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0147\n",
      "[INFO] Training model: epoch 1th 25800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0145\n",
      "[INFO] Training model: epoch 1th 25900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0143\n",
      "[INFO] Training model: epoch 1th 26000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0140\n",
      "[INFO] Training model: epoch 1th 26100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0140\n",
      "[INFO] Training model: epoch 1th 26200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0137\n",
      "[INFO] Training model: epoch 1th 26300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0136\n",
      "[INFO] Training model: epoch 1th 26400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0134\n",
      "[INFO] Training model: epoch 1th 26500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0132\n",
      "[INFO] Training model: epoch 1th 26600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0130\n",
      "[INFO] Training model: epoch 1th 26700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0129\n",
      "[INFO] Training model: epoch 1th 26800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0127\n",
      "[INFO] Training model: epoch 1th 26900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0126\n",
      "[INFO] Training model: epoch 1th 27000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0124\n",
      "[INFO] Training model: epoch 1th 27100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0123\n",
      "[INFO] Training model: epoch 1th 27200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0122\n",
      "[INFO] Training model: epoch 1th 27300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0120\n",
      "[INFO] Training model: epoch 1th 27400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0119\n",
      "[INFO] Training model: epoch 1th 27500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0117\n",
      "[INFO] Training model: epoch 1th 27600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0115\n",
      "[INFO] Training model: epoch 1th 27700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0114\n",
      "[INFO] Training model: epoch 1th 27800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0113\n",
      "[INFO] Training model: epoch 1th 27900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0111\n",
      "[INFO] Training model: epoch 1th 28000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0110\n",
      "[INFO] Training model: epoch 1th 28100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0109\n",
      "[INFO] Training model: epoch 1th 28200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0108\n",
      "[INFO] Training model: epoch 1th 28300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0106\n",
      "[INFO] Training model: epoch 1th 28400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0105\n",
      "[INFO] Training model: epoch 1th 28500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0104\n",
      "[INFO] Training model: epoch 1th 28600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0103\n",
      "[INFO] Training model: epoch 1th 28700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0101\n",
      "[INFO] Training model: epoch 1th 28800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0100\n",
      "[INFO] Training model: epoch 1th 28900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0099\n",
      "[INFO] Training model: epoch 1th 29000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0098\n",
      "[INFO] Training model: epoch 1th 29100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0097\n",
      "[INFO] Training model: epoch 1th 29200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0096\n",
      "[INFO] Training model: epoch 1th 29300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0095\n",
      "[INFO] Training model: epoch 1th 29400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0094\n",
      "[INFO] Training model: epoch 1th 29500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0093\n",
      "[INFO] Training model: epoch 1th 29600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0091\n",
      "[INFO] Training model: epoch 1th 29700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0091\n",
      "[INFO] Training model: epoch 1th 29800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0089\n",
      "[INFO] Training model: epoch 1th 29900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0089\n",
      "[INFO] Training model: epoch 1th 30000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0087\n",
      "[INFO] Training model: epoch 1th 30100/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0086\n",
      "[INFO] Training model: epoch 1th 30200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0085\n",
      "[INFO] Training model: epoch 1th 30300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0085\n",
      "[INFO] Training model: epoch 1th 30400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0084\n",
      "[INFO] Training model: epoch 1th 30500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0083\n",
      "[INFO] Training model: epoch 1th 30600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0082\n",
      "[INFO] Training model: epoch 1th 30700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0081\n",
      "[INFO] Training model: epoch 1th 30800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0080\n",
      "[INFO] Training model: epoch 1th 30900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0079\n",
      "[INFO] Training model: epoch 1th 31000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0078\n",
      "[INFO] Training model: epoch 1th 31100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0077\n",
      "[INFO] Training model: epoch 1th 31200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0076\n",
      "[INFO] Training model: epoch 1th 31300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0076\n",
      "[INFO] Training model: epoch 1th 31400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0075\n",
      "[INFO] Training model: epoch 1th 31500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0074\n",
      "[INFO] Training model: epoch 1th 31600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0073\n",
      "[INFO] Training model: epoch 1th 31700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0072\n",
      "[INFO] Training model: epoch 1th 31800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0072\n",
      "[INFO] Training model: epoch 1th 31900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0071\n",
      "[INFO] Training model: epoch 1th 32000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0070\n",
      "[INFO] Training model: epoch 1th 32100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0069\n",
      "[INFO] Training model: epoch 1th 32200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0069\n",
      "[INFO] Training model: epoch 1th 32300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0068\n",
      "[INFO] Training model: epoch 1th 32400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0067\n",
      "[INFO] Training model: epoch 1th 32500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0067\n",
      "[INFO] Training model: epoch 1th 32600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0066\n",
      "[INFO] Training model: epoch 1th 32700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0065\n",
      "[INFO] Training model: epoch 1th 32800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0064\n",
      "[INFO] Training model: epoch 1th 32900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0064\n",
      "[INFO] Training model: epoch 1th 33000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0063\n",
      "[INFO] Training model: epoch 1th 33100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0062\n",
      "[INFO] Training model: epoch 1th 33200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0062\n",
      "[INFO] Training model: epoch 1th 33300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0061\n",
      "[INFO] Training model: epoch 1th 33400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0060\n",
      "[INFO] Training model: epoch 1th 33500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0060\n",
      "[INFO] Training model: epoch 1th 33600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0059\n",
      "[INFO] Training model: epoch 1th 33700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0059\n",
      "[INFO] Training model: epoch 1th 33800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0058\n",
      "[INFO] Training model: epoch 1th 33900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0057\n",
      "[INFO] Training model: epoch 1th 34000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0057\n",
      "[INFO] Training model: epoch 1th 34100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0056\n",
      "[INFO] Training model: epoch 1th 34200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0056\n",
      "[INFO] Training model: epoch 1th 34300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0055\n",
      "[INFO] Training model: epoch 1th 34400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0055\n",
      "[INFO] Training model: epoch 1th 34500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0054\n",
      "[INFO] Training model: epoch 1th 34600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0053\n",
      "[INFO] Training model: epoch 1th 34700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0053\n",
      "[INFO] Training model: epoch 1th 34800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0052\n",
      "[INFO] Training model: epoch 1th 34900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0052\n",
      "[INFO] Training model: epoch 1th 35000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0051\n",
      "[INFO] Training model: epoch 1th 35100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0051\n",
      "[INFO] Training model: epoch 1th 35200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0050\n",
      "[INFO] Training model: epoch 1th 35300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0050\n",
      "[INFO] Training model: epoch 1th 35400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0049\n",
      "[INFO] Training model: epoch 1th 35500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0049\n",
      "[INFO] Training model: epoch 1th 35600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0048\n",
      "[INFO] Training model: epoch 1th 35700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0048\n",
      "[INFO] Training model: epoch 1th 35800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0047\n",
      "[INFO] Training model: epoch 1th 35900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0047\n",
      "[INFO] Training model: epoch 1th 36000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0046\n",
      "[INFO] Training model: epoch 1th 36100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0046\n",
      "[INFO] Training model: epoch 1th 36200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0046\n",
      "[INFO] Training model: epoch 1th 36300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0045\n",
      "[INFO] Training model: epoch 1th 36400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0045\n",
      "[INFO] Training model: epoch 1th 36500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0044\n",
      "[INFO] Training model: epoch 1th 36600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0044\n",
      "[INFO] Training model: epoch 1th 36700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0043\n",
      "[INFO] Training model: epoch 1th 36800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0043\n",
      "[INFO] Training model: epoch 1th 36900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0042\n",
      "[INFO] Training model: epoch 1th 37000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0042\n",
      "[INFO] Training model: epoch 1th 37100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0042\n",
      "[INFO] Training model: epoch 1th 37200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0041\n",
      "[INFO] Training model: epoch 1th 37300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0041\n",
      "[INFO] Training model: epoch 1th 37400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0040\n",
      "[INFO] Training model: epoch 1th 37500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0040\n",
      "[INFO] Training model: epoch 1th 37600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0040\n",
      "[INFO] Training model: epoch 1th 37700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0039\n",
      "[INFO] Training model: epoch 1th 37800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0039\n",
      "[INFO] Training model: epoch 1th 37900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0039\n",
      "[INFO] Training model: epoch 1th 38000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0038\n",
      "[INFO] Training model: epoch 1th 38100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0038\n",
      "[INFO] Training model: epoch 1th 38200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0037\n",
      "[INFO] Training model: epoch 1th 38300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0037\n",
      "[INFO] Training model: epoch 1th 38400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0037\n",
      "[INFO] Training model: epoch 1th 38500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0036\n",
      "[INFO] Training model: epoch 1th 38600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0036\n",
      "[INFO] Training model: epoch 1th 38700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0036\n",
      "[INFO] Training model: epoch 1th 38800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
      "[INFO] Training model: epoch 1th 38900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
      "[INFO] Training model: epoch 1th 39000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
      "[INFO] Training model: epoch 1th 39100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0034\n",
      "[INFO] Training model: epoch 1th 39200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0034\n",
      "[INFO] Training model: epoch 1th 39300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0034\n",
      "[INFO] Training model: epoch 1th 39400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0033\n",
      "[INFO] Training model: epoch 1th 39500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0033\n",
      "[INFO] Training model: epoch 1th 39600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0033\n",
      "[INFO] Training model: epoch 1th 39700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0032\n",
      "[INFO] Training model: epoch 1th 39800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0032\n",
      "[INFO] Training model: epoch 1th 39900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0032\n",
      "[INFO] Training model: epoch 2th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 4.4112\n",
      "[INFO] Training model: epoch 2th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.8805\n",
      "[INFO] Training model: epoch 2th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0963\n",
      "[INFO] Training model: epoch 2th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.6697\n",
      "[INFO] Training model: epoch 2th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.3972\n",
      "[INFO] Training model: epoch 2th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.1917\n",
      "[INFO] Training model: epoch 2th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0092\n",
      "[INFO] Training model: epoch 2th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8786\n",
      "[INFO] Training model: epoch 2th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7527\n",
      "[INFO] Training model: epoch 2th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6522\n",
      "[INFO] Training model: epoch 2th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5660\n",
      "[INFO] Training model: epoch 2th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4948\n",
      "[INFO] Training model: epoch 2th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4346\n",
      "[INFO] Training model: epoch 2th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3884\n",
      "[INFO] Training model: epoch 2th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3491\n",
      "[INFO] Training model: epoch 2th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3140\n",
      "[INFO] Training model: epoch 2th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2866\n",
      "[INFO] Training model: epoch 2th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2632\n",
      "[INFO] Training model: epoch 2th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2408\n",
      "[INFO] Training model: epoch 2th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2232\n",
      "[INFO] Training model: epoch 2th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2064\n",
      "[INFO] Training model: epoch 2th 2100/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1920\n",
      "[INFO] Training model: epoch 2th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1810\n",
      "[INFO] Training model: epoch 2th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1711\n",
      "[INFO] Training model: epoch 2th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1607\n",
      "[INFO] Training model: epoch 2th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1515\n",
      "[INFO] Training model: epoch 2th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1445\n",
      "[INFO] Training model: epoch 2th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1381\n",
      "[INFO] Training model: epoch 2th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1327\n",
      "[INFO] Training model: epoch 2th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1277\n",
      "[INFO] Training model: epoch 2th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1206\n",
      "[INFO] Training model: epoch 2th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1158\n",
      "[INFO] Training model: epoch 2th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1110\n",
      "[INFO] Training model: epoch 2th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1076\n",
      "[INFO] Training model: epoch 2th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1048\n",
      "[INFO] Training model: epoch 2th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1004\n",
      "[INFO] Training model: epoch 2th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0963\n",
      "[INFO] Training model: epoch 2th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0939\n",
      "[INFO] Training model: epoch 2th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0915\n",
      "[INFO] Training model: epoch 2th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0888\n",
      "[INFO] Training model: epoch 2th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0867\n",
      "[INFO] Training model: epoch 2th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0842\n",
      "[INFO] Training model: epoch 2th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0816\n",
      "[INFO] Training model: epoch 2th 4300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0802\n",
      "[INFO] Training model: epoch 2th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0787\n",
      "[INFO] Training model: epoch 2th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0767\n",
      "[INFO] Training model: epoch 2th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0752\n",
      "[INFO] Training model: epoch 2th 4700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0735\n",
      "[INFO] Training model: epoch 2th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0721\n",
      "[INFO] Training model: epoch 2th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0708\n",
      "[INFO] Training model: epoch 2th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0696\n",
      "[INFO] Training model: epoch 2th 5100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0684\n",
      "[INFO] Training model: epoch 2th 5200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0678\n",
      "[INFO] Training model: epoch 2th 5300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0661\n",
      "[INFO] Training model: epoch 2th 5400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0649\n",
      "[INFO] Training model: epoch 2th 5500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0641\n",
      "[INFO] Training model: epoch 2th 5600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0631\n",
      "[INFO] Training model: epoch 2th 5700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0624\n",
      "[INFO] Training model: epoch 2th 5800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0617\n",
      "[INFO] Training model: epoch 2th 5900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0607\n",
      "[INFO] Training model: epoch 2th 6000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0600\n",
      "[INFO] Training model: epoch 2th 6100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0594\n",
      "[INFO] Training model: epoch 2th 6200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0586\n",
      "[INFO] Training model: epoch 2th 6300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0581\n",
      "[INFO] Training model: epoch 2th 6400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0574\n",
      "[INFO] Training model: epoch 2th 6500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0568\n",
      "[INFO] Training model: epoch 2th 6600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0562\n",
      "[INFO] Training model: epoch 2th 6700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0555\n",
      "[INFO] Training model: epoch 2th 6800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0551\n",
      "[INFO] Training model: epoch 2th 6900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0544\n",
      "[INFO] Training model: epoch 2th 7000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0539\n",
      "[INFO] Training model: epoch 2th 7100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0535\n",
      "[INFO] Training model: epoch 2th 7200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0531\n",
      "[INFO] Training model: epoch 2th 7300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0526\n",
      "[INFO] Training model: epoch 2th 7400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0521\n",
      "[INFO] Training model: epoch 2th 7500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0518\n",
      "[INFO] Training model: epoch 2th 7600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0513\n",
      "[INFO] Training model: epoch 2th 7700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0509\n",
      "[INFO] Training model: epoch 2th 7800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0505\n",
      "[INFO] Training model: epoch 2th 7900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0501\n",
      "[INFO] Training model: epoch 2th 8000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0498\n",
      "[INFO] Training model: epoch 2th 8100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0495\n",
      "[INFO] Training model: epoch 2th 8200/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0491\n",
      "[INFO] Training model: epoch 2th 8300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0488\n",
      "[INFO] Training model: epoch 2th 8400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0485\n",
      "[INFO] Training model: epoch 2th 8500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0483\n",
      "[INFO] Training model: epoch 2th 8600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0479\n",
      "[INFO] Training model: epoch 2th 8700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0476\n",
      "[INFO] Training model: epoch 2th 8800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0473\n",
      "[INFO] Training model: epoch 2th 8900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0470\n",
      "[INFO] Training model: epoch 2th 9000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0467\n",
      "[INFO] Training model: epoch 2th 9100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0465\n",
      "[INFO] Training model: epoch 2th 9200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0462\n",
      "[INFO] Training model: epoch 2th 9300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0460\n",
      "[INFO] Training model: epoch 2th 9400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0457\n",
      "[INFO] Training model: epoch 2th 9500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0455\n",
      "[INFO] Training model: epoch 2th 9600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0452\n",
      "[INFO] Training model: epoch 2th 9700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0450\n",
      "[INFO] Training model: epoch 2th 9800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0449\n",
      "[INFO] Training model: epoch 2th 9900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0447\n",
      "[INFO] Training model: epoch 2th 10000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0445\n",
      "[INFO] Training model: epoch 2th 10100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0443\n",
      "[INFO] Training model: epoch 2th 10200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0440\n",
      "[INFO] Training model: epoch 2th 10300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0439\n",
      "[INFO] Training model: epoch 2th 10400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0437\n",
      "[INFO] Training model: epoch 2th 10500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0435\n",
      "[INFO] Training model: epoch 2th 10600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0433\n",
      "[INFO] Training model: epoch 2th 10700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0431\n",
      "[INFO] Training model: epoch 2th 10800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0429\n",
      "[INFO] Training model: epoch 2th 10900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0428\n",
      "[INFO] Training model: epoch 2th 11000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0426\n",
      "[INFO] Training model: epoch 2th 11100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0424\n",
      "[INFO] Training model: epoch 2th 11200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0423\n",
      "[INFO] Training model: epoch 2th 11300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0422\n",
      "[INFO] Training model: epoch 2th 11400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0420\n",
      "[INFO] Training model: epoch 2th 11500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0419\n",
      "[INFO] Training model: epoch 2th 11600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0417\n",
      "[INFO] Training model: epoch 2th 11700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0416\n",
      "[INFO] Training model: epoch 2th 11800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0414\n",
      "[INFO] Training model: epoch 2th 11900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0413\n",
      "[INFO] Training model: epoch 2th 12000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0412\n",
      "[INFO] Training model: epoch 2th 12100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0410\n",
      "[INFO] Training model: epoch 2th 12200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0409\n",
      "[INFO] Training model: epoch 2th 12300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0408\n",
      "[INFO] Training model: epoch 2th 12400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0407\n",
      "[INFO] Training model: epoch 2th 12500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0405\n",
      "[INFO] Training model: epoch 2th 12600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0404\n",
      "[INFO] Training model: epoch 2th 12700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0403\n",
      "[INFO] Training model: epoch 2th 12800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0402\n",
      "[INFO] Training model: epoch 2th 12900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0401\n",
      "[INFO] Training model: epoch 2th 13000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0400\n",
      "[INFO] Training model: epoch 2th 13100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0399\n",
      "[INFO] Training model: epoch 2th 13200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0398\n",
      "[INFO] Training model: epoch 2th 13300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0397\n",
      "[INFO] Training model: epoch 2th 13400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0396\n",
      "[INFO] Training model: epoch 2th 13500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0395\n",
      "[INFO] Training model: epoch 2th 13600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0394\n",
      "[INFO] Training model: epoch 2th 13700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0393\n",
      "[INFO] Training model: epoch 2th 13800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0392\n",
      "[INFO] Training model: epoch 2th 13900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0391\n",
      "[INFO] Training model: epoch 2th 14000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0390\n",
      "[INFO] Training model: epoch 2th 14100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0389\n",
      "[INFO] Training model: epoch 2th 14200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0388\n",
      "[INFO] Training model: epoch 2th 14300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0387\n",
      "[INFO] Training model: epoch 2th 14400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0387\n",
      "[INFO] Training model: epoch 2th 14500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0386\n",
      "[INFO] Training model: epoch 2th 14600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0385\n",
      "[INFO] Training model: epoch 2th 14700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0384\n",
      "[INFO] Training model: epoch 2th 14800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0384\n",
      "[INFO] Training model: epoch 2th 14900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0383\n",
      "[INFO] Training model: epoch 2th 15000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0382\n",
      "[INFO] Training model: epoch 2th 15100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0381\n",
      "[INFO] Training model: epoch 2th 15200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0381\n",
      "[INFO] Training model: epoch 2th 15300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0380\n",
      "[INFO] Training model: epoch 2th 15400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0379\n",
      "[INFO] Training model: epoch 2th 15500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0379\n",
      "[INFO] Training model: epoch 2th 15600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0378\n",
      "[INFO] Training model: epoch 2th 15700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0377\n",
      "[INFO] Training model: epoch 2th 15800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0376\n",
      "[INFO] Training model: epoch 2th 15900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0376\n",
      "[INFO] Training model: epoch 2th 16000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0375\n",
      "[INFO] Training model: epoch 2th 16100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0374\n",
      "[INFO] Training model: epoch 2th 16200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0374\n",
      "[INFO] Training model: epoch 2th 16300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0373\n",
      "[INFO] Training model: epoch 2th 16400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0373\n",
      "[INFO] Training model: epoch 2th 16500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0372\n",
      "[INFO] Training model: epoch 2th 16600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0371\n",
      "[INFO] Training model: epoch 2th 16700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0371\n",
      "[INFO] Training model: epoch 2th 16800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0370\n",
      "[INFO] Training model: epoch 2th 16900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0369\n",
      "[INFO] Training model: epoch 2th 17000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0369\n",
      "[INFO] Training model: epoch 2th 17100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0368\n",
      "[INFO] Training model: epoch 2th 17200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0368\n",
      "[INFO] Training model: epoch 2th 17300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0367\n",
      "[INFO] Training model: epoch 2th 17400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0367\n",
      "[INFO] Training model: epoch 2th 17500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0366\n",
      "[INFO] Training model: epoch 2th 17600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0366\n",
      "[INFO] Training model: epoch 2th 17700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0365\n",
      "[INFO] Training model: epoch 2th 17800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0365\n",
      "[INFO] Training model: epoch 2th 17900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0364\n",
      "[INFO] Training model: epoch 2th 18000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0364\n",
      "[INFO] Training model: epoch 2th 18100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0364\n",
      "[INFO] Training model: epoch 2th 18200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0363\n",
      "[INFO] Training model: epoch 2th 18300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0363\n",
      "[INFO] Training model: epoch 2th 18400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0362\n",
      "[INFO] Training model: epoch 2th 18500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0362\n",
      "[INFO] Training model: epoch 2th 18600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0361\n",
      "[INFO] Training model: epoch 2th 18700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0361\n",
      "[INFO] Training model: epoch 2th 18800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0360\n",
      "[INFO] Training model: epoch 2th 18900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0360\n",
      "[INFO] Training model: epoch 2th 19000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0360\n",
      "[INFO] Training model: epoch 2th 19100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0359\n",
      "[INFO] Training model: epoch 2th 19200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0359\n",
      "[INFO] Training model: epoch 2th 19300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0358\n",
      "[INFO] Training model: epoch 2th 19400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0358\n",
      "[INFO] Training model: epoch 2th 19500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0357\n",
      "[INFO] Training model: epoch 2th 19600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0357\n",
      "[INFO] Training model: epoch 2th 19700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0357\n",
      "[INFO] Training model: epoch 2th 19800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0356\n",
      "[INFO] Training model: epoch 2th 19900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0356\n",
      "[INFO] Training model: epoch 2th 20000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0356\n",
      "[INFO] Training model: epoch 2th 20100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0355\n",
      "[INFO] Training model: epoch 2th 20200/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0355\n",
      "[INFO] Training model: epoch 2th 20300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0355\n",
      "[INFO] Training model: epoch 2th 20400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0354\n",
      "[INFO] Training model: epoch 2th 20500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0354\n",
      "[INFO] Training model: epoch 2th 20600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0354\n",
      "[INFO] Training model: epoch 2th 20700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0353\n",
      "[INFO] Training model: epoch 2th 20800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0353\n",
      "[INFO] Training model: epoch 2th 20900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0353\n",
      "[INFO] Training model: epoch 2th 21000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0352\n",
      "[INFO] Training model: epoch 2th 21100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0352\n",
      "[INFO] Training model: epoch 2th 21200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0352\n",
      "[INFO] Training model: epoch 2th 21300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0351\n",
      "[INFO] Training model: epoch 2th 21400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0351\n",
      "[INFO] Training model: epoch 2th 21500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0351\n",
      "[INFO] Training model: epoch 2th 21600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0351\n",
      "[INFO] Training model: epoch 2th 21700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0350\n",
      "[INFO] Training model: epoch 2th 21800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0350\n",
      "[INFO] Training model: epoch 2th 21900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0350\n",
      "[INFO] Training model: epoch 2th 22000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0349\n",
      "[INFO] Training model: epoch 2th 22100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
      "[INFO] Training model: epoch 2th 22200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0349\n",
      "[INFO] Training model: epoch 2th 22300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
      "[INFO] Training model: epoch 2th 22400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0348\n",
      "[INFO] Training model: epoch 2th 22500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0348\n",
      "[INFO] Training model: epoch 2th 22600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0348\n",
      "[INFO] Training model: epoch 2th 22700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0348\n",
      "[INFO] Training model: epoch 2th 22800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0347\n",
      "[INFO] Training model: epoch 2th 22900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
      "[INFO] Training model: epoch 2th 23000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
      "[INFO] Training model: epoch 2th 23100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
      "[INFO] Training model: epoch 2th 23200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0346\n",
      "[INFO] Training model: epoch 2th 23300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0346\n",
      "[INFO] Training model: epoch 2th 23400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0346\n",
      "[INFO] Training model: epoch 2th 23500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0346\n",
      "[INFO] Training model: epoch 2th 23600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0345\n",
      "[INFO] Training model: epoch 2th 23700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0345\n",
      "[INFO] Training model: epoch 2th 23800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0345\n",
      "[INFO] Training model: epoch 2th 23900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0345\n",
      "[INFO] Training model: epoch 2th 24000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
      "[INFO] Training model: epoch 2th 24600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0343\n",
      "[INFO] Training model: epoch 2th 24700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0343\n",
      "[INFO] Training model: epoch 2th 24800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0343\n",
      "[INFO] Training model: epoch 2th 24900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0343\n",
      "[INFO] Training model: epoch 2th 25000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0342\n",
      "[INFO] Training model: epoch 2th 25100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0342\n",
      "[INFO] Training model: epoch 2th 25200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0342\n",
      "[INFO] Training model: epoch 2th 25300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0342\n",
      "[INFO] Training model: epoch 2th 25400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0342\n",
      "[INFO] Training model: epoch 2th 25500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 25600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 25700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 25800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 25900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 26000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
      "[INFO] Training model: epoch 2th 26100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0340\n",
      "[INFO] Training model: epoch 2th 26700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 26800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 26900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 27000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 27100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 27200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0339\n",
      "[INFO] Training model: epoch 2th 27300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 27900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
      "[INFO] Training model: epoch 2th 28000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
      "[INFO] Training model: epoch 2th 28700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 28800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 28900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0336\n",
      "[INFO] Training model: epoch 2th 29500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 29600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 29700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 29800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 29900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
      "[INFO] Training model: epoch 2th 30600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 30700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 30800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 30900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
      "[INFO] Training model: epoch 2th 31500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 31600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 31700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 31800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 31900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32200/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
      "[INFO] Training model: epoch 2th 32500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 32600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 32700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 32800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 32900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0332\n",
      "[INFO] Training model: epoch 2th 33600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 33700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 33800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 33900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0331\n",
      "[INFO] Training model: epoch 2th 34900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 35900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 36000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 36100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 36200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 36300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
      "[INFO] Training model: epoch 2th 36400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 36500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 36600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 36700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 36800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 36900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 37900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 38000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 38100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
      "[INFO] Training model: epoch 2th 38200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 38900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 2th 39900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
      "[INFO] Training model: epoch 3th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 4.3832\n",
      "[INFO] Training model: epoch 3th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.7905\n",
      "[INFO] Training model: epoch 3th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9715\n",
      "[INFO] Training model: epoch 3th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5261\n",
      "[INFO] Training model: epoch 3th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2324\n",
      "[INFO] Training model: epoch 3th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.0139\n",
      "[INFO] Training model: epoch 3th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8576\n",
      "[INFO] Training model: epoch 3th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7429\n",
      "[INFO] Training model: epoch 3th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6533\n",
      "[INFO] Training model: epoch 3th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5831\n",
      "[INFO] Training model: epoch 3th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5278\n",
      "[INFO] Training model: epoch 3th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4839\n",
      "[INFO] Training model: epoch 3th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4455\n",
      "[INFO] Training model: epoch 3th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4175\n",
      "[INFO] Training model: epoch 3th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3906\n",
      "[INFO] Training model: epoch 3th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3701\n",
      "[INFO] Training model: epoch 3th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3553\n",
      "[INFO] Training model: epoch 3th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3402\n",
      "[INFO] Training model: epoch 3th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3252\n",
      "[INFO] Training model: epoch 3th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3144\n",
      "[INFO] Training model: epoch 3th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3050\n",
      "[INFO] Training model: epoch 3th 2100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2975\n",
      "[INFO] Training model: epoch 3th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2905\n",
      "[INFO] Training model: epoch 3th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2836\n",
      "[INFO] Training model: epoch 3th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2782\n",
      "[INFO] Training model: epoch 3th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2731\n",
      "[INFO] Training model: epoch 3th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2695\n",
      "[INFO] Training model: epoch 3th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2645\n",
      "[INFO] Training model: epoch 3th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2612\n",
      "[INFO] Training model: epoch 3th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2580\n",
      "[INFO] Training model: epoch 3th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2558\n",
      "[INFO] Training model: epoch 3th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2526\n",
      "[INFO] Training model: epoch 3th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2503\n",
      "[INFO] Training model: epoch 3th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2480\n",
      "[INFO] Training model: epoch 3th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2460\n",
      "[INFO] Training model: epoch 3th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2445\n",
      "[INFO] Training model: epoch 3th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2426\n",
      "[INFO] Training model: epoch 3th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2405\n",
      "[INFO] Training model: epoch 3th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2392\n",
      "[INFO] Training model: epoch 3th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2376\n",
      "[INFO] Training model: epoch 3th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2364\n",
      "[INFO] Training model: epoch 3th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2352\n",
      "[INFO] Training model: epoch 3th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2340\n",
      "[INFO] Training model: epoch 3th 4300/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2328\n",
      "[INFO] Training model: epoch 3th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2315\n",
      "[INFO] Training model: epoch 3th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2307\n",
      "[INFO] Training model: epoch 3th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2296\n",
      "[INFO] Training model: epoch 3th 4700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2288\n",
      "[INFO] Training model: epoch 3th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2279\n",
      "[INFO] Training model: epoch 3th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2272\n",
      "[INFO] Training model: epoch 3th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2264\n",
      "[INFO] Training model: epoch 3th 5100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2255\n",
      "[INFO] Training model: epoch 3th 5200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2248\n",
      "[INFO] Training model: epoch 3th 5300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2241\n",
      "[INFO] Training model: epoch 3th 5400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2235\n",
      "[INFO] Training model: epoch 3th 5500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2229\n",
      "[INFO] Training model: epoch 3th 5600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2223\n",
      "[INFO] Training model: epoch 3th 5700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2217\n",
      "[INFO] Training model: epoch 3th 5800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2214\n",
      "[INFO] Training model: epoch 3th 5900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2208\n",
      "[INFO] Training model: epoch 3th 6000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2203\n",
      "[INFO] Training model: epoch 3th 6100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2197\n",
      "[INFO] Training model: epoch 3th 6200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2192\n",
      "[INFO] Training model: epoch 3th 6300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2187\n",
      "[INFO] Training model: epoch 3th 6400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2184\n",
      "[INFO] Training model: epoch 3th 6500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2179\n",
      "[INFO] Training model: epoch 3th 6600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2176\n",
      "[INFO] Training model: epoch 3th 6700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2172\n",
      "[INFO] Training model: epoch 3th 6800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2169\n",
      "[INFO] Training model: epoch 3th 6900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2165\n",
      "[INFO] Training model: epoch 3th 7000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2162\n",
      "[INFO] Training model: epoch 3th 7100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2159\n",
      "[INFO] Training model: epoch 3th 7200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2155\n",
      "[INFO] Training model: epoch 3th 7300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2152\n",
      "[INFO] Training model: epoch 3th 7400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2149\n",
      "[INFO] Training model: epoch 3th 7500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2147\n",
      "[INFO] Training model: epoch 3th 7600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2144\n",
      "[INFO] Training model: epoch 3th 7700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2142\n",
      "[INFO] Training model: epoch 3th 7800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2139\n",
      "[INFO] Training model: epoch 3th 7900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2136\n",
      "[INFO] Training model: epoch 3th 8000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2134\n",
      "[INFO] Training model: epoch 3th 8100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2132\n",
      "[INFO] Training model: epoch 3th 8200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2130\n",
      "[INFO] Training model: epoch 3th 8300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2127\n",
      "[INFO] Training model: epoch 3th 8400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2125\n",
      "[INFO] Training model: epoch 3th 8500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2124\n",
      "[INFO] Training model: epoch 3th 8600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2121\n",
      "[INFO] Training model: epoch 3th 8700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2120\n",
      "[INFO] Training model: epoch 3th 8800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2118\n",
      "[INFO] Training model: epoch 3th 8900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2116\n",
      "[INFO] Training model: epoch 3th 9000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2114\n",
      "[INFO] Training model: epoch 3th 9100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2113\n",
      "[INFO] Training model: epoch 3th 9200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2111\n",
      "[INFO] Training model: epoch 3th 9300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2109\n",
      "[INFO] Training model: epoch 3th 9400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2107\n",
      "[INFO] Training model: epoch 3th 9500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2106\n",
      "[INFO] Training model: epoch 3th 9600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2104\n",
      "[INFO] Training model: epoch 3th 9700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2103\n",
      "[INFO] Training model: epoch 3th 9800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2101\n",
      "[INFO] Training model: epoch 3th 9900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2100\n",
      "[INFO] Training model: epoch 3th 10000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2101\n",
      "[INFO] Training model: epoch 3th 10100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2097\n",
      "[INFO] Training model: epoch 3th 10200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2096\n",
      "[INFO] Training model: epoch 3th 10300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2095\n",
      "[INFO] Training model: epoch 3th 10400/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2093\n",
      "[INFO] Training model: epoch 3th 10500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2092\n",
      "[INFO] Training model: epoch 3th 10600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2091\n",
      "[INFO] Training model: epoch 3th 10700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2090\n",
      "[INFO] Training model: epoch 3th 10800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2089\n",
      "[INFO] Training model: epoch 3th 10900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2088\n",
      "[INFO] Training model: epoch 3th 11000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2087\n",
      "[INFO] Training model: epoch 3th 11100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2085\n",
      "[INFO] Training model: epoch 3th 11200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2084\n",
      "[INFO] Training model: epoch 3th 11300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2083\n",
      "[INFO] Training model: epoch 3th 11400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2082\n",
      "[INFO] Training model: epoch 3th 11500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2081\n",
      "[INFO] Training model: epoch 3th 11600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2081\n",
      "[INFO] Training model: epoch 3th 11700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2079\n",
      "[INFO] Training model: epoch 3th 11800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2078\n",
      "[INFO] Training model: epoch 3th 11900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2077\n",
      "[INFO] Training model: epoch 3th 12000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2077\n",
      "[INFO] Training model: epoch 3th 12100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2076\n",
      "[INFO] Training model: epoch 3th 12200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2075\n",
      "[INFO] Training model: epoch 3th 12300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2074\n",
      "[INFO] Training model: epoch 3th 12400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2073\n",
      "[INFO] Training model: epoch 3th 12500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2072\n",
      "[INFO] Training model: epoch 3th 12600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2072\n",
      "[INFO] Training model: epoch 3th 12700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2071\n",
      "[INFO] Training model: epoch 3th 12800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2070\n",
      "[INFO] Training model: epoch 3th 12900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2070\n",
      "[INFO] Training model: epoch 3th 13000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2069\n",
      "[INFO] Training model: epoch 3th 13100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2068\n",
      "[INFO] Training model: epoch 3th 13200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2067\n",
      "[INFO] Training model: epoch 3th 13300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2067\n",
      "[INFO] Training model: epoch 3th 13400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2066\n",
      "[INFO] Training model: epoch 3th 13500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2065\n",
      "[INFO] Training model: epoch 3th 13600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2064\n",
      "[INFO] Training model: epoch 3th 13700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2064\n",
      "[INFO] Training model: epoch 3th 13800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2063\n",
      "[INFO] Training model: epoch 3th 13900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2063\n",
      "[INFO] Training model: epoch 3th 14000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2062\n",
      "[INFO] Training model: epoch 3th 14100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2061\n",
      "[INFO] Training model: epoch 3th 14200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2061\n",
      "[INFO] Training model: epoch 3th 14300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2060\n",
      "[INFO] Training model: epoch 3th 14400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2060\n",
      "[INFO] Training model: epoch 3th 14500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2059\n",
      "[INFO] Training model: epoch 3th 14600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2059\n",
      "[INFO] Training model: epoch 3th 14700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2058\n",
      "[INFO] Training model: epoch 3th 14800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2057\n",
      "[INFO] Training model: epoch 3th 14900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2057\n",
      "[INFO] Training model: epoch 3th 15000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2056\n",
      "[INFO] Training model: epoch 3th 15100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2056\n",
      "[INFO] Training model: epoch 3th 15200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2055\n",
      "[INFO] Training model: epoch 3th 15300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2055\n",
      "[INFO] Training model: epoch 3th 15400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2054\n",
      "[INFO] Training model: epoch 3th 15500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2054\n",
      "[INFO] Training model: epoch 3th 15600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2053\n",
      "[INFO] Training model: epoch 3th 15700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2053\n",
      "[INFO] Training model: epoch 3th 15800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2053\n",
      "[INFO] Training model: epoch 3th 15900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2052\n",
      "[INFO] Training model: epoch 3th 16000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2052\n",
      "[INFO] Training model: epoch 3th 16100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2051\n",
      "[INFO] Training model: epoch 3th 16200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2051\n",
      "[INFO] Training model: epoch 3th 16300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2050\n",
      "[INFO] Training model: epoch 3th 16400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2050\n",
      "[INFO] Training model: epoch 3th 16500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2050\n",
      "[INFO] Training model: epoch 3th 16600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2049\n",
      "[INFO] Training model: epoch 3th 16700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2049\n",
      "[INFO] Training model: epoch 3th 16800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
      "[INFO] Training model: epoch 3th 16900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
      "[INFO] Training model: epoch 3th 17000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
      "[INFO] Training model: epoch 3th 17100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
      "[INFO] Training model: epoch 3th 17200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
      "[INFO] Training model: epoch 3th 17300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
      "[INFO] Training model: epoch 3th 17400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2046\n",
      "[INFO] Training model: epoch 3th 17500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2046\n",
      "[INFO] Training model: epoch 3th 17600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
      "[INFO] Training model: epoch 3th 17700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
      "[INFO] Training model: epoch 3th 17800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
      "[INFO] Training model: epoch 3th 17900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2044\n",
      "[INFO] Training model: epoch 3th 18000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2044\n",
      "[INFO] Training model: epoch 3th 18100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2044\n",
      "[INFO] Training model: epoch 3th 18200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
      "[INFO] Training model: epoch 3th 18300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
      "[INFO] Training model: epoch 3th 18400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
      "[INFO] Training model: epoch 3th 18500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
      "[INFO] Training model: epoch 3th 18600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2042\n",
      "[INFO] Training model: epoch 3th 18700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
      "[INFO] Training model: epoch 3th 18800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
      "[INFO] Training model: epoch 3th 18900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2041\n",
      "[INFO] Training model: epoch 3th 19000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
      "[INFO] Training model: epoch 3th 19100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
      "[INFO] Training model: epoch 3th 19200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
      "[INFO] Training model: epoch 3th 19300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2040\n",
      "[INFO] Training model: epoch 3th 19400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2040\n",
      "[INFO] Training model: epoch 3th 19500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2040\n",
      "[INFO] Training model: epoch 3th 19600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2039\n",
      "[INFO] Training model: epoch 3th 19700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
      "[INFO] Training model: epoch 3th 19800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
      "[INFO] Training model: epoch 3th 19900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
      "[INFO] Training model: epoch 3th 20000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2038\n",
      "[INFO] Training model: epoch 3th 20100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
      "[INFO] Training model: epoch 3th 20200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
      "[INFO] Training model: epoch 3th 20300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
      "[INFO] Training model: epoch 3th 20400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2037\n",
      "[INFO] Training model: epoch 3th 20500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
      "[INFO] Training model: epoch 3th 20600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
      "[INFO] Training model: epoch 3th 20700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
      "[INFO] Training model: epoch 3th 20800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
      "[INFO] Training model: epoch 3th 20900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
      "[INFO] Training model: epoch 3th 21000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2036\n",
      "[INFO] Training model: epoch 3th 21100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
      "[INFO] Training model: epoch 3th 21200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
      "[INFO] Training model: epoch 3th 21300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2035\n",
      "[INFO] Training model: epoch 3th 21400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
      "[INFO] Training model: epoch 3th 21500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
      "[INFO] Training model: epoch 3th 21600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
      "[INFO] Training model: epoch 3th 21700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
      "[INFO] Training model: epoch 3th 21800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
      "[INFO] Training model: epoch 3th 21900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
      "[INFO] Training model: epoch 3th 22000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
      "[INFO] Training model: epoch 3th 22100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
      "[INFO] Training model: epoch 3th 22200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
      "[INFO] Training model: epoch 3th 22300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
      "[INFO] Training model: epoch 3th 22400/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
      "[INFO] Training model: epoch 3th 22500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2033\n",
      "[INFO] Training model: epoch 3th 22600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2033\n",
      "[INFO] Training model: epoch 3th 22700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
      "[INFO] Training model: epoch 3th 22800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 22900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 23000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 23100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 23200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 23300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
      "[INFO] Training model: epoch 3th 23400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 23500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 23600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 23700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 23800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 23900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 24000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2031\n",
      "[INFO] Training model: epoch 3th 24100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
      "[INFO] Training model: epoch 3th 24800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 24900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
      "[INFO] Training model: epoch 3th 25500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 25600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 25700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 25800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 25900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 26000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 26100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 26200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
      "[INFO] Training model: epoch 3th 26300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 26900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 27000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 27100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
      "[INFO] Training model: epoch 3th 27200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
      "[INFO] Training model: epoch 3th 27300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
      "[INFO] Training model: epoch 3th 27400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
      "[INFO] Training model: epoch 3th 27500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2000\n",
      "[INFO] Training model: epoch 3th 27600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1978\n",
      "[INFO] Training model: epoch 3th 27700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1952\n",
      "[INFO] Training model: epoch 3th 27800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1947\n",
      "[INFO] Training model: epoch 3th 27900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
      "[INFO] Training model: epoch 3th 28000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
      "[INFO] Training model: epoch 3th 28100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
      "[INFO] Training model: epoch 3th 28200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
      "[INFO] Training model: epoch 3th 28800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 28900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
      "[INFO] Training model: epoch 3th 29700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 29800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 29900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
      "[INFO] Training model: epoch 3th 30900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 31900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 32000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 32100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 32200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
      "[INFO] Training model: epoch 3th 32300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 32900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 33900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
      "[INFO] Training model: epoch 3th 34000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34400/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 34900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 35900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
      "[INFO] Training model: epoch 3th 36000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 36900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 37900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 38000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 38100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 38200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 38300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
      "[INFO] Training model: epoch 3th 38400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 38500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 38600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 38700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 38800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 38900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 3th 39900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
      "[INFO] Training model: epoch 4th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 4.2757\n",
      "[INFO] Training model: epoch 4th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.0279\n",
      "[INFO] Training model: epoch 4th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2302\n",
      "[INFO] Training model: epoch 4th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7639\n",
      "[INFO] Training model: epoch 4th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.4405\n",
      "[INFO] Training model: epoch 4th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2107\n",
      "[INFO] Training model: epoch 4th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0591\n",
      "[INFO] Training model: epoch 4th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9443\n",
      "[INFO] Training model: epoch 4th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8729\n",
      "[INFO] Training model: epoch 4th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8091\n",
      "[INFO] Training model: epoch 4th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7665\n",
      "[INFO] Training model: epoch 4th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7336\n",
      "[INFO] Training model: epoch 4th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7080\n",
      "[INFO] Training model: epoch 4th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6881\n",
      "[INFO] Training model: epoch 4th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6741\n",
      "[INFO] Training model: epoch 4th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6622\n",
      "[INFO] Training model: epoch 4th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6519\n",
      "[INFO] Training model: epoch 4th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6436\n",
      "[INFO] Training model: epoch 4th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6366\n",
      "[INFO] Training model: epoch 4th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6305\n",
      "[INFO] Training model: epoch 4th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6255\n",
      "[INFO] Training model: epoch 4th 2100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6220\n",
      "[INFO] Training model: epoch 4th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6186\n",
      "[INFO] Training model: epoch 4th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6152\n",
      "[INFO] Training model: epoch 4th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6120\n",
      "[INFO] Training model: epoch 4th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6098\n",
      "[INFO] Training model: epoch 4th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6080\n",
      "[INFO] Training model: epoch 4th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6060\n",
      "[INFO] Training model: epoch 4th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6037\n",
      "[INFO] Training model: epoch 4th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6022\n",
      "[INFO] Training model: epoch 4th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6010\n",
      "[INFO] Training model: epoch 4th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5993\n",
      "[INFO] Training model: epoch 4th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5981\n",
      "[INFO] Training model: epoch 4th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5972\n",
      "[INFO] Training model: epoch 4th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5959\n",
      "[INFO] Training model: epoch 4th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5951\n",
      "[INFO] Training model: epoch 4th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5943\n",
      "[INFO] Training model: epoch 4th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5933\n",
      "[INFO] Training model: epoch 4th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5926\n",
      "[INFO] Training model: epoch 4th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5918\n",
      "[INFO] Training model: epoch 4th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5912\n",
      "[INFO] Training model: epoch 4th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5906\n",
      "[INFO] Training model: epoch 4th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5899\n",
      "[INFO] Training model: epoch 4th 4300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5893\n",
      "[INFO] Training model: epoch 4th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5888\n",
      "[INFO] Training model: epoch 4th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5883\n",
      "[INFO] Training model: epoch 4th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5879\n",
      "[INFO] Training model: epoch 4th 4700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5874\n",
      "[INFO] Training model: epoch 4th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5869\n",
      "[INFO] Training model: epoch 4th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5865\n",
      "[INFO] Training model: epoch 4th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5861\n",
      "[INFO] Training model: epoch 4th 5100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5858\n",
      "[INFO] Training model: epoch 4th 5200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5853\n",
      "[INFO] Training model: epoch 4th 5300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5851\n",
      "[INFO] Training model: epoch 4th 5400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5847\n",
      "[INFO] Training model: epoch 4th 5500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5844\n",
      "[INFO] Training model: epoch 4th 5600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5841\n",
      "[INFO] Training model: epoch 4th 5700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5839\n",
      "[INFO] Training model: epoch 4th 5800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5836\n",
      "[INFO] Training model: epoch 4th 5900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5833\n",
      "[INFO] Training model: epoch 4th 6000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5830\n",
      "[INFO] Training model: epoch 4th 6100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5828\n",
      "[INFO] Training model: epoch 4th 6200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5826\n",
      "[INFO] Training model: epoch 4th 6300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5824\n",
      "[INFO] Training model: epoch 4th 6400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5822\n",
      "[INFO] Training model: epoch 4th 6500/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5820\n",
      "[INFO] Training model: epoch 4th 6600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5817\n",
      "[INFO] Training model: epoch 4th 6700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5815\n",
      "[INFO] Training model: epoch 4th 6800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5813\n",
      "[INFO] Training model: epoch 4th 6900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5811\n",
      "[INFO] Training model: epoch 4th 7000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5810\n",
      "[INFO] Training model: epoch 4th 7100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5808\n",
      "[INFO] Training model: epoch 4th 7200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5806\n",
      "[INFO] Training model: epoch 4th 7300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5804\n",
      "[INFO] Training model: epoch 4th 7400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5803\n",
      "[INFO] Training model: epoch 4th 7500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5802\n",
      "[INFO] Training model: epoch 4th 7600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5800\n",
      "[INFO] Training model: epoch 4th 7700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5798\n",
      "[INFO] Training model: epoch 4th 7800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5797\n",
      "[INFO] Training model: epoch 4th 7900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5795\n",
      "[INFO] Training model: epoch 4th 8000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5794\n",
      "[INFO] Training model: epoch 4th 8100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5793\n",
      "[INFO] Training model: epoch 4th 8200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5792\n",
      "[INFO] Training model: epoch 4th 8300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5790\n",
      "[INFO] Training model: epoch 4th 8400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5789\n",
      "[INFO] Training model: epoch 4th 8500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5788\n",
      "[INFO] Training model: epoch 4th 8600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5787\n",
      "[INFO] Training model: epoch 4th 8700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5786\n",
      "[INFO] Training model: epoch 4th 8800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5785\n",
      "[INFO] Training model: epoch 4th 8900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5784\n",
      "[INFO] Training model: epoch 4th 9000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5783\n",
      "[INFO] Training model: epoch 4th 9100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5782\n",
      "[INFO] Training model: epoch 4th 9200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5781\n",
      "[INFO] Training model: epoch 4th 9300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5780\n",
      "[INFO] Training model: epoch 4th 9400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5779\n",
      "[INFO] Training model: epoch 4th 9500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5778\n",
      "[INFO] Training model: epoch 4th 9600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5777\n",
      "[INFO] Training model: epoch 4th 9700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5776\n",
      "[INFO] Training model: epoch 4th 9800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5775\n",
      "[INFO] Training model: epoch 4th 9900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5775\n",
      "[INFO] Training model: epoch 4th 10000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5774\n",
      "[INFO] Training model: epoch 4th 10100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5773\n",
      "[INFO] Training model: epoch 4th 10200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5772\n",
      "[INFO] Training model: epoch 4th 10300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5771\n",
      "[INFO] Training model: epoch 4th 10400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5771\n",
      "[INFO] Training model: epoch 4th 10500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5770\n",
      "[INFO] Training model: epoch 4th 10600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5769\n",
      "[INFO] Training model: epoch 4th 10700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5768\n",
      "[INFO] Training model: epoch 4th 10800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5768\n",
      "[INFO] Training model: epoch 4th 10900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5767\n",
      "[INFO] Training model: epoch 4th 11000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5766\n",
      "[INFO] Training model: epoch 4th 11100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5766\n",
      "[INFO] Training model: epoch 4th 11200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5765\n",
      "[INFO] Training model: epoch 4th 11300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5765\n",
      "[INFO] Training model: epoch 4th 11400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5764\n",
      "[INFO] Training model: epoch 4th 11500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5763\n",
      "[INFO] Training model: epoch 4th 11600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5763\n",
      "[INFO] Training model: epoch 4th 11700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5762\n",
      "[INFO] Training model: epoch 4th 11800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5762\n",
      "[INFO] Training model: epoch 4th 11900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5761\n",
      "[INFO] Training model: epoch 4th 12000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5760\n",
      "[INFO] Training model: epoch 4th 12100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5760\n",
      "[INFO] Training model: epoch 4th 12200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5759\n",
      "[INFO] Training model: epoch 4th 12300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5759\n",
      "[INFO] Training model: epoch 4th 12400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5758\n",
      "[INFO] Training model: epoch 4th 12500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5758\n",
      "[INFO] Training model: epoch 4th 12600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5757\n",
      "[INFO] Training model: epoch 4th 12700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5758\n",
      "[INFO] Training model: epoch 4th 12800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5757\n",
      "[INFO] Training model: epoch 4th 12900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5756\n",
      "[INFO] Training model: epoch 4th 13000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5756\n",
      "[INFO] Training model: epoch 4th 13100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5755\n",
      "[INFO] Training model: epoch 4th 13200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5755\n",
      "[INFO] Training model: epoch 4th 13300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5754\n",
      "[INFO] Training model: epoch 4th 13400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5754\n",
      "[INFO] Training model: epoch 4th 13500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5753\n",
      "[INFO] Training model: epoch 4th 13600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5753\n",
      "[INFO] Training model: epoch 4th 13700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5753\n",
      "[INFO] Training model: epoch 4th 13800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5752\n",
      "[INFO] Training model: epoch 4th 13900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5752\n",
      "[INFO] Training model: epoch 4th 14000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5752\n",
      "[INFO] Training model: epoch 4th 14100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5751\n",
      "[INFO] Training model: epoch 4th 14200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5751\n",
      "[INFO] Training model: epoch 4th 14300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5751\n",
      "[INFO] Training model: epoch 4th 14400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5750\n",
      "[INFO] Training model: epoch 4th 14500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5750\n",
      "[INFO] Training model: epoch 4th 14600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5749\n",
      "[INFO] Training model: epoch 4th 14700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5749\n",
      "[INFO] Training model: epoch 4th 14800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5749\n",
      "[INFO] Training model: epoch 4th 14900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5748\n",
      "[INFO] Training model: epoch 4th 15000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5748\n",
      "[INFO] Training model: epoch 4th 15100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5748\n",
      "[INFO] Training model: epoch 4th 15200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5748\n",
      "[INFO] Training model: epoch 4th 15300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5747\n",
      "[INFO] Training model: epoch 4th 15400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5747\n",
      "[INFO] Training model: epoch 4th 15500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5747\n",
      "[INFO] Training model: epoch 4th 15600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5746\n",
      "[INFO] Training model: epoch 4th 15700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5746\n",
      "[INFO] Training model: epoch 4th 15800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5746\n",
      "[INFO] Training model: epoch 4th 15900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5745\n",
      "[INFO] Training model: epoch 4th 16000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5745\n",
      "[INFO] Training model: epoch 4th 16100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5745\n",
      "[INFO] Training model: epoch 4th 16200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5745\n",
      "[INFO] Training model: epoch 4th 16300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5744\n",
      "[INFO] Training model: epoch 4th 16400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5744\n",
      "[INFO] Training model: epoch 4th 16500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5744\n",
      "[INFO] Training model: epoch 4th 16600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5744\n",
      "[INFO] Training model: epoch 4th 16700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5743\n",
      "[INFO] Training model: epoch 4th 16800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5743\n",
      "[INFO] Training model: epoch 4th 16900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5743\n",
      "[INFO] Training model: epoch 4th 17000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5743\n",
      "[INFO] Training model: epoch 4th 17100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
      "[INFO] Training model: epoch 4th 17200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
      "[INFO] Training model: epoch 4th 17300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
      "[INFO] Training model: epoch 4th 17400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5742\n",
      "[INFO] Training model: epoch 4th 17500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5742\n",
      "[INFO] Training model: epoch 4th 17600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5741\n",
      "[INFO] Training model: epoch 4th 17700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5741\n",
      "[INFO] Training model: epoch 4th 17800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5741\n",
      "[INFO] Training model: epoch 4th 17900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5741\n",
      "[INFO] Training model: epoch 4th 18000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18500/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
      "[INFO] Training model: epoch 4th 18600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5739\n",
      "[INFO] Training model: epoch 4th 18700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5739\n",
      "[INFO] Training model: epoch 4th 18800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5739\n",
      "[INFO] Training model: epoch 4th 18900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5739\n",
      "[INFO] Training model: epoch 4th 19000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5739\n",
      "[INFO] Training model: epoch 4th 19100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
      "[INFO] Training model: epoch 4th 19700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 19800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 19900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 20000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 20100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 20200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 20300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
      "[INFO] Training model: epoch 4th 20400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 20500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 20600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 20700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 20800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 20900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
      "[INFO] Training model: epoch 4th 21000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
      "[INFO] Training model: epoch 4th 21800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 21900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
      "[INFO] Training model: epoch 4th 22600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 22700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 22800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 22900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
      "[INFO] Training model: epoch 4th 23600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 23700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 23800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 23900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5732\n",
      "[INFO] Training model: epoch 4th 24600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 24700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 24800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 24900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
      "[INFO] Training model: epoch 4th 25800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 25900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 26900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 27000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
      "[INFO] Training model: epoch 4th 27100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 27900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
      "[INFO] Training model: epoch 4th 28700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 28800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 28900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 29900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
      "[INFO] Training model: epoch 4th 30500/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 30600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 30700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 30800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 30900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 31900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
      "[INFO] Training model: epoch 4th 32700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 32800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 32900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 33900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 34900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 35000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 35100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 35200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 35300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
      "[INFO] Training model: epoch 4th 35400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 35500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 35600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 35700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 35800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 35900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 36900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 37900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 38900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 39000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 39100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
      "[INFO] Training model: epoch 4th 39200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 4th 39900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5724\n",
      "[INFO] Training model: epoch 5th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 4.5747\n",
      "[INFO] Training model: epoch 5th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.5030\n",
      "[INFO] Training model: epoch 5th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 2.6280\n",
      "[INFO] Training model: epoch 5th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9808\n",
      "[INFO] Training model: epoch 5th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5904\n",
      "[INFO] Training model: epoch 5th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.3163\n",
      "[INFO] Training model: epoch 5th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1409\n",
      "[INFO] Training model: epoch 5th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0266\n",
      "[INFO] Training model: epoch 5th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9519\n",
      "[INFO] Training model: epoch 5th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8980\n",
      "[INFO] Training model: epoch 5th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8545\n",
      "[INFO] Training model: epoch 5th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.8240\n",
      "[INFO] Training model: epoch 5th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7974\n",
      "[INFO] Training model: epoch 5th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7797\n",
      "[INFO] Training model: epoch 5th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7650\n",
      "[INFO] Training model: epoch 5th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7540\n",
      "[INFO] Training model: epoch 5th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7446\n",
      "[INFO] Training model: epoch 5th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7357\n",
      "[INFO] Training model: epoch 5th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7291\n",
      "[INFO] Training model: epoch 5th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7235\n",
      "[INFO] Training model: epoch 5th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7190\n",
      "[INFO] Training model: epoch 5th 2100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7149\n",
      "[INFO] Training model: epoch 5th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7118\n",
      "[INFO] Training model: epoch 5th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7084\n",
      "[INFO] Training model: epoch 5th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7053\n",
      "[INFO] Training model: epoch 5th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7031\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 5th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7010\n",
      "[INFO] Training model: epoch 5th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6989\n",
      "[INFO] Training model: epoch 5th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6973\n",
      "[INFO] Training model: epoch 5th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6957\n",
      "[INFO] Training model: epoch 5th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6944\n",
      "[INFO] Training model: epoch 5th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6930\n",
      "[INFO] Training model: epoch 5th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6921\n",
      "[INFO] Training model: epoch 5th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6910\n",
      "[INFO] Training model: epoch 5th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6899\n",
      "[INFO] Training model: epoch 5th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6891\n",
      "[INFO] Training model: epoch 5th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6883\n",
      "[INFO] Training model: epoch 5th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6875\n",
      "[INFO] Training model: epoch 5th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6868\n",
      "[INFO] Training model: epoch 5th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6861\n",
      "[INFO] Training model: epoch 5th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6856\n",
      "[INFO] Training model: epoch 5th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6851\n",
      "[INFO] Training model: epoch 5th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6846\n",
      "[INFO] Training model: epoch 5th 4300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6839\n",
      "[INFO] Training model: epoch 5th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6835\n",
      "[INFO] Training model: epoch 5th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6830\n",
      "[INFO] Training model: epoch 5th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6826\n",
      "[INFO] Training model: epoch 5th 4700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6822\n",
      "[INFO] Training model: epoch 5th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6818\n",
      "[INFO] Training model: epoch 5th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6814\n",
      "[INFO] Training model: epoch 5th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6811\n",
      "[INFO] Training model: epoch 5th 5100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6807\n",
      "[INFO] Training model: epoch 5th 5200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6804\n",
      "[INFO] Training model: epoch 5th 5300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6801\n",
      "[INFO] Training model: epoch 5th 5400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6798\n",
      "[INFO] Training model: epoch 5th 5500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6795\n",
      "[INFO] Training model: epoch 5th 5600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6792\n",
      "[INFO] Training model: epoch 5th 5700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6790\n",
      "[INFO] Training model: epoch 5th 5800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6788\n",
      "[INFO] Training model: epoch 5th 5900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6785\n",
      "[INFO] Training model: epoch 5th 6000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6783\n",
      "[INFO] Training model: epoch 5th 6100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6781\n",
      "[INFO] Training model: epoch 5th 6200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6779\n",
      "[INFO] Training model: epoch 5th 6300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6777\n",
      "[INFO] Training model: epoch 5th 6400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6775\n",
      "[INFO] Training model: epoch 5th 6500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6773\n",
      "[INFO] Training model: epoch 5th 6600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6771\n",
      "[INFO] Training model: epoch 5th 6700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6769\n",
      "[INFO] Training model: epoch 5th 6800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6768\n",
      "[INFO] Training model: epoch 5th 6900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6766\n",
      "[INFO] Training model: epoch 5th 7000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6765\n",
      "[INFO] Training model: epoch 5th 7100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6763\n",
      "[INFO] Training model: epoch 5th 7200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6762\n",
      "[INFO] Training model: epoch 5th 7300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6760\n",
      "[INFO] Training model: epoch 5th 7400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6759\n",
      "[INFO] Training model: epoch 5th 7500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6757\n",
      "[INFO] Training model: epoch 5th 7600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6756\n",
      "[INFO] Training model: epoch 5th 7700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6755\n",
      "[INFO] Training model: epoch 5th 7800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6754\n",
      "[INFO] Training model: epoch 5th 7900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6752\n",
      "[INFO] Training model: epoch 5th 8000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6751\n",
      "[INFO] Training model: epoch 5th 8100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6750\n",
      "[INFO] Training model: epoch 5th 8200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6749\n",
      "[INFO] Training model: epoch 5th 8300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6748\n",
      "[INFO] Training model: epoch 5th 8400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6747\n",
      "[INFO] Training model: epoch 5th 8500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6746\n",
      "[INFO] Training model: epoch 5th 8600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6745\n",
      "[INFO] Training model: epoch 5th 8700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6744\n",
      "[INFO] Training model: epoch 5th 8800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6743\n",
      "[INFO] Training model: epoch 5th 8900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6742\n",
      "[INFO] Training model: epoch 5th 9000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6742\n",
      "[INFO] Training model: epoch 5th 9100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6741\n",
      "[INFO] Training model: epoch 5th 9200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6740\n",
      "[INFO] Training model: epoch 5th 9300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6739\n",
      "[INFO] Training model: epoch 5th 9400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6738\n",
      "[INFO] Training model: epoch 5th 9500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6737\n",
      "[INFO] Training model: epoch 5th 9600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6737\n",
      "[INFO] Training model: epoch 5th 9700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6736\n",
      "[INFO] Training model: epoch 5th 9800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6735\n",
      "[INFO] Training model: epoch 5th 9900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6735\n",
      "[INFO] Training model: epoch 5th 10000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6734\n",
      "[INFO] Training model: epoch 5th 10100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6733\n",
      "[INFO] Training model: epoch 5th 10200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6733\n",
      "[INFO] Training model: epoch 5th 10300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6732\n",
      "[INFO] Training model: epoch 5th 10400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6731\n",
      "[INFO] Training model: epoch 5th 10500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6731\n",
      "[INFO] Training model: epoch 5th 10600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6730\n",
      "[INFO] Training model: epoch 5th 10700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6730\n",
      "[INFO] Training model: epoch 5th 10800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6729\n",
      "[INFO] Training model: epoch 5th 10900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6729\n",
      "[INFO] Training model: epoch 5th 11000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6728\n",
      "[INFO] Training model: epoch 5th 11100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6727\n",
      "[INFO] Training model: epoch 5th 11200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6727\n",
      "[INFO] Training model: epoch 5th 11300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6726\n",
      "[INFO] Training model: epoch 5th 11400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6726\n",
      "[INFO] Training model: epoch 5th 11500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6725\n",
      "[INFO] Training model: epoch 5th 11600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6725\n",
      "[INFO] Training model: epoch 5th 11700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6724\n",
      "[INFO] Training model: epoch 5th 11800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6724\n",
      "[INFO] Training model: epoch 5th 11900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6724\n",
      "[INFO] Training model: epoch 5th 12000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6723\n",
      "[INFO] Training model: epoch 5th 12100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6723\n",
      "[INFO] Training model: epoch 5th 12200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6722\n",
      "[INFO] Training model: epoch 5th 12300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6722\n",
      "[INFO] Training model: epoch 5th 12400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6721\n",
      "[INFO] Training model: epoch 5th 12500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6721\n",
      "[INFO] Training model: epoch 5th 12600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6720\n",
      "[INFO] Training model: epoch 5th 12700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6720\n",
      "[INFO] Training model: epoch 5th 12800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6720\n",
      "[INFO] Training model: epoch 5th 12900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6719\n",
      "[INFO] Training model: epoch 5th 13000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6719\n",
      "[INFO] Training model: epoch 5th 13100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6719\n",
      "[INFO] Training model: epoch 5th 13200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6718\n",
      "[INFO] Training model: epoch 5th 13300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6718\n",
      "[INFO] Training model: epoch 5th 13400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6717\n",
      "[INFO] Training model: epoch 5th 13500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6717\n",
      "[INFO] Training model: epoch 5th 13600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6717\n",
      "[INFO] Training model: epoch 5th 13700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6716\n",
      "[INFO] Training model: epoch 5th 13800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6716\n",
      "[INFO] Training model: epoch 5th 13900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6716\n",
      "[INFO] Training model: epoch 5th 14000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6715\n",
      "[INFO] Training model: epoch 5th 14100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6715\n",
      "[INFO] Training model: epoch 5th 14200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6715\n",
      "[INFO] Training model: epoch 5th 14300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
      "[INFO] Training model: epoch 5th 14400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
      "[INFO] Training model: epoch 5th 14500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
      "[INFO] Training model: epoch 5th 14600/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
      "[INFO] Training model: epoch 5th 14700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
      "[INFO] Training model: epoch 5th 14800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
      "[INFO] Training model: epoch 5th 14900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
      "[INFO] Training model: epoch 5th 15000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6712\n",
      "[INFO] Training model: epoch 5th 15100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
      "[INFO] Training model: epoch 5th 15200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
      "[INFO] Training model: epoch 5th 15300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
      "[INFO] Training model: epoch 5th 15400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
      "[INFO] Training model: epoch 5th 15500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
      "[INFO] Training model: epoch 5th 15600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
      "[INFO] Training model: epoch 5th 15700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
      "[INFO] Training model: epoch 5th 15800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6710\n",
      "[INFO] Training model: epoch 5th 15900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6710\n",
      "[INFO] Training model: epoch 5th 16000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6710\n",
      "[INFO] Training model: epoch 5th 16100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6710\n",
      "[INFO] Training model: epoch 5th 16200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
      "[INFO] Training model: epoch 5th 16300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
      "[INFO] Training model: epoch 5th 16400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
      "[INFO] Training model: epoch 5th 16500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
      "[INFO] Training model: epoch 5th 16600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
      "[INFO] Training model: epoch 5th 16700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
      "[INFO] Training model: epoch 5th 16800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
      "[INFO] Training model: epoch 5th 16900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
      "[INFO] Training model: epoch 5th 17000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
      "[INFO] Training model: epoch 5th 17100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6708\n",
      "[INFO] Training model: epoch 5th 17200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
      "[INFO] Training model: epoch 5th 17300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
      "[INFO] Training model: epoch 5th 17400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6707\n",
      "[INFO] Training model: epoch 5th 17500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
      "[INFO] Training model: epoch 5th 17600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
      "[INFO] Training model: epoch 5th 17700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 17800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 17900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 18000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 18100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 18200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
      "[INFO] Training model: epoch 5th 18300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
      "[INFO] Training model: epoch 5th 18900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6704\n",
      "[INFO] Training model: epoch 5th 19600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 19700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 19800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 19900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 20000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 20100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6703\n",
      "[INFO] Training model: epoch 5th 20200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 20900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
      "[INFO] Training model: epoch 5th 21000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
      "[INFO] Training model: epoch 5th 21800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 21900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
      "[INFO] Training model: epoch 5th 22800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 22900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
      "[INFO] Training model: epoch 5th 23900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 24900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 25000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
      "[INFO] Training model: epoch 5th 25100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 25900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 26000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 26100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 26200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 26300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
      "[INFO] Training model: epoch 5th 26400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 26500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 26600/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 26700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 26800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 26900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 27900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
      "[INFO] Training model: epoch 5th 28000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 28900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 29900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
      "[INFO] Training model: epoch 5th 30000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 30900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 31900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 32000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 32100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 32200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
      "[INFO] Training model: epoch 5th 32300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 32900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 33900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 34900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 35000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 35100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
      "[INFO] Training model: epoch 5th 35200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 35900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 36900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 37900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38600/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 38900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 39000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 39100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 39200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
      "[INFO] Training model: epoch 5th 39300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 5th 39900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6691\n",
      "[INFO] Training model: epoch 6th 0/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 4.5190\n",
      "[INFO] Training model: epoch 6th 100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 3.2467\n",
      "[INFO] Training model: epoch 6th 200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 2.3786\n",
      "[INFO] Training model: epoch 6th 300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.9020\n",
      "[INFO] Training model: epoch 6th 400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.5864\n",
      "[INFO] Training model: epoch 6th 500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.3882\n",
      "[INFO] Training model: epoch 6th 600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.2605\n",
      "[INFO] Training model: epoch 6th 700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.1820\n",
      "[INFO] Training model: epoch 6th 800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.1270\n",
      "[INFO] Training model: epoch 6th 900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0886\n",
      "[INFO] Training model: epoch 6th 1000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0620\n",
      "[INFO] Training model: epoch 6th 1100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0440\n",
      "[INFO] Training model: epoch 6th 1200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0306\n",
      "[INFO] Training model: epoch 6th 1300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 1.0197\n",
      "[INFO] Training model: epoch 6th 1400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0109\n",
      "[INFO] Training model: epoch 6th 1500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 1.0038\n",
      "[INFO] Training model: epoch 6th 1600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9987\n",
      "[INFO] Training model: epoch 6th 1700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9942\n",
      "[INFO] Training model: epoch 6th 1800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9906\n",
      "[INFO] Training model: epoch 6th 1900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9873\n",
      "[INFO] Training model: epoch 6th 2000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9845\n",
      "[INFO] Training model: epoch 6th 2100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9825\n",
      "[INFO] Training model: epoch 6th 2200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9801\n",
      "[INFO] Training model: epoch 6th 2300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9783\n",
      "[INFO] Training model: epoch 6th 2400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9767\n",
      "[INFO] Training model: epoch 6th 2500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9753\n",
      "[INFO] Training model: epoch 6th 2600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9740\n",
      "[INFO] Training model: epoch 6th 2700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9728\n",
      "[INFO] Training model: epoch 6th 2800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9719\n",
      "[INFO] Training model: epoch 6th 2900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9707\n",
      "[INFO] Training model: epoch 6th 3000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9699\n",
      "[INFO] Training model: epoch 6th 3100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9691\n",
      "[INFO] Training model: epoch 6th 3200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9684\n",
      "[INFO] Training model: epoch 6th 3300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9676\n",
      "[INFO] Training model: epoch 6th 3400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9670\n",
      "[INFO] Training model: epoch 6th 3500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9663\n",
      "[INFO] Training model: epoch 6th 3600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9658\n",
      "[INFO] Training model: epoch 6th 3700/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9653\n",
      "[INFO] Training model: epoch 6th 3800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9648\n",
      "[INFO] Training model: epoch 6th 3900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9643\n",
      "[INFO] Training model: epoch 6th 4000/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9639\n",
      "[INFO] Training model: epoch 6th 4100/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9634\n",
      "[INFO] Training model: epoch 6th 4200/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9630\n",
      "[INFO] Training model: epoch 6th 4300/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9627\n",
      "[INFO] Training model: epoch 6th 4400/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9623\n",
      "[INFO] Training model: epoch 6th 4500/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9620\n",
      "[INFO] Training model: epoch 6th 4600/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9617\n",
      "[INFO] Training model: epoch 6th 4700/40000 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9613\n",
      "[INFO] Training model: epoch 6th 4800/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9611\n",
      "[INFO] Training model: epoch 6th 4900/40000 samples\n",
      "Epoch 1/1\n",
      "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9608\n",
      "[INFO] Training model: epoch 6th 5000/40000 samples\n",
      "Epoch 1/1\n",
      "1792/2000 [=========================>....] - ETA: 1s - loss: 0.9810"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-34-3ddd008f6fa2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     81\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     82\u001b[0m         \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'[INFO] Training model: epoch {}th {}/{} samples'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_examples\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 83\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mI_1_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mI_2_train\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mY_set_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mBATCH_SIZE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     84\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'kerascheckpoint_epoch_{}.hdf5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Basing training in sets code on here - https://github.com/ChunML/seq2seq/blob/master/seq2seq.py\n",
    "\n",
    "BATCH_SIZE = 128 # Depends on GPU - most values are around this 32-128 \n",
    "NB_EPOCH = 1\n",
    "# Number of examples to group together in a set\n",
    "NB_SET = 100\n",
    "\n",
    "def find_checkpoint_file(folder):\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'kerascheckpoint' in f]\n",
    "    if len(checkpoint_file) == 0:\n",
    "        return []\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "# Finding trained weights of previous epoch if any\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "\n",
    "k_start = 1\n",
    "\n",
    "# If any trained weight was found, then load them into the model\n",
    "if len(saved_weights) != 0:\n",
    "    print('[INFO] Saved weights found, loading...')\n",
    "    epoch = saved_weights[saved_weights.rfind('_')+1:saved_weights.rfind('.')]\n",
    "    model.load_weights(saved_weights)\n",
    "    k_start = int(epoch) + 1\n",
    "\n",
    "i_end = 0\n",
    "num_examples = len(X_train)\n",
    "# Initialise history of accuracy\n",
    "acc = list()\n",
    "\n",
    "# So instead of X we have [inputs1, inputs2] - this is where we need to fold in \n",
    "# - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py\n",
    "\n",
    "# So we have inputs2 that build up - we have a set of inputs2 up to the length of inputs2\n",
    "\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(num_examples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    y_train = Y_train[indices]\n",
    "\n",
    "    # Training 100 sequences at a time\n",
    "    for i in range(0, num_examples, NB_SET):\n",
    "        if i + NB_SET >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + NB_SET\n",
    "        \n",
    "        set_size = (i_end-i)*y_max_len # e.g. 2000 for len = 20 and set = 100\n",
    "        I_1_train = np.zeros((set_size, X_max_len))\n",
    "        I_2_train = np.zeros((set_size, y_max_len))\n",
    "        # This below is a big array\n",
    "        Y_set_train = np.zeros((set_size, y_vocab_len))\n",
    "        \n",
    "        count = 0\n",
    "        # Now we want to create, for each sample, a set of examples for each word in the title\n",
    "        for l in range(0, (i_end - i)):\n",
    "            # for each X and y in set of 100 \n",
    "            \n",
    "            # We need to build the input for the second encoder for the next word in y\n",
    "            # I.e. for word 3 in the title the input2 consists of words 1 and 2 (using teacher forcing)\n",
    "            \n",
    "            # We only need to create examples up to the length of the title - but we can iterate up to\n",
    "            # y_max_len for now\n",
    "            for m in range(1, y_max_len):\n",
    "                \n",
    "                # Generate our one-hot y out\n",
    "                one_hot_out = np.zeros((1, y_vocab_len))\n",
    "                # This builds our one-hot generation into our training loop\n",
    "                # The l and m respectively iterate through the samples and the output sequence elements\n",
    "                one_hot_out[0, y_train[l][m]] = 1\n",
    "                \n",
    "                # Create a blank row/array for a partial input - this is fed into the decoder\n",
    "                # It is of the same size as our title\n",
    "                partial_input = np.zeros((1, y_max_len))\n",
    "                # Because we are zero padding add words up to m to end - DOES THIS STILL WORK IF WE ZERO PAD\n",
    "                # AT THE END? - Yes but we just feed the words with zeros first?\n",
    "                partial_input[0, -m:] = y_train[l][0:m]\n",
    "            \n",
    "                # This fills in each sample of the training data, i.e. count increments up to set size\n",
    "                I_1_train[count, :] = X_train[l]\n",
    "                I_2_train[count, :] = partial_input\n",
    "                Y_set_train[count, :] = one_hot_out\n",
    "                count += 1\n",
    "            \n",
    "        print('[INFO] Training model: epoch {} - {}/{} samples'.format(k, i, num_examples))\n",
    "        callback = model.fit([I_1_train, I_2_train], Y_set_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "        big_acc = acc + callback.history['acc']\n",
    "        # Get history and apppend new data to running set here\n",
    "    model.save_weights('kerascheckpoint_epoch_{}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If we get a low loss is it just memorising the provided claims and titles?\n",
    "\n",
    "Can we introduce some validation data?\n",
    "\n",
    "We probably need to shuffle the created data in each set. Problem is that our validation data will be reused with the next set. Unless we generate a set of validation data for a reserved portion of data?\n",
    "\n",
    "Yes we can pass validation data via - `history = model.fit(X_train, Y_train, validation_data=(X_test, Y_test))` \n",
    "\n",
    "I can use the test data I create above.\n",
    "\n",
    "The model uses the last output of the LSTM not the hidden state. Is this okay?\n",
    "\n",
    "Here is another model - https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/\n",
    "\n",
    "Stopped at epoch 6 because it looks like it stuck in a minima - epoch 3 is the best\n",
    "\n",
    "```\n",
    "[INFO] Training model: epoch 1th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 136s - loss: 0.1721   \n",
    "\n",
    "[INFO] Training model: epoch 5th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 133s - loss: 0.9014 \n",
    "# Basing training in sets code on here - https://github.com/ChunML/seq2seq/blob/master/seq2seq.py\n",
    "\n",
    "\n",
    "\n",
    "BATCH_SIZE = 128 # Depends on GPU - most values are around this 32-128 \n",
    "\n",
    "NB_EPOCH = 1\n",
    "\n",
    "# Number of examples to group together in a set\n",
    "\n",
    "NB_SET = 100\n",
    "\n",
    "\n",
    "\n",
    "def find_checkpoint_file(folder):\n",
    "\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'kerascheckpoint' in f]\n",
    "\n",
    "    if len(checkpoint_file) == 0:\n",
    "\n",
    "        return []\n",
    "\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "\n",
    "\n",
    "# Finding trained weights of previous epoch if any\n",
    "\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "\n",
    "\n",
    "\n",
    "k_start = 1\n",
    "\n",
    "\n",
    "\n",
    "# If any trained weight was found, then load them into the model\n",
    "\n",
    "if len(saved_weights) != 0:\n",
    "\n",
    "    print('[INFO] Saved weights found, loading...')\n",
    "\n",
    "    epoch = saved_weights[saved_weights.rfind('_')+1:saved_weights.rfind('.')]\n",
    "\n",
    "    model.load_weights(saved_weights)\n",
    "\n",
    "    k_start = int(epoch) + 1\n",
    "\n",
    "\n",
    "\n",
    "i_end = 0\n",
    "\n",
    "num_examples = len(X_train)\n",
    "\n",
    "# Initialise history of accuracy\n",
    "\n",
    "acc = list()\n",
    "\n",
    "\n",
    "\n",
    "# So instead of X we have [inputs1, inputs2] - this is where we need to fold in \n",
    "\n",
    "# - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py\n",
    "\n",
    "\n",
    "\n",
    "# So we have inputs2 that build up - we have a set of inputs2 up to the length of inputs2\n",
    "\n",
    "\n",
    "\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "\n",
    "    indices = np.arange(num_examples)\n",
    "\n",
    "    np.random.shuffle(indices)\n",
    "\n",
    "    X_train = X_train[indices]\n",
    "\n",
    "    y_train = Y_train[indices]\n",
    "\n",
    "\n",
    "\n",
    "    # Training 100 sequences at a time\n",
    "\n",
    "    for i in range(0, num_examples, NB_SET):\n",
    "\n",
    "        if i + NB_SET >= num_examples:\n",
    "\n",
    "            i_end = num_examples\n",
    "\n",
    "        else:\n",
    "\n",
    "            i_end = i + NB_SET\n",
    "\n",
    "        \n",
    "\n",
    "        set_size = (i_end-i)*y_max_len # e.g. 2000 for len = 20 and set = 100\n",
    "\n",
    "        I_1_train = np.zeros((set_size, X_max_len))\n",
    "\n",
    "        I_2_train = np.zeros((set_size, y_max_len))\n",
    "\n",
    "        # This below is a big array\n",
    "\n",
    "        Y_set_train = np.zeros((set_size, y_vocab_len))\n",
    "\n",
    "        \n",
    "\n",
    "        count = 0\n",
    "\n",
    "        # Now we want to create, for each sample, a set of examples for each word in the title\n",
    "\n",
    "        for l in range(0, (i_end - i)):\n",
    "\n",
    "            # for each X and y in set of 100 \n",
    "\n",
    "            \n",
    "\n",
    "            # We need to build the input for the second encoder for the next word in y\n",
    "\n",
    "            # I.e. for word 3 in the title the input2 consists of words 1 and 2 (using teacher forcing)\n",
    "\n",
    "            \n",
    "\n",
    "            # We only need to create examples up to the length of the title - but we can iterate up to\n",
    "\n",
    "            # y_max_len for now\n",
    "\n",
    "            for m in range(1, y_max_len):\n",
    "\n",
    "                \n",
    "\n",
    "                # Generate our one-hot y out\n",
    "\n",
    "                one_hot_out = np.zeros((1, y_vocab_len))\n",
    "\n",
    "                # This builds our one-hot generation into our training loop\n",
    "\n",
    "                # The l and m respectively iterate through the samples and the output sequence elements\n",
    "\n",
    "                one_hot_out[0, y_train[l][m]] = 1\n",
    "\n",
    "                \n",
    "\n",
    "                # Create a blank row/array for a partial input - this is fed into the decoder\n",
    "\n",
    "                # It is of the same size as our title\n",
    "\n",
    "                partial_input = np.zeros((1, y_max_len))\n",
    "\n",
    "                # Because we are zero padding add words up to m to end - DOES THIS STILL WORK IF WE ZERO PAD\n",
    "\n",
    "                # AT THE END? - Yes but we just feed the words with zeros first?\n",
    "\n",
    "                partial_input[0, -m:] = y_train[l][0:m]\n",
    "\n",
    "            \n",
    "\n",
    "                # This fills in each sample of the training data, i.e. count increments up to set size\n",
    "\n",
    "                I_1_train[count, :] = X_train[l]\n",
    "\n",
    "                I_2_train[count, :] = partial_input\n",
    "\n",
    "                Y_set_train[count, :] = one_hot_out\n",
    "\n",
    "                count += 1\n",
    "\n",
    "            \n",
    "\n",
    "        print('[INFO] Training model: epoch {} - {}/{} samples'.format(k, i, num_examples))\n",
    "\n",
    "        callback = model.fit([I_1_train, I_2_train], Y_set_train, batch_size=BATCH_SIZE, epochs=1)\n",
    "\n",
    "        big_acc = acc + callback.history['acc']\n",
    "\n",
    "        # Get history and apppend new data to running set here\n",
    "\n",
    "    model.save_weights('kerascheckpoint_epoch_{}.hdf5'.format(k))\n",
    "\n",
    "[INFO] Training model: epoch 1th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 6.7545\n",
    "[INFO] Training model: epoch 1th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.3911\n",
    "[INFO] Training model: epoch 1th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.1002\n",
    "[INFO] Training model: epoch 1th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.0144\n",
    "[INFO] Training model: epoch 1th 400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.9499\n",
    "[INFO] Training model: epoch 1th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.8704\n",
    "[INFO] Training model: epoch 1th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.7579\n",
    "[INFO] Training model: epoch 1th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.6246\n",
    "[INFO] Training model: epoch 1th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.5086\n",
    "[INFO] Training model: epoch 1th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.4338\n",
    "[INFO] Training model: epoch 1th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3895\n",
    "[INFO] Training model: epoch 1th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3620\n",
    "[INFO] Training model: epoch 1th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3386\n",
    "[INFO] Training model: epoch 1th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.3133\n",
    "[INFO] Training model: epoch 1th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2910\n",
    "[INFO] Training model: epoch 1th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 2.2637\n",
    "[INFO] Training model: epoch 1th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2320\n",
    "[INFO] Training model: epoch 1th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1966\n",
    "[INFO] Training model: epoch 1th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1643\n",
    "[INFO] Training model: epoch 1th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.1287\n",
    "[INFO] Training model: epoch 1th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0962\n",
    "[INFO] Training model: epoch 1th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0629\n",
    "[INFO] Training model: epoch 1th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0297\n",
    "[INFO] Training model: epoch 1th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0008\n",
    "[INFO] Training model: epoch 1th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9688\n",
    "[INFO] Training model: epoch 1th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9382\n",
    "[INFO] Training model: epoch 1th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9096\n",
    "[INFO] Training model: epoch 1th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8800\n",
    "[INFO] Training model: epoch 1th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8485\n",
    "[INFO] Training model: epoch 1th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.8213\n",
    "[INFO] Training model: epoch 1th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7916\n",
    "[INFO] Training model: epoch 1th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.7648\n",
    "[INFO] Training model: epoch 1th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7375\n",
    "[INFO] Training model: epoch 1th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.7070\n",
    "[INFO] Training model: epoch 1th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6786\n",
    "[INFO] Training model: epoch 1th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6553\n",
    "[INFO] Training model: epoch 1th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.6243\n",
    "[INFO] Training model: epoch 1th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5973\n",
    "[INFO] Training model: epoch 1th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5662\n",
    "[INFO] Training model: epoch 1th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5398\n",
    "[INFO] Training model: epoch 1th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5074\n",
    "[INFO] Training model: epoch 1th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.4776\n",
    "[INFO] Training model: epoch 1th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.4469\n",
    "[INFO] Training model: epoch 1th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.4144\n",
    "[INFO] Training model: epoch 1th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.3827\n",
    "[INFO] Training model: epoch 1th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.3515\n",
    "[INFO] Training model: epoch 1th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.3213\n",
    "[INFO] Training model: epoch 1th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2865\n",
    "[INFO] Training model: epoch 1th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2569\n",
    "[INFO] Training model: epoch 1th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.2243\n",
    "[INFO] Training model: epoch 1th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1942\n",
    "[INFO] Training model: epoch 1th 5100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.1615\n",
    "[INFO] Training model: epoch 1th 5200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1316\n",
    "[INFO] Training model: epoch 1th 5300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1022\n",
    "[INFO] Training model: epoch 1th 5400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0701\n",
    "[INFO] Training model: epoch 1th 5500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0401\n",
    "[INFO] Training model: epoch 1th 5600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0085\n",
    "[INFO] Training model: epoch 1th 5700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9800\n",
    "[INFO] Training model: epoch 1th 5800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9521\n",
    "[INFO] Training model: epoch 1th 5900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9232\n",
    "[INFO] Training model: epoch 1th 6000/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8933\n",
    "[INFO] Training model: epoch 1th 6100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8655\n",
    "[INFO] Training model: epoch 1th 6200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8398\n",
    "[INFO] Training model: epoch 1th 6300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8130\n",
    "[INFO] Training model: epoch 1th 6400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7876\n",
    "[INFO] Training model: epoch 1th 6500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7625\n",
    "[INFO] Training model: epoch 1th 6600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7380\n",
    "[INFO] Training model: epoch 1th 6700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.7153\n",
    "[INFO] Training model: epoch 1th 6800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6896\n",
    "[INFO] Training model: epoch 1th 6900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6681\n",
    "[INFO] Training model: epoch 1th 7000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6473\n",
    "[INFO] Training model: epoch 1th 7100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6243\n",
    "[INFO] Training model: epoch 1th 7200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6047\n",
    "[INFO] Training model: epoch 1th 7300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5855\n",
    "[INFO] Training model: epoch 1th 7400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5670\n",
    "[INFO] Training model: epoch 1th 7500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5478\n",
    "[INFO] Training model: epoch 1th 7600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5296\n",
    "[INFO] Training model: epoch 1th 7700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5129\n",
    "[INFO] Training model: epoch 1th 7800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4964\n",
    "[INFO] Training model: epoch 1th 7900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4810\n",
    "[INFO] Training model: epoch 1th 8000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4655\n",
    "[INFO] Training model: epoch 1th 8100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4547\n",
    "[INFO] Training model: epoch 1th 8200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4478\n",
    "[INFO] Training model: epoch 1th 8300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.4263\n",
    "[INFO] Training model: epoch 1th 8400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4103\n",
    "[INFO] Training model: epoch 1th 8500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3970\n",
    "[INFO] Training model: epoch 1th 8600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3852\n",
    "[INFO] Training model: epoch 1th 8700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3725\n",
    "[INFO] Training model: epoch 1th 8800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3627\n",
    "[INFO] Training model: epoch 1th 8900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.3511\n",
    "[INFO] Training model: epoch 1th 9000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3406\n",
    "[INFO] Training model: epoch 1th 9100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3303\n",
    "[INFO] Training model: epoch 1th 9200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3213\n",
    "[INFO] Training model: epoch 1th 9300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3121\n",
    "[INFO] Training model: epoch 1th 9400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3047\n",
    "[INFO] Training model: epoch 1th 9500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2955\n",
    "[INFO] Training model: epoch 1th 9600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2868\n",
    "[INFO] Training model: epoch 1th 9700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2780\n",
    "[INFO] Training model: epoch 1th 9800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2715\n",
    "[INFO] Training model: epoch 1th 9900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2639\n",
    "[INFO] Training model: epoch 1th 10000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2565\n",
    "[INFO] Training model: epoch 1th 10100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2506\n",
    "[INFO] Training model: epoch 1th 10200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2431\n",
    "[INFO] Training model: epoch 1th 10300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2360\n",
    "[INFO] Training model: epoch 1th 10400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2303\n",
    "[INFO] Training model: epoch 1th 10500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2242\n",
    "[INFO] Training model: epoch 1th 10600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2184\n",
    "[INFO] Training model: epoch 1th 10700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2138\n",
    "[INFO] Training model: epoch 1th 10800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2077\n",
    "[INFO] Training model: epoch 1th 10900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2017\n",
    "[INFO] Training model: epoch 1th 11000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1966\n",
    "[INFO] Training model: epoch 1th 11100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1928\n",
    "[INFO] Training model: epoch 1th 11200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1882\n",
    "[INFO] Training model: epoch 1th 11300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1840\n",
    "[INFO] Training model: epoch 1th 11400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1793\n",
    "[INFO] Training model: epoch 1th 11500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1750\n",
    "[INFO] Training model: epoch 1th 11600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1712\n",
    "[INFO] Training model: epoch 1th 11700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1656\n",
    "[INFO] Training model: epoch 1th 11800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1626\n",
    "[INFO] Training model: epoch 1th 11900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1587\n",
    "[INFO] Training model: epoch 1th 12000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1552\n",
    "\n",
    "[INFO] Training model: epoch 1th 12100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1521\n",
    "[INFO] Training model: epoch 1th 12200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1485\n",
    "[INFO] Training model: epoch 1th 12300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1455\n",
    "[INFO] Training model: epoch 1th 12400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1417\n",
    "[INFO] Training model: epoch 1th 12500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1385\n",
    "[INFO] Training model: epoch 1th 12600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1356\n",
    "[INFO] Training model: epoch 1th 12700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1324\n",
    "[INFO] Training model: epoch 1th 12800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1298\n",
    "[INFO] Training model: epoch 1th 12900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1263\n",
    "[INFO] Training model: epoch 1th 13000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1249\n",
    "[INFO] Training model: epoch 1th 13100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1215\n",
    "[INFO] Training model: epoch 1th 13200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1191\n",
    "[INFO] Training model: epoch 1th 13300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1169\n",
    "[INFO] Training model: epoch 1th 13400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1146\n",
    "[INFO] Training model: epoch 1th 13500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1117\n",
    "[INFO] Training model: epoch 1th 13600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1092\n",
    "[INFO] Training model: epoch 1th 13700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1066\n",
    "[INFO] Training model: epoch 1th 13800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1046\n",
    "[INFO] Training model: epoch 1th 13900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1021\n",
    "[INFO] Training model: epoch 1th 14000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1000\n",
    "[INFO] Training model: epoch 1th 14100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0983\n",
    "[INFO] Training model: epoch 1th 14200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0963\n",
    "[INFO] Training model: epoch 1th 14300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0942\n",
    "[INFO] Training model: epoch 1th 14400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0926\n",
    "[INFO] Training model: epoch 1th 14500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0907\n",
    "[INFO] Training model: epoch 1th 14600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0889\n",
    "[INFO] Training model: epoch 1th 14700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0870\n",
    "[INFO] Training model: epoch 1th 14800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0854\n",
    "[INFO] Training model: epoch 1th 14900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0838\n",
    "[INFO] Training model: epoch 1th 15000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0817\n",
    "[INFO] Training model: epoch 1th 15100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0808\n",
    "[INFO] Training model: epoch 1th 15200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0790\n",
    "[INFO] Training model: epoch 1th 15300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0774\n",
    "[INFO] Training model: epoch 1th 15400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0759\n",
    "[INFO] Training model: epoch 1th 15500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0742\n",
    "[INFO] Training model: epoch 1th 15600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0729\n",
    "[INFO] Training model: epoch 1th 15700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0712\n",
    "[INFO] Training model: epoch 1th 15800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0699\n",
    "[INFO] Training model: epoch 1th 15900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0684\n",
    "[INFO] Training model: epoch 1th 16000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0672\n",
    "[INFO] Training model: epoch 1th 16100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0662\n",
    "[INFO] Training model: epoch 1th 16200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0647\n",
    "[INFO] Training model: epoch 1th 16300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0634\n",
    "[INFO] Training model: epoch 1th 16400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0624\n",
    "[INFO] Training model: epoch 1th 16500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0613\n",
    "[INFO] Training model: epoch 1th 16600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0600\n",
    "[INFO] Training model: epoch 1th 16700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0592\n",
    "[INFO] Training model: epoch 1th 16800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0578\n",
    "[INFO] Training model: epoch 1th 16900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0569\n",
    "[INFO] Training model: epoch 1th 17000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0559\n",
    "[INFO] Training model: epoch 1th 17100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0549\n",
    "[INFO] Training model: epoch 1th 17200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0541\n",
    "[INFO] Training model: epoch 1th 17300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0531\n",
    "[INFO] Training model: epoch 1th 17400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0517\n",
    "[INFO] Training model: epoch 1th 17500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0508\n",
    "[INFO] Training model: epoch 1th 17600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0498\n",
    "[INFO] Training model: epoch 1th 17700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0491\n",
    "[INFO] Training model: epoch 1th 17800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0483\n",
    "[INFO] Training model: epoch 1th 17900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0474\n",
    "[INFO] Training model: epoch 1th 18000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0465\n",
    "[INFO] Training model: epoch 1th 18100/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0460\n",
    "[INFO] Training model: epoch 1th 18200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0450\n",
    "[INFO] Training model: epoch 1th 18300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0440\n",
    "[INFO] Training model: epoch 1th 18400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0435\n",
    "[INFO] Training model: epoch 1th 18500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0426\n",
    "[INFO] Training model: epoch 1th 18600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0421\n",
    "[INFO] Training model: epoch 1th 18700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0414\n",
    "[INFO] Training model: epoch 1th 18800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0405\n",
    "[INFO] Training model: epoch 1th 18900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0401\n",
    "[INFO] Training model: epoch 1th 19000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0392\n",
    "[INFO] Training model: epoch 1th 19100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0385\n",
    "[INFO] Training model: epoch 1th 19200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0378\n",
    "[INFO] Training model: epoch 1th 19300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0372\n",
    "[INFO] Training model: epoch 1th 19400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0366\n",
    "[INFO] Training model: epoch 1th 19500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0360\n",
    "[INFO] Training model: epoch 1th 19600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0354\n",
    "[INFO] Training model: epoch 1th 19700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
    "[INFO] Training model: epoch 1th 19800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 1th 19900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 1th 20000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 1th 20100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0327\n",
    "[INFO] Training model: epoch 1th 20200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0323\n",
    "[INFO] Training model: epoch 1th 20300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0317\n",
    "[INFO] Training model: epoch 1th 20400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0311\n",
    "[INFO] Training model: epoch 1th 20500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0307\n",
    "[INFO] Training model: epoch 1th 20600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0304\n",
    "[INFO] Training model: epoch 1th 20700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0298\n",
    "[INFO] Training model: epoch 1th 20800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0293\n",
    "[INFO] Training model: epoch 1th 20900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0288\n",
    "[INFO] Training model: epoch 1th 21000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0286\n",
    "[INFO] Training model: epoch 1th 21100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0281\n",
    "[INFO] Training model: epoch 1th 21200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0274\n",
    "[INFO] Training model: epoch 1th 21300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0270\n",
    "[INFO] Training model: epoch 1th 21400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0267\n",
    "[INFO] Training model: epoch 1th 21500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0262\n",
    "[INFO] Training model: epoch 1th 21600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0259\n",
    "[INFO] Training model: epoch 1th 21700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0255\n",
    "[INFO] Training model: epoch 1th 21800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0252\n",
    "[INFO] Training model: epoch 1th 21900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0248\n",
    "[INFO] Training model: epoch 1th 22000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0245\n",
    "[INFO] Training model: epoch 1th 22100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0240\n",
    "[INFO] Training model: epoch 1th 22200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0236\n",
    "[INFO] Training model: epoch 1th 22300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0233\n",
    "[INFO] Training model: epoch 1th 22400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0230\n",
    "[INFO] Training model: epoch 1th 22500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0228\n",
    "[INFO] Training model: epoch 1th 22600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0222\n",
    "[INFO] Training model: epoch 1th 22700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0220\n",
    "[INFO] Training model: epoch 1th 22800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0218\n",
    "[INFO] Training model: epoch 1th 22900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0214\n",
    "[INFO] Training model: epoch 1th 23000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0210\n",
    "[INFO] Training model: epoch 1th 23100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0208\n",
    "[INFO] Training model: epoch 1th 23200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0205\n",
    "[INFO] Training model: epoch 1th 23300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0203\n",
    "[INFO] Training model: epoch 1th 23400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0200\n",
    "[INFO] Training model: epoch 1th 23500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0197\n",
    "[INFO] Training model: epoch 1th 23600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0194\n",
    "[INFO] Training model: epoch 1th 23700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0191\n",
    "[INFO] Training model: epoch 1th 23800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0188\n",
    "[INFO] Training model: epoch 1th 23900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0186\n",
    "[INFO] Training model: epoch 1th 24000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0183\n",
    "[INFO] Training model: epoch 1th 24100/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0181\n",
    "[INFO] Training model: epoch 1th 24200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0178\n",
    "[INFO] Training model: epoch 1th 24300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0176\n",
    "[INFO] Training model: epoch 1th 24400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0173\n",
    "[INFO] Training model: epoch 1th 24500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0171\n",
    "[INFO] Training model: epoch 1th 24600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0169\n",
    "[INFO] Training model: epoch 1th 24700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0167\n",
    "[INFO] Training model: epoch 1th 24800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0164\n",
    "[INFO] Training model: epoch 1th 24900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0162\n",
    "[INFO] Training model: epoch 1th 25000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0160\n",
    "[INFO] Training model: epoch 1th 25100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0158\n",
    "[INFO] Training model: epoch 1th 25200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0156\n",
    "[INFO] Training model: epoch 1th 25300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0154\n",
    "[INFO] Training model: epoch 1th 25400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0153\n",
    "[INFO] Training model: epoch 1th 25500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0150\n",
    "[INFO] Training model: epoch 1th 25600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0148\n",
    "[INFO] Training model: epoch 1th 25700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0147\n",
    "[INFO] Training model: epoch 1th 25800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0145\n",
    "[INFO] Training model: epoch 1th 25900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0143\n",
    "[INFO] Training model: epoch 1th 26000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0140\n",
    "[INFO] Training model: epoch 1th 26100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0140\n",
    "[INFO] Training model: epoch 1th 26200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0137\n",
    "[INFO] Training model: epoch 1th 26300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0136\n",
    "[INFO] Training model: epoch 1th 26400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0134\n",
    "[INFO] Training model: epoch 1th 26500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0132\n",
    "[INFO] Training model: epoch 1th 26600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0130\n",
    "[INFO] Training model: epoch 1th 26700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0129\n",
    "[INFO] Training model: epoch 1th 26800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0127\n",
    "[INFO] Training model: epoch 1th 26900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0126\n",
    "[INFO] Training model: epoch 1th 27000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0124\n",
    "[INFO] Training model: epoch 1th 27100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0123\n",
    "[INFO] Training model: epoch 1th 27200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0122\n",
    "[INFO] Training model: epoch 1th 27300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0120\n",
    "[INFO] Training model: epoch 1th 27400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0119\n",
    "[INFO] Training model: epoch 1th 27500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0117\n",
    "[INFO] Training model: epoch 1th 27600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0115\n",
    "[INFO] Training model: epoch 1th 27700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0114\n",
    "[INFO] Training model: epoch 1th 27800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0113\n",
    "[INFO] Training model: epoch 1th 27900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0111\n",
    "[INFO] Training model: epoch 1th 28000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0110\n",
    "[INFO] Training model: epoch 1th 28100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0109\n",
    "[INFO] Training model: epoch 1th 28200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0108\n",
    "[INFO] Training model: epoch 1th 28300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0106\n",
    "[INFO] Training model: epoch 1th 28400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0105\n",
    "[INFO] Training model: epoch 1th 28500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0104\n",
    "[INFO] Training model: epoch 1th 28600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0103\n",
    "[INFO] Training model: epoch 1th 28700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0101\n",
    "[INFO] Training model: epoch 1th 28800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0100\n",
    "[INFO] Training model: epoch 1th 28900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0099\n",
    "[INFO] Training model: epoch 1th 29000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0098\n",
    "[INFO] Training model: epoch 1th 29100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0097\n",
    "[INFO] Training model: epoch 1th 29200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0096\n",
    "[INFO] Training model: epoch 1th 29300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0095\n",
    "[INFO] Training model: epoch 1th 29400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0094\n",
    "[INFO] Training model: epoch 1th 29500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0093\n",
    "[INFO] Training model: epoch 1th 29600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0091\n",
    "[INFO] Training model: epoch 1th 29700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0091\n",
    "[INFO] Training model: epoch 1th 29800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0089\n",
    "[INFO] Training model: epoch 1th 29900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0089\n",
    "[INFO] Training model: epoch 1th 30000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0087\n",
    "[INFO] Training model: epoch 1th 30100/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0086\n",
    "[INFO] Training model: epoch 1th 30200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0085\n",
    "[INFO] Training model: epoch 1th 30300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0085\n",
    "[INFO] Training model: epoch 1th 30400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0084\n",
    "[INFO] Training model: epoch 1th 30500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0083\n",
    "[INFO] Training model: epoch 1th 30600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0082\n",
    "[INFO] Training model: epoch 1th 30700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0081\n",
    "[INFO] Training model: epoch 1th 30800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0080\n",
    "[INFO] Training model: epoch 1th 30900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0079\n",
    "[INFO] Training model: epoch 1th 31000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0078\n",
    "[INFO] Training model: epoch 1th 31100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0077\n",
    "[INFO] Training model: epoch 1th 31200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0076\n",
    "[INFO] Training model: epoch 1th 31300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0076\n",
    "[INFO] Training model: epoch 1th 31400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0075\n",
    "[INFO] Training model: epoch 1th 31500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0074\n",
    "[INFO] Training model: epoch 1th 31600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0073\n",
    "[INFO] Training model: epoch 1th 31700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0072\n",
    "[INFO] Training model: epoch 1th 31800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0072\n",
    "[INFO] Training model: epoch 1th 31900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0071\n",
    "[INFO] Training model: epoch 1th 32000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0070\n",
    "[INFO] Training model: epoch 1th 32100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0069\n",
    "[INFO] Training model: epoch 1th 32200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0069\n",
    "[INFO] Training model: epoch 1th 32300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0068\n",
    "[INFO] Training model: epoch 1th 32400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0067\n",
    "[INFO] Training model: epoch 1th 32500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0067\n",
    "[INFO] Training model: epoch 1th 32600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0066\n",
    "[INFO] Training model: epoch 1th 32700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0065\n",
    "[INFO] Training model: epoch 1th 32800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0064\n",
    "[INFO] Training model: epoch 1th 32900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0064\n",
    "[INFO] Training model: epoch 1th 33000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0063\n",
    "[INFO] Training model: epoch 1th 33100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0062\n",
    "[INFO] Training model: epoch 1th 33200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0062\n",
    "[INFO] Training model: epoch 1th 33300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0061\n",
    "[INFO] Training model: epoch 1th 33400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0060\n",
    "[INFO] Training model: epoch 1th 33500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0060\n",
    "[INFO] Training model: epoch 1th 33600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0059\n",
    "[INFO] Training model: epoch 1th 33700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0059\n",
    "[INFO] Training model: epoch 1th 33800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0058\n",
    "[INFO] Training model: epoch 1th 33900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0057\n",
    "[INFO] Training model: epoch 1th 34000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0057\n",
    "[INFO] Training model: epoch 1th 34100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0056\n",
    "[INFO] Training model: epoch 1th 34200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0056\n",
    "[INFO] Training model: epoch 1th 34300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0055\n",
    "[INFO] Training model: epoch 1th 34400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0055\n",
    "[INFO] Training model: epoch 1th 34500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0054\n",
    "[INFO] Training model: epoch 1th 34600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0053\n",
    "[INFO] Training model: epoch 1th 34700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0053\n",
    "[INFO] Training model: epoch 1th 34800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0052\n",
    "[INFO] Training model: epoch 1th 34900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0052\n",
    "[INFO] Training model: epoch 1th 35000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0051\n",
    "[INFO] Training model: epoch 1th 35100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0051\n",
    "[INFO] Training model: epoch 1th 35200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0050\n",
    "[INFO] Training model: epoch 1th 35300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0050\n",
    "[INFO] Training model: epoch 1th 35400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0049\n",
    "[INFO] Training model: epoch 1th 35500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0049\n",
    "[INFO] Training model: epoch 1th 35600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0048\n",
    "[INFO] Training model: epoch 1th 35700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0048\n",
    "[INFO] Training model: epoch 1th 35800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0047\n",
    "[INFO] Training model: epoch 1th 35900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0047\n",
    "[INFO] Training model: epoch 1th 36000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0046\n",
    "[INFO] Training model: epoch 1th 36100/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0046\n",
    "[INFO] Training model: epoch 1th 36200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0046\n",
    "[INFO] Training model: epoch 1th 36300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0045\n",
    "[INFO] Training model: epoch 1th 36400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0045\n",
    "[INFO] Training model: epoch 1th 36500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0044\n",
    "[INFO] Training model: epoch 1th 36600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0044\n",
    "[INFO] Training model: epoch 1th 36700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0043\n",
    "[INFO] Training model: epoch 1th 36800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0043\n",
    "[INFO] Training model: epoch 1th 36900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0042\n",
    "[INFO] Training model: epoch 1th 37000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0042\n",
    "[INFO] Training model: epoch 1th 37100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0042\n",
    "[INFO] Training model: epoch 1th 37200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0041\n",
    "[INFO] Training model: epoch 1th 37300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0041\n",
    "[INFO] Training model: epoch 1th 37400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0040\n",
    "[INFO] Training model: epoch 1th 37500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0040\n",
    "[INFO] Training model: epoch 1th 37600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0040\n",
    "[INFO] Training model: epoch 1th 37700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0039\n",
    "[INFO] Training model: epoch 1th 37800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0039\n",
    "[INFO] Training model: epoch 1th 37900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0039\n",
    "[INFO] Training model: epoch 1th 38000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0038\n",
    "[INFO] Training model: epoch 1th 38100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0038\n",
    "[INFO] Training model: epoch 1th 38200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0037\n",
    "[INFO] Training model: epoch 1th 38300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0037\n",
    "[INFO] Training model: epoch 1th 38400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0037\n",
    "[INFO] Training model: epoch 1th 38500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0036\n",
    "[INFO] Training model: epoch 1th 38600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0036\n",
    "[INFO] Training model: epoch 1th 38700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0036\n",
    "[INFO] Training model: epoch 1th 38800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
    "[INFO] Training model: epoch 1th 38900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
    "[INFO] Training model: epoch 1th 39000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0035\n",
    "[INFO] Training model: epoch 1th 39100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0034\n",
    "[INFO] Training model: epoch 1th 39200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0034\n",
    "[INFO] Training model: epoch 1th 39300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0034\n",
    "[INFO] Training model: epoch 1th 39400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0033\n",
    "[INFO] Training model: epoch 1th 39500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0033\n",
    "[INFO] Training model: epoch 1th 39600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0033\n",
    "[INFO] Training model: epoch 1th 39700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0032\n",
    "[INFO] Training model: epoch 1th 39800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0032\n",
    "[INFO] Training model: epoch 1th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0032\n",
    "[INFO] Training model: epoch 2th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 4.4112\n",
    "[INFO] Training model: epoch 2th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.8805\n",
    "[INFO] Training model: epoch 2th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.0963\n",
    "[INFO] Training model: epoch 2th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.6697\n",
    "[INFO] Training model: epoch 2th 400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.3972\n",
    "[INFO] Training model: epoch 2th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.1917\n",
    "[INFO] Training model: epoch 2th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0092\n",
    "[INFO] Training model: epoch 2th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8786\n",
    "[INFO] Training model: epoch 2th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7527\n",
    "[INFO] Training model: epoch 2th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6522\n",
    "[INFO] Training model: epoch 2th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5660\n",
    "[INFO] Training model: epoch 2th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4948\n",
    "[INFO] Training model: epoch 2th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.4346\n",
    "[INFO] Training model: epoch 2th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3884\n",
    "[INFO] Training model: epoch 2th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.3491\n",
    "[INFO] Training model: epoch 2th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3140\n",
    "[INFO] Training model: epoch 2th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2866\n",
    "[INFO] Training model: epoch 2th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2632\n",
    "[INFO] Training model: epoch 2th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2408\n",
    "[INFO] Training model: epoch 2th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2232\n",
    "[INFO] Training model: epoch 2th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2064\n",
    "[INFO] Training model: epoch 2th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1920\n",
    "[INFO] Training model: epoch 2th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1810\n",
    "[INFO] Training model: epoch 2th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1711\n",
    "[INFO] Training model: epoch 2th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1607\n",
    "[INFO] Training model: epoch 2th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1515\n",
    "[INFO] Training model: epoch 2th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1445\n",
    "[INFO] Training model: epoch 2th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1381\n",
    "[INFO] Training model: epoch 2th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1327\n",
    "[INFO] Training model: epoch 2th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1277\n",
    "[INFO] Training model: epoch 2th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1206\n",
    "[INFO] Training model: epoch 2th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.1158\n",
    "[INFO] Training model: epoch 2th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1110\n",
    "[INFO] Training model: epoch 2th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.1076\n",
    "[INFO] Training model: epoch 2th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.1048\n",
    "[INFO] Training model: epoch 2th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1004\n",
    "[INFO] Training model: epoch 2th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0963\n",
    "[INFO] Training model: epoch 2th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0939\n",
    "[INFO] Training model: epoch 2th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0915\n",
    "[INFO] Training model: epoch 2th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0888\n",
    "[INFO] Training model: epoch 2th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0867\n",
    "[INFO] Training model: epoch 2th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0842\n",
    "[INFO] Training model: epoch 2th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0816\n",
    "[INFO] Training model: epoch 2th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0802\n",
    "[INFO] Training model: epoch 2th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0787\n",
    "[INFO] Training model: epoch 2th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0767\n",
    "[INFO] Training model: epoch 2th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0752\n",
    "[INFO] Training model: epoch 2th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0735\n",
    "[INFO] Training model: epoch 2th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0721\n",
    "[INFO] Training model: epoch 2th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0708\n",
    "[INFO] Training model: epoch 2th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0696\n",
    "[INFO] Training model: epoch 2th 5100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0684\n",
    "[INFO] Training model: epoch 2th 5200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0678\n",
    "[INFO] Training model: epoch 2th 5300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0661\n",
    "[INFO] Training model: epoch 2th 5400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0649\n",
    "[INFO] Training model: epoch 2th 5500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0641\n",
    "[INFO] Training model: epoch 2th 5600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0631\n",
    "[INFO] Training model: epoch 2th 5700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0624\n",
    "[INFO] Training model: epoch 2th 5800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0617\n",
    "[INFO] Training model: epoch 2th 5900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0607\n",
    "[INFO] Training model: epoch 2th 6000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0600\n",
    "[INFO] Training model: epoch 2th 6100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0594\n",
    "[INFO] Training model: epoch 2th 6200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0586\n",
    "[INFO] Training model: epoch 2th 6300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0581\n",
    "[INFO] Training model: epoch 2th 6400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0574\n",
    "[INFO] Training model: epoch 2th 6500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0568\n",
    "[INFO] Training model: epoch 2th 6600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0562\n",
    "[INFO] Training model: epoch 2th 6700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0555\n",
    "[INFO] Training model: epoch 2th 6800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0551\n",
    "[INFO] Training model: epoch 2th 6900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0544\n",
    "[INFO] Training model: epoch 2th 7000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0539\n",
    "[INFO] Training model: epoch 2th 7100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0535\n",
    "[INFO] Training model: epoch 2th 7200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0531\n",
    "[INFO] Training model: epoch 2th 7300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0526\n",
    "[INFO] Training model: epoch 2th 7400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0521\n",
    "[INFO] Training model: epoch 2th 7500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0518\n",
    "[INFO] Training model: epoch 2th 7600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0513\n",
    "[INFO] Training model: epoch 2th 7700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0509\n",
    "[INFO] Training model: epoch 2th 7800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0505\n",
    "[INFO] Training model: epoch 2th 7900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0501\n",
    "[INFO] Training model: epoch 2th 8000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0498\n",
    "[INFO] Training model: epoch 2th 8100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0495\n",
    "[INFO] Training model: epoch 2th 8200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0491\n",
    "[INFO] Training model: epoch 2th 8300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0488\n",
    "[INFO] Training model: epoch 2th 8400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0485\n",
    "[INFO] Training model: epoch 2th 8500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0483\n",
    "[INFO] Training model: epoch 2th 8600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0479\n",
    "[INFO] Training model: epoch 2th 8700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0476\n",
    "[INFO] Training model: epoch 2th 8800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0473\n",
    "[INFO] Training model: epoch 2th 8900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0470\n",
    "[INFO] Training model: epoch 2th 9000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0467\n",
    "[INFO] Training model: epoch 2th 9100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0465\n",
    "[INFO] Training model: epoch 2th 9200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0462\n",
    "[INFO] Training model: epoch 2th 9300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0460\n",
    "[INFO] Training model: epoch 2th 9400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0457\n",
    "[INFO] Training model: epoch 2th 9500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0455\n",
    "[INFO] Training model: epoch 2th 9600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0452\n",
    "[INFO] Training model: epoch 2th 9700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0450\n",
    "[INFO] Training model: epoch 2th 9800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0449\n",
    "[INFO] Training model: epoch 2th 9900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0447\n",
    "[INFO] Training model: epoch 2th 10000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0445\n",
    "[INFO] Training model: epoch 2th 10100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0443\n",
    "[INFO] Training model: epoch 2th 10200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0440\n",
    "[INFO] Training model: epoch 2th 10300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0439\n",
    "[INFO] Training model: epoch 2th 10400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0437\n",
    "[INFO] Training model: epoch 2th 10500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0435\n",
    "[INFO] Training model: epoch 2th 10600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0433\n",
    "[INFO] Training model: epoch 2th 10700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0431\n",
    "[INFO] Training model: epoch 2th 10800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0429\n",
    "[INFO] Training model: epoch 2th 10900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0428\n",
    "[INFO] Training model: epoch 2th 11000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0426\n",
    "[INFO] Training model: epoch 2th 11100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0424\n",
    "[INFO] Training model: epoch 2th 11200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0423\n",
    "[INFO] Training model: epoch 2th 11300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0422\n",
    "[INFO] Training model: epoch 2th 11400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0420\n",
    "[INFO] Training model: epoch 2th 11500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0419\n",
    "[INFO] Training model: epoch 2th 11600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0417\n",
    "[INFO] Training model: epoch 2th 11700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0416\n",
    "[INFO] Training model: epoch 2th 11800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0414\n",
    "[INFO] Training model: epoch 2th 11900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0413\n",
    "[INFO] Training model: epoch 2th 12000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0412\n",
    "[INFO] Training model: epoch 2th 12100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0410\n",
    "[INFO] Training model: epoch 2th 12200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0409\n",
    "[INFO] Training model: epoch 2th 12300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0408\n",
    "[INFO] Training model: epoch 2th 12400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0407\n",
    "[INFO] Training model: epoch 2th 12500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0405\n",
    "[INFO] Training model: epoch 2th 12600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0404\n",
    "[INFO] Training model: epoch 2th 12700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0403\n",
    "[INFO] Training model: epoch 2th 12800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0402\n",
    "[INFO] Training model: epoch 2th 12900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0401\n",
    "[INFO] Training model: epoch 2th 13000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0400\n",
    "[INFO] Training model: epoch 2th 13100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0399\n",
    "[INFO] Training model: epoch 2th 13200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0398\n",
    "[INFO] Training model: epoch 2th 13300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0397\n",
    "[INFO] Training model: epoch 2th 13400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0396\n",
    "[INFO] Training model: epoch 2th 13500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0395\n",
    "[INFO] Training model: epoch 2th 13600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0394\n",
    "[INFO] Training model: epoch 2th 13700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0393\n",
    "[INFO] Training model: epoch 2th 13800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0392\n",
    "[INFO] Training model: epoch 2th 13900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0391\n",
    "[INFO] Training model: epoch 2th 14000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0390\n",
    "[INFO] Training model: epoch 2th 14100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0389\n",
    "[INFO] Training model: epoch 2th 14200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0388\n",
    "[INFO] Training model: epoch 2th 14300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0387\n",
    "[INFO] Training model: epoch 2th 14400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0387\n",
    "[INFO] Training model: epoch 2th 14500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 18s 9ms/step - loss: 0.0386\n",
    "[INFO] Training model: epoch 2th 14600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 17s 8ms/step - loss: 0.0385\n",
    "[INFO] Training model: epoch 2th 14700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0384\n",
    "[INFO] Training model: epoch 2th 14800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0384\n",
    "[INFO] Training model: epoch 2th 14900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0383\n",
    "[INFO] Training model: epoch 2th 15000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0382\n",
    "[INFO] Training model: epoch 2th 15100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0381\n",
    "[INFO] Training model: epoch 2th 15200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0381\n",
    "[INFO] Training model: epoch 2th 15300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0380\n",
    "[INFO] Training model: epoch 2th 15400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0379\n",
    "[INFO] Training model: epoch 2th 15500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0379\n",
    "[INFO] Training model: epoch 2th 15600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0378\n",
    "[INFO] Training model: epoch 2th 15700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0377\n",
    "[INFO] Training model: epoch 2th 15800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0376\n",
    "[INFO] Training model: epoch 2th 15900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0376\n",
    "[INFO] Training model: epoch 2th 16000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0375\n",
    "[INFO] Training model: epoch 2th 16100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0374\n",
    "[INFO] Training model: epoch 2th 16200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0374\n",
    "[INFO] Training model: epoch 2th 16300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0373\n",
    "[INFO] Training model: epoch 2th 16400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0373\n",
    "[INFO] Training model: epoch 2th 16500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0372\n",
    "[INFO] Training model: epoch 2th 16600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0371\n",
    "[INFO] Training model: epoch 2th 16700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0371\n",
    "[INFO] Training model: epoch 2th 16800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0370\n",
    "[INFO] Training model: epoch 2th 16900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0369\n",
    "[INFO] Training model: epoch 2th 17000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0369\n",
    "[INFO] Training model: epoch 2th 17100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0368\n",
    "[INFO] Training model: epoch 2th 17200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0368\n",
    "[INFO] Training model: epoch 2th 17300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0367\n",
    "[INFO] Training model: epoch 2th 17400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0367\n",
    "[INFO] Training model: epoch 2th 17500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0366\n",
    "[INFO] Training model: epoch 2th 17600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0366\n",
    "[INFO] Training model: epoch 2th 17700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0365\n",
    "[INFO] Training model: epoch 2th 17800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0365\n",
    "[INFO] Training model: epoch 2th 17900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0364\n",
    "[INFO] Training model: epoch 2th 18000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0364\n",
    "[INFO] Training model: epoch 2th 18100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0364\n",
    "[INFO] Training model: epoch 2th 18200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0363\n",
    "[INFO] Training model: epoch 2th 18300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0363\n",
    "[INFO] Training model: epoch 2th 18400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0362\n",
    "[INFO] Training model: epoch 2th 18500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0362\n",
    "[INFO] Training model: epoch 2th 18600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0361\n",
    "[INFO] Training model: epoch 2th 18700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0361\n",
    "[INFO] Training model: epoch 2th 18800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0360\n",
    "[INFO] Training model: epoch 2th 18900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0360\n",
    "[INFO] Training model: epoch 2th 19000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0360\n",
    "[INFO] Training model: epoch 2th 19100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0359\n",
    "[INFO] Training model: epoch 2th 19200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0359\n",
    "[INFO] Training model: epoch 2th 19300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0358\n",
    "[INFO] Training model: epoch 2th 19400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0358\n",
    "[INFO] Training model: epoch 2th 19500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0357\n",
    "[INFO] Training model: epoch 2th 19600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0357\n",
    "[INFO] Training model: epoch 2th 19700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0357\n",
    "[INFO] Training model: epoch 2th 19800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0356\n",
    "[INFO] Training model: epoch 2th 19900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0356\n",
    "[INFO] Training model: epoch 2th 20000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0356\n",
    "[INFO] Training model: epoch 2th 20100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0355\n",
    "[INFO] Training model: epoch 2th 20200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0355\n",
    "[INFO] Training model: epoch 2th 20300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0355\n",
    "[INFO] Training model: epoch 2th 20400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0354\n",
    "[INFO] Training model: epoch 2th 20500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0354\n",
    "[INFO] Training model: epoch 2th 20600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0354\n",
    "[INFO] Training model: epoch 2th 20700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0353\n",
    "[INFO] Training model: epoch 2th 20800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0353\n",
    "[INFO] Training model: epoch 2th 20900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0353\n",
    "[INFO] Training model: epoch 2th 21000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0352\n",
    "[INFO] Training model: epoch 2th 21100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0352\n",
    "[INFO] Training model: epoch 2th 21200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0352\n",
    "[INFO] Training model: epoch 2th 21300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0351\n",
    "[INFO] Training model: epoch 2th 21400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0351\n",
    "[INFO] Training model: epoch 2th 21500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0351\n",
    "[INFO] Training model: epoch 2th 21600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0351\n",
    "[INFO] Training model: epoch 2th 21700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0350\n",
    "[INFO] Training model: epoch 2th 21800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0350\n",
    "[INFO] Training model: epoch 2th 21900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0350\n",
    "[INFO] Training model: epoch 2th 22000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0349\n",
    "[INFO] Training model: epoch 2th 22100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
    "[INFO] Training model: epoch 2th 22200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0349\n",
    "[INFO] Training model: epoch 2th 22300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0349\n",
    "[INFO] Training model: epoch 2th 22400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0348\n",
    "[INFO] Training model: epoch 2th 22500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0348\n",
    "[INFO] Training model: epoch 2th 22600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0348\n",
    "[INFO] Training model: epoch 2th 22700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0348\n",
    "[INFO] Training model: epoch 2th 22800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0347\n",
    "[INFO] Training model: epoch 2th 22900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
    "[INFO] Training model: epoch 2th 23000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
    "[INFO] Training model: epoch 2th 23100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0347\n",
    "[INFO] Training model: epoch 2th 23200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0346\n",
    "[INFO] Training model: epoch 2th 23300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0346\n",
    "[INFO] Training model: epoch 2th 23400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0346\n",
    "[INFO] Training model: epoch 2th 23500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0346\n",
    "[INFO] Training model: epoch 2th 23600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0345\n",
    "[INFO] Training model: epoch 2th 23700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0345\n",
    "[INFO] Training model: epoch 2th 23800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0345\n",
    "[INFO] Training model: epoch 2th 23900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0345\n",
    "[INFO] Training model: epoch 2th 24000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0344\n",
    "[INFO] Training model: epoch 2th 24600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0343\n",
    "[INFO] Training model: epoch 2th 24700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0343\n",
    "[INFO] Training model: epoch 2th 24800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0343\n",
    "[INFO] Training model: epoch 2th 24900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0343\n",
    "[INFO] Training model: epoch 2th 25000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0342\n",
    "[INFO] Training model: epoch 2th 25100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0342\n",
    "[INFO] Training model: epoch 2th 25200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0342\n",
    "[INFO] Training model: epoch 2th 25300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0342\n",
    "[INFO] Training model: epoch 2th 25400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0342\n",
    "[INFO] Training model: epoch 2th 25500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 25600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 25700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 25800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 25900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 26000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0341\n",
    "[INFO] Training model: epoch 2th 26100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0340\n",
    "[INFO] Training model: epoch 2th 26700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 26800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 26900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 27000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 27100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 27200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0339\n",
    "[INFO] Training model: epoch 2th 27300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 27900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0338\n",
    "[INFO] Training model: epoch 2th 28000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0337\n",
    "[INFO] Training model: epoch 2th 28700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 28800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 28900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0336\n",
    "[INFO] Training model: epoch 2th 29500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 29600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 29700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 29800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 29900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0335\n",
    "[INFO] Training model: epoch 2th 30600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 30700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 30800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 30900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0334\n",
    "[INFO] Training model: epoch 2th 31500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 31600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 31700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 31800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 31900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0333\n",
    "[INFO] Training model: epoch 2th 32500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 32600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 32700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 32800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 32900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0332\n",
    "[INFO] Training model: epoch 2th 33600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 33700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 33800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 33900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0331\n",
    "[INFO] Training model: epoch 2th 34900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 35900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 36000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 36100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 36200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 36300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0330\n",
    "[INFO] Training model: epoch 2th 36400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 36500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 36600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 36700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 36800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 36900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 37900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 38000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 38100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0329\n",
    "[INFO] Training model: epoch 2th 38200/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 38900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 2th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.0328\n",
    "[INFO] Training model: epoch 3th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 4.3832\n",
    "[INFO] Training model: epoch 3th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.7905\n",
    "[INFO] Training model: epoch 3th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9715\n",
    "[INFO] Training model: epoch 3th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5261\n",
    "[INFO] Training model: epoch 3th 400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2324\n",
    "[INFO] Training model: epoch 3th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.0139\n",
    "[INFO] Training model: epoch 3th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8576\n",
    "[INFO] Training model: epoch 3th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7429\n",
    "[INFO] Training model: epoch 3th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6533\n",
    "[INFO] Training model: epoch 3th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5831\n",
    "[INFO] Training model: epoch 3th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5278\n",
    "[INFO] Training model: epoch 3th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4839\n",
    "[INFO] Training model: epoch 3th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.4455\n",
    "[INFO] Training model: epoch 3th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.4175\n",
    "[INFO] Training model: epoch 3th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3906\n",
    "[INFO] Training model: epoch 3th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3701\n",
    "[INFO] Training model: epoch 3th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3553\n",
    "[INFO] Training model: epoch 3th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3402\n",
    "[INFO] Training model: epoch 3th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3252\n",
    "[INFO] Training model: epoch 3th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.3144\n",
    "[INFO] Training model: epoch 3th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.3050\n",
    "[INFO] Training model: epoch 3th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2975\n",
    "[INFO] Training model: epoch 3th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2905\n",
    "[INFO] Training model: epoch 3th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2836\n",
    "[INFO] Training model: epoch 3th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2782\n",
    "[INFO] Training model: epoch 3th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2731\n",
    "[INFO] Training model: epoch 3th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2695\n",
    "[INFO] Training model: epoch 3th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2645\n",
    "[INFO] Training model: epoch 3th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2612\n",
    "[INFO] Training model: epoch 3th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2580\n",
    "[INFO] Training model: epoch 3th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2558\n",
    "[INFO] Training model: epoch 3th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2526\n",
    "[INFO] Training model: epoch 3th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2503\n",
    "[INFO] Training model: epoch 3th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2480\n",
    "[INFO] Training model: epoch 3th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2460\n",
    "[INFO] Training model: epoch 3th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2445\n",
    "[INFO] Training model: epoch 3th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2426\n",
    "[INFO] Training model: epoch 3th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2405\n",
    "[INFO] Training model: epoch 3th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2392\n",
    "[INFO] Training model: epoch 3th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2376\n",
    "[INFO] Training model: epoch 3th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2364\n",
    "[INFO] Training model: epoch 3th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2352\n",
    "[INFO] Training model: epoch 3th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2340\n",
    "[INFO] Training model: epoch 3th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2328\n",
    "[INFO] Training model: epoch 3th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2315\n",
    "[INFO] Training model: epoch 3th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2307\n",
    "[INFO] Training model: epoch 3th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2296\n",
    "[INFO] Training model: epoch 3th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2288\n",
    "[INFO] Training model: epoch 3th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2279\n",
    "[INFO] Training model: epoch 3th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2272\n",
    "[INFO] Training model: epoch 3th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2264\n",
    "[INFO] Training model: epoch 3th 5100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2255\n",
    "[INFO] Training model: epoch 3th 5200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2248\n",
    "[INFO] Training model: epoch 3th 5300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2241\n",
    "[INFO] Training model: epoch 3th 5400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2235\n",
    "[INFO] Training model: epoch 3th 5500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2229\n",
    "[INFO] Training model: epoch 3th 5600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2223\n",
    "[INFO] Training model: epoch 3th 5700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2217\n",
    "[INFO] Training model: epoch 3th 5800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2214\n",
    "[INFO] Training model: epoch 3th 5900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2208\n",
    "[INFO] Training model: epoch 3th 6000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2203\n",
    "[INFO] Training model: epoch 3th 6100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2197\n",
    "[INFO] Training model: epoch 3th 6200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2192\n",
    "[INFO] Training model: epoch 3th 6300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2187\n",
    "[INFO] Training model: epoch 3th 6400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2184\n",
    "[INFO] Training model: epoch 3th 6500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2179\n",
    "[INFO] Training model: epoch 3th 6600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2176\n",
    "[INFO] Training model: epoch 3th 6700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2172\n",
    "[INFO] Training model: epoch 3th 6800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2169\n",
    "[INFO] Training model: epoch 3th 6900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2165\n",
    "[INFO] Training model: epoch 3th 7000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2162\n",
    "[INFO] Training model: epoch 3th 7100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2159\n",
    "[INFO] Training model: epoch 3th 7200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2155\n",
    "[INFO] Training model: epoch 3th 7300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2152\n",
    "[INFO] Training model: epoch 3th 7400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2149\n",
    "[INFO] Training model: epoch 3th 7500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2147\n",
    "[INFO] Training model: epoch 3th 7600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2144\n",
    "[INFO] Training model: epoch 3th 7700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2142\n",
    "[INFO] Training model: epoch 3th 7800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2139\n",
    "[INFO] Training model: epoch 3th 7900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2136\n",
    "[INFO] Training model: epoch 3th 8000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2134\n",
    "[INFO] Training model: epoch 3th 8100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2132\n",
    "[INFO] Training model: epoch 3th 8200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2130\n",
    "[INFO] Training model: epoch 3th 8300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2127\n",
    "[INFO] Training model: epoch 3th 8400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2125\n",
    "[INFO] Training model: epoch 3th 8500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2124\n",
    "[INFO] Training model: epoch 3th 8600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2121\n",
    "[INFO] Training model: epoch 3th 8700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2120\n",
    "[INFO] Training model: epoch 3th 8800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2118\n",
    "[INFO] Training model: epoch 3th 8900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2116\n",
    "[INFO] Training model: epoch 3th 9000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2114\n",
    "[INFO] Training model: epoch 3th 9100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2113\n",
    "[INFO] Training model: epoch 3th 9200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2111\n",
    "[INFO] Training model: epoch 3th 9300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2109\n",
    "[INFO] Training model: epoch 3th 9400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2107\n",
    "[INFO] Training model: epoch 3th 9500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2106\n",
    "[INFO] Training model: epoch 3th 9600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2104\n",
    "[INFO] Training model: epoch 3th 9700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2103\n",
    "[INFO] Training model: epoch 3th 9800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2101\n",
    "[INFO] Training model: epoch 3th 9900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2100\n",
    "[INFO] Training model: epoch 3th 10000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2101\n",
    "[INFO] Training model: epoch 3th 10100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2097\n",
    "[INFO] Training model: epoch 3th 10200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2096\n",
    "[INFO] Training model: epoch 3th 10300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2095\n",
    "[INFO] Training model: epoch 3th 10400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2093\n",
    "[INFO] Training model: epoch 3th 10500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2092\n",
    "[INFO] Training model: epoch 3th 10600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2091\n",
    "[INFO] Training model: epoch 3th 10700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2090\n",
    "[INFO] Training model: epoch 3th 10800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2089\n",
    "[INFO] Training model: epoch 3th 10900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2088\n",
    "[INFO] Training model: epoch 3th 11000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2087\n",
    "[INFO] Training model: epoch 3th 11100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2085\n",
    "[INFO] Training model: epoch 3th 11200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2084\n",
    "[INFO] Training model: epoch 3th 11300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2083\n",
    "[INFO] Training model: epoch 3th 11400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2082\n",
    "[INFO] Training model: epoch 3th 11500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2081\n",
    "[INFO] Training model: epoch 3th 11600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2081\n",
    "[INFO] Training model: epoch 3th 11700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2079\n",
    "[INFO] Training model: epoch 3th 11800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2078\n",
    "[INFO] Training model: epoch 3th 11900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2077\n",
    "[INFO] Training model: epoch 3th 12000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2077\n",
    "[INFO] Training model: epoch 3th 12100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2076\n",
    "[INFO] Training model: epoch 3th 12200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.2075\n",
    "[INFO] Training model: epoch 3th 12300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2074\n",
    "[INFO] Training model: epoch 3th 12400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2073\n",
    "[INFO] Training model: epoch 3th 12500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2072\n",
    "[INFO] Training model: epoch 3th 12600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2072\n",
    "[INFO] Training model: epoch 3th 12700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2071\n",
    "[INFO] Training model: epoch 3th 12800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2070\n",
    "[INFO] Training model: epoch 3th 12900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2070\n",
    "[INFO] Training model: epoch 3th 13000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2069\n",
    "[INFO] Training model: epoch 3th 13100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2068\n",
    "[INFO] Training model: epoch 3th 13200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2067\n",
    "[INFO] Training model: epoch 3th 13300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2067\n",
    "[INFO] Training model: epoch 3th 13400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2066\n",
    "[INFO] Training model: epoch 3th 13500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2065\n",
    "[INFO] Training model: epoch 3th 13600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2064\n",
    "[INFO] Training model: epoch 3th 13700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2064\n",
    "[INFO] Training model: epoch 3th 13800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2063\n",
    "[INFO] Training model: epoch 3th 13900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2063\n",
    "[INFO] Training model: epoch 3th 14000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2062\n",
    "[INFO] Training model: epoch 3th 14100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2061\n",
    "[INFO] Training model: epoch 3th 14200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2061\n",
    "[INFO] Training model: epoch 3th 14300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2060\n",
    "[INFO] Training model: epoch 3th 14400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2060\n",
    "[INFO] Training model: epoch 3th 14500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2059\n",
    "[INFO] Training model: epoch 3th 14600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2059\n",
    "[INFO] Training model: epoch 3th 14700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2058\n",
    "[INFO] Training model: epoch 3th 14800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2057\n",
    "[INFO] Training model: epoch 3th 14900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2057\n",
    "[INFO] Training model: epoch 3th 15000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2056\n",
    "[INFO] Training model: epoch 3th 15100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2056\n",
    "[INFO] Training model: epoch 3th 15200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2055\n",
    "[INFO] Training model: epoch 3th 15300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2055\n",
    "[INFO] Training model: epoch 3th 15400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2054\n",
    "[INFO] Training model: epoch 3th 15500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2054\n",
    "[INFO] Training model: epoch 3th 15600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2053\n",
    "[INFO] Training model: epoch 3th 15700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2053\n",
    "[INFO] Training model: epoch 3th 15800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2053\n",
    "[INFO] Training model: epoch 3th 15900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2052\n",
    "[INFO] Training model: epoch 3th 16000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2052\n",
    "[INFO] Training model: epoch 3th 16100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2051\n",
    "[INFO] Training model: epoch 3th 16200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2051\n",
    "[INFO] Training model: epoch 3th 16300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2050\n",
    "[INFO] Training model: epoch 3th 16400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2050\n",
    "[INFO] Training model: epoch 3th 16500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2050\n",
    "[INFO] Training model: epoch 3th 16600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2049\n",
    "[INFO] Training model: epoch 3th 16700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2049\n",
    "[INFO] Training model: epoch 3th 16800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
    "[INFO] Training model: epoch 3th 16900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
    "[INFO] Training model: epoch 3th 17000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2048\n",
    "[INFO] Training model: epoch 3th 17100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
    "[INFO] Training model: epoch 3th 17200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
    "[INFO] Training model: epoch 3th 17300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2047\n",
    "[INFO] Training model: epoch 3th 17400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2046\n",
    "[INFO] Training model: epoch 3th 17500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2046\n",
    "[INFO] Training model: epoch 3th 17600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
    "[INFO] Training model: epoch 3th 17700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
    "[INFO] Training model: epoch 3th 17800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2045\n",
    "[INFO] Training model: epoch 3th 17900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2044\n",
    "[INFO] Training model: epoch 3th 18000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2044\n",
    "[INFO] Training model: epoch 3th 18100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2044\n",
    "[INFO] Training model: epoch 3th 18200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
    "[INFO] Training model: epoch 3th 18300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
    "[INFO] Training model: epoch 3th 18400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2043\n",
    "[INFO] Training model: epoch 3th 18500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
    "[INFO] Training model: epoch 3th 18600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2042\n",
    "[INFO] Training model: epoch 3th 18700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
    "[INFO] Training model: epoch 3th 18800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2042\n",
    "[INFO] Training model: epoch 3th 18900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2041\n",
    "[INFO] Training model: epoch 3th 19000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
    "[INFO] Training model: epoch 3th 19100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
    "[INFO] Training model: epoch 3th 19200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2041\n",
    "[INFO] Training model: epoch 3th 19300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2040\n",
    "[INFO] Training model: epoch 3th 19400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2040\n",
    "[INFO] Training model: epoch 3th 19500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2040\n",
    "[INFO] Training model: epoch 3th 19600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2039\n",
    "[INFO] Training model: epoch 3th 19700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
    "[INFO] Training model: epoch 3th 19800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
    "[INFO] Training model: epoch 3th 19900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2039\n",
    "[INFO] Training model: epoch 3th 20000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2038\n",
    "[INFO] Training model: epoch 3th 20100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
    "[INFO] Training model: epoch 3th 20200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
    "[INFO] Training model: epoch 3th 20300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2038\n",
    "[INFO] Training model: epoch 3th 20400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2037\n",
    "[INFO] Training model: epoch 3th 20500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
    "[INFO] Training model: epoch 3th 20600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
    "[INFO] Training model: epoch 3th 20700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
    "[INFO] Training model: epoch 3th 20800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2037\n",
    "[INFO] Training model: epoch 3th 20900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
    "[INFO] Training model: epoch 3th 21000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2036\n",
    "[INFO] Training model: epoch 3th 21100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
    "[INFO] Training model: epoch 3th 21200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2036\n",
    "[INFO] Training model: epoch 3th 21300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2035\n",
    "[INFO] Training model: epoch 3th 21400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
    "[INFO] Training model: epoch 3th 21500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
    "[INFO] Training model: epoch 3th 21600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
    "[INFO] Training model: epoch 3th 21700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2035\n",
    "[INFO] Training model: epoch 3th 21800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
    "[INFO] Training model: epoch 3th 21900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
    "[INFO] Training model: epoch 3th 22000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
    "[INFO] Training model: epoch 3th 22100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
    "[INFO] Training model: epoch 3th 22200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2034\n",
    "[INFO] Training model: epoch 3th 22300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
    "[INFO] Training model: epoch 3th 22400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
    "[INFO] Training model: epoch 3th 22500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2033\n",
    "[INFO] Training model: epoch 3th 22600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2033\n",
    "[INFO] Training model: epoch 3th 22700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2033\n",
    "[INFO] Training model: epoch 3th 22800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 22900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 23000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 23100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 23200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 23300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2032\n",
    "[INFO] Training model: epoch 3th 23400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 23500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 23600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 23700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 23800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 23900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 24000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2031\n",
    "[INFO] Training model: epoch 3th 24100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2030\n",
    "[INFO] Training model: epoch 3th 24800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 24900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2029\n",
    "[INFO] Training model: epoch 3th 25500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 25600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 25700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 25800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 25900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 26000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 26100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 26200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2028\n",
    "[INFO] Training model: epoch 3th 26300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 26900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 27000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 27100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2027\n",
    "[INFO] Training model: epoch 3th 27200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
    "[INFO] Training model: epoch 3th 27300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
    "[INFO] Training model: epoch 3th 27400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2026\n",
    "[INFO] Training model: epoch 3th 27500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.2000\n",
    "[INFO] Training model: epoch 3th 27600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1978\n",
    "[INFO] Training model: epoch 3th 27700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1952\n",
    "[INFO] Training model: epoch 3th 27800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1947\n",
    "[INFO] Training model: epoch 3th 27900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
    "[INFO] Training model: epoch 3th 28000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
    "[INFO] Training model: epoch 3th 28100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1946\n",
    "[INFO] Training model: epoch 3th 28200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1945\n",
    "[INFO] Training model: epoch 3th 28800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 28900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1944\n",
    "[INFO] Training model: epoch 3th 29700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 29800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 29900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1943\n",
    "[INFO] Training model: epoch 3th 30900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 31900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 32000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 32100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 32200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1942\n",
    "[INFO] Training model: epoch 3th 32300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 32900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 33900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1941\n",
    "[INFO] Training model: epoch 3th 34000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 34900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 35900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1940\n",
    "[INFO] Training model: epoch 3th 36000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 36900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 37900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 38000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 38100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 38200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 38300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1939\n",
    "[INFO] Training model: epoch 3th 38400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 38500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 38600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 38700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 38800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 38900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 3th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.1938\n",
    "[INFO] Training model: epoch 4th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 4.2757\n",
    "[INFO] Training model: epoch 4th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.0279\n",
    "[INFO] Training model: epoch 4th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 2.2302\n",
    "[INFO] Training model: epoch 4th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.7639\n",
    "[INFO] Training model: epoch 4th 400/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.4405\n",
    "[INFO] Training model: epoch 4th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.2107\n",
    "[INFO] Training model: epoch 4th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0591\n",
    "[INFO] Training model: epoch 4th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9443\n",
    "[INFO] Training model: epoch 4th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8729\n",
    "[INFO] Training model: epoch 4th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8091\n",
    "[INFO] Training model: epoch 4th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7665\n",
    "[INFO] Training model: epoch 4th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7336\n",
    "[INFO] Training model: epoch 4th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7080\n",
    "[INFO] Training model: epoch 4th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6881\n",
    "[INFO] Training model: epoch 4th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6741\n",
    "[INFO] Training model: epoch 4th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6622\n",
    "[INFO] Training model: epoch 4th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6519\n",
    "[INFO] Training model: epoch 4th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6436\n",
    "[INFO] Training model: epoch 4th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6366\n",
    "[INFO] Training model: epoch 4th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6305\n",
    "[INFO] Training model: epoch 4th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6255\n",
    "[INFO] Training model: epoch 4th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6220\n",
    "[INFO] Training model: epoch 4th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6186\n",
    "[INFO] Training model: epoch 4th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6152\n",
    "[INFO] Training model: epoch 4th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6120\n",
    "[INFO] Training model: epoch 4th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6098\n",
    "[INFO] Training model: epoch 4th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6080\n",
    "[INFO] Training model: epoch 4th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6060\n",
    "[INFO] Training model: epoch 4th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6037\n",
    "[INFO] Training model: epoch 4th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6022\n",
    "[INFO] Training model: epoch 4th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6010\n",
    "[INFO] Training model: epoch 4th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5993\n",
    "[INFO] Training model: epoch 4th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5981\n",
    "[INFO] Training model: epoch 4th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5972\n",
    "[INFO] Training model: epoch 4th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5959\n",
    "[INFO] Training model: epoch 4th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5951\n",
    "[INFO] Training model: epoch 4th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5943\n",
    "[INFO] Training model: epoch 4th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5933\n",
    "[INFO] Training model: epoch 4th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5926\n",
    "[INFO] Training model: epoch 4th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5918\n",
    "[INFO] Training model: epoch 4th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5912\n",
    "[INFO] Training model: epoch 4th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5906\n",
    "[INFO] Training model: epoch 4th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5899\n",
    "[INFO] Training model: epoch 4th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5893\n",
    "[INFO] Training model: epoch 4th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5888\n",
    "[INFO] Training model: epoch 4th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5883\n",
    "[INFO] Training model: epoch 4th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5879\n",
    "[INFO] Training model: epoch 4th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5874\n",
    "[INFO] Training model: epoch 4th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5869\n",
    "[INFO] Training model: epoch 4th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5865\n",
    "[INFO] Training model: epoch 4th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5861\n",
    "[INFO] Training model: epoch 4th 5100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5858\n",
    "[INFO] Training model: epoch 4th 5200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5853\n",
    "[INFO] Training model: epoch 4th 5300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5851\n",
    "[INFO] Training model: epoch 4th 5400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5847\n",
    "[INFO] Training model: epoch 4th 5500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5844\n",
    "[INFO] Training model: epoch 4th 5600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5841\n",
    "[INFO] Training model: epoch 4th 5700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5839\n",
    "[INFO] Training model: epoch 4th 5800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5836\n",
    "[INFO] Training model: epoch 4th 5900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5833\n",
    "[INFO] Training model: epoch 4th 6000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5830\n",
    "[INFO] Training model: epoch 4th 6100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5828\n",
    "[INFO] Training model: epoch 4th 6200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5826\n",
    "[INFO] Training model: epoch 4th 6300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5824\n",
    "[INFO] Training model: epoch 4th 6400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5822\n",
    "[INFO] Training model: epoch 4th 6500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5820\n",
    "[INFO] Training model: epoch 4th 6600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5817\n",
    "[INFO] Training model: epoch 4th 6700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5815\n",
    "[INFO] Training model: epoch 4th 6800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5813\n",
    "[INFO] Training model: epoch 4th 6900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5811\n",
    "[INFO] Training model: epoch 4th 7000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5810\n",
    "[INFO] Training model: epoch 4th 7100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5808\n",
    "[INFO] Training model: epoch 4th 7200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5806\n",
    "[INFO] Training model: epoch 4th 7300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5804\n",
    "[INFO] Training model: epoch 4th 7400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5803\n",
    "[INFO] Training model: epoch 4th 7500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5802\n",
    "[INFO] Training model: epoch 4th 7600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5800\n",
    "[INFO] Training model: epoch 4th 7700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5798\n",
    "[INFO] Training model: epoch 4th 7800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5797\n",
    "[INFO] Training model: epoch 4th 7900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5795\n",
    "[INFO] Training model: epoch 4th 8000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5794\n",
    "[INFO] Training model: epoch 4th 8100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5793\n",
    "[INFO] Training model: epoch 4th 8200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5792\n",
    "[INFO] Training model: epoch 4th 8300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5790\n",
    "[INFO] Training model: epoch 4th 8400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5789\n",
    "[INFO] Training model: epoch 4th 8500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5788\n",
    "[INFO] Training model: epoch 4th 8600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5787\n",
    "[INFO] Training model: epoch 4th 8700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5786\n",
    "[INFO] Training model: epoch 4th 8800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5785\n",
    "[INFO] Training model: epoch 4th 8900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5784\n",
    "[INFO] Training model: epoch 4th 9000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5783\n",
    "[INFO] Training model: epoch 4th 9100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5782\n",
    "[INFO] Training model: epoch 4th 9200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5781\n",
    "[INFO] Training model: epoch 4th 9300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5780\n",
    "[INFO] Training model: epoch 4th 9400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5779\n",
    "[INFO] Training model: epoch 4th 9500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5778\n",
    "[INFO] Training model: epoch 4th 9600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5777\n",
    "[INFO] Training model: epoch 4th 9700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5776\n",
    "[INFO] Training model: epoch 4th 9800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5775\n",
    "[INFO] Training model: epoch 4th 9900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5775\n",
    "[INFO] Training model: epoch 4th 10000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5774\n",
    "[INFO] Training model: epoch 4th 10100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5773\n",
    "[INFO] Training model: epoch 4th 10200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5772\n",
    "[INFO] Training model: epoch 4th 10300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5771\n",
    "[INFO] Training model: epoch 4th 10400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5771\n",
    "[INFO] Training model: epoch 4th 10500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5770\n",
    "[INFO] Training model: epoch 4th 10600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5769\n",
    "[INFO] Training model: epoch 4th 10700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5768\n",
    "[INFO] Training model: epoch 4th 10800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5768\n",
    "[INFO] Training model: epoch 4th 10900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5767\n",
    "[INFO] Training model: epoch 4th 11000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5766\n",
    "[INFO] Training model: epoch 4th 11100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5766\n",
    "[INFO] Training model: epoch 4th 11200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5765\n",
    "[INFO] Training model: epoch 4th 11300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5765\n",
    "[INFO] Training model: epoch 4th 11400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5764\n",
    "[INFO] Training model: epoch 4th 11500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5763\n",
    "[INFO] Training model: epoch 4th 11600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5763\n",
    "[INFO] Training model: epoch 4th 11700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5762\n",
    "[INFO] Training model: epoch 4th 11800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5762\n",
    "[INFO] Training model: epoch 4th 11900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5761\n",
    "[INFO] Training model: epoch 4th 12000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5760\n",
    "[INFO] Training model: epoch 4th 12100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5760\n",
    "[INFO] Training model: epoch 4th 12200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5759\n",
    "[INFO] Training model: epoch 4th 12300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5759\n",
    "[INFO] Training model: epoch 4th 12400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5758\n",
    "[INFO] Training model: epoch 4th 12500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5758\n",
    "[INFO] Training model: epoch 4th 12600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5757\n",
    "[INFO] Training model: epoch 4th 12700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5758\n",
    "[INFO] Training model: epoch 4th 12800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5757\n",
    "[INFO] Training model: epoch 4th 12900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5756\n",
    "[INFO] Training model: epoch 4th 13000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5756\n",
    "[INFO] Training model: epoch 4th 13100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5755\n",
    "[INFO] Training model: epoch 4th 13200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5755\n",
    "[INFO] Training model: epoch 4th 13300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5754\n",
    "[INFO] Training model: epoch 4th 13400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5754\n",
    "[INFO] Training model: epoch 4th 13500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5753\n",
    "[INFO] Training model: epoch 4th 13600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5753\n",
    "[INFO] Training model: epoch 4th 13700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5753\n",
    "[INFO] Training model: epoch 4th 13800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5752\n",
    "[INFO] Training model: epoch 4th 13900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5752\n",
    "[INFO] Training model: epoch 4th 14000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5752\n",
    "[INFO] Training model: epoch 4th 14100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5751\n",
    "[INFO] Training model: epoch 4th 14200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5751\n",
    "[INFO] Training model: epoch 4th 14300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5751\n",
    "[INFO] Training model: epoch 4th 14400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5750\n",
    "[INFO] Training model: epoch 4th 14500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5750\n",
    "[INFO] Training model: epoch 4th 14600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5749\n",
    "[INFO] Training model: epoch 4th 14700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5749\n",
    "[INFO] Training model: epoch 4th 14800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5749\n",
    "[INFO] Training model: epoch 4th 14900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5748\n",
    "[INFO] Training model: epoch 4th 15000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5748\n",
    "[INFO] Training model: epoch 4th 15100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5748\n",
    "[INFO] Training model: epoch 4th 15200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5748\n",
    "[INFO] Training model: epoch 4th 15300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5747\n",
    "[INFO] Training model: epoch 4th 15400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5747\n",
    "[INFO] Training model: epoch 4th 15500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5747\n",
    "[INFO] Training model: epoch 4th 15600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5746\n",
    "[INFO] Training model: epoch 4th 15700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5746\n",
    "[INFO] Training model: epoch 4th 15800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5746\n",
    "[INFO] Training model: epoch 4th 15900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5745\n",
    "[INFO] Training model: epoch 4th 16000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5745\n",
    "[INFO] Training model: epoch 4th 16100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5745\n",
    "[INFO] Training model: epoch 4th 16200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5745\n",
    "[INFO] Training model: epoch 4th 16300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5744\n",
    "[INFO] Training model: epoch 4th 16400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5744\n",
    "[INFO] Training model: epoch 4th 16500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5744\n",
    "[INFO] Training model: epoch 4th 16600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5744\n",
    "[INFO] Training model: epoch 4th 16700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5743\n",
    "[INFO] Training model: epoch 4th 16800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5743\n",
    "[INFO] Training model: epoch 4th 16900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5743\n",
    "[INFO] Training model: epoch 4th 17000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5743\n",
    "[INFO] Training model: epoch 4th 17100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
    "[INFO] Training model: epoch 4th 17200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
    "[INFO] Training model: epoch 4th 17300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5742\n",
    "[INFO] Training model: epoch 4th 17400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5742\n",
    "[INFO] Training model: epoch 4th 17500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5742\n",
    "[INFO] Training model: epoch 4th 17600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5741\n",
    "[INFO] Training model: epoch 4th 17700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5741\n",
    "[INFO] Training model: epoch 4th 17800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5741\n",
    "[INFO] Training model: epoch 4th 17900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5741\n",
    "[INFO] Training model: epoch 4th 18000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5740\n",
    "[INFO] Training model: epoch 4th 18600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5739\n",
    "[INFO] Training model: epoch 4th 18700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5739\n",
    "[INFO] Training model: epoch 4th 18800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5739\n",
    "[INFO] Training model: epoch 4th 18900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5739\n",
    "[INFO] Training model: epoch 4th 19000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5739\n",
    "[INFO] Training model: epoch 4th 19100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5738\n",
    "[INFO] Training model: epoch 4th 19700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 19800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 19900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 20000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 20100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 20200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 20300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5737\n",
    "[INFO] Training model: epoch 4th 20400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 20500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 20600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 20700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 20800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 20900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5736\n",
    "[INFO] Training model: epoch 4th 21000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5735\n",
    "[INFO] Training model: epoch 4th 21800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 21900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5734\n",
    "[INFO] Training model: epoch 4th 22600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 22700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 22800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 22900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5733\n",
    "[INFO] Training model: epoch 4th 23600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 23700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 23800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 23900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5732\n",
    "[INFO] Training model: epoch 4th 24600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 24700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 24800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 24900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5731\n",
    "[INFO] Training model: epoch 4th 25800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 25900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 26900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 27000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5730\n",
    "[INFO] Training model: epoch 4th 27100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 27900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5729\n",
    "[INFO] Training model: epoch 4th 28700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 28800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 28900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 29900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5728\n",
    "[INFO] Training model: epoch 4th 30500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 30600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 30700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 30800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 30900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 31900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5727\n",
    "[INFO] Training model: epoch 4th 32700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 32800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 32900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 33900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 34900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 35000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 35100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 35200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 35300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5726\n",
    "[INFO] Training model: epoch 4th 35400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 35500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 35600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 35700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 35800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 35900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36500/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 36900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 37900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 38900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 39000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 39100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5725\n",
    "[INFO] Training model: epoch 4th 39200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 4th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.5724\n",
    "[INFO] Training model: epoch 5th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 4.5747\n",
    "[INFO] Training model: epoch 5th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.5030\n",
    "[INFO] Training model: epoch 5th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 2.6280\n",
    "[INFO] Training model: epoch 5th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.9808\n",
    "[INFO] Training model: epoch 5th 400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.5904\n",
    "[INFO] Training model: epoch 5th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.3163\n",
    "[INFO] Training model: epoch 5th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.1409\n",
    "[INFO] Training model: epoch 5th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0266\n",
    "[INFO] Training model: epoch 5th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9519\n",
    "[INFO] Training model: epoch 5th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.8980\n",
    "[INFO] Training model: epoch 5th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.8545\n",
    "[INFO] Training model: epoch 5th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.8240\n",
    "[INFO] Training model: epoch 5th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7974\n",
    "[INFO] Training model: epoch 5th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7797\n",
    "[INFO] Training model: epoch 5th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7650\n",
    "[INFO] Training model: epoch 5th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.7540\n",
    "[INFO] Training model: epoch 5th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7446\n",
    "[INFO] Training model: epoch 5th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7357\n",
    "[INFO] Training model: epoch 5th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7291\n",
    "[INFO] Training model: epoch 5th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7235\n",
    "[INFO] Training model: epoch 5th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7190\n",
    "[INFO] Training model: epoch 5th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7149\n",
    "[INFO] Training model: epoch 5th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7118\n",
    "[INFO] Training model: epoch 5th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7084\n",
    "[INFO] Training model: epoch 5th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7053\n",
    "[INFO] Training model: epoch 5th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.7031\n",
    "\n",
    "[INFO] Training model: epoch 5th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.7010\n",
    "[INFO] Training model: epoch 5th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6989\n",
    "[INFO] Training model: epoch 5th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6973\n",
    "[INFO] Training model: epoch 5th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6957\n",
    "[INFO] Training model: epoch 5th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6944\n",
    "[INFO] Training model: epoch 5th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6930\n",
    "[INFO] Training model: epoch 5th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6921\n",
    "[INFO] Training model: epoch 5th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6910\n",
    "[INFO] Training model: epoch 5th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6899\n",
    "[INFO] Training model: epoch 5th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6891\n",
    "[INFO] Training model: epoch 5th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6883\n",
    "[INFO] Training model: epoch 5th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6875\n",
    "[INFO] Training model: epoch 5th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6868\n",
    "[INFO] Training model: epoch 5th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6861\n",
    "[INFO] Training model: epoch 5th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6856\n",
    "[INFO] Training model: epoch 5th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6851\n",
    "[INFO] Training model: epoch 5th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6846\n",
    "[INFO] Training model: epoch 5th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6839\n",
    "[INFO] Training model: epoch 5th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6835\n",
    "[INFO] Training model: epoch 5th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6830\n",
    "[INFO] Training model: epoch 5th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6826\n",
    "[INFO] Training model: epoch 5th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6822\n",
    "[INFO] Training model: epoch 5th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6818\n",
    "[INFO] Training model: epoch 5th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6814\n",
    "[INFO] Training model: epoch 5th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6811\n",
    "[INFO] Training model: epoch 5th 5100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6807\n",
    "[INFO] Training model: epoch 5th 5200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6804\n",
    "[INFO] Training model: epoch 5th 5300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6801\n",
    "[INFO] Training model: epoch 5th 5400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6798\n",
    "[INFO] Training model: epoch 5th 5500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6795\n",
    "[INFO] Training model: epoch 5th 5600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6792\n",
    "[INFO] Training model: epoch 5th 5700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6790\n",
    "[INFO] Training model: epoch 5th 5800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6788\n",
    "[INFO] Training model: epoch 5th 5900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6785\n",
    "[INFO] Training model: epoch 5th 6000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6783\n",
    "[INFO] Training model: epoch 5th 6100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6781\n",
    "[INFO] Training model: epoch 5th 6200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6779\n",
    "[INFO] Training model: epoch 5th 6300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6777\n",
    "[INFO] Training model: epoch 5th 6400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6775\n",
    "[INFO] Training model: epoch 5th 6500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6773\n",
    "[INFO] Training model: epoch 5th 6600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6771\n",
    "[INFO] Training model: epoch 5th 6700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6769\n",
    "[INFO] Training model: epoch 5th 6800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6768\n",
    "[INFO] Training model: epoch 5th 6900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6766\n",
    "[INFO] Training model: epoch 5th 7000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6765\n",
    "[INFO] Training model: epoch 5th 7100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6763\n",
    "[INFO] Training model: epoch 5th 7200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6762\n",
    "[INFO] Training model: epoch 5th 7300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6760\n",
    "[INFO] Training model: epoch 5th 7400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6759\n",
    "[INFO] Training model: epoch 5th 7500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6757\n",
    "[INFO] Training model: epoch 5th 7600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6756\n",
    "[INFO] Training model: epoch 5th 7700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6755\n",
    "[INFO] Training model: epoch 5th 7800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6754\n",
    "[INFO] Training model: epoch 5th 7900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6752\n",
    "[INFO] Training model: epoch 5th 8000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6751\n",
    "[INFO] Training model: epoch 5th 8100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6750\n",
    "[INFO] Training model: epoch 5th 8200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6749\n",
    "[INFO] Training model: epoch 5th 8300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6748\n",
    "[INFO] Training model: epoch 5th 8400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6747\n",
    "[INFO] Training model: epoch 5th 8500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6746\n",
    "[INFO] Training model: epoch 5th 8600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6745\n",
    "[INFO] Training model: epoch 5th 8700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6744\n",
    "[INFO] Training model: epoch 5th 8800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6743\n",
    "[INFO] Training model: epoch 5th 8900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6742\n",
    "[INFO] Training model: epoch 5th 9000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6742\n",
    "[INFO] Training model: epoch 5th 9100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6741\n",
    "[INFO] Training model: epoch 5th 9200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6740\n",
    "[INFO] Training model: epoch 5th 9300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6739\n",
    "[INFO] Training model: epoch 5th 9400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6738\n",
    "[INFO] Training model: epoch 5th 9500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6737\n",
    "[INFO] Training model: epoch 5th 9600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6737\n",
    "[INFO] Training model: epoch 5th 9700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6736\n",
    "[INFO] Training model: epoch 5th 9800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6735\n",
    "[INFO] Training model: epoch 5th 9900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6735\n",
    "[INFO] Training model: epoch 5th 10000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6734\n",
    "[INFO] Training model: epoch 5th 10100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6733\n",
    "[INFO] Training model: epoch 5th 10200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6733\n",
    "[INFO] Training model: epoch 5th 10300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6732\n",
    "[INFO] Training model: epoch 5th 10400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6731\n",
    "[INFO] Training model: epoch 5th 10500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6731\n",
    "[INFO] Training model: epoch 5th 10600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6730\n",
    "[INFO] Training model: epoch 5th 10700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6730\n",
    "[INFO] Training model: epoch 5th 10800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6729\n",
    "[INFO] Training model: epoch 5th 10900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6729\n",
    "[INFO] Training model: epoch 5th 11000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6728\n",
    "[INFO] Training model: epoch 5th 11100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6727\n",
    "[INFO] Training model: epoch 5th 11200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6727\n",
    "[INFO] Training model: epoch 5th 11300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6726\n",
    "[INFO] Training model: epoch 5th 11400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6726\n",
    "[INFO] Training model: epoch 5th 11500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6725\n",
    "[INFO] Training model: epoch 5th 11600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6725\n",
    "[INFO] Training model: epoch 5th 11700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6724\n",
    "[INFO] Training model: epoch 5th 11800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6724\n",
    "[INFO] Training model: epoch 5th 11900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6724\n",
    "[INFO] Training model: epoch 5th 12000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6723\n",
    "[INFO] Training model: epoch 5th 12100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6723\n",
    "[INFO] Training model: epoch 5th 12200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6722\n",
    "[INFO] Training model: epoch 5th 12300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6722\n",
    "[INFO] Training model: epoch 5th 12400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6721\n",
    "[INFO] Training model: epoch 5th 12500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6721\n",
    "[INFO] Training model: epoch 5th 12600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6720\n",
    "[INFO] Training model: epoch 5th 12700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6720\n",
    "[INFO] Training model: epoch 5th 12800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6720\n",
    "[INFO] Training model: epoch 5th 12900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6719\n",
    "[INFO] Training model: epoch 5th 13000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6719\n",
    "[INFO] Training model: epoch 5th 13100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6719\n",
    "[INFO] Training model: epoch 5th 13200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6718\n",
    "[INFO] Training model: epoch 5th 13300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6718\n",
    "[INFO] Training model: epoch 5th 13400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6717\n",
    "[INFO] Training model: epoch 5th 13500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6717\n",
    "[INFO] Training model: epoch 5th 13600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6717\n",
    "[INFO] Training model: epoch 5th 13700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6716\n",
    "[INFO] Training model: epoch 5th 13800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6716\n",
    "[INFO] Training model: epoch 5th 13900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6716\n",
    "[INFO] Training model: epoch 5th 14000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6715\n",
    "[INFO] Training model: epoch 5th 14100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6715\n",
    "[INFO] Training model: epoch 5th 14200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6715\n",
    "[INFO] Training model: epoch 5th 14300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
    "[INFO] Training model: epoch 5th 14400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
    "[INFO] Training model: epoch 5th 14500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
    "[INFO] Training model: epoch 5th 14600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6714\n",
    "[INFO] Training model: epoch 5th 14700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
    "[INFO] Training model: epoch 5th 14800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
    "[INFO] Training model: epoch 5th 14900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6713\n",
    "[INFO] Training model: epoch 5th 15000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6712\n",
    "[INFO] Training model: epoch 5th 15100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
    "[INFO] Training model: epoch 5th 15200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
    "[INFO] Training model: epoch 5th 15300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6712\n",
    "[INFO] Training model: epoch 5th 15400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
    "[INFO] Training model: epoch 5th 15500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
    "[INFO] Training model: epoch 5th 15600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
    "[INFO] Training model: epoch 5th 15700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6711\n",
    "[INFO] Training model: epoch 5th 15800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6710\n",
    "[INFO] Training model: epoch 5th 15900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6710\n",
    "[INFO] Training model: epoch 5th 16000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6710\n",
    "[INFO] Training model: epoch 5th 16100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6710\n",
    "[INFO] Training model: epoch 5th 16200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
    "[INFO] Training model: epoch 5th 16300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
    "[INFO] Training model: epoch 5th 16400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
    "[INFO] Training model: epoch 5th 16500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
    "[INFO] Training model: epoch 5th 16600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6709\n",
    "[INFO] Training model: epoch 5th 16700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
    "[INFO] Training model: epoch 5th 16800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
    "[INFO] Training model: epoch 5th 16900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
    "[INFO] Training model: epoch 5th 17000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6708\n",
    "[INFO] Training model: epoch 5th 17100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6708\n",
    "[INFO] Training model: epoch 5th 17200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
    "[INFO] Training model: epoch 5th 17300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
    "[INFO] Training model: epoch 5th 17400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6707\n",
    "[INFO] Training model: epoch 5th 17500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
    "[INFO] Training model: epoch 5th 17600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6707\n",
    "[INFO] Training model: epoch 5th 17700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 17800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 17900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 18000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 18100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 18200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6706\n",
    "[INFO] Training model: epoch 5th 18300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6705\n",
    "[INFO] Training model: epoch 5th 18900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6704\n",
    "[INFO] Training model: epoch 5th 19600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 19700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 19800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 19900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 20000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 20100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6703\n",
    "[INFO] Training model: epoch 5th 20200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 20900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6702\n",
    "[INFO] Training model: epoch 5th 21000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6701\n",
    "[INFO] Training model: epoch 5th 21800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 21900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6700\n",
    "[INFO] Training model: epoch 5th 22800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 22900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6699\n",
    "[INFO] Training model: epoch 5th 23900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 24900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 25000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6698\n",
    "[INFO] Training model: epoch 5th 25100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 25900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 26000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 26100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 26200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 26300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6697\n",
    "[INFO] Training model: epoch 5th 26400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 26500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 26600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 26700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 26800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 26900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 27900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6696\n",
    "[INFO] Training model: epoch 5th 28000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 28900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 29900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6695\n",
    "[INFO] Training model: epoch 5th 30000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 30900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 31900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 32000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 32100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 32200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6694\n",
    "[INFO] Training model: epoch 5th 32300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 32900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 33900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 34900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 35000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 35100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6693\n",
    "[INFO] Training model: epoch 5th 35200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 35900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 36900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 37900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38600/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 17s 9ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 38900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 39000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 39100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 39200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6692\n",
    "[INFO] Training model: epoch 5th 39300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 5th 39900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.6691\n",
    "[INFO] Training model: epoch 6th 0/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 4.5190\n",
    "[INFO] Training model: epoch 6th 100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 3.2467\n",
    "[INFO] Training model: epoch 6th 200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 2.3786\n",
    "[INFO] Training model: epoch 6th 300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.9020\n",
    "[INFO] Training model: epoch 6th 400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.5864\n",
    "[INFO] Training model: epoch 6th 500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.3882\n",
    "[INFO] Training model: epoch 6th 600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.2605\n",
    "[INFO] Training model: epoch 6th 700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.1820\n",
    "[INFO] Training model: epoch 6th 800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.1270\n",
    "[INFO] Training model: epoch 6th 900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0886\n",
    "[INFO] Training model: epoch 6th 1000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 1.0620\n",
    "[INFO] Training model: epoch 6th 1100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0440\n",
    "[INFO] Training model: epoch 6th 1200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0306\n",
    "[INFO] Training model: epoch 6th 1300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 1.0197\n",
    "[INFO] Training model: epoch 6th 1400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 1.0109\n",
    "[INFO] Training model: epoch 6th 1500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 1.0038\n",
    "[INFO] Training model: epoch 6th 1600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9987\n",
    "[INFO] Training model: epoch 6th 1700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9942\n",
    "[INFO] Training model: epoch 6th 1800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9906\n",
    "[INFO] Training model: epoch 6th 1900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9873\n",
    "[INFO] Training model: epoch 6th 2000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9845\n",
    "[INFO] Training model: epoch 6th 2100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9825\n",
    "[INFO] Training model: epoch 6th 2200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9801\n",
    "[INFO] Training model: epoch 6th 2300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9783\n",
    "[INFO] Training model: epoch 6th 2400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9767\n",
    "[INFO] Training model: epoch 6th 2500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9753\n",
    "[INFO] Training model: epoch 6th 2600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9740\n",
    "[INFO] Training model: epoch 6th 2700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9728\n",
    "[INFO] Training model: epoch 6th 2800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9719\n",
    "[INFO] Training model: epoch 6th 2900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9707\n",
    "[INFO] Training model: epoch 6th 3000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9699\n",
    "[INFO] Training model: epoch 6th 3100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9691\n",
    "[INFO] Training model: epoch 6th 3200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9684\n",
    "[INFO] Training model: epoch 6th 3300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9676\n",
    "[INFO] Training model: epoch 6th 3400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9670\n",
    "[INFO] Training model: epoch 6th 3500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9663\n",
    "[INFO] Training model: epoch 6th 3600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9658\n",
    "[INFO] Training model: epoch 6th 3700/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9653\n",
    "[INFO] Training model: epoch 6th 3800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9648\n",
    "[INFO] Training model: epoch 6th 3900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9643\n",
    "[INFO] Training model: epoch 6th 4000/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9639\n",
    "[INFO] Training model: epoch 6th 4100/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9634\n",
    "[INFO] Training model: epoch 6th 4200/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9630\n",
    "[INFO] Training model: epoch 6th 4300/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9627\n",
    "[INFO] Training model: epoch 6th 4400/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9623\n",
    "[INFO] Training model: epoch 6th 4500/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 16s 8ms/step - loss: 0.9620\n",
    "[INFO] Training model: epoch 6th 4600/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9617\n",
    "[INFO] Training model: epoch 6th 4700/40000 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2000/2000 [==============================] - 15s 7ms/step - loss: 0.9613\n",
    "[INFO] Training model: epoch 6th 4800/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 15s 8ms/step - loss: 0.9611\n",
    "[INFO] Training model: epoch 6th 4900/40000 samples\n",
    "Epoch 1/1\n",
    "2000/2000 [==============================] - 14s 7ms/step - loss: 0.9608\n",
    "[INFO] Training model: epoch 6th 5000/40000 samples\n",
    "Epoch 1/1\n",
    "1792/2000 [=========================>....] - ETA: 1s - loss: 0.9810\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up dictionary to translate indices to words\n",
    "y_dictionary = dict(\n",
    "            (i, char) for char, i in t_title.word_index.items()\n",
    "        )\n",
    "\n",
    "x_dictionary = dict(\n",
    "            (i, char) for char, i in t_claim.word_index.items()\n",
    "        )\n",
    "\n",
    "def seq2text(seq, dictionary):\n",
    "    text = ''\n",
    "    for k in seq:\n",
    "        k = k.astype(int)\n",
    "        if k > 0 and k < (len(dictionary)-1):\n",
    "            w = dictionary[k]\n",
    "            text = text + w + ' '\n",
    "    return text\n",
    "\n",
    "def greedy_decoder(X_seq):\n",
    "    # reformat input seq\n",
    "    input_seq = np.zeros((1, X_max_len))\n",
    "    input_seq[0, :] = X_seq\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1, y_max_len))\n",
    "    ans_partial[0, -1] = 1  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(y_max_len - 1):\n",
    "        ye = model.predict([input_seq, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == 2:  #  the index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = seq2text(ans_partial[0], y_dictionary)\n",
    "    return(text, prob)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can test on X_test and Y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 10):\n",
    "    text, prob = greedy_decoder(X_test[i])\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {} (with prob {}). \\n Test title is: {} \\n---\\n\".format(text, prob, Y_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'Dot'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-2f6d2edceb2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mplot_model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mplot_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mplot_model\u001b[0;34m(model, to_file, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m    133\u001b[0m             \u001b[0;34m'LR'\u001b[0m \u001b[0mcreates\u001b[0m \u001b[0ma\u001b[0m \u001b[0mhorizontal\u001b[0m \u001b[0mplot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     \"\"\"\n\u001b[0;32m--> 135\u001b[0;31m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_layer_names\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m     \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mextension\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpath\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msplitext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mto_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    137\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mextension\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils import plot_model\n",
    "\n",
    "plot_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model below needs to be adapted based on the tests above."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Need to adapt this based on the model above\n",
    "\n",
    "class ModelWrapper:\n",
    "    \n",
    "    def __init__(\n",
    "        self, \n",
    "        seqin_dict,\n",
    "        seqout_dict,\n",
    "        seqin_max_len=300, \n",
    "        seqout_max_len=20, \n",
    "        seqin_vocab_len=10000, \n",
    "        seqout_vocab_len=5000,\n",
    "        hidden_size=100,\n",
    "        filepath=\"weights-best.hdf5\"\n",
    "    ):\n",
    "        \"\"\" Initialise.\"\"\"\n",
    "        self.filepath = filepath\n",
    "        self.batch_size = 64\n",
    "        self.seqin_max_len = seqin_max_len\n",
    "        self.seqout_max_len = seqout_max_len\n",
    "        self.seqin_vocab_len = seqin_vocab_len\n",
    "        self.seqout_vocab_len = seqout_vocab_len\n",
    "        self.hidden_size = hidden_size\n",
    "        \n",
    "        self.target_char_index = seqout_dict\n",
    "        # Generate a reverse dictionary for our title characters\n",
    "        self.reverse_target_char_index = dict(\n",
    "            (i, char) for char, i in seqin_dict.items()\n",
    "        )\n",
    "        self.input_char_index = seqout_dict\n",
    "        # Generate a reverse dictionary for our title characters\n",
    "        self.reverse_input_char_index = dict(\n",
    "            (i, char) for char, i in seqout_dict.items()\n",
    "        )\n",
    "        self.build_model()\n",
    "    \n",
    "    def build_model(self, print_summary=False):\n",
    "        \"\"\" Build keras model.\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def load_weights(self):\n",
    "        try:\n",
    "            # load weights\n",
    "            self.model.load_weights(self.filepath)\n",
    "            print(\"Loaded weights\")\n",
    "        except:\n",
    "            print(\"No existing weights found\")\n",
    "        \n",
    "    def print_summary(self):\n",
    "        \"\"\" Print model summary.\"\"\"\n",
    "        print(\"Training Model:\\n\")\n",
    "        print(self.model.summary())\n",
    "               \n",
    "    def to_one_hot(self, output_seq):\n",
    "        \"\"\" Convert a sequence of integers to a sequence of one-hot vectors.\"\"\"\n",
    "        one_hot_out = np.zeros((len(output_seq), self.seqout_max_len, self.seqout_vocab_len))\n",
    "        for i, sequence in enumerate(output_seq):\n",
    "            for t, word_int in enumerate(sequence):\n",
    "                one_hot_out[i, t, word_int] = 1\n",
    "                if t > 0:\n",
    "                    # Shift decoder target get so it is one ahead\n",
    "                    one_hot_out[i, t-1, word_int] = 1\n",
    "        return one_hot_out\n",
    "        \n",
    "    def train(self, epochs, X, Y):\n",
    "        \"\"\" Train the Training Model.\"\"\"\n",
    "        pass\n",
    "        \n",
    "    def sample(self, preds, temperature=1.0):\n",
    "        # helper function to sample an index from a probability array\n",
    "        preds = np.asarray(preds).astype('float64')\n",
    "        preds = np.log(preds) / temperature\n",
    "        exp_preds = np.exp(preds)\n",
    "        preds = exp_preds / np.sum(exp_preds)\n",
    "        probas = np.random.multinomial(1, preds, 1)\n",
    "        return np.argmax(probas)\n",
    "        \n",
    "    def seq2text(self, seq, dictionary):\n",
    "        \"\"\" Convert an integer seq to text using the supplied dictionary.\"\"\"\n",
    "        text = ''\n",
    "        for k in seq:\n",
    "            k = k.astype(int)\n",
    "            # 0 is a reserved token and 1 and 2 are start/stop characters\n",
    "            # This needs to be tweaked as X doesn't have 1 and 2\n",
    "            if k > 2 and k < len(dictionary):\n",
    "                w = dictionary[k]\n",
    "                text = text + w + ' '\n",
    "        return text\n",
    "    \n",
    "    def decode_sequence(self, input_seq, temp=1.0):\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class RecursiveModelA(ModelWrapper):\n",
    "    \n",
    "    def build_model(self, print_summary=False):\n",
    "        \"\"\" Build keras model.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    def decode_sequence(self, input_seq, temp=1.0):\n",
    "        \"\"\"Use greedy decoder.\"\"\"\n",
    "        # reformat input seq\n",
    "        input_seq = np.zeros((1, X_max_len))\n",
    "        input_seq[0, :] = X_seq\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1, y_max_len))\n",
    "    ans_partial[0, -1] = 1  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(y_max_len - 1):\n",
    "        ye = model.predict([input_seq, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == 2:  #  the index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = seq2text(ans_partial[0], y_dictionary)\n",
    "    return(text, prob)\n",
    "    \n",
    "    def train(self, epochs, X, Y):\n",
    "        \"\"\" Train the Training Model.\"\"\"\n",
    "        pass\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2t = Claims2Title(t_title.word_index, hidden_size=300, filepath=\"300_hidden.hd5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "c2t.train(1, X, Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2t.decode_sequence(X[-1].reshape(1,300), 0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to generate some completely separate test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_texts[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2t.decode_sequence(X[5].reshape(1,300))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_texts[5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "c2t.decode_sequence(X[15].reshape(1,300))"
   ]
  },
  {
   "attachments": {
    "temperature_explan.png": {
     "image/png": "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"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think we need to adjust the temperature of our sampling - the output is getting stuck in regular patterns. Here is an explanation of temperature - https://stats.stackexchange.com/questions/255223/the-effect-of-temperature-in-temperature-sampling.\n",
    "\n",
    "![temperature_explan.png](attachment:temperature_explan.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for temp in [0.1, 0.3, 0.6, 0.9]:\n",
    "    for sent_i in [5, 150, 350, 5000]:\n",
    "        print(c2t.decode_sequence(X[sent_i].reshape(1,300), temp), \"\\n\")\n",
    "        print(Y_texts[sent_i], \"\\n\")\n",
    "        print(\"---\")\n",
    "    print(\"====\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for temp in [0.1, 0.3, 0.6, 0.9]:\n",
    "    print(temp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "print(c2t.decode_sequence(X[1].reshape(1,300), 0.1), \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
