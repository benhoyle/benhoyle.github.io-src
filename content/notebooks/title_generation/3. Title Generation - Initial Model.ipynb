{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: 3. Title Generation - Initial Model\n",
    "Tags: preparing_data\n",
    "Authors: Ben Hoyle\n",
    "Summary: This post looks at implementing an initial model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Title Generation - Initial Model\n",
    "\n",
    "Given our analysis in the previous post we will now construct our model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load and Tokenize Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_decoder_tokens = 2500 # This is our output title vocabulary\n",
    "num_encoder_tokens = 5000 # This is our input claim vocabulary\n",
    "encoder_seq_length = 300 # This is our limit for our input claim length\n",
    "decoder_seq_length = 22 # This is our limit for our output title length - 20 + 2 for start/stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "30000 samples loaded\n",
      "\n",
      "\n",
      "Adding start and stop tokens to output\n",
      "\n",
      "\n",
      "An example title: startseq System and method for session restoration at geo-redundant gateways stopseq\n",
      "----\n",
      "An example claim: \n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PIK = \"claim_and_title.data\"\n",
    "\n",
    "if not os.path.isfile(PIK):\n",
    "    # Download file\n",
    "    !wget https://benhoyle.github.io/notebooks/title_generation/claim_and_title.data\n",
    "\n",
    "with open(PIK, \"rb\") as f:\n",
    "    print(\"Loading data\")\n",
    "    data = pickle.load(f)\n",
    "    print(\"{0} samples loaded\".format(len(data)))\n",
    "    \n",
    "print(\"\\n\\nAdding start and stop tokens to output\")\n",
    "data = [(c, \"startseq {0} stopseq\".format(t)) for c, t in data]\n",
    "                                      \n",
    "print(\"\\n\\nAn example title:\", data[0][1])\n",
    "print(\"----\")\n",
    "print(\"An example claim:\", data[0][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Should we use a common tokenizer for both the input and output? This seems sensible and would save memory. It would also make it easier to share an embedding layer. It might also help in the training as common numbers will be assigned to common words. Maybe we try this after the initial run as below?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input sequences (claims) have a vocabulary of 49376 words\n",
      "Our output sequences (titles) have a vocabulary of 11080 words\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "t_claim = text.Tokenizer(\n",
    "                num_words=num_encoder_tokens, \n",
    "                filters='1.:;\\n()',\n",
    "                lower=True,\n",
    "                split=\" \",\n",
    "                char_level=False,\n",
    "                oov_token=\"<UNK>\"\n",
    ")\n",
    "X_texts = [d[0] for d in data]\n",
    "t_claim.fit_on_texts(X_texts)\n",
    "X_seqs = t_claim.texts_to_sequences(X_texts)\n",
    "\n",
    "t_title = text.Tokenizer( \n",
    "                num_words=num_decoder_tokens,\n",
    "                lower=True,\n",
    "                char_level=False,\n",
    "                oov_token=\"<UNK>\"\n",
    ")\n",
    "Y_texts = [d[1] for d in data]\n",
    "t_title.fit_on_texts(Y_texts)\n",
    "Y_seqs = t_title.texts_to_sequences(Y_texts)\n",
    "\n",
    "print(\"Our input sequences (claims) have a vocabulary of {0} words\".format(max([v for k, v in t_claim.word_index.items()])))\n",
    "print(\"Our output sequences (titles) have a vocabulary of {0} words\".format(max([v for k, v in t_title.word_index.items()])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest input sequence is 300 tokens long.\n",
      "Our longest output sequence is 22 tokens long.\n"
     ]
    }
   ],
   "source": [
    "filtered_seqs = [(x, y) for x,y in zip(X_seqs, Y_seqs) if len(x) <= encoder_seq_length and len(y) <= decoder_seq_length]\n",
    "X_seqs = [x for x, _ in filtered_seqs]\n",
    "Y_seqs = [y for _, y in filtered_seqs]\n",
    "\n",
    "X_length = [len(x) for x in X_seqs]\n",
    "max_length = max(X_length)\n",
    "print(\"Our longest input sequence is {0} tokens long.\".format(max_length))\n",
    "\n",
    "Y_length = [len(y) for y in Y_seqs]\n",
    "max_length = max(Y_length)\n",
    "print(\"Our longest output sequence is {0} tokens long.\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      " [2, 33, 9, 584, 2, 552, 95, 1217, 37, 20, 2, 363, 1, 33, 25, 1953, 56, 19, 1, 363, 14, 24, 2, 70, 3, 49, 3528, 364, 118, 244, 1, 86, 70, 3, 364, 118, 27, 46, 2315, 4, 754, 1, 552, 4, 944, 4, 11, 160, 275, 23, 58, 11, 500, 364, 1542, 15, 1, 363, 48, 6, 2, 1852, 118, 5, 6, 68, 4, 2, 974, 3, 1, 363, 1, 552, 160, 3, 621, 735, 5, 1051, 37, 20, 16, 363, 5, 272, 2, 10, 485, 1603, 2, 160, 275, 9, 28, 3, 16, 58, 11, 500, 364, 1542, 15, 1, 2422, 363, 4, 19, 1, 60, 5, 4, 1, 305, 17, 28, 900, 1, 4, 736, 2, 62, 20, 2, 62, 98, 4, 1, 100, 3528]\n",
      "startseq System and method for session restoration at geo-redundant gateways stopseq [1, 6, 3, 5, 4, 383, 1183, 166, 775, 2]\n"
     ]
    }
   ],
   "source": [
    "print(X_texts[0], X_seqs[0])\n",
    "print(Y_texts[0], Y_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X data has shape (25529, 300) and our Y data has shape (25529, 22)\n"
     ]
    }
   ],
   "source": [
    "# Pad the data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(X_seqs, maxlen=encoder_seq_length)\n",
    "Y = pad_sequences(Y_seqs, maxlen=decoder_seq_length, padding='post')\n",
    "\n",
    "print(\"Our X data has shape {0} and our Y data has shape {1}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can't use the function above as it results in a memory error."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Models\n",
    "\n",
    "We have a number of models we can try out. Initially we can run the models with minimal tweaking. Then later we can expand on the better models.\n",
    "\n",
    "The models we can use are as follows:\n",
    "\n",
    "1. The Chollet/Brownlee Model based on the [sequential encoder-decoder system](https://machinelearningmastery.com/develop-encoder-decoder-model-sequence-sequence-prediction-keras/) as described by Jason Brownlee of Machine Learning Mastery, which is in turn based on a [sequence-to-sequence model](https://blog.keras.io/a-ten-minute-introduction-to-sequence-to-sequence-learning-in-keras.html) as described by Francois Chollet; and\n",
    "2. The Ludwig Model [chatbot encoder-decoder model](https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras) as described by Oswaldo Ludwig.\n",
    "\n",
    "All use Keras as this point. This helps to simplify our model and let us experiment with the basics.\n",
    "\n",
    "The original model in 1. is designed based on character data. We can either use at the character level or adapt to use word-level features, e.g. as suggested at the bottom of the Chollet blog post.\n",
    "\n",
    "The model in 2. uses word-level features. We are thus able to use this with less adaptation."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ludwig Model\n",
    "\n",
    "There are actually two models described by Oswaldo. A first introductory model and a second model that uses an additional adversarial network. The first model is easier to understand so we will start with that."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first introductory model has the following features:\n",
    "\n",
    "* A source text input model based around an Embedding layer and an LSTM. The claim features (i.e. words as integers) are projected to a dense vector by the embedding layer and then fed into the LSTM. The last output timestep of the LSTM is then taken as the output. The output of the LSTM can be thought of as a \"context vector\" that represents the claim.\n",
    "* A summary input model. This is similar to the source text input model. It has an Embedding layer and an LSTM. It takes a full or partial sequence of integers representing the words in our titles. The output of the last timestep is take as the output of the LSTM. The output of the LSTM can be thought of as an \"answer vector\" that represents a state of a current answer in time.\n",
    "* The output of both models, i.e. the context vector and the answer vector are concatenated and fed into a feed forward or Dense layer that outputs a vector the size of our title vocabulary. A softmax activation is used to generate a pseudo-probability value. The output of the model is thus a vector of probabilities across the vocabulary of the title. This can then be compared with a one-hot encoding of the actual word."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.layers import concatenate\n",
    "\n",
    "y_vocab_len = num_decoder_tokens # This is our output title vocabulary\n",
    "X_vocab_len = num_encoder_tokens # This is our input claim vocabulary\n",
    "X_max_len = encoder_seq_length # This is our limit for our input claim length\n",
    "y_max_len = decoder_seq_length # This is our limit for our output title length - 20 + 2 for start/stop\n",
    "\n",
    "# source text input model\n",
    "inputs1 = Input(shape=(X_max_len,))\n",
    "am1 = Embedding(X_vocab_len, 128)(inputs1)\n",
    "am2 = LSTM(128)(am1)\n",
    "# summary input model\n",
    "inputs2 = Input(shape=(y_max_len,))\n",
    "sm1 = Embedding(y_vocab_len, 128)(inputs2)\n",
    "sm2 = LSTM(128)(sm1)\n",
    "# decoder output model\n",
    "decoder1 = concatenate([am2, sm2])\n",
    "outputs = Dense(y_vocab_len, activation='softmax')(decoder1)\n",
    "# tie it together [article, summary] [word]\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_2 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_1 (Embedding)         (None, 300, 128)     640000      input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, 22, 128)      320000      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_1 (LSTM)                   (None, 128)          131584      embedding_1[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_2 (LSTM)                   (None, 128)          131584      embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 256)          0           lstm_1[0][0]                     \n",
      "                                                                 lstm_2[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 2500)         642500      concatenate_1[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,865,668\n",
      "Trainable params: 1,865,668\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The model is fairly simple. However, a little bit of work is required to prepare our data for training. There are two main issues we need to address:\n",
    "\n",
    "* The model requires a one-hot encoding for each word in the title. If our vocabulary is 2500 (relatively small) and our titles are limited to 20 words, we have a matrix of 50,000 items per data sample. If we have 25,000 data samples then we have 1.25 billion items. If each item is a 32 or 64-bit float we have a memory issue.\n",
    "* The summary model is designed to take partially-complete sequences as the output sequence is built. We thus need to train on various levels of completeness. For example, if our title is 20 words long, we train with 1 word to predict the second word, 2 words to predict the third word, 3 words to predict the fourth word etc.\n",
    "\n",
    "To address the first issue, we train in smaller sets. For example, we can group 100 examples together and train on these.\n",
    "\n",
    "To address the second issue, we build up sets of partial titles for each training example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1009"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set_size = 0\n",
    "for sent in Y[0:100]:\n",
    "    limit = np.where(sent==2)[0][0]  #  the position od the symbol EOS\n",
    "    set_size += limit + 1\n",
    "set_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([   1,    6,    3,    5,    4,  383, 1183,  166,  775,    2,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ah - it's because we've been reversing our Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_set(X, Y, i_end, i):\n",
    "    \"\"\" Generate the data for training/validation from X and Y.\n",
    "    i_end is the end of the set, i is the start.\"\"\"\n",
    "    set_size = 0\n",
    "    limit_list = list()\n",
    "    for sent in Y[i:i_end]:\n",
    "        limit = np.where(sent==2)[0][0]  #  the position od the symbol EOS\n",
    "        set_size += limit + 1\n",
    "        limit_list.append(limit)\n",
    "   \n",
    "    # We need to change this bit to set our array size based on the limit values\n",
    "    # Generate blank arrays for the set\n",
    "    I_1 = np.zeros((set_size, X_max_len))\n",
    "    I_2 = np.zeros((set_size, y_max_len))\n",
    "    # This below is a big array\n",
    "    Y_set = np.zeros((set_size, y_vocab_len))\n",
    "    count = 0\n",
    "    # Now we want to create, for each sample, a set of examples for each word in the title\n",
    "    # Have we just been training on 0 to 100?!?!\n",
    "    for l in range(0, (i_end - i)):\n",
    "        # for each X and y in set of NB_SET \n",
    "            \n",
    "        # We need to build the input for the second encoder for the next word in y\n",
    "        # I.e. for word 3 in the title the input2 consists of words 1 and 2 (using teacher forcing)\n",
    "            \n",
    "        # Get length of current title - i.e. where the integer = 2 = stopseq\n",
    "        limit = limit_list[l]\n",
    "            \n",
    "        # We only need to create examples up to the length of the title \n",
    "        for m in range(1, limit+1):\n",
    "                \n",
    "            # Generate our one-hot y out\n",
    "            one_hot_out = np.zeros((1, y_vocab_len))\n",
    "            # This builds our one-hot generation into our training loop\n",
    "            # The l and m respectively iterate through the samples and the output sequence elements\n",
    "            one_hot_out[0, Y[l+i][m]] = 1\n",
    "                \n",
    "            # Create a blank row/array for a partial input for our summary model - this is fed into the decoder\n",
    "            # It is of the same size as our title\n",
    "            partial_input = np.zeros((1, y_max_len))\n",
    "            # Because we are zero padding add words up to m to end - DOES THIS STILL WORK IF WE ZERO PAD\n",
    "            # AT THE END? - Yes but we just feed the words with zeros first?\n",
    "            partial_input[0, -m:] = Y[l+i][0:m]\n",
    "            \n",
    "            # This fills in each sample of the training data, i.e. count increments up to set size\n",
    "            I_1[count, :] = X_train[l+i]\n",
    "            I_2[count, :] = partial_input\n",
    "            Y_set[count, :] = one_hot_out\n",
    "            count += 1\n",
    "                \n",
    "        # Shuffle the I_1, I_2 and Y_set vectors for better training - trick from RL\n",
    "        # - see here - np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X);\n",
    "        indices = np.random.permutation(I_1.shape[0])\n",
    "        np.take(I_1, indices, axis=0, out=I_1)\n",
    "        np.take(I_2, indices, axis=0, out=I_2)\n",
    "        np.take(Y_set, indices, axis=0, out=Y_set)\n",
    "    return I_1, I_2, Y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved weights found, loading...\n"
     ]
    }
   ],
   "source": [
    "# Basing training in sets code on here - https://github.com/ChunML/seq2seq/blob/master/seq2seq.py\n",
    "\n",
    "# Function to look for saved weights file\n",
    "def find_checkpoint_file(folder):\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'kerascheckpoint' in f]\n",
    "    if len(checkpoint_file) == 0:\n",
    "        return []\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "# Finding trained weights of previous epoch if any\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "\n",
    "k_start = 1\n",
    "\n",
    "# If any trained weight was found, then load them into the model\n",
    "if len(saved_weights) != 0:\n",
    "    print('[INFO] Saved weights found, loading...')\n",
    "    epoch = saved_weights[saved_weights.rfind('_')+1:saved_weights.rfind('.')]\n",
    "    model.load_weights(saved_weights)\n",
    "    k_start = int(epoch) + 1\n",
    "\n",
    "# So instead of X we have [inputs1, inputs2] - this is where we need to fold in \n",
    "# - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py\n",
    "\n",
    "# So we have inputs2 that build up - we have a set of inputs2 up to the length of inputs2\n",
    "\n",
    "# We need to refactor some of the loops below as functions - we can then apply to test data to generate a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 2 - 0/20423 samples\n",
      "Train on 2463 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 2.5461 - val_loss: 3.0267\n",
      "[INFO] Training model: epoch 2 - 250/20423 samples\n",
      "Train on 2552 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2552/2552 [==============================] - 24s 9ms/step - loss: 2.5839 - val_loss: 2.8048\n",
      "[INFO] Training model: epoch 2 - 500/20423 samples\n",
      "Train on 2446 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 24s 10ms/step - loss: 2.4230 - val_loss: 2.7162\n",
      "[INFO] Training model: epoch 2 - 750/20423 samples\n",
      "Train on 2572 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 24s 9ms/step - loss: 2.5362 - val_loss: 2.9778\n",
      "[INFO] Training model: epoch 2 - 1000/20423 samples\n",
      "Train on 2526 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 25s 10ms/step - loss: 2.5542 - val_loss: 3.0614\n",
      "[INFO] Training model: epoch 2 - 1250/20423 samples\n",
      "Train on 2592 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 26s 10ms/step - loss: 2.5401 - val_loss: 2.6013\n",
      "[INFO] Training model: epoch 2 - 1500/20423 samples\n",
      "Train on 2492 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 25s 10ms/step - loss: 2.4967 - val_loss: 2.8973\n",
      "[INFO] Training model: epoch 2 - 1750/20423 samples\n",
      "Train on 2607 samples, validate on 675 samples\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 26s 10ms/step - loss: 2.5795 - val_loss: 3.0124\n",
      "[INFO] Training model: epoch 2 - 2000/20423 samples\n",
      "Train on 2525 samples, validate on 677 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 26s 10ms/step - loss: 2.4945 - val_loss: 2.9818\n",
      "[INFO] Training model: epoch 2 - 2250/20423 samples\n",
      "Train on 2530 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 25s 10ms/step - loss: 2.4569 - val_loss: 2.8095\n",
      "[INFO] Training model: epoch 2 - 2500/20423 samples\n",
      "Train on 2542 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 26s 10ms/step - loss: 2.5170 - val_loss: 2.6293\n",
      "[INFO] Training model: epoch 2 - 2750/20423 samples\n",
      "Train on 2497 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 26s 10ms/step - loss: 2.5201 - val_loss: 2.9004\n",
      "[INFO] Training model: epoch 2 - 3000/20423 samples\n",
      "Train on 2617 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2617/2617 [==============================] - 26s 10ms/step - loss: 2.5869 - val_loss: 3.0075\n",
      "[INFO] Training model: epoch 2 - 3250/20423 samples\n",
      "Train on 2514 samples, validate on 687 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 26s 10ms/step - loss: 2.4700 - val_loss: 2.8688\n",
      "[INFO] Training model: epoch 2 - 3500/20423 samples\n",
      "Train on 2463 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 25s 10ms/step - loss: 2.5413 - val_loss: 2.8625\n",
      "[INFO] Training model: epoch 2 - 3750/20423 samples\n",
      "Train on 2440 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 25s 10ms/step - loss: 2.4597 - val_loss: 3.0249\n",
      "[INFO] Training model: epoch 2 - 4000/20423 samples\n",
      "Train on 2475 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 25s 10ms/step - loss: 2.6151 - val_loss: 2.7236\n",
      "[INFO] Training model: epoch 2 - 4250/20423 samples\n",
      "Train on 2576 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 26s 10ms/step - loss: 2.4784 - val_loss: 2.7992\n",
      "[INFO] Training model: epoch 2 - 4500/20423 samples\n",
      "Train on 2487 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 25s 10ms/step - loss: 2.5378 - val_loss: 2.6937\n",
      "[INFO] Training model: epoch 2 - 4750/20423 samples\n",
      "Train on 2501 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 25s 10ms/step - loss: 2.5563 - val_loss: 2.8764\n",
      "[INFO] Training model: epoch 2 - 5000/20423 samples\n",
      "Train on 2617 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2617/2617 [==============================] - 27s 10ms/step - loss: 2.5362 - val_loss: 2.8573\n",
      "[INFO] Training model: epoch 2 - 5250/20423 samples\n",
      "Train on 2525 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 26s 10ms/step - loss: 2.5082 - val_loss: 2.8590\n",
      "[INFO] Training model: epoch 2 - 5500/20423 samples\n",
      "Train on 2484 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 25s 10ms/step - loss: 2.6240 - val_loss: 2.9242\n",
      "[INFO] Training model: epoch 2 - 5750/20423 samples\n",
      "Train on 2469 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 26s 10ms/step - loss: 2.3302 - val_loss: 2.8556\n",
      "[INFO] Training model: epoch 2 - 6000/20423 samples\n",
      "Train on 2427 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 25s 10ms/step - loss: 2.5707 - val_loss: 2.9247\n",
      "[INFO] Training model: epoch 2 - 6250/20423 samples\n",
      "Train on 2551 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 27s 10ms/step - loss: 2.5628 - val_loss: 2.6603\n",
      "[INFO] Training model: epoch 2 - 6500/20423 samples\n",
      "Train on 2537 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 27s 10ms/step - loss: 2.4532 - val_loss: 2.7540\n",
      "[INFO] Training model: epoch 2 - 6750/20423 samples\n",
      "Train on 2556 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2556/2556 [==============================] - 26s 10ms/step - loss: 2.5068 - val_loss: 3.0887\n",
      "[INFO] Training model: epoch 2 - 7000/20423 samples\n",
      "Train on 2468 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 26s 11ms/step - loss: 2.5587 - val_loss: 2.8159\n",
      "[INFO] Training model: epoch 2 - 7250/20423 samples\n",
      "Train on 2530 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 26s 10ms/step - loss: 2.5007 - val_loss: 2.9069\n",
      "[INFO] Training model: epoch 2 - 7500/20423 samples\n",
      "Train on 2520 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 25s 10ms/step - loss: 2.4892 - val_loss: 2.8692\n",
      "[INFO] Training model: epoch 2 - 7750/20423 samples\n",
      "Train on 2559 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 26s 10ms/step - loss: 2.4715 - val_loss: 2.6655\n",
      "[INFO] Training model: epoch 2 - 8000/20423 samples\n",
      "Train on 2551 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 26s 10ms/step - loss: 2.6281 - val_loss: 3.0931\n",
      "[INFO] Training model: epoch 2 - 8250/20423 samples\n",
      "Train on 2562 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 27s 10ms/step - loss: 2.5223 - val_loss: 2.9672\n",
      "[INFO] Training model: epoch 2 - 8500/20423 samples\n",
      "Train on 2592 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 27s 10ms/step - loss: 2.4504 - val_loss: 2.9558\n",
      "[INFO] Training model: epoch 2 - 8750/20423 samples\n",
      "Train on 2609 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 27s 10ms/step - loss: 2.4715 - val_loss: 2.9098\n",
      "[INFO] Training model: epoch 2 - 9000/20423 samples\n",
      "Train on 2485 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 26s 10ms/step - loss: 2.4156 - val_loss: 2.7285\n",
      "[INFO] Training model: epoch 2 - 9250/20423 samples\n",
      "Train on 2455 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 25s 10ms/step - loss: 2.4501 - val_loss: 2.8327\n",
      "[INFO] Training model: epoch 2 - 9500/20423 samples\n",
      "Train on 2518 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 25s 10ms/step - loss: 2.6332 - val_loss: 2.7614\n",
      "[INFO] Training model: epoch 2 - 9750/20423 samples\n",
      "Train on 2547 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 25s 10ms/step - loss: 2.4632 - val_loss: 2.8831\n",
      "[INFO] Training model: epoch 2 - 10000/20423 samples\n",
      "Train on 2635 samples, validate on 608 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2635/2635 [==============================] - 26s 10ms/step - loss: 2.5661 - val_loss: 2.6622\n",
      "[INFO] Training model: epoch 2 - 10250/20423 samples\n",
      "Train on 2528 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 25s 10ms/step - loss: 2.5130 - val_loss: 2.6851\n",
      "[INFO] Training model: epoch 2 - 10500/20423 samples\n",
      "Train on 2527 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 26s 10ms/step - loss: 2.5259 - val_loss: 2.6705\n",
      "[INFO] Training model: epoch 2 - 10750/20423 samples\n",
      "Train on 2599 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2599/2599 [==============================] - 27s 10ms/step - loss: 2.4307 - val_loss: 2.7845\n",
      "[INFO] Training model: epoch 2 - 11000/20423 samples\n",
      "Train on 2552 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2552/2552 [==============================] - 26s 10ms/step - loss: 2.5966 - val_loss: 2.8254\n",
      "[INFO] Training model: epoch 2 - 11250/20423 samples\n",
      "Train on 2466 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 26s 11ms/step - loss: 2.4094 - val_loss: 2.7882\n",
      "[INFO] Training model: epoch 2 - 11500/20423 samples\n",
      "Train on 2519 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 26s 10ms/step - loss: 2.5736 - val_loss: 2.6627\n",
      "[INFO] Training model: epoch 2 - 11750/20423 samples\n",
      "Train on 2490 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 26s 10ms/step - loss: 2.4802 - val_loss: 2.7618\n",
      "[INFO] Training model: epoch 2 - 12000/20423 samples\n",
      "Train on 2631 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2631/2631 [==============================] - 27s 10ms/step - loss: 2.4868 - val_loss: 2.7780\n",
      "[INFO] Training model: epoch 2 - 12250/20423 samples\n",
      "Train on 2479 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 25s 10ms/step - loss: 2.4741 - val_loss: 2.8244\n",
      "[INFO] Training model: epoch 2 - 12500/20423 samples\n",
      "Train on 2620 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2620/2620 [==============================] - 26s 10ms/step - loss: 2.3884 - val_loss: 2.7133\n",
      "[INFO] Training model: epoch 2 - 12750/20423 samples\n",
      "Train on 2505 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 25s 10ms/step - loss: 2.4360 - val_loss: 2.8718\n",
      "[INFO] Training model: epoch 2 - 13000/20423 samples\n",
      "Train on 2488 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 25s 10ms/step - loss: 2.5148 - val_loss: 2.7442\n",
      "[INFO] Training model: epoch 2 - 13250/20423 samples\n",
      "Train on 2477 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 25s 10ms/step - loss: 2.3307 - val_loss: 2.9383\n",
      "[INFO] Training model: epoch 2 - 13500/20423 samples\n",
      "Train on 2451 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 25s 10ms/step - loss: 2.3576 - val_loss: 3.0506\n",
      "[INFO] Training model: epoch 2 - 13750/20423 samples\n",
      "Train on 2458 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 24s 10ms/step - loss: 2.5399 - val_loss: 2.9005\n",
      "[INFO] Training model: epoch 2 - 14000/20423 samples\n",
      "Train on 2538 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 26s 10ms/step - loss: 2.4439 - val_loss: 2.5874\n",
      "[INFO] Training model: epoch 2 - 14250/20423 samples\n",
      "Train on 2518 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 25s 10ms/step - loss: 2.5228 - val_loss: 3.1204\n",
      "[INFO] Training model: epoch 2 - 14500/20423 samples\n",
      "Train on 2514 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 25s 10ms/step - loss: 2.4926 - val_loss: 2.5919\n",
      "[INFO] Training model: epoch 2 - 14750/20423 samples\n",
      "Train on 2594 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2594/2594 [==============================] - 26s 10ms/step - loss: 2.4201 - val_loss: 2.7632\n",
      "[INFO] Training model: epoch 2 - 15000/20423 samples\n",
      "Train on 2360 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 24s 10ms/step - loss: 2.4969 - val_loss: 2.9441\n",
      "[INFO] Training model: epoch 2 - 15250/20423 samples\n",
      "Train on 2473 samples, validate on 713 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 24s 10ms/step - loss: 2.5184 - val_loss: 2.9971\n",
      "[INFO] Training model: epoch 2 - 15500/20423 samples\n",
      "Train on 2485 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 24s 10ms/step - loss: 2.5373 - val_loss: 2.7995\n",
      "[INFO] Training model: epoch 2 - 15750/20423 samples\n",
      "Train on 2472 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 24s 10ms/step - loss: 2.4791 - val_loss: 2.5648\n",
      "[INFO] Training model: epoch 2 - 16000/20423 samples\n",
      "Train on 2576 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 26s 10ms/step - loss: 2.4938 - val_loss: 2.9202\n",
      "[INFO] Training model: epoch 2 - 16250/20423 samples\n",
      "Train on 2529 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 2.3959 - val_loss: 2.6484\n",
      "[INFO] Training model: epoch 2 - 16500/20423 samples\n",
      "Train on 2493 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 25s 10ms/step - loss: 2.4309 - val_loss: 3.0211\n",
      "[INFO] Training model: epoch 2 - 16750/20423 samples\n",
      "Train on 2498 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 2.5476 - val_loss: 2.8655\n",
      "[INFO] Training model: epoch 2 - 17000/20423 samples\n",
      "Train on 2539 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 25s 10ms/step - loss: 2.4758 - val_loss: 3.0723\n",
      "[INFO] Training model: epoch 2 - 17250/20423 samples\n",
      "Train on 2475 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 25s 10ms/step - loss: 2.4944 - val_loss: 2.7414\n",
      "[INFO] Training model: epoch 2 - 17500/20423 samples\n",
      "Train on 2513 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 25s 10ms/step - loss: 2.5161 - val_loss: 2.7245\n",
      "[INFO] Training model: epoch 2 - 17750/20423 samples\n",
      "Train on 2475 samples, validate on 685 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 2.4001 - val_loss: 2.7077\n",
      "[INFO] Training model: epoch 2 - 18000/20423 samples\n",
      "Train on 2456 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 24s 10ms/step - loss: 2.4307 - val_loss: 2.8027\n",
      "[INFO] Training model: epoch 2 - 18250/20423 samples\n",
      "Train on 2584 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2584/2584 [==============================] - 26s 10ms/step - loss: 2.5158 - val_loss: 2.7719\n",
      "[INFO] Training model: epoch 2 - 18500/20423 samples\n",
      "Train on 2433 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 24s 10ms/step - loss: 2.4057 - val_loss: 2.8736\n",
      "[INFO] Training model: epoch 2 - 18750/20423 samples\n",
      "Train on 2513 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 26s 10ms/step - loss: 2.4995 - val_loss: 2.8910\n",
      "[INFO] Training model: epoch 2 - 19000/20423 samples\n",
      "Train on 2536 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 26s 10ms/step - loss: 2.4018 - val_loss: 2.8042\n",
      "[INFO] Training model: epoch 2 - 19250/20423 samples\n",
      "Train on 2654 samples, validate on 673 samples\n",
      "Epoch 1/1\n",
      "2654/2654 [==============================] - 27s 10ms/step - loss: 2.5447 - val_loss: 2.8682\n",
      "[INFO] Training model: epoch 2 - 19500/20423 samples\n",
      "Train on 2494 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 26s 10ms/step - loss: 2.5280 - val_loss: 2.6361\n",
      "[INFO] Training model: epoch 2 - 19750/20423 samples\n",
      "Train on 2514 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 26s 10ms/step - loss: 2.4726 - val_loss: 2.8416\n",
      "[INFO] Training model: epoch 2 - 20000/20423 samples\n",
      "Train on 2422 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 25s 10ms/step - loss: 2.4810 - val_loss: 2.8054\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 2 - 20250/20423 samples\n",
      "Train on 1810 samples, validate on 472 samples\n",
      "Epoch 1/1\n",
      "1810/1810 [==============================] - 19s 10ms/step - loss: 2.4741 - val_loss: 3.0421\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "BATCH_SIZE = 32 # Depends on GPU - most values are around this 32-128 \n",
    "NB_EPOCH = 2\n",
    "# Number of examples to group together in a set - 100 is fast / 1000 is too much on an 8-core i7 laptop\n",
    "# I think 100 is good - 250 takes a time to generate the sets of test data\n",
    "NB_SET = 250\n",
    "\n",
    "i_end = 0\n",
    "num_examples = len(X_train)\n",
    "num_test = len(X_test)\n",
    "# Initialise history of accuracy\n",
    "train_loss = list()\n",
    "val_loss = list()\n",
    "\n",
    "# Continue from loaded epoch number or new epoch if not loaded\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(num_examples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    Y_train = Y_train[indices]\n",
    "    indices = np.arange(num_test)\n",
    "    np.random.shuffle(indices)\n",
    "    X_test = X_test[indices]\n",
    "    Y_test = Y_test[indices]\n",
    "\n",
    "    # This for loop rotates through NB_SET samples at a time to avoid memory issues\n",
    "    # E.g. Training 100 sequences at a time\n",
    "    for i in range(0, num_examples, NB_SET):\n",
    "        if i + NB_SET >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + NB_SET\n",
    "        \n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "            \n",
    "        I_1_train, I_2_train, Y_set_train = generate_set(X_train, Y_train, i_end, i)\n",
    "        I_1_test, I_2_test, Y_set_test = generate_set(X_test, Y_test, i_test_end, i_test)\n",
    "              \n",
    "        print('[INFO] Training model: epoch {} - {}/{} samples'.format(k, i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size=BATCH_SIZE, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "        # Get history and apppend new data to running set here\n",
    "    model.save_weights('kerascheckpoint_epoch_{}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've trained our model we need some code to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: live dual validated independently verified dynamic match audit system comprising first device for transmitting an element effort event data, which data details an effort of an element on an event, and\n",
      "\n",
      "Predicted title is: system and method for generating a plurality of  (with prob 2.988668487895419e-05). \n",
      " Test title is: match system and event data recorder method thereof  \n",
      "---\n",
      "\n",
      "Sample of claim text: method comprising facilitating receipt of two or more images of scene, two or more images being associated with different capture parameters determining intensity at corresponding pixel locations of a\n",
      "\n",
      "Predicted title is: image processing apparatus and image processing method apparatus and computer readable medium  (with prob 0.007207380954881892). \n",
      " Test title is: method apparatus and computer program product for generating images of scenes having high dynamic range  \n",
      "---\n",
      "\n",
      "Sample of claim text: an information terminal for reducing touch point reading errors and releasing security lock of information terminal, comprising touch panel that displays plurality of touch points coordinate determini\n",
      "\n",
      "Predicted title is: touch panel and method of controlling the same  (with prob 0.0002631053677347134). \n",
      " Test title is: information terminal  \n",
      "---\n",
      "\n",
      "Sample of claim text: method comprising receiving message having coded therein information identifying desired transport mechanism for request and/or response, received message including portion and portion processing, by \n",
      "\n",
      "Predicted title is: method and system for providing a network  (with prob 3.861037278558291e-05). \n",
      " Test title is: request and response via in a service oriented pipeline architecture for a request response message exchange pattern  \n",
      "---\n",
      "\n",
      "Sample of claim text: an apparatus, comprising block processing pipeline implemented in video encoder circuit and configured to process blocks of pixels from video frames wherein block processing pipeline comprises block i\n",
      "\n",
      "Predicted title is: method and apparatus for generating a three dimensional image  (with prob 7.063415872216406e-07). \n",
      " Test title is: encoding blocks in video frames containing text using of  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Set up dictionary to translate indices to words\n",
    "y_dictionary = dict(\n",
    "            (i, char) for char, i in t_title.word_index.items()\n",
    "        )\n",
    "\n",
    "x_dictionary = dict(\n",
    "            (i, char) for char, i in t_claim.word_index.items()\n",
    "        )\n",
    "\n",
    "def seq2text(seq, dictionary):\n",
    "    text = ''\n",
    "    for k in seq:\n",
    "        k = k.astype(int)\n",
    "        if k > 2 and k < (len(dictionary)-1):\n",
    "            w = dictionary[k]\n",
    "            text = text + w + ' '\n",
    "    return text\n",
    "\n",
    "def greedy_decoder(X_seq):\n",
    "    # reformat input seq\n",
    "    input_seq = np.zeros((1, X_max_len))\n",
    "    input_seq[0, :] = X_seq\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1, y_max_len))\n",
    "    ans_partial[0, -1] = 1  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(y_max_len - 1):\n",
    "        ye = model.predict([input_seq, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == 2:  #  the index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = seq2text(ans_partial[0], y_dictionary)\n",
    "    return(text, prob)\n",
    "\n",
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    text, prob = greedy_decoder(X_test[i])\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {} (with prob {}). \\n Test title is: {} \\n---\\n\".format(text, prob, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chollet/Brownlee Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "def target_one_hot(input_seqs, seq_max_len, vocab_len):\n",
    "    \"\"\" Convert a sequence of integers to a one element shifted sequence of one-hot vectors.\"\"\"\n",
    "    one_hot_out = np.zeros((len(input_seqs), seq_max_len, vocab_len))\n",
    "    for i, sequence in enumerate(input_seqs):\n",
    "        for t, word_int in enumerate(sequence):\n",
    "            if t > 0:\n",
    "                # Shift decoder target get so it is one ahead\n",
    "                one_hot_out[i, t-1, word_int] = 1\n",
    "    return one_hot_out\n",
    "\n",
    "# We need to convert this for our present problem - this is similar to our generate dataset above\n",
    "# prepare data for the LSTM\n",
    "def get_dataset(X, Y, i, i_end, num_decoder_tokens):\n",
    "    \"\"\"Return encoder_input_data, decoder_input_data, and decoder_target_data, latter as one-hot\"\"\"\n",
    "    encoder_input_data = X[i:i_end]\n",
    "    decoder_input_data = Y[i:i_end]\n",
    "    decoder_target_data = target_one_hot(decoder_input_data, Y.shape[1], num_decoder_tokens)\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(num_encoder_tokens, num_decoder_tokens, latent_dim):\n",
    "    # define training encoder\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    encoder_embedding = Embedding(num_encoder_tokens, latent_dim)(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    # Possibly share the embedding below\n",
    "    decoder_embedding = Embedding(num_decoder_tokens, latent_dim)(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    # Need to adjust this line for the embedding\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def train_model(X_train, Y_train, X_test, Y_test, model, set_size, batch_size, num_decoder_tokens):\n",
    "    \"\"\" Code to train model in sets of set_size.\"\"\"\n",
    "    num_examples = len(X_train)\n",
    "    num_test = len(X_test)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    # Loop here to avoid memory issues with the target one hot vector\n",
    "    for i in range(0, num_examples, set_size):\n",
    "        if i + set_size >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + set_size\n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "        # Generate small sets of train and test data\n",
    "        I_1_train, I_2_train, Y_set_train = get_dataset(X_train, Y_train, i, i_end, num_decoder_tokens)\n",
    "        I_1_test, I_2_test, Y_set_test = get_dataset(X_test, Y_test, i_test, i_test_end, num_decoder_tokens)\n",
    "        print('[INFO] Training model: {}/{} samples'.format(i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size= batch_size, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "# define model\n",
    "train, infenc, infdec = define_models(num_encoder_tokens, num_decoder_tokens, 128)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 5.6419 - acc: 0.5533 - val_loss: 2.9519 - val_acc: 0.5856\n",
      "[INFO] Training model: 1000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 17s 17ms/step - loss: 2.8468 - acc: 0.5810 - val_loss: 2.7023 - val_acc: 0.5878\n",
      "[INFO] Training model: 2000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.6481 - acc: 0.5871 - val_loss: 2.5984 - val_acc: 0.5971\n",
      "[INFO] Training model: 3000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.5464 - acc: 0.6063 - val_loss: 2.5094 - val_acc: 0.6147\n",
      "[INFO] Training model: 4000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.4768 - acc: 0.6075 - val_loss: 2.3110 - val_acc: 0.6211\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 20s 20ms/step - loss: 2.3509 - acc: 0.6191 - val_loss: 2.2871 - val_acc: 0.6409\n",
      "[INFO] Training model: 6000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.3189 - acc: 0.6423 - val_loss: 2.2689 - val_acc: 0.6504\n",
      "[INFO] Training model: 7000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.2640 - acc: 0.6492 - val_loss: 2.2682 - val_acc: 0.6484\n",
      "[INFO] Training model: 8000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.2950 - acc: 0.6398 - val_loss: 2.2693 - val_acc: 0.6445\n",
      "[INFO] Training model: 9000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.1982 - acc: 0.6543 - val_loss: 2.2466 - val_acc: 0.6493\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.2617 - acc: 0.6487 - val_loss: 2.2077 - val_acc: 0.6575\n",
      "[INFO] Training model: 11000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.1895 - acc: 0.6631 - val_loss: 2.0775 - val_acc: 0.6773\n",
      "[INFO] Training model: 12000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.1947 - acc: 0.6560 - val_loss: 2.2084 - val_acc: 0.6616\n",
      "[INFO] Training model: 13000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 19s 19ms/step - loss: 2.0927 - acc: 0.6741 - val_loss: 2.2469 - val_acc: 0.6482\n",
      "[INFO] Training model: 14000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.1450 - acc: 0.6670 - val_loss: 2.0694 - val_acc: 0.6800\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      "1000/1000 [==============================] - 18s 18ms/step - loss: 2.0810 - acc: 0.6798 - val_loss: 2.0448 - val_acc: 0.6833\n",
      "[INFO] Training model: 16000/20423 samples\n",
      "Train on 1000 samples, validate on 250 samples\n",
      "Epoch 1/1\n",
      " 320/1000 [========>.....................] - ETA: 10s - loss: 2.0254 - acc: 0.6821"
     ]
    }
   ],
   "source": [
    "# setup variables\n",
    "epochs = 1\n",
    "batch_size = 32\n",
    "set_size = 1000\n",
    "\n",
    "for e in range(0, epochs):\n",
    "    train, tl, vl = train_model(X_train, Y_train, X_test, Y_test, train, set_size, batch_size, num_decoder_tokens)\n",
    "    train_loss += tl\n",
    "    val_loss += vl\n",
    "    model.save_weights(\"chollet_weights.hdf5\", overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_1_train, I_2_train, Y_set_train = get_dataset(X_train, Y_train, 100, 0, num_decoder_tokens)\n",
    "I_1_test, I_2_test, Y_set_test = get_dataset(X_test, Y_test, 10, 0, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 300) (0, 22) (0, 22, 2500)\n",
      "(0, 300) (0, 22) (0, 22, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(I_1_train.shape, I_2_train.shape, Y_set_train.shape)\n",
    "print(I_1_test.shape, I_2_test.shape, Y_set_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, n_steps, cardinality):\n",
    "\t# encode\n",
    "\tstate = infenc.predict(source)\n",
    "\t# start of sequence input\n",
    "\ttarget_seq = array([0.0 for _ in range(cardinality)]).reshape(1, 1, cardinality)\n",
    "\t# collect predictions\n",
    "\toutput = list()\n",
    "\tfor t in range(n_steps):\n",
    "\t\t# predict next char\n",
    "\t\tyhat, h, c = infdec.predict([target_seq] + state)\n",
    "\t\t# store prediction\n",
    "\t\toutput.append(yhat[0,0,:])\n",
    "\t\t# update state\n",
    "\t\tstate = [h, c]\n",
    "\t\t# update target sequence\n",
    "\t\ttarget_seq = yhat\n",
    "\treturn array(output)\n",
    "\n",
    "# decode a one hot encoded string\n",
    "def one_hot_decode(encoded_seq):\n",
    "\treturn [argmax(vector) for vector in encoded_seq]\n",
    "\n",
    "# generate training dataset\n",
    "X1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 100000)\n",
    "print(X1.shape,X2.shape,y.shape)\n",
    "# train model\n",
    "train.fit([X1, X2], y, epochs=1)\n",
    "# Note that `decoder_target_data` needs to be one-hot encoded,\n",
    "# rather than sequences of integers like `decoder_input_data`!\n",
    "train.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)\n",
    "# evaluate LSTM\n",
    "total, correct = 100, 0\n",
    "for _ in range(total):\n",
    "\tX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "\ttarget = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "\tif array_equal(one_hot_decode(y[0]), one_hot_decode(target)):\n",
    "\t\tcorrect += 1\n",
    "print('Accuracy: %.2f%%' % (float(correct)/float(total)*100.0))\n",
    "# spot check some examples\n",
    "for _ in range(10):\n",
    "\tX1, X2, y = get_dataset(n_steps_in, n_steps_out, n_features, 1)\n",
    "\ttarget = predict_sequence(infenc, infdec, X1, n_steps_out, n_features)\n",
    "\tprint('X=%s y=%s, yhat=%s' % (one_hot_decode(X1[0]), one_hot_decode(y[0]), one_hot_decode(target)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
