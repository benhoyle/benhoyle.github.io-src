{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Claim2Title\n",
    "\n",
    "This notebook will investigate whether I can use a sequence to sequence model to generate patent specification title from patent claim text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting the Data\n",
    "\n",
    "First we need a source of say ~ 10,000 titles and claims. We'll concentrate on G06 as crossing the streams of chemistry and computing results in some funky chimeras."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# imports\n",
    "from patentdata.corpus import USPublications\n",
    "from patentdata.models.patentcorpus import LazyPatentCorpus\n",
    "import os, pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to fold in the functions below into patentdata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "12000 claims and titles loaded\n"
     ]
    }
   ],
   "source": [
    "# Get the claim 1 and classificationt text\n",
    "\n",
    "PIK = \"claim_and_title.data\"\n",
    "\n",
    "if os.path.isfile(PIK):\n",
    "    with open(PIK, \"rb\") as f:\n",
    "        print(\"Loading data\")\n",
    "        data = pickle.load(f)\n",
    "        print(\"{0} claims and titles loaded\".format(len(data)))\n",
    "else:\n",
    "    # Load our list of G06 records\n",
    "    records_file = \"12000recordsG06.data\"\n",
    "\n",
    "    if os.path.isfile(records_file):\n",
    "        with open(records_file, \"rb\") as f:\n",
    "            print(\"Loading data\")\n",
    "            records = pickle.load(f)\n",
    "            print(\"{0} records loaded\".format(len(records)))\n",
    "        ds = USPublications(path)\n",
    "    else:\n",
    "        path = '/media/SAMSUNG1/Patent_Downloads'\n",
    "        ds = USPublications(path)\n",
    "        records = ds.get_records([\"G\", \"06\"], \"name\", sample_size=12000)\n",
    "        with open(records_file, \"wb\") as f:\n",
    "            pickle.dump(records, f)\n",
    "            print(\"{0} records saved\".format(len(records)))\n",
    "    \n",
    "    lzy = LazyPatentCorpus()\n",
    "    lzy.init_by_filenames(ds, records)\n",
    "    \n",
    "    data = list()\n",
    "    for i, pd in enumerate(lzy.documents):\n",
    "        try:\n",
    "            title = pd.title\n",
    "        except:\n",
    "            title = \"\"\n",
    "        try:\n",
    "            claim1_text = pd.claimset.get_claim(1).text\n",
    "        except:\n",
    "            claim1_text = \"\"\n",
    "        current_data = (claim1_text, title)\n",
    "        data.append(current_data)\n",
    "        if (i % 500) == 0:\n",
    "            print(\"Saving a checkpoint at {0} files\".format(i))\n",
    "            print(\"Current data = \", current_data)\n",
    "            with open(PIK, \"wb\") as f:\n",
    "                pickle.dump(data, f)\n",
    "            \n",
    "    with open(PIK, \"wb\") as f:\n",
    "        pickle.dump(data, f)\n",
    "        \n",
    "    print(\"{0} claims saved\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('\\n1. An image forming apparatus, comprising: \\nsetting section to be used by a user for setting, as a copying mode, a writing space mode in which a document image in a preset number are printed on a half of a single paper sheet, thus forming a writing space on the other half of the paper sheet, and \\nimage forming section for printing the document image in the preset number on a half of a single paper sheet when the writing space mode has been set as a copying mode. \\n\\n',\n",
       " 'Image forming apparatus having writing space mode')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 11428 claims after filtering out cancelled claims\n"
     ]
    }
   ],
   "source": [
    "# Check for and remove 'cancelled' claims\n",
    "data = [d for d in data if '(canceled)' not in d[0]]\n",
    "\n",
    "print(\"There are now {0} claims after filtering out cancelled claims\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Clean the characters in the data to use a reduced set of printable characters\n",
    "# There is a function in patentdata to do this\n",
    "from patentdata.models.lib.utils import clean_characters\n",
    "\n",
    "data = [(clean_characters(d[0]), clean_characters(d[1])) for d in data]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Breaking Up Claims\n",
    "\n",
    "Studies of human reading comprehension show that sentences of length 8-15 words long are easily understood. Over that comprehension quickly decreases. (See here: http://prsay.prsa.org/2009/01/14/how-to-make-your-copy-more-readable-make-sentences-shorter/)\n",
    "\n",
    "This suggests we want to be breaking our claims into ~8-15 word chunks then combining an output of these chunks. Break on punctuation - e.g. comma clauses (but not lists) and semi-colons.  \n",
    "\n",
    "We can start with our hacky split_into_features method in patentdata library.\n",
    "\n",
    "Can we parse chunks through an RNN encoder and then combine those chunks? Concatenation would not work as you may have a variable number of chunks. Averaging or summing encoded vectors may work.  \n",
    "\n",
    "\"A reasonable limit of 250-500 time steps is often used in practice with large LSTM models.\" - as per https://machinelearningmastery.com/handle-long-sequences-long-short-term-memory-recurrent-neural-networks/."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we cascade RNN cells as per here: http://www.xiaodanzhu.com/publications/zhu_icml_15.pdf?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest claim is 23654 characters long.\n"
     ]
    }
   ],
   "source": [
    "length = max([len(d[0]) for d in data])\n",
    "print(\"Our longest claim is {0} characters long.\".format(length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest title is 397 characters long.\n"
     ]
    }
   ],
   "source": [
    "length = max([len(d[1]) for d in data])\n",
    "print(\"Our longest title is {0} characters long.\".format(length))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is too long for simple LSTM seq2seq systems that rely on 250-500 timesteps.  \n",
    "\n",
    "We could though use characters out and words in?!\n",
    "\n",
    "Thinking about text tokenisation - TF-IDF or count seems wrong - we have more of a summarisation task."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "t_claim = text.Tokenizer(\n",
    "                num_words=10000, \n",
    "                filters='1.:;\\n',\n",
    "                lower=True,\n",
    "                split=\" \",\n",
    "                char_level=False\n",
    ")\n",
    "X_texts = [d[0] for d in data]\n",
    "t_claim.fit_on_texts(X_texts)\n",
    "X_seqs = t_claim.texts_to_sequences(X_texts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start just with a words to words seq-to-seq. We can branch out to a words to chars seq-to-seq later if necessary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t_title = text.Tokenizer( \n",
    "                num_words=5000,\n",
    "                lower=True,\n",
    "                char_level=False\n",
    ")\n",
    "Y_texts = [d[1] for d in data]\n",
    "t_title.fit_on_texts(Y_texts)\n",
    "Y_seqs = t_title.texts_to_sequences(Y_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input sequences (claims) have a vocabulary of 25871 words\n",
      "Our output sequences (titles) have a vocabulary of 7273 words\n"
     ]
    }
   ],
   "source": [
    "print(\"Our input sequences (claims) have a vocabulary of {0} words\".format(max([v for k, v in t_claim.word_index.items()])))\n",
    "print(\"Our output sequences (titles) have a vocabulary of {0} words\".format(max([v for k, v in t_title.word_index.items()])))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will adjust our code above to limit our input space to 10,000 words and our output space to 5000 words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. A mail management method for retrieving and adding e-mail messages to an existing business software application database, comprising: \n",
      "scanning a header portion of each message to locate an identification; \n",
      "comparing the identification with a plurality of identifications stored in a business software application database to identify a matching identification; \n",
      "adding the message with the matching identification into the business software application database wherein the message is associated with the matching identification; and \n",
      "creating a Task associated with the message that is linked to the business software application database. \n",
      "\n",
      " [2, 964, 104, 25, 6, 472, 5, 735, 1137, 576, 4, 10, 1041, 265, 130, 69, 583, 13, 674, 2, 1725, 78, 3, 29, 100, 4, 1803, 10, 169, 321, 1, 169, 17, 2, 23, 3, 4723, 85, 7, 2, 265, 130, 69, 86, 4, 380, 2, 392, 169, 735, 1, 100, 17, 1, 392, 169, 73, 1, 265, 130, 69, 86, 28, 1, 100, 19, 41, 17, 1, 392, 169, 5, 234, 2, 348, 41, 17, 1, 100, 26, 19, 1124, 4, 1, 265, 130, 69, 86]\n"
     ]
    }
   ],
   "source": [
    "print(X_texts[0], X_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mail management system and method [310, 22, 4, 1, 3]\n"
     ]
    }
   ],
   "source": [
    "print(Y_texts[0], Y_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'simultaneously,': 6312,\n",
       " 'repositories': 6359,\n",
       " 'prim': 11476,\n",
       " '(k)': 4703,\n",
       " 'soft': 2690,\n",
       " 'high-frequency': 7115,\n",
       " 'length': 874,\n",
       " 'scan': 782,\n",
       " 'adaptors,': 13369,\n",
       " 'adapter,': 3763,\n",
       " 'burst-signals': 22864,\n",
       " 'voted': 21894,\n",
       " 'deceptive': 13129,\n",
       " 'ability,': 24746,\n",
       " 'stoles': 24343,\n",
       " 'confirmed': 8451,\n",
       " 'comports': 18697,\n",
       " 'accumulates': 14180,\n",
       " 'map': 387,\n",
       " 'page,': 1871,\n",
       " 'outage': 5975,\n",
       " 'demagnifying': 16817,\n",
       " 'stones': 23444,\n",
       " 'fatigue': 8177,\n",
       " 'hot-swappable': 21798,\n",
       " 'saddle-stitch': 10024,\n",
       " 'necessity': 11784,\n",
       " '36': 9397,\n",
       " 'denmark': 22063,\n",
       " 'character-based': 12253,\n",
       " 'biological': 1585,\n",
       " 'motion,': 6653,\n",
       " 'kerning': 11820,\n",
       " 'processes': 596,\n",
       " \"consumers'\": 15171,\n",
       " 'iteration,': 10965,\n",
       " 'turnout': 15120,\n",
       " 'absorptive': 20982,\n",
       " 'synthesized': 2909,\n",
       " 'overlap': 2246,\n",
       " 'retains': 4158,\n",
       " 'auspices': 25588,\n",
       " 'concerns': 9462,\n",
       " 'operation': 93,\n",
       " 'diffractive': 19259,\n",
       " 'instructions': 168,\n",
       " \"processor's\": 11614,\n",
       " 'fatigue,': 22316,\n",
       " 'xii': 18963,\n",
       " 'operand': 1776,\n",
       " 'merging,': 9950,\n",
       " 'lapses': 22803,\n",
       " 'non-steady': 14271,\n",
       " 'uptimes': 20125,\n",
       " 'buyer-specific': 12111,\n",
       " 'sought,': 13959,\n",
       " 'deck': 10441,\n",
       " 'leaf': 3759,\n",
       " 'revenue': 2661,\n",
       " '(\"im\")': 18160,\n",
       " 'long-standing': 18117,\n",
       " 'searching,': 3524,\n",
       " '(\"sas\")': 17038,\n",
       " 'silos': 16377,\n",
       " 'enroll': 19594,\n",
       " 'contrast,': 14578,\n",
       " 'stratigraphic': 12137,\n",
       " 'profiling': 4081,\n",
       " 'blistered': 16467,\n",
       " 'thermal,': 19138,\n",
       " 'impede': 15217,\n",
       " 'weighted-graph': 18917,\n",
       " 'verifiable': 7743,\n",
       " 'advection': 3988,\n",
       " 'types,': 2914,\n",
       " 'securely': 3634,\n",
       " 'collector,': 11527,\n",
       " '\"sma': 15591,\n",
       " 'wisps': 24751,\n",
       " 'therapy': 6404,\n",
       " 'apparatus)': 23453,\n",
       " 'fore-aft': 21267,\n",
       " 'cameras': 3570,\n",
       " 'bounds': 9441,\n",
       " '(fsa)': 18837,\n",
       " 'capsule-related': 10082,\n",
       " 'job-processing': 10930,\n",
       " 'lattice': 4695,\n",
       " 'classifying,': 13108,\n",
       " 'valve,': 15270,\n",
       " 'ics': 10692,\n",
       " '{': 18600,\n",
       " 'narrowband': 23607,\n",
       " 'second-layer': 12556,\n",
       " 'd3)': 19905,\n",
       " 'specialized': 7376,\n",
       " 'local': 243,\n",
       " 'inoperable': 24630,\n",
       " 'discounts': 7478,\n",
       " 'characteristic': 457,\n",
       " 'than': 154,\n",
       " 'roller,': 10230,\n",
       " 'idle': 2507,\n",
       " 'scrollable': 15912,\n",
       " 'bottomside': 17126,\n",
       " 'colors': 2147,\n",
       " 'derivatives,': 15639,\n",
       " 'right-view': 22247,\n",
       " 'indirect': 4475,\n",
       " 'hydrological': 21980,\n",
       " 'runbooks': 10310,\n",
       " 'measurable': 7552,\n",
       " 'multi-pipe': 10061,\n",
       " 'consensus,': 22578,\n",
       " \"athlete's\": 20952,\n",
       " 'restart': 4358,\n",
       " 'sweeping': 17777,\n",
       " 'stories,': 22338,\n",
       " 'crisis': 16584,\n",
       " '(pi)': 16122,\n",
       " 'comprise': 1440,\n",
       " 'annotation,': 21077,\n",
       " 'removable': 2071,\n",
       " 'mosfets': 11382,\n",
       " '(oma)': 21941,\n",
       " 'assembling,': 17340,\n",
       " 'interdiction': 16846,\n",
       " 'pallet': 15713,\n",
       " 'gc': 13553,\n",
       " 'regenerate': 12361,\n",
       " 'traceable': 5289,\n",
       " '(vafm),': 20942,\n",
       " 'plb': 8974,\n",
       " 'roles': 4176,\n",
       " 'period,': 1439,\n",
       " '(artifacts': 20061,\n",
       " 'spyware': 9303,\n",
       " 'freedom,': 9620,\n",
       " 'outlines': 10637,\n",
       " 'dspecific+dmmimum': 22625,\n",
       " 'non-alterable': 13348,\n",
       " 'absorbing': 9562,\n",
       " 'transparency': 3782,\n",
       " 'members': 972,\n",
       " 'sub-channels': 10336,\n",
       " 'coalesced': 13996,\n",
       " 'payment-affecting': 17492,\n",
       " 'convention,': 24804,\n",
       " 'mask': 844,\n",
       " '(i<k)': 24791,\n",
       " 'borrowers,': 16448,\n",
       " 'clasp': 6778,\n",
       " 'pyrroline-5-carboxylate': 17260,\n",
       " 'imputing': 23226,\n",
       " 'beings': 23605,\n",
       " 'jetting': 24829,\n",
       " 'blades': 7414,\n",
       " 'lir': 12590,\n",
       " 'time-domain': 8552,\n",
       " 'spelling': 9155,\n",
       " 'request\"': 16935,\n",
       " 'negotiate': 22755,\n",
       " 'defaulting': 12757,\n",
       " 'vary': 6074,\n",
       " 'photograph,': 7802,\n",
       " 'fourier': 5367,\n",
       " 'probability-based': 11439,\n",
       " 'subnetwork': 14129,\n",
       " 'acceptable': 2609,\n",
       " 'caches': 4529,\n",
       " 'homes': 10118,\n",
       " 'ruleset': 8746,\n",
       " 'luminance,': 10730,\n",
       " 'scholarly': 7145,\n",
       " 'repeated,': 13360,\n",
       " 'regime': 15210,\n",
       " 'protocol)': 13512,\n",
       " 'changes,': 5774,\n",
       " 'distinguishable': 6234,\n",
       " 'multi-variable': 12527,\n",
       " 'consumer-desired': 13415,\n",
       " 'infrared-sensitive': 23811,\n",
       " 'concrete,': 17136,\n",
       " 'renewable': 7480,\n",
       " 'incentives,': 14009,\n",
       " '-(mmp-p)/mmp': 21226,\n",
       " 'xor': 4796,\n",
       " 'realm,': 20765,\n",
       " '_i_n,': 22463,\n",
       " 'etherchannel': 10074,\n",
       " 'geo-location': 10527,\n",
       " 'move-from': 21132,\n",
       " 'travelling': 23467,\n",
       " 'during': 218,\n",
       " 'round': 5390,\n",
       " \"items'\": 25590,\n",
       " 'logistics': 3092,\n",
       " 'z-axis,': 13675,\n",
       " 'navigational': 10412,\n",
       " 'extracts,': 7715,\n",
       " 'dialogue': 3242,\n",
       " 'k,': 7333,\n",
       " \"ctmc's,\": 16181,\n",
       " 'z-valuation,': 17742,\n",
       " 'stockouts': 23218,\n",
       " 'computerized-implemented': 20690,\n",
       " 'compensator,': 16145,\n",
       " 'acrylic': 10671,\n",
       " 'self-decommission': 25746,\n",
       " 'well-defined': 13733,\n",
       " 'identity-based': 22987,\n",
       " 'workstations,': 15240,\n",
       " 'approximating,': 23766,\n",
       " 'deleting': 2497,\n",
       " 'contactless': 4102,\n",
       " 'sale': 1043,\n",
       " '(sid)': 24437,\n",
       " 'touchdown': 5817,\n",
       " 'informing': 2888,\n",
       " 'subsystem': 1157,\n",
       " 'deferring': 8788,\n",
       " 'slice,': 25805,\n",
       " 'proxy-requested': 23831,\n",
       " 'casino': 22321,\n",
       " 'encased': 24916,\n",
       " '(cs)': 10271,\n",
       " '(gk)': 17497,\n",
       " 'scrollbar,': 23703,\n",
       " '(co': 20197,\n",
       " 'ease': 15538,\n",
       " 'lathe': 11016,\n",
       " 'addressable,': 22284,\n",
       " 'dynamically': 831,\n",
       " 'state-variables': 8833,\n",
       " 'closing': 2855,\n",
       " 'resume,': 13752,\n",
       " 'read-out': 5015,\n",
       " 'ipl,': 24323,\n",
       " 'reviewable': 11516,\n",
       " 'task-scheduling': 18344,\n",
       " 'preloaded': 15469,\n",
       " '(irm)': 17491,\n",
       " 'margin-like': 16594,\n",
       " 'chinese': 4880,\n",
       " 'section,': 1114,\n",
       " 'fabricated': 7595,\n",
       " 'downloading,': 6978,\n",
       " 'transients': 17043,\n",
       " 'empowering': 19988,\n",
       " 'front': 913,\n",
       " 'steganographically': 11730,\n",
       " 'transmitting': 190,\n",
       " 'particulates': 21268,\n",
       " 'sandwiched': 7181,\n",
       " 'multi-packet': 25307,\n",
       " '(vi)': 5982,\n",
       " 'payout': 6455,\n",
       " ')th': 14038,\n",
       " 'situating': 22470,\n",
       " 'interpolator': 20877,\n",
       " 'designation': 1450,\n",
       " 'marks': 3822,\n",
       " 'managing,': 7739,\n",
       " '(ui)': 6121,\n",
       " 'inspect': 9694,\n",
       " 'allocating': 1025,\n",
       " 'triggering,': 22138,\n",
       " 'subscribing': 6268,\n",
       " 'uncoded': 7451,\n",
       " 'n': 504,\n",
       " 'returning,': 7744,\n",
       " 'tenured': 9812,\n",
       " 'submenu': 15099,\n",
       " 'quick': 5954,\n",
       " 'now': 9312,\n",
       " 'chromatography': 23040,\n",
       " 'circulates': 22236,\n",
       " 'heuristic': 5699,\n",
       " 'sound': 1715,\n",
       " '(magnetic': 25786,\n",
       " 'ailment': 21375,\n",
       " 'handling,': 14898,\n",
       " 'chilled': 8182,\n",
       " 'rgb': 4178,\n",
       " 'renderable': 12005,\n",
       " 'inducement': 15937,\n",
       " 'late': 7107,\n",
       " 'n/k+': 16276,\n",
       " 'artifacts': 2286,\n",
       " 'hid': 6347,\n",
       " \"shippers'\": 21899,\n",
       " 'depletion': 16867,\n",
       " 'streamed': 6495,\n",
       " '03a,': 20677,\n",
       " 'vendor,': 4418,\n",
       " 'multi-temperature': 18779,\n",
       " 'diagnostics': 8835,\n",
       " 'each': 29,\n",
       " 'presentations,': 19366,\n",
       " '(b)-(c)': 20097,\n",
       " 'container': 1301,\n",
       " 'pre-configured': 8292,\n",
       " 'invited': 6259,\n",
       " 'inactive': 3444,\n",
       " 'repricing': 20965,\n",
       " 'pot': 20192,\n",
       " 'absorbing,': 23390,\n",
       " 'ibis': 10495,\n",
       " 'mediated': 17946,\n",
       " 'feedlot': 13635,\n",
       " 'emulating': 5309,\n",
       " 'rack,': 9515,\n",
       " 'ip-can': 15083,\n",
       " 'moment': 2963,\n",
       " 'postings,': 17903,\n",
       " 'extracted': 502,\n",
       " 'accruing': 24894,\n",
       " 'y-axis,': 9535,\n",
       " 'diagramming': 24315,\n",
       " 'extractor,': 11539,\n",
       " 'slab': 18972,\n",
       " 'filled': 5298,\n",
       " 'edited,': 25053,\n",
       " '(g': 7039,\n",
       " '(c),': 7637,\n",
       " 'concludes': 11926,\n",
       " 'multipliers,': 14617,\n",
       " 'paired,': 18705,\n",
       " 'entities,': 2135,\n",
       " 'plane': 1102,\n",
       " 'mepkc,': 21205,\n",
       " '(ocv)': 20862,\n",
       " 'tickets,': 22319,\n",
       " 'feature-value': 19040,\n",
       " 'funding': 4226,\n",
       " 'itar-related': 22306,\n",
       " 'start-of-retention-time': 17915,\n",
       " 'gesture': 681,\n",
       " 'placement,': 10884,\n",
       " 'grid': 894,\n",
       " 'bid-cutoff': 12743,\n",
       " 'payment-over-phone': 25695,\n",
       " 'consoles': 11709,\n",
       " 'clustering,': 6521,\n",
       " 'zero': 2074,\n",
       " '(m*k)/v': 19209,\n",
       " 'namespaces': 20816,\n",
       " 'taskbar,': 19850,\n",
       " 'charged': 2377,\n",
       " 'hop': 13963,\n",
       " 'macroblock': 9958,\n",
       " '(arp)': 17638,\n",
       " '/c/': 15447,\n",
       " 'icc': 15821,\n",
       " 'intervector': 15732,\n",
       " 'conveys': 7892,\n",
       " 'resolved-attribute': 12037,\n",
       " 'mime': 12321,\n",
       " 'communicators': 10170,\n",
       " 'qubo': 12034,\n",
       " 'dialing': 13915,\n",
       " 'terminations': 23675,\n",
       " 'crowd-sourced': 12934,\n",
       " 'compositing': 8663,\n",
       " 'work-seeking': 7449,\n",
       " 'ith': 10078,\n",
       " 'those': 1554,\n",
       " 'materialized': 4048,\n",
       " '(e)': 852,\n",
       " 'current,': 9343,\n",
       " 'histograms,': 14201,\n",
       " 'producers': 11401,\n",
       " 'illness': 25375,\n",
       " '(3d-mm)': 24553,\n",
       " 'lawful': 25066,\n",
       " 'ses': 8202,\n",
       " '(f2),': 23129,\n",
       " 'dynamics': 11102,\n",
       " 'fs': 21099,\n",
       " '(s-t)': 19396,\n",
       " 'upgrading': 9254,\n",
       " '44)': 14168,\n",
       " 'embracing': 12962,\n",
       " 'work-related': 14468,\n",
       " 'demoting': 11634,\n",
       " 'ml': 8244,\n",
       " 'manageable': 6730,\n",
       " 'stimulating,': 21265,\n",
       " '(78)': 12777,\n",
       " 'initializer': 13244,\n",
       " 'e(km,': 10541,\n",
       " 'legal': 2482,\n",
       " 'powered': 2605,\n",
       " 'premiums,': 12157,\n",
       " 'opens': 10045,\n",
       " 'words,': 3355,\n",
       " 'communicating,': 4786,\n",
       " 'clicks,': 23693,\n",
       " 'mmc': 8257,\n",
       " 'determining': 53,\n",
       " 'multi-layer': 5908,\n",
       " 'router,': 4740,\n",
       " 'processings': 21378,\n",
       " 'pre-profiled': 11191,\n",
       " 'operates,': 13098,\n",
       " 'misaligned': 16193,\n",
       " 'analyzer)': 21031,\n",
       " 'catalog': 1676,\n",
       " 'stably': 13551,\n",
       " 'secs': 12263,\n",
       " 're-sampled': 20774,\n",
       " 'f(i)=(im': 20702,\n",
       " 'well,': 19125,\n",
       " 'inward': 9685,\n",
       " 'resin,': 8767,\n",
       " 'stamp': 2806,\n",
       " 'exhibitors': 14602,\n",
       " 'generate': 164,\n",
       " 'namely,': 8429,\n",
       " \"collaborators'\": 10833,\n",
       " 'discharges': 25114,\n",
       " 'baseband': 12092,\n",
       " 'fuzzy': 5926,\n",
       " 'amino': 5249,\n",
       " 'oriented': 2789,\n",
       " 'wireless-communication': 19452,\n",
       " 'forming,': 15793,\n",
       " 'queues': 3392,\n",
       " 'consolidator': 10188,\n",
       " 'indications,': 18620,\n",
       " 'attaching': 4406,\n",
       " 'feeding': 3029,\n",
       " 'restrictive': 16190,\n",
       " 'will,': 16974,\n",
       " 'installers,': 23889,\n",
       " 'over-drive': 6917,\n",
       " 'cushion': 16300,\n",
       " 'microscopic': 11565,\n",
       " 'synergistic': 20267,\n",
       " 'rotates': 9204,\n",
       " 'effecting': 2277,\n",
       " 'lift': 8541,\n",
       " 'biochemical': 9504,\n",
       " 'whips,': 23471,\n",
       " 'minutia': 16522,\n",
       " 'microfluidic': 20917,\n",
       " '(gpe),': 19898,\n",
       " 'tick': 15567,\n",
       " 'dentifrices,': 23387,\n",
       " 'tentative': 17557,\n",
       " '\"9\"': 22404,\n",
       " 'mini-map': 13206,\n",
       " 'film,': 5644,\n",
       " 'spheres,': 21489,\n",
       " '(pattern)': 18519,\n",
       " 'asymptomatic': 16894,\n",
       " 'worse,': 21519,\n",
       " 'periodically-updated': 13534,\n",
       " 'break-point': 12139,\n",
       " 'conflicting': 7329,\n",
       " 'player': 1323,\n",
       " 'recalculating': 6258,\n",
       " 'correctness': 8351,\n",
       " 'tokenizing': 9212,\n",
       " 'executable': 482,\n",
       " 'computer-mediated': 11512,\n",
       " 'leased': 3996,\n",
       " 'inter-packet': 21274,\n",
       " 'wheel': 1712,\n",
       " '(cps)': 20344,\n",
       " 'money,': 22312,\n",
       " 'essential': 13848,\n",
       " 'existed': 24661,\n",
       " 'contending': 15766,\n",
       " 'interval': 927,\n",
       " 'trial,': 11464,\n",
       " 'established': 1361,\n",
       " '%,': 18196,\n",
       " 'sub-bond': 15863,\n",
       " 'questions,': 24510,\n",
       " 'snoops': 18113,\n",
       " 'sonar': 10416,\n",
       " 'batch,': 14938,\n",
       " 'radioactive': 8862,\n",
       " 'finished': 6320,\n",
       " 'rectified': 21052,\n",
       " '(308)': 11504,\n",
       " 'babies': 23398,\n",
       " 'self-identifier': 9962,\n",
       " 'defect,': 11597,\n",
       " 'composed': 1858,\n",
       " 'audio/visual': 12988,\n",
       " 'illustrative': 20059,\n",
       " 'netlist': 2433,\n",
       " 'learning-model': 22343,\n",
       " 'gap': 2693,\n",
       " 'velcro': 17159,\n",
       " 'stand-alone,': 17865,\n",
       " 'nodal': 5414,\n",
       " 'bore': 5317,\n",
       " 'telecentric': 9163,\n",
       " 'bot,': 24736,\n",
       " 'trilingual': 9180,\n",
       " 'affixed': 5906,\n",
       " 'reactor': 6388,\n",
       " 'dspecific-dmmimum': 22624,\n",
       " 'superposition': 8624,\n",
       " 'manipulator)': 15980,\n",
       " 'current-time-period-expected-service-request': 13260,\n",
       " 'forbid': 19206,\n",
       " 'non-terminal': 6161,\n",
       " 'fpga': 6965,\n",
       " 'directing,': 7608,\n",
       " 'cancels': 21607,\n",
       " 'anatomic': 9170,\n",
       " 'usefulness': 11018,\n",
       " 'cuff,': 18003,\n",
       " 'differential-current': 22433,\n",
       " 'touched': 2294,\n",
       " 'regular': 2712,\n",
       " 'optimally': 10026,\n",
       " 'short-range': 8942,\n",
       " 'designed-in': 22742,\n",
       " 'successively': 3682,\n",
       " 'mouse': 2781,\n",
       " 'low-order': 5650,\n",
       " 'facility': 916,\n",
       " 'p2': 10682,\n",
       " 'multifunctional': 7774,\n",
       " 'then': 730,\n",
       " '(320)': 11566,\n",
       " 'lookups': 11413,\n",
       " '255)': 25844,\n",
       " 'and,': 568,\n",
       " 'notable': 25400,\n",
       " 'commencing': 5734,\n",
       " 'hinges,': 21902,\n",
       " 'explaining': 15227,\n",
       " 'miss,': 7786,\n",
       " 'graphics,': 13794,\n",
       " 'empty,': 9679,\n",
       " 'output-color': 24976,\n",
       " 'thread-specific': 10528,\n",
       " 'downloader,': 20872,\n",
       " 'warranty/maintenance/service': 15620,\n",
       " 'main-door-open': 14908,\n",
       " 'subordinating': 13144,\n",
       " 'filtered': 1922,\n",
       " 'masses,': 20474,\n",
       " 'idl': 15290,\n",
       " 'accommodation': 6297,\n",
       " 'located': 440,\n",
       " 'shows)': 19916,\n",
       " 'granted': 4000,\n",
       " 'probability,': 9375,\n",
       " 'fraud,': 23963,\n",
       " 'impulses': 14958,\n",
       " 'evaporator,': 22388,\n",
       " 'criticality': 14660,\n",
       " 'variogram-based': 23244,\n",
       " 'xmlhttprequest': 17193,\n",
       " 'acknowledge': 23731,\n",
       " 'faqs': 9868,\n",
       " 'bilingual': 10562,\n",
       " 'overrideable': 16270,\n",
       " 'legends': 15071,\n",
       " 'let': 11754,\n",
       " 'framework,': 8754,\n",
       " 'probably-correct': 11447,\n",
       " 'vbus': 16526,\n",
       " 'sc': 12574,\n",
       " 'computed': 1596,\n",
       " 'pagewidth': 15113,\n",
       " 'collage': 15360,\n",
       " 'parent': 2208,\n",
       " 'cardboard': 10361,\n",
       " 'completely': 5003,\n",
       " 'likeness,': 20117,\n",
       " '\"work-seeking': 21471,\n",
       " 'uninstalls': 25459,\n",
       " 'variances': 23155,\n",
       " 'two-terminal': 8186,\n",
       " ')ci-': 20310,\n",
       " '(7)': 4032,\n",
       " 'awarded': 7232,\n",
       " 'xslt': 23967,\n",
       " 'me': 7507,\n",
       " 'covariance': 4552,\n",
       " '\"8\",': 22403,\n",
       " 'sigmoid': 12250,\n",
       " 'schedulable': 5671,\n",
       " 'fails': 3820,\n",
       " 'au': 15385,\n",
       " 'user-selection': 23180,\n",
       " 'ledge': 16670,\n",
       " 'down-conversion': 14629,\n",
       " 'package-designing': 20076,\n",
       " 'fixer': 10566,\n",
       " 'tabulation': 18302,\n",
       " 'analyzer,': 5816,\n",
       " 'spite': 23734,\n",
       " 'constitute': 4771,\n",
       " '(sut),': 25280,\n",
       " 're-encoding': 17695,\n",
       " 'wearing': 5603,\n",
       " 'xij,': 18597,\n",
       " '(eda)': 13811,\n",
       " 'media-metadata': 20330,\n",
       " 'mechanical': 2346,\n",
       " 'set-document': 6413,\n",
       " 'instancing': 13525,\n",
       " 'owned': 2755,\n",
       " 'reserve': 2913,\n",
       " 'sequence-of-events': 18583,\n",
       " 'reckonings': 25719,\n",
       " 'images,': 1132,\n",
       " 'up-to-date': 14083,\n",
       " 'keystrokes,': 15611,\n",
       " 'dr),': 24887,\n",
       " '(uniform': 24973,\n",
       " 'him/herself,': 24722,\n",
       " 'correction,': 3718,\n",
       " 'spine-based': 15715,\n",
       " 'premises': 4309,\n",
       " 'survivor': 5141,\n",
       " 'deferred': 5901,\n",
       " 'authorize': 6502,\n",
       " 'address/control': 17923,\n",
       " 'fitting': 3716,\n",
       " 'tube': 3805,\n",
       " 'rg2': 20423,\n",
       " 'url,': 15919,\n",
       " 'correspondence,': 11258,\n",
       " 'unit-time': 19493,\n",
       " 'trigger,': 9546,\n",
       " 'leaves,': 13388,\n",
       " 'latency,': 9425,\n",
       " 'heat-generating': 8508,\n",
       " 'auto-launch': 20385,\n",
       " 'assigning': 496,\n",
       " 'non-confidential': 6611,\n",
       " 'line-item': 12673,\n",
       " '(eet)': 22309,\n",
       " 'ownership': 2907,\n",
       " 'female': 11007,\n",
       " 'redirecting,': 18910,\n",
       " 'transformed': 2278,\n",
       " 'deleted': 4581,\n",
       " 'delivers': 4950,\n",
       " 'holders': 7502,\n",
       " 'inspected,': 14620,\n",
       " 'b-splines': 10586,\n",
       " 'tissue-particle': 12666,\n",
       " 'therethrough': 8464,\n",
       " 'inception': 16717,\n",
       " 'store,': 2131,\n",
       " 'encoder,': 5863,\n",
       " 'elevations': 25303,\n",
       " 'consult': 12223,\n",
       " '2m+': 14691,\n",
       " 'self-diagnosis': 22301,\n",
       " 'technical': 1810,\n",
       " \"'force\": 12060,\n",
       " 'persistently': 9259,\n",
       " 's-th': 13759,\n",
       " 'file-level': 8468,\n",
       " 'thresholds': 7042,\n",
       " 'fiduciary': 8220,\n",
       " 'salience': 14462,\n",
       " '(t_l': 22364,\n",
       " 'drink': 8435,\n",
       " 'arithmetically': 7866,\n",
       " 'integer,': 7831,\n",
       " 'tubular': 4847,\n",
       " 'tone-generator-providing': 25793,\n",
       " 'oes': 18591,\n",
       " 'memory,': 411,\n",
       " '\"retailers\")': 25577,\n",
       " 'equivalencies,': 22871,\n",
       " 'circulating': 11749,\n",
       " 'industry-accepted': 17993,\n",
       " 'anterior': 19852,\n",
       " 'desiccant': 8403,\n",
       " 'cps': 14187,\n",
       " 'raster,': 24568,\n",
       " '(qi)': 25801,\n",
       " 'consolidating': 8960,\n",
       " 'simulation': 760,\n",
       " 'selected': 75,\n",
       " 'relaxin3,': 21255,\n",
       " 'pertain': 12724,\n",
       " 'supermarket': 13254,\n",
       " 'npm': 21693,\n",
       " 'mandrel': 10474,\n",
       " 'conditions': 809,\n",
       " 'unidentified': 24732,\n",
       " 'wear-leveling': 17786,\n",
       " 'randomization': 10448,\n",
       " 'substrates,': 11259,\n",
       " 'configuration,': 3442,\n",
       " \"id's\": 19177,\n",
       " 'solved,': 25157,\n",
       " 'patient-authorizing': 20728,\n",
       " 'sub-group': 8167,\n",
       " '(uut)': 24899,\n",
       " 'distributorship': 14869,\n",
       " 'discrete': 1482,\n",
       " 'dimensionally-reduced': 16549,\n",
       " 'hypothetical': 8825,\n",
       " 'facilitate': 1594,\n",
       " 'properties': 868,\n",
       " 'sheathing': 25696,\n",
       " 'allow': 962,\n",
       " 'placeholder': 5346,\n",
       " 'layering': 7171,\n",
       " 'totes,': 23086,\n",
       " 'raid': 2108,\n",
       " 'reading,': 5718,\n",
       " 'universe': 6291,\n",
       " '(6),': 10688,\n",
       " 'firms,': 16439,\n",
       " 'transmission,': 3560,\n",
       " 'yarn,': 25673,\n",
       " 'likewise': 14642,\n",
       " 'irregularity-information': 10249,\n",
       " 'non-tissue': 25851,\n",
       " 'boot': 1480,\n",
       " '()': 6788,\n",
       " '(va)': 18029,\n",
       " 'semiconducting': 20793,\n",
       " 'boxes,': 21359,\n",
       " 'wearout': 23743,\n",
       " 'management-discipline': 18679,\n",
       " 'pod': 20260,\n",
       " 'supervisory': 21709,\n",
       " 'informative': 5109,\n",
       " '56)': 10646,\n",
       " 'cleared': 9495,\n",
       " 'left-,': 12747,\n",
       " 'arginine': 12289,\n",
       " 'detached': 11554,\n",
       " 'snooping': 9835,\n",
       " 'emission': 2825,\n",
       " 'appending,': 21924,\n",
       " 'resending': 12769,\n",
       " 'positional': 1796,\n",
       " 'skippable': 23707,\n",
       " 'stored-program': 12685,\n",
       " 'column/row': 7522,\n",
       " '(m,': 13728,\n",
       " 'movable': 1863,\n",
       " '(gi)': 18222,\n",
       " 'constitution': 14033,\n",
       " 'works': 4156,\n",
       " 'size,': 3003,\n",
       " 'expression': 998,\n",
       " 'pits,': 17309,\n",
       " 'furthermore': 11314,\n",
       " 'replenishing': 18637,\n",
       " 'extendable,': 15515,\n",
       " 'buddy': 9258,\n",
       " 'activation': 1397,\n",
       " '830)': 15728,\n",
       " 'electrode': 654,\n",
       " 'inquiries': 6791,\n",
       " 'refactorings,': 25852,\n",
       " 'segmentally': 20381,\n",
       " 'billable': 20905,\n",
       " 'sustained': 4384,\n",
       " 'multiple': 275,\n",
       " 'expressions,': 8322,\n",
       " 'information-transmitting': 21700,\n",
       " 'unrecognized': 7263,\n",
       " 'browsers,': 23997,\n",
       " 'authenticate': 3357,\n",
       " '=n,': 19212,\n",
       " 'external-motion': 25030,\n",
       " 'fulfils': 25672,\n",
       " 'attitude': 4828,\n",
       " 'evenly': 10291,\n",
       " 'weight': 1315,\n",
       " 'bulletin': 7513,\n",
       " 'off-lattice': 15280,\n",
       " 'check-cashing': 12271,\n",
       " 'arbitrated': 9968,\n",
       " 'crossword,': 21194,\n",
       " 'purse': 14573,\n",
       " 'sourcing': 7204,\n",
       " '(ngs)': 22099,\n",
       " 'double': 7090,\n",
       " 'develop': 4629,\n",
       " 'disabling,': 13755,\n",
       " 'macros': 11082,\n",
       " 'hotkeys': 8259,\n",
       " 'referring': 1681,\n",
       " '(aldh': 17294,\n",
       " 'infrared-ray': 14349,\n",
       " 'forwarding': 1248,\n",
       " 'recompiling': 21881,\n",
       " '(a-2)': 19217,\n",
       " 'effectiveness,': 20956,\n",
       " 'osf': 24638,\n",
       " 'describe': 3773,\n",
       " 'grate': 9801,\n",
       " 'autocorrelation': 9928,\n",
       " 'products': 547,\n",
       " 'impart': 11048,\n",
       " 'designer,': 9024,\n",
       " '(rom)': 12368,\n",
       " 'guaranteeing': 14784,\n",
       " 'leave,': 13861,\n",
       " 'isochronous': 7080,\n",
       " 'consignee,': 24279,\n",
       " 'k-space': 7300,\n",
       " 'nvm': 9711,\n",
       " 'hotkeys,': 25161,\n",
       " 'lumen,': 19363,\n",
       " 'valid,': 4442,\n",
       " 'dll': 25173,\n",
       " 'assessment-event': 12543,\n",
       " 'ionized': 23886,\n",
       " 'impedance': 2765,\n",
       " 'archived': 5138,\n",
       " 'behavioral': 2190,\n",
       " 'fifth': 2887,\n",
       " 're-using': 23104,\n",
       " 'health-care': 2900,\n",
       " 'light-reflecting': 11372,\n",
       " 'policyholder': 13826,\n",
       " 'entity-set': 17996,\n",
       " '(sdram)': 23030,\n",
       " 'providable': 21420,\n",
       " 'conveying': 2415,\n",
       " 'nominally': 11980,\n",
       " 'photos,': 12151,\n",
       " 'investment-resulting': 15710,\n",
       " 'ball': 25252,\n",
       " 'torsion': 16581,\n",
       " 'off-map': 6902,\n",
       " 'skin-pixels': 24845,\n",
       " 'branches,': 11664,\n",
       " 'engagable': 12183,\n",
       " 'esa': 16797,\n",
       " 'attribute': 359,\n",
       " 'analog-to-digital': 4098,\n",
       " 'entity-instance-entity-influence': 12397,\n",
       " 'patterning': 12191,\n",
       " 'sub-pixel': 9115,\n",
       " 'reissuing': 25736,\n",
       " '(d),': 5269,\n",
       " 'stackable': 17301,\n",
       " 'mash-up': 19707,\n",
       " 'geodetic': 14502,\n",
       " 'lease,': 10635,\n",
       " 'service-group': 21707,\n",
       " 'ordinal': 8188,\n",
       " 'signal': 62,\n",
       " 'audio,': 7685,\n",
       " 'avatars,': 21141,\n",
       " 'phrasal': 9907,\n",
       " 'unitless': 20521,\n",
       " 'inter-integrated': 25593,\n",
       " 'tapioca,': 23557,\n",
       " 'lets': 13487,\n",
       " 'color,': 4449,\n",
       " 'threads': 1741,\n",
       " 'uneven': 23895,\n",
       " 'created,': 7709,\n",
       " 'over-approximation': 17977,\n",
       " 'developer': 5271,\n",
       " 'non-meta-data': 18457,\n",
       " 'repositioning': 4532,\n",
       " 'save': 2331,\n",
       " 'commanding': 5202,\n",
       " 'customer': 224,\n",
       " 'superposed': 6672,\n",
       " 'commercialization,': 23686,\n",
       " 'snapshot,': 8035,\n",
       " 'imposed': 6757,\n",
       " 'means,': 707,\n",
       " 'need,': 9774,\n",
       " 'vpn': 4889,\n",
       " 'automating': 11215,\n",
       " 'simulant': 6337,\n",
       " 'scenarios,': 13245,\n",
       " 'security,': 4034,\n",
       " 'backing': 4153,\n",
       " 'protected': 1752,\n",
       " 'armed': 19297,\n",
       " 'rpc': 13234,\n",
       " 'pr2': 13151,\n",
       " 'pins': 2160,\n",
       " 'extrovert': 12933,\n",
       " 'strip,': 7850,\n",
       " 'time-varying': 4983,\n",
       " 'understandable': 14387,\n",
       " 'conjoined': 11244,\n",
       " 'superimposed': 4163,\n",
       " 'providers,': 4563,\n",
       " 'staring': 18142,\n",
       " 'fasten': 13233,\n",
       " 'status,': 2984,\n",
       " 'locomotive': 4842,\n",
       " 'equations,': 7134,\n",
       " 'mainshaft': 8502,\n",
       " 'value\",': 22988,\n",
       " 'integer': 1552,\n",
       " '(scps)': 25608,\n",
       " '(\"second': 20526,\n",
       " 'pauses': 13091,\n",
       " 'outage,': 23185,\n",
       " 'propriety': 25726,\n",
       " 'boards': 3972,\n",
       " 'succeed': 10360,\n",
       " 'redistribute': 24248,\n",
       " 'lba': 12178,\n",
       " '(tsrsb)': 18817,\n",
       " 'parameters': 249,\n",
       " 'quantization': 3488,\n",
       " 'filename,': 18691,\n",
       " 'contact,': 8693,\n",
       " 'vender': 25207,\n",
       " 'synthesized/laid': 16621,\n",
       " 'assumption,': 21153,\n",
       " 'crankshaft': 12644,\n",
       " 'readable': 461,\n",
       " 'negotiation': 3967,\n",
       " 'exponential': 8598,\n",
       " 'bunk': 13634,\n",
       " \"compartment's\": 11962,\n",
       " 'productmark': 9431,\n",
       " 'life-expectancy': 19186,\n",
       " 'hardness': 21259,\n",
       " '(tec)': 25727,\n",
       " 'uml': 14854,\n",
       " 'totals': 25841,\n",
       " 'hcps': 16531,\n",
       " 'talking': 17605,\n",
       " 'subpixels': 11723,\n",
       " 'mashable': 24537,\n",
       " 'hybrid': 2283,\n",
       " 'biopsy': 7418,\n",
       " 'accelerator': 2431,\n",
       " '(4,5),': 24723,\n",
       " 'positive': 1379,\n",
       " 'precision': 10757,\n",
       " 'tax-advantaged': 11607,\n",
       " 'celebrity': 12622,\n",
       " 'technology)': 24018,\n",
       " 'prestored': 7844,\n",
       " '(dam),': 24369,\n",
       " 'profile-based': 15233,\n",
       " 'growth': 5187,\n",
       " 'subrack': 12601,\n",
       " 'certap': 21155,\n",
       " 'desktop,': 14607,\n",
       " '(das)': 23874,\n",
       " '(mod': 6769,\n",
       " 'owl': 8949,\n",
       " 'pen-like': 20092,\n",
       " 'limitation': 5021,\n",
       " 'imaged,': 24703,\n",
       " 'flap': 5958,\n",
       " 'take-off': 11059,\n",
       " '(dc)': 16857,\n",
       " 'moreover': 13030,\n",
       " 'cached': 2226,\n",
       " 'internet-based,': 16438,\n",
       " 'describes': 2186,\n",
       " 'bearer': 10619,\n",
       " 'credentials,': 6579,\n",
       " 'drms': 10158,\n",
       " 'twelfth': 22169,\n",
       " 'comprehension': 7278,\n",
       " 'arbitrage': 10656,\n",
       " 'provisioned': 5575,\n",
       " 'prespecifying': 23315,\n",
       " 'minimum,': 18957,\n",
       " 'insulation': 6210,\n",
       " 'tagging,': 18804,\n",
       " 'countries,': 14716,\n",
       " '(canceled)': 10828,\n",
       " 'compiling': 2383,\n",
       " 'embodiment': 7196,\n",
       " 'authenticates': 5552,\n",
       " 'slidably': 5201,\n",
       " 'longitudinally': 11202,\n",
       " 'merchants': 5391,\n",
       " '(nms)': 19392,\n",
       " 'virial': 14707,\n",
       " 'lower-temperature': 22505,\n",
       " 'fluid,': 7628,\n",
       " 'logins': 16280,\n",
       " 'productions': 24835,\n",
       " 'truncating': 25571,\n",
       " '(san)': 10924,\n",
       " 'seminars': 12719,\n",
       " 'preposition,': 22888,\n",
       " 'pixel-offset': 19153,\n",
       " '(c)': 426,\n",
       " ...}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_claim.word_index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's have a look at our sequence length distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest sequence is 3338 tokens long.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAZcAAAEWCAYAAACqitpwAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nxczMCve/4YlxA6xFAq8AAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4fbf67f908>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "X_length = [len(x) for x in X_seqs]\n",
    "max_length = max(X_length)\n",
    "print(\"Our longest sequence is {0} tokens long.\".format(max_length))\n",
    "\n",
    "bins = np.linspace(0, max_length, 200)\n",
    "plt.hist(X_length, bins)\n",
    "plt.title('Claim 1 - Sequence Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEWCAYAAAB8LwAVAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nQZiZWan/D9yBiU1QFvGHAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4fbf6a2c88>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Let's zoom in on 0 to 500\n",
    "bins = np.linspace(0, 500, 100)\n",
    "plt.hist(X_length, bins)\n",
    "plt.title('Claim 1 - Sequence Length')\n",
    "plt.ylabel('No. of claims');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit our sequence length to 300 on our input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest sequence is 57 tokens long.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAY4AAAEWCAYAAABxMXBSAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f4fbd6c1278>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Y_length = [len(y) for y in Y_seqs]\n",
    "max_y_length = max(Y_length)\n",
    "print(\"Our longest sequence is {0} tokens long.\".format(max_y_length))\n",
    "\n",
    "bins = np.linspace(0, max_y_length, 60)\n",
    "plt.hist(Y_length, bins)\n",
    "plt.title('Title - Sequence Length')\n",
    "plt.ylabel('No. of samples');\n",
    "plt.xlabel('Sequence Length (words)');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's limit to 20 on our output.  \n",
    "\n",
    "So we can pad our input and output sequences, limiting to 300 on the input and 20 on the output."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(X_seqs, maxlen=300)\n",
    "Y = pad_sequences(Y_seqs, maxlen=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X data has shape (11428, 300) and our Y data has shape (11428, 20)\n"
     ]
    }
   ],
   "source": [
    "print(\"Our X data has shape {0} and our Y data has shape {1}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Building the Sequence to Sequence Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Some hyperparameters - start with those used in this example -\n",
    "# https://github.com/fchollet/keras/blob/master/examples/lstm_seq2seq.py\n",
    "batch_size = 64  # Batch size for training.\n",
    "epochs = 20  # Number of epochs to train for.\n",
    "\n",
    "# The number of encoder tokens - we have limited our vocabulary to 10000\n",
    "X_vocab_len = 10000 \n",
    "X_max_len = 300\n",
    "# We limit our decoder to a vocabulary of 5000\n",
    "y_vocab_len = 5000\n",
    "y_max_len = 20\n",
    "\n",
    "hidden_size = 100 # Latent dimensionality of the encoding space.\n",
    "num_layers = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This blog post - https://chunml.github.io/ChunML.github.io/project/Sequence-To-Sequence/ and the code here - https://github.com/ChunML/seq2seq/blob/master/seq2seq_utils.py is useful for a word level seq2seq model.  \n",
    "\n",
    "We can have the input as integers but we need the decoder output (i.e. our Y) as one-hot encoding. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def to_one_hot(input_seqs, seq_max_len, vocab_len):\n",
    "    \"\"\" Convert a sequence of integers to a sequence of one-hot vectors.\"\"\"\n",
    "    one_hot = np.zeros((len(input_seqs), seq_max_len, vocab_len))\n",
    "    for i, sequence in enumerate(input_seqs):\n",
    "        for t, word_int in enumerate(sequence):\n",
    "            one_hot[i, t, word_int] = 1\n",
    "    return one_hot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get a memory error when we try to create a complete Y_one_hot matrix. As per the above blogpost we can chop into blocks of 1000 for training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4999"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max([max(y) for y in Y])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Activation, TimeDistributed, Dense, RepeatVector, recurrent, Embedding\n",
    "from keras.layers.recurrent import LSTM\n",
    "from keras.optimizers import Adam, RMSprop\n",
    "\n",
    "def create_model(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers):\n",
    "    model = Sequential()\n",
    "\n",
    "    # Creating encoder network\n",
    "    model.add(Embedding(X_vocab_len, 1000, input_length=X_max_len, mask_zero=True))\n",
    "    model.add(LSTM(hidden_size))\n",
    "    model.add(RepeatVector(y_max_len))\n",
    "\n",
    "    # Creating decoder network\n",
    "    for _ in range(num_layers):\n",
    "        model.add(LSTM(hidden_size, return_sequences=True))\n",
    "    model.add(TimeDistributed(Dense(y_vocab_len)))\n",
    "    model.add(Activation('softmax'))\n",
    "    model.compile(loss='categorical_crossentropy',\n",
    "            optimizer='rmsprop',\n",
    "            metrics=['accuracy'])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Compiling model...\n"
     ]
    }
   ],
   "source": [
    "print('[INFO] Compiling model...')\n",
    "model = create_model(X_vocab_len, X_max_len, y_vocab_len, y_max_len, hidden_size, num_layers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 300, 1000)         10000000  \n",
      "_________________________________________________________________\n",
      "lstm_1 (LSTM)                (None, 100)               440400    \n",
      "_________________________________________________________________\n",
      "repeat_vector_1 (RepeatVecto (None, 20, 100)           0         \n",
      "_________________________________________________________________\n",
      "lstm_2 (LSTM)                (None, 20, 100)           80400     \n",
      "_________________________________________________________________\n",
      "time_distributed_1 (TimeDist (None, 20, 5000)          505000    \n",
      "_________________________________________________________________\n",
      "activation_1 (Activation)    (None, 20, 5000)          0         \n",
      "=================================================================\n",
      "Total params: 11,025,800\n",
      "Trainable params: 11,025,800\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 0th 0/11428 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/keras/callbacks.py:405: RuntimeWarning: Can save best model only with val_acc available, skipping.\n",
      "  'skipping.' % (self.monitor), RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "287s - loss: 6.1390 - acc: 0.5384\n",
      "[INFO] Training model: epoch 0th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "270s - loss: 3.8113 - acc: 0.5733\n",
      "[INFO] Training model: epoch 0th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "287s - loss: 3.3611 - acc: 0.5739\n",
      "[INFO] Training model: epoch 0th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "332s - loss: 3.3687 - acc: 0.5711\n",
      "[INFO] Training model: epoch 0th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "324s - loss: 3.3579 - acc: 0.5738\n",
      "[INFO] Training model: epoch 0th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "313s - loss: 3.3085 - acc: 0.5797\n",
      "[INFO] Training model: epoch 0th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "257s - loss: 3.4082 - acc: 0.5678\n",
      "[INFO] Training model: epoch 0th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.4375 - acc: 0.5634\n",
      "[INFO] Training model: epoch 0th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.4586 - acc: 0.5649\n",
      "[INFO] Training model: epoch 0th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.4049 - acc: 0.5746\n",
      "[INFO] Training model: epoch 0th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.4159 - acc: 0.5709\n",
      "[INFO] Training model: epoch 0th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.4065 - acc: 0.5707\n",
      "[INFO] Training model: epoch 1th 0/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.3416 - acc: 0.5749\n",
      "[INFO] Training model: epoch 1th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3778 - acc: 0.5756\n",
      "[INFO] Training model: epoch 1th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4505 - acc: 0.5613\n",
      "[INFO] Training model: epoch 1th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.3187 - acc: 0.5794\n",
      "[INFO] Training model: epoch 1th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3991 - acc: 0.5737\n",
      "[INFO] Training model: epoch 1th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.4407 - acc: 0.5679\n",
      "[INFO] Training model: epoch 1th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.4355 - acc: 0.5701\n",
      "[INFO] Training model: epoch 1th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3633 - acc: 0.5822\n",
      "[INFO] Training model: epoch 1th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3950 - acc: 0.5752\n",
      "[INFO] Training model: epoch 1th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4673 - acc: 0.5664\n",
      "[INFO] Training model: epoch 1th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "242s - loss: 3.4952 - acc: 0.5600\n",
      "[INFO] Training model: epoch 1th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.4073 - acc: 0.5745\n",
      "[INFO] Training model: epoch 2th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4065 - acc: 0.5703\n",
      "[INFO] Training model: epoch 2th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3815 - acc: 0.5762\n",
      "[INFO] Training model: epoch 2th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3703 - acc: 0.5742\n",
      "[INFO] Training model: epoch 2th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4144 - acc: 0.5678\n",
      "[INFO] Training model: epoch 2th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4393 - acc: 0.5654\n",
      "[INFO] Training model: epoch 2th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4079 - acc: 0.5655\n",
      "[INFO] Training model: epoch 2th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3477 - acc: 0.5778\n",
      "[INFO] Training model: epoch 2th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3655 - acc: 0.5731\n",
      "[INFO] Training model: epoch 2th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3703 - acc: 0.5759\n",
      "[INFO] Training model: epoch 2th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4561 - acc: 0.5675\n",
      "[INFO] Training model: epoch 2th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3593 - acc: 0.5749\n",
      "[INFO] Training model: epoch 2th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "104s - loss: 3.3689 - acc: 0.5703\n",
      "[INFO] Training model: epoch 3th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3188 - acc: 0.5737\n",
      "[INFO] Training model: epoch 3th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4081 - acc: 0.5652\n",
      "[INFO] Training model: epoch 3th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.2864 - acc: 0.5826\n",
      "[INFO] Training model: epoch 3th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3737 - acc: 0.5680\n",
      "[INFO] Training model: epoch 3th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.4268 - acc: 0.5647\n",
      "[INFO] Training model: epoch 3th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3475 - acc: 0.5720\n",
      "[INFO] Training model: epoch 3th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3700 - acc: 0.5707\n",
      "[INFO] Training model: epoch 3th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3447 - acc: 0.5697\n",
      "[INFO] Training model: epoch 3th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.2800 - acc: 0.5812\n",
      "[INFO] Training model: epoch 3th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2875 - acc: 0.5789\n",
      "[INFO] Training model: epoch 3th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3890 - acc: 0.5637\n",
      "[INFO] Training model: epoch 3th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.3338 - acc: 0.5662\n",
      "[INFO] Training model: epoch 4th 0/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1837 - acc: 0.5869\n",
      "[INFO] Training model: epoch 4th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.3425 - acc: 0.5714\n",
      "[INFO] Training model: epoch 4th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3358 - acc: 0.5649\n",
      "[INFO] Training model: epoch 4th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.3389 - acc: 0.5689\n",
      "[INFO] Training model: epoch 4th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3292 - acc: 0.5695\n",
      "[INFO] Training model: epoch 4th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.3068 - acc: 0.5726\n",
      "[INFO] Training model: epoch 4th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2690 - acc: 0.5805\n",
      "[INFO] Training model: epoch 4th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3308 - acc: 0.5669\n",
      "[INFO] Training model: epoch 4th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3035 - acc: 0.5736\n",
      "[INFO] Training model: epoch 4th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3082 - acc: 0.5700\n",
      "[INFO] Training model: epoch 4th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.3580 - acc: 0.5673\n",
      "[INFO] Training model: epoch 4th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "102s - loss: 3.3230 - acc: 0.5613\n",
      "[INFO] Training model: epoch 5th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2487 - acc: 0.5709\n",
      "[INFO] Training model: epoch 5th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.2901 - acc: 0.5711\n",
      "[INFO] Training model: epoch 5th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1776 - acc: 0.5779\n",
      "[INFO] Training model: epoch 5th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2565 - acc: 0.5762\n",
      "[INFO] Training model: epoch 5th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2646 - acc: 0.5754\n",
      "[INFO] Training model: epoch 5th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.2566 - acc: 0.5762\n",
      "[INFO] Training model: epoch 5th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3281 - acc: 0.5649\n",
      "[INFO] Training model: epoch 5th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2482 - acc: 0.5734\n",
      "[INFO] Training model: epoch 5th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.3389 - acc: 0.5615\n",
      "[INFO] Training model: epoch 5th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "242s - loss: 3.2456 - acc: 0.5733\n",
      "[INFO] Training model: epoch 5th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2677 - acc: 0.5680\n",
      "[INFO] Training model: epoch 5th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.2825 - acc: 0.5701\n",
      "[INFO] Training model: epoch 6th 0/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.2061 - acc: 0.5721\n",
      "[INFO] Training model: epoch 6th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.2657 - acc: 0.5614\n",
      "[INFO] Training model: epoch 6th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2020 - acc: 0.5723\n",
      "[INFO] Training model: epoch 6th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1914 - acc: 0.5749\n",
      "[INFO] Training model: epoch 6th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1989 - acc: 0.5753\n",
      "[INFO] Training model: epoch 6th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1566 - acc: 0.5801\n",
      "[INFO] Training model: epoch 6th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2550 - acc: 0.5663\n",
      "[INFO] Training model: epoch 6th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.2323 - acc: 0.5780\n",
      "[INFO] Training model: epoch 6th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1834 - acc: 0.5713\n",
      "[INFO] Training model: epoch 6th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2559 - acc: 0.5659\n",
      "[INFO] Training model: epoch 6th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2131 - acc: 0.5739\n",
      "[INFO] Training model: epoch 6th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.3072 - acc: 0.5634\n",
      "[INFO] Training model: epoch 7th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1807 - acc: 0.5712\n",
      "[INFO] Training model: epoch 7th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1615 - acc: 0.5767\n",
      "[INFO] Training model: epoch 7th 2000/11428 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "239s - loss: 3.1373 - acc: 0.5751\n",
      "[INFO] Training model: epoch 7th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1758 - acc: 0.5728\n",
      "[INFO] Training model: epoch 7th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1753 - acc: 0.5706\n",
      "[INFO] Training model: epoch 7th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2149 - acc: 0.5611\n",
      "[INFO] Training model: epoch 7th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.2025 - acc: 0.5716\n",
      "[INFO] Training model: epoch 7th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1298 - acc: 0.5801\n",
      "[INFO] Training model: epoch 7th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1686 - acc: 0.5738\n",
      "[INFO] Training model: epoch 7th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1335 - acc: 0.5743\n",
      "[INFO] Training model: epoch 7th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1897 - acc: 0.5685\n",
      "[INFO] Training model: epoch 7th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "102s - loss: 3.3269 - acc: 0.5539\n",
      "[INFO] Training model: epoch 8th 0/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1597 - acc: 0.5705\n",
      "[INFO] Training model: epoch 8th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0833 - acc: 0.5765\n",
      "[INFO] Training model: epoch 8th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0594 - acc: 0.5859\n",
      "[INFO] Training model: epoch 8th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1545 - acc: 0.5715\n",
      "[INFO] Training model: epoch 8th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2405 - acc: 0.5594\n",
      "[INFO] Training model: epoch 8th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2194 - acc: 0.5616\n",
      "[INFO] Training model: epoch 8th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1385 - acc: 0.5779\n",
      "[INFO] Training model: epoch 8th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0449 - acc: 0.5829\n",
      "[INFO] Training model: epoch 8th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1167 - acc: 0.5753\n",
      "[INFO] Training model: epoch 8th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1244 - acc: 0.5762\n",
      "[INFO] Training model: epoch 8th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2457 - acc: 0.5526\n",
      "[INFO] Training model: epoch 8th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "102s - loss: 3.1744 - acc: 0.5658\n",
      "[INFO] Training model: epoch 9th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.2005 - acc: 0.5653\n",
      "[INFO] Training model: epoch 9th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1667 - acc: 0.5712\n",
      "[INFO] Training model: epoch 9th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1094 - acc: 0.5745\n",
      "[INFO] Training model: epoch 9th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1287 - acc: 0.5697\n",
      "[INFO] Training model: epoch 9th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1943 - acc: 0.5663\n",
      "[INFO] Training model: epoch 9th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1028 - acc: 0.5763\n",
      "[INFO] Training model: epoch 9th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1706 - acc: 0.5628\n",
      "[INFO] Training model: epoch 9th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0655 - acc: 0.5802\n",
      "[INFO] Training model: epoch 9th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.0791 - acc: 0.5827\n",
      "[INFO] Training model: epoch 9th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0969 - acc: 0.5730\n",
      "[INFO] Training model: epoch 9th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "241s - loss: 3.1894 - acc: 0.5618\n",
      "[INFO] Training model: epoch 9th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.0169 - acc: 0.5815\n",
      "[INFO] Training model: epoch 10th 0/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1638 - acc: 0.5630\n",
      "[INFO] Training model: epoch 10th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0600 - acc: 0.5785\n",
      "[INFO] Training model: epoch 10th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.0750 - acc: 0.5742\n",
      "[INFO] Training model: epoch 10th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1940 - acc: 0.5624\n",
      "[INFO] Training model: epoch 10th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1299 - acc: 0.5684\n",
      "[INFO] Training model: epoch 10th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1750 - acc: 0.5659\n",
      "[INFO] Training model: epoch 10th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1801 - acc: 0.5659\n",
      "[INFO] Training model: epoch 10th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0950 - acc: 0.5748\n",
      "[INFO] Training model: epoch 10th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1859 - acc: 0.5682\n",
      "[INFO] Training model: epoch 10th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0464 - acc: 0.5806\n",
      "[INFO] Training model: epoch 10th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.0640 - acc: 0.5799\n",
      "[INFO] Training model: epoch 10th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "103s - loss: 3.0370 - acc: 0.5863\n",
      "[INFO] Training model: epoch 11th 0/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.0209 - acc: 0.5788\n",
      "[INFO] Training model: epoch 11th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1330 - acc: 0.5692\n",
      "[INFO] Training model: epoch 11th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1035 - acc: 0.5692\n",
      "[INFO] Training model: epoch 11th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0984 - acc: 0.5738\n",
      "[INFO] Training model: epoch 11th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.0705 - acc: 0.5750\n",
      "[INFO] Training model: epoch 11th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "238s - loss: 3.1905 - acc: 0.5636\n",
      "[INFO] Training model: epoch 11th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1458 - acc: 0.5657\n",
      "[INFO] Training model: epoch 11th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0989 - acc: 0.5729\n",
      "[INFO] Training model: epoch 11th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.0958 - acc: 0.5754\n",
      "[INFO] Training model: epoch 11th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1222 - acc: 0.5713\n",
      "[INFO] Training model: epoch 11th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0943 - acc: 0.5710\n",
      "[INFO] Training model: epoch 11th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "104s - loss: 3.1366 - acc: 0.5764\n",
      "[INFO] Training model: epoch 12th 0/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1324 - acc: 0.5656\n",
      "[INFO] Training model: epoch 12th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0941 - acc: 0.5745\n",
      "[INFO] Training model: epoch 12th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0707 - acc: 0.5758\n",
      "[INFO] Training model: epoch 12th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0488 - acc: 0.5743\n",
      "[INFO] Training model: epoch 12th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1184 - acc: 0.5696\n",
      "[INFO] Training model: epoch 12th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0334 - acc: 0.5773\n",
      "[INFO] Training model: epoch 12th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0979 - acc: 0.5701\n",
      "[INFO] Training model: epoch 12th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "249s - loss: 3.0872 - acc: 0.5769\n",
      "[INFO] Training model: epoch 12th 8000/11428 samples\n",
      "Epoch 1/1\n",
      "250s - loss: 3.1888 - acc: 0.5624\n",
      "[INFO] Training model: epoch 12th 9000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.0983 - acc: 0.5682\n",
      "[INFO] Training model: epoch 12th 10000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.1142 - acc: 0.5723\n",
      "[INFO] Training model: epoch 12th 11000/11428 samples\n",
      "Epoch 1/1\n",
      "102s - loss: 3.0866 - acc: 0.5746\n",
      "[INFO] Training model: epoch 13th 0/11428 samples\n",
      "Epoch 1/1\n",
      "327s - loss: 3.1047 - acc: 0.5660\n",
      "[INFO] Training model: epoch 13th 1000/11428 samples\n",
      "Epoch 1/1\n",
      "245s - loss: 3.1265 - acc: 0.5699\n",
      "[INFO] Training model: epoch 13th 2000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0494 - acc: 0.5758\n",
      "[INFO] Training model: epoch 13th 3000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0458 - acc: 0.5770\n",
      "[INFO] Training model: epoch 13th 4000/11428 samples\n",
      "Epoch 1/1\n",
      "239s - loss: 3.0247 - acc: 0.5796\n",
      "[INFO] Training model: epoch 13th 5000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1899 - acc: 0.5595\n",
      "[INFO] Training model: epoch 13th 6000/11428 samples\n",
      "Epoch 1/1\n",
      "240s - loss: 3.1230 - acc: 0.5698\n",
      "[INFO] Training model: epoch 13th 7000/11428 samples\n",
      "Epoch 1/1\n",
      "249s - loss: 3.1430 - acc: 0.5698\n",
      "[INFO] Training model: epoch 13th 8000/11428 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-24-ab347849a326>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mi_end\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_sequences\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mbatch_size\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcallbacks_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     26\u001b[0m     \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'checkpoint_epoch_{}.hdf5'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/models.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, **kwargs)\u001b[0m\n\u001b[1;32m    865\u001b[0m                               \u001b[0mclass_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mclass_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    866\u001b[0m                               \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 867\u001b[0;31m                               initial_epoch=initial_epoch)\n\u001b[0m\u001b[1;32m    868\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    869\u001b[0m     def evaluate(self, x, y, batch_size=32, verbose=1,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1596\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1597\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1598\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1599\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1600\u001b[0m     def evaluate(self, x, y,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1181\u001b[0m                     \u001b[0mbatch_logs\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'size'\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_ids\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1182\u001b[0m                     \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbatch_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1183\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1184\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1185\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2271\u001b[0m         updated = session.run(self.outputs + [self.updates_op],\n\u001b[1;32m   2272\u001b[0m                               \u001b[0mfeed_dict\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2273\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2274\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2275\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1122\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1124\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1125\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1319\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1320\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1321\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1322\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1323\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1325\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1327\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1328\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1329\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1304\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1305\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1306\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1307\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1308\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from keras.callbacks import ModelCheckpoint\n",
    "\n",
    "k_start = 0\n",
    "\n",
    "\n",
    "for k in range(k_start, epochs+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(len(X))\n",
    "    np.random.shuffle(indices)\n",
    "    X = X[indices]\n",
    "    Y = Y[indices]\n",
    "\n",
    "    # Training 1000 sequences at a time\n",
    "    for i in range(0, len(X), 1000):\n",
    "        if i + 1000 >= len(X):\n",
    "            i_end = len(X)\n",
    "        else:\n",
    "            i_end = i + 1000\n",
    "        y_sequences = to_one_hot(Y[i:i_end], y_max_len, y_vocab_len)\n",
    "\n",
    "        print('[INFO] Training model: epoch {}th {}/{} samples'.format(k, i, len(X)))\n",
    "        \n",
    "        \n",
    "        model.fit(X[i:i_end], y_sequences, batch_size=batch_size, epochs=1, verbose=2)\n",
    "    model.save_weights('checkpoint_epoch_{}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Accuracy doesn't really raise above 57% - need to look at what is happening and revise code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'load_test_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mNameError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-25-f1f1253457a2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# Testing Code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_test_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'test'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_word_to_ix\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mMAX_LEN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpad_sequences\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxlen\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mX_max_len\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'int32'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_weights\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msaved_weights\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'load_test_data' is not defined"
     ]
    }
   ],
   "source": [
    "# Testing Code\n",
    "X_test = load_test_data('test', X_word_to_ix, MAX_LEN)\n",
    "X_test = pad_sequences(X_test, maxlen=X_max_len, dtype='int32')\n",
    "model.load_weights(saved_weights)\n",
    "            \n",
    "predictions = np.argmax(model.predict(X_test), axis=2)\n",
    "sequences = []\n",
    "for prediction in predictions:\n",
    "    sequence = ' '.join([y_ix_to_word(index) for index in prediction if index > 0])\n",
    "    print(sequence)\n",
    "    sequences.append(sequence)\n",
    "np.savetxt('test_result', sequences, fmt='%s')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Word2Word model as above is very slow to train.  \n",
    "\n",
    "Ideas to speed up:\n",
    "- Have characters on the output.\n",
    "- Use the model from the Keras blog post (see below).\n",
    "\n",
    "(We also haven't got any test data! We'll need to grab some more claims.)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
