{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can we create an encoder-decoder model for character data that acts as an embedding layer?\n",
    "\n",
    "If we could, our models could just predict the embedding, which may then be decoded to generate the word. For example, our decoder could just predict a 100D vector for each timestamp, which represents the word.\n",
    "\n",
    "Don't reset our GRU state as we read in characters?\n",
    "\n",
    "Plan:\n",
    "\n",
    "* Load Glove Embeddings.\n",
    "* Load text.\n",
    "* Tokenize text > words.\n",
    "* For each word - build an encoder:\n",
    "    * Clean characters.\n",
    "    * Add control characters to start and end > convert to numbers.\n",
    "    * Batch by length of word - 0-5,5-10,10-20, 20+ (or cap /arbitrarily break at 20?)\n",
    "    * Set as GRU sequences;\n",
    "    * Set Y as embedding for word;\n",
    "    * Use MSE loss and train.\n",
    "* Also build a decoder:\n",
    "    * Input initial state = embedding. Token = start sequence.\n",
    "    * Train with input sequence char + output sequence char shifted by one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "30000 samples loaded\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PIK = \"claim_and_title.data\"\n",
    "\n",
    "if not os.path.isfile(PIK):\n",
    "    # Download file\n",
    "    !wget https://benhoyle.github.io/notebooks/title_generation/claim_and_title.data\n",
    "\n",
    "with open(PIK, \"rb\") as f:\n",
    "    print(\"Loading data\")\n",
    "    data = pickle.load(f)\n",
    "    print(\"{0} samples loaded\".format(len(data)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from nltk import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Tokenize words\n",
    "data_as_words = [word_tokenize(d[0].lower().strip()) for d in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['1.',\n",
       " 'a',\n",
       " 'method',\n",
       " 'for',\n",
       " 'managing',\n",
       " 'a',\n",
       " 'backup',\n",
       " 'service',\n",
       " 'gateway',\n",
       " '(']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_words[0][0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Filter out non-words\n",
    "data_as_words = [word for claim in data_as_words for word in claim if word.isalpha()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "We have 6268278 words.\n"
     ]
    }
   ],
   "source": [
    "print(\"We have {} words.\".format(len(data_as_words)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['a',\n",
       " 'method',\n",
       " 'for',\n",
       " 'managing',\n",
       " 'a',\n",
       " 'backup',\n",
       " 'service',\n",
       " 'gateway',\n",
       " 'sgw',\n",
       " 'associated']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_as_words[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading GloVe 100d embeddings from file\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Load Glove Embeddings\n",
    "print(\"Loading GloVe 100d embeddings from file\")\n",
    "GLOVE_DIR = \"glove/\"\n",
    "\n",
    "embeddings_index = {}\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), 'rb')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    # Tweaked to decode the binary text values\n",
    "    word = values[0].decode('utf-8')\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 29 character tokens\n"
     ]
    }
   ],
   "source": [
    "# Setup character vocab \n",
    "import string\n",
    "char_vocab = [\"_PAD_\", \"_SOW_\", \"_EOW_\"] + list(string.ascii_lowercase)\n",
    "print(\"There are {} character tokens\".format(len(char_vocab)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Convert words to ints\n",
    "# Build dictionaries\n",
    "reverse_dict = {i: c for i, c in enumerate(char_vocab)}\n",
    "forward_dict = {v: k for k, v in reverse_dict.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Generate embedding - character list pairs\n",
    "dataset = []\n",
    "for word in data_as_words:\n",
    "    embedding = embeddings_index.get(word, None)\n",
    "    if embedding is not None:\n",
    "        try:\n",
    "            word_as_int = [forward_dict[\"_SOW_\"]] + [forward_dict[c] for c in word] + [forward_dict[\"_EOW_\"]]\n",
    "            dataset.append((embedding, word_as_int))\n",
    "        except KeyError:\n",
    "            continue\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are now 6251296 entries in the dataset\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(array([-4.1796e-01,  5.3241e-01, -3.3693e-01,  6.9262e-01,  6.8686e-02,\n",
       "        -8.7566e-02,  2.7663e-01, -7.1203e-02, -3.3530e-01,  3.3365e-01,\n",
       "        -5.2407e-01, -5.3341e-01,  4.0460e-02, -1.6659e-01,  4.5481e-01,\n",
       "        -3.4785e-01,  2.4926e-01,  2.2734e-02,  4.2120e-01,  6.2452e-03,\n",
       "        -1.3359e-01, -5.1309e-01,  2.1382e-01, -2.4943e-01, -3.6553e-01,\n",
       "        -1.0690e-02,  2.5961e-01, -2.9090e-01, -7.6780e-01,  3.7387e-02,\n",
       "        -4.6895e-01,  8.9278e-01, -5.3101e-01, -3.8841e-01,  3.5913e-01,\n",
       "        -4.7930e-01, -3.3601e-01, -2.0371e-01,  3.9182e-01, -9.5175e-01,\n",
       "        -6.2779e-01,  1.7753e-01, -3.5282e-02, -1.2463e-01, -8.4179e-01,\n",
       "        -3.4632e-01, -1.9631e-01, -8.4428e-01, -5.4253e-01, -1.9322e-01,\n",
       "         2.5287e-01, -1.2990e-02, -1.4000e-03,  1.4574e+00, -7.6291e-01,\n",
       "        -1.5731e+00, -2.3982e-01,  2.2269e-01,  8.7785e-01, -3.4078e-02,\n",
       "        -3.6702e-02, -3.1008e-01,  8.0324e-01,  6.1032e-01,  1.3546e+00,\n",
       "        -1.4522e-01, -1.9501e-01, -6.8654e-01, -9.6186e-02, -5.0487e-01,\n",
       "        -1.0144e+00,  3.7278e-01,  6.3403e-01,  6.6473e-01,  3.3144e-01,\n",
       "        -6.2283e-01, -1.1496e-01, -6.0323e-01, -4.6632e-01, -1.7908e-01,\n",
       "         2.3923e-01,  2.5257e-01, -1.1826e+00, -6.0126e-01, -1.8759e+00,\n",
       "         9.2491e-01,  8.7735e-01, -6.2709e-01, -2.6522e-01, -1.0025e-01,\n",
       "        -5.8459e-01,  1.2821e-01,  3.4710e-01,  5.2632e-01,  7.4769e-01,\n",
       "        -3.3396e-01, -3.6954e-01, -7.5431e-01,  3.4056e-01,  2.8563e-01],\n",
       "       dtype=float32), [1, 15, 7, 22, 10, 17, 6, 2])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(\"There are now {0} entries in the dataset\".format(len(dataset)))\n",
    "dataset[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# char_emb_dim = 8\n",
    "#decoder_embedding = Embedding(input_dim = num_decoder_tokens, output_dim=char_emb_dim)(decoder_inputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To cut a long story short - we need to use one-hot encodings of our character data for our decoder inputs and outputs. As there are around 6m samples, we need to break up our training data into batches (we have matrices of 6m, 20, 29). As we need to break our training data into batches, we can maybe create batches of different sizes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from keras.layers import GRU, Input, Dense, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "embedding_dim = 100\n",
    "num_decoder_tokens = len(char_vocab)\n",
    "# Limit word length to 20\n",
    "decoder_seq_length = 20\n",
    "\n",
    "encoded_state = Input(shape=(embedding_dim,), name=\"EncodedState\")\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens), name=\"DecoderInputs\")\n",
    "decoder_gru = GRU(embedding_dim, return_sequences=True, name=\"Decoder\")\n",
    "decoder_outputs = decoder_gru(decoder_inputs, initial_state=encoded_state)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name=\"VocabProjection\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoded_state, decoder_inputs], decoder_outputs)\n",
    "\n",
    "model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['acc']\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOSError\u001b[0m                                   Traceback (most recent call last)",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     26\u001b[0m         \u001b[0;31m# to check the pydot/graphviz installation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m         \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/pydot.py\u001b[0m in \u001b[0;36mcreate\u001b[0;34m(self, prog, format, encoding)\u001b[0m\n\u001b[1;32m   1860\u001b[0m                 \u001b[0mshell\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1861\u001b[0;31m                 stderr=subprocess.PIPE, stdout=subprocess.PIPE)\n\u001b[0m\u001b[1;32m   1862\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds)\u001b[0m\n\u001b[1;32m    946\u001b[0m                                 \u001b[0merrread\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrwrite\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m                                 restore_signals, start_new_session)\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/lib/python3.5/subprocess.py\u001b[0m in \u001b[0;36m_execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, start_new_session)\u001b[0m\n\u001b[1;32m   1489\u001b[0m                             \u001b[0merrpipe_read\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merrpipe_write\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1490\u001b[0;31m                             restore_signals, start_new_session, preexec_fn)\n\u001b[0m\u001b[1;32m   1491\u001b[0m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_child_created\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mOSError\u001b[0m: [Errno 12] Cannot allocate memory",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-86-512d6967aa33>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvis_utils\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mIPython\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel_to_dot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mshow_shapes\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprog\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'dot'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36mmodel_to_dot\u001b[0;34m(model, show_shapes, show_layer_names, rankdir)\u001b[0m\n\u001b[1;32m     54\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodels\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mSequential\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     55\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 56\u001b[0;31m     \u001b[0m_check_pydot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     57\u001b[0m     \u001b[0mdot\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mdot\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'rankdir'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrankdir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/utils/vis_utils.py\u001b[0m in \u001b[0;36m_check_pydot\u001b[0;34m()\u001b[0m\n\u001b[1;32m     29\u001b[0m         \u001b[0;31m# pydot raises a generic Exception here,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     30\u001b[0m         \u001b[0;31m# so no specific class can be caught.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 31\u001b[0;31m         raise ImportError('Failed to import pydot. You must install pydot'\n\u001b[0m\u001b[1;32m     32\u001b[0m                           ' and graphviz for `pydotprint` to work.')\n\u001b[1;32m     33\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mImportError\u001b[0m: Failed to import pydot. You must install pydot and graphviz for `pydotprint` to work."
     ]
    }
   ],
   "source": [
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import Image\n",
    "Image(model_to_dot(model, show_shapes=True).create_png(prog='dot'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "def inputs_to_one_hot(input_seqs, decoder_seq_length, num_decoder_tokens):\n",
    "    \"\"\" Convert a sequence of integers to normal and shifted one-hot representations a one element shifted\n",
    "        sequence of one-hot vectors.\"\"\"\n",
    "    length = len(input_seqs)\n",
    "    one_hot_in = np.zeros(\n",
    "            (length, decoder_seq_length, num_decoder_tokens)\n",
    "            )\n",
    "    one_hot_out = np.zeros(\n",
    "            (length, decoder_seq_length, num_decoder_tokens)\n",
    "            )\n",
    "    for i, sequence in enumerate(input_seqs):\n",
    "        for timestamp, word_int in enumerate(sequence):\n",
    "            one_hot_in[i, timestamp, word_int] = 1\n",
    "            if timestamp > 0:\n",
    "                # Shift decoder target get so it is one ahead\n",
    "                one_hot_out[i, timestamp-1, word_int] = 1\n",
    "    return one_hot_in, one_hot_out"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With embedding for characters.\n",
    "```\n",
    "from keras.layers import GRU, Input, Dense, Embedding\n",
    "from keras.models import Model\n",
    "\n",
    "embedding_dim = 100\n",
    "num_decoder_tokens = len(char_vocab)\n",
    "# Limit word length to 20\n",
    "decoder_seq_length = 20\n",
    "# Character embedding dimension\n",
    "char_emb_dim = 8\n",
    "\n",
    "encoded_state = Input(shape=(embedding_dim,), name=\"EncodedState\")\n",
    "decoder_inputs = Input(shape=(None, ), name=\"DecoderInputs\")\n",
    "decoder_embedding = Embedding(input_dim = num_decoder_tokens, output_dim=char_emb_dim)(decoder_inputs)\n",
    "decoder_gru = GRU(embedding_dim, return_sequences=True, name=\"Decoder\")\n",
    "decoder_outputs = decoder_gru(decoder_embedding, initial_state=encoded_state)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax', name=\"VocabProjection\")\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "model = Model([encoded_state, decoder_inputs], decoder_outputs)\n",
    "```\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest sequence is 24 tokens long.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2d3b90ac18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "# Let's have a look at our word length distribution\n",
    "Y_length = [len(y) for e, y in dataset]\n",
    "max_y_length = max(Y_length)\n",
    "print(\"Our longest sequence is {0} tokens long.\".format(max_y_length))\n",
    "\n",
    "bins = np.linspace(0, max_y_length, 25)\n",
    "plt.hist(Y_length, bins)\n",
    "plt.title('Title - Sequence Length')\n",
    "plt.ylabel('No. of samples')\n",
    "plt.xlabel('Sequence Length (words)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shall we try using the keras to_categorial method and then shift this as before\n",
    "# To test our model works we'll just select the first 500k sampes\n",
    "decoder_in_seqs = [y for e,y in dataset[0:50000]]\n",
    "decoder_in_seqs, decoder_out_seqs = inputs_to_one_hot(decoder_in_seqs, decoder_seq_length, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(50000, 20, 29) (50000, 20, 29)\n"
     ]
    }
   ],
   "source": [
    "print(decoder_in_seqs.shape, decoder_out_seqs.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Here we split our data into batches of different lengths - we can then compute our shifted output vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Note - with ints we can use just array slicing to shift\n",
    "# Could we build one hot conversion into model as a layer? Would save having to convert all the data first\n",
    "# decoder_out_seqs = np.zeros(decoder_in_seqs.shape, dtype='int32')\n",
    "# decoder_out_seqs[:, 0:19] = decoder_in_seqs[:, 1:20]\n",
    "# decoder_out_seqs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "encoded_states = np.array([e for e, y in dataset[0:50000]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 100)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded_states.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 45000 samples, validate on 5000 samples\n",
      "Epoch 1/100\n",
      "45000/45000 [==============================] - 24s 523us/step - loss: 0.3078 - acc: 0.2275 - val_loss: 0.2953 - val_acc: 0.2339\n",
      "Epoch 2/100\n",
      "45000/45000 [==============================] - 23s 519us/step - loss: 0.2238 - acc: 0.2523 - val_loss: 0.2541 - val_acc: 0.2459\n",
      "Epoch 3/100\n",
      "45000/45000 [==============================] - 24s 524us/step - loss: 0.1766 - acc: 0.2657 - val_loss: 0.2285 - val_acc: 0.2539\n",
      "Epoch 4/100\n",
      "45000/45000 [==============================] - 23s 522us/step - loss: 0.1460 - acc: 0.2744 - val_loss: 0.2124 - val_acc: 0.2604\n",
      "Epoch 5/100\n",
      "45000/45000 [==============================] - 23s 521us/step - loss: 0.1247 - acc: 0.2808 - val_loss: 0.2050 - val_acc: 0.2630\n",
      "Epoch 6/100\n",
      "45000/45000 [==============================] - 24s 523us/step - loss: 0.1091 - acc: 0.2850 - val_loss: 0.1967 - val_acc: 0.2672\n",
      "Epoch 7/100\n",
      "45000/45000 [==============================] - 23s 522us/step - loss: 0.0972 - acc: 0.2882 - val_loss: 0.1954 - val_acc: 0.2696\n",
      "Epoch 8/100\n",
      "45000/45000 [==============================] - 23s 520us/step - loss: 0.0874 - acc: 0.2910 - val_loss: 0.1912 - val_acc: 0.2711\n",
      "Epoch 9/100\n",
      "45000/45000 [==============================] - 23s 518us/step - loss: 0.0797 - acc: 0.2930 - val_loss: 0.1935 - val_acc: 0.2714\n",
      "Epoch 10/100\n",
      "45000/45000 [==============================] - 23s 516us/step - loss: 0.0734 - acc: 0.2947 - val_loss: 0.1907 - val_acc: 0.2738\n",
      "Epoch 11/100\n",
      "45000/45000 [==============================] - 23s 516us/step - loss: 0.0679 - acc: 0.2961 - val_loss: 0.1920 - val_acc: 0.2746\n",
      "Epoch 12/100\n",
      "42688/45000 [===========================>..] - ETA: 1s - loss: 0.0629 - acc: 0.2973"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-105-1d2d7ece8517>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mcallback\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mencoded_states\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_in_seqs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdecoder_out_seqs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_split\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m100\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1667\u001b[0m                               \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1668\u001b[0m                               \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1669\u001b[0;31m                               validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1670\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1671\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/engine/training.py\u001b[0m in \u001b[0;36m_fit_loop\u001b[0;34m(self, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m   1204\u001b[0m                         \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1205\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1206\u001b[0;31m                     \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1207\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1208\u001b[0m                         \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2473\u001b[0m         \u001b[0msession\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mget_session\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2474\u001b[0m         updated = session.run(fetches=fetches, feed_dict=feed_dict,\n\u001b[0;32m-> 2475\u001b[0;31m                               **self.session_kwargs)\n\u001b[0m\u001b[1;32m   2476\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mupdated\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2477\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    893\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    894\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 895\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    896\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    897\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1126\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1127\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1128\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1129\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1342\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1343\u001b[0m       return self._do_call(_run_fn, self._session, feeds, fetches, targets,\n\u001b[0;32m-> 1344\u001b[0;31m                            options, run_metadata)\n\u001b[0m\u001b[1;32m   1345\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1346\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1348\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1349\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1350\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1351\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1352\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.5/dist-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(session, feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1327\u001b[0m           return tf_session.TF_Run(session, options,\n\u001b[1;32m   1328\u001b[0m                                    \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1329\u001b[0;31m                                    status, run_metadata)\n\u001b[0m\u001b[1;32m   1330\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1331\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msession\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "callback = model.fit([encoded_states, decoder_in_seqs], decoder_out_seqs, validation_split=0.1, batch_size=64, epochs=100)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comments on Initial Training\n",
    "\n",
    "This seems to reach a local minima within 10 epochs.\n",
    "\n",
    "Now we need to code up our loop through the 6million examples in sets of 100k. We'll need to initially create different test and training datasets that we keep separate. Can we use / edit our existing models?\n",
    "\n",
    "What does training do? It captures information about two things:\n",
    "\n",
    "* The data values themselves (e.g. character sequences per word); and\n",
    "* The distribution of the words in the dataset.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_data = [e for e, y in dataset]\n",
    "output_data = [y for e, y in dataset]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "from char_gen import CharS2S"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We want to build an abstract class that has the encoder and decoder systems as separate replaceable modules. E.g. process_encoder_input, process_decoder_input."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building model\n",
      "Loaded weights\n",
      "Generating training and test data\n"
     ]
    }
   ],
   "source": [
    "char_s2s = CharS2S(\n",
    "    encoder_states=input_data,\n",
    "    decoder_seqs=output_data,\n",
    "    decoder_seq_length=20,\n",
    "    latent_dim=100,\n",
    "    weights_file=\"charstate2seq.hdf5\",\n",
    "    training_set_size=50000,  # Due to memory we need to train in sets\n",
    "    batch_size=128\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 0\n",
      "Training on batch 0 to 50000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 22s 439us/step - loss: 0.6185 - acc: 0.1368 - val_loss: 0.4443 - val_acc: 0.1886\n",
      "Training on batch 50000 to 100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 380us/step - loss: 0.3761 - acc: 0.2077 - val_loss: 0.3261 - val_acc: 0.2227\n",
      "Training on batch 100000 to 150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 0.2954 - acc: 0.2294 - val_loss: 0.2736 - val_acc: 0.2381\n",
      "Training on batch 150000 to 200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 0.2524 - acc: 0.2438 - val_loss: 0.2303 - val_acc: 0.2492\n",
      "Training on batch 200000 to 250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.2182 - acc: 0.2527 - val_loss: 0.2063 - val_acc: 0.2558\n",
      "Training on batch 250000 to 300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.1979 - acc: 0.2589 - val_loss: 0.1833 - val_acc: 0.2622\n",
      "Training on batch 300000 to 350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.1813 - acc: 0.2640 - val_loss: 0.1764 - val_acc: 0.2681\n",
      "Training on batch 350000 to 400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 0.1678 - acc: 0.2662 - val_loss: 0.1661 - val_acc: 0.2702\n",
      "Training on batch 400000 to 450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 0.1570 - acc: 0.2716 - val_loss: 0.1524 - val_acc: 0.2698\n",
      "Training on batch 450000 to 500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.1485 - acc: 0.2734 - val_loss: 0.1445 - val_acc: 0.2731\n",
      "Training on batch 500000 to 550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 0.1405 - acc: 0.2736 - val_loss: 0.1398 - val_acc: 0.2772\n",
      "Training on batch 550000 to 600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.1344 - acc: 0.2752 - val_loss: 0.1312 - val_acc: 0.2765\n",
      "Training on batch 600000 to 650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.1286 - acc: 0.2773 - val_loss: 0.1255 - val_acc: 0.2753\n",
      "Training on batch 650000 to 700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.1258 - acc: 0.2797 - val_loss: 0.1195 - val_acc: 0.2815\n",
      "Training on batch 700000 to 750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.1207 - acc: 0.2810 - val_loss: 0.1176 - val_acc: 0.2825\n",
      "Training on batch 750000 to 800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.1144 - acc: 0.2796 - val_loss: 0.1138 - val_acc: 0.2828\n",
      "Training on batch 800000 to 850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.1148 - acc: 0.2816 - val_loss: 0.1134 - val_acc: 0.2834\n",
      "Training on batch 850000 to 900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.1092 - acc: 0.2825 - val_loss: 0.1092 - val_acc: 0.2827\n",
      "Training on batch 900000 to 950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.1069 - acc: 0.2830 - val_loss: 0.1058 - val_acc: 0.2833\n",
      "Training on batch 950000 to 1000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.1048 - acc: 0.2833 - val_loss: 0.1068 - val_acc: 0.2833\n",
      "Training on batch 1000000 to 1050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.1024 - acc: 0.2837 - val_loss: 0.0973 - val_acc: 0.2854\n",
      "Training on batch 1050000 to 1100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 393us/step - loss: 0.1008 - acc: 0.2835 - val_loss: 0.0974 - val_acc: 0.2860\n",
      "Training on batch 1100000 to 1150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0977 - acc: 0.2855 - val_loss: 0.0962 - val_acc: 0.2838\n",
      "Training on batch 1150000 to 1200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 0.0985 - acc: 0.2864 - val_loss: 0.0947 - val_acc: 0.2864\n",
      "Training on batch 1200000 to 1250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.0948 - acc: 0.2875 - val_loss: 0.0970 - val_acc: 0.2866\n",
      "Training on batch 1250000 to 1300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 0.0927 - acc: 0.2873 - val_loss: 0.0911 - val_acc: 0.2879\n",
      "Training on batch 1300000 to 1350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0919 - acc: 0.2882 - val_loss: 0.0856 - val_acc: 0.2880\n",
      "Training on batch 1350000 to 1400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0908 - acc: 0.2871 - val_loss: 0.0904 - val_acc: 0.2897\n",
      "Training on batch 1400000 to 1450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0882 - acc: 0.2877 - val_loss: 0.0897 - val_acc: 0.2887\n",
      "Training on batch 1450000 to 1500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 0.0898 - acc: 0.2882 - val_loss: 0.0884 - val_acc: 0.2878\n",
      "Training on batch 1500000 to 1550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 377us/step - loss: 0.0870 - acc: 0.2881 - val_loss: 0.0885 - val_acc: 0.2890\n",
      "Training on batch 1550000 to 1600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0868 - acc: 0.2900 - val_loss: 0.0856 - val_acc: 0.2882\n",
      "Training on batch 1600000 to 1650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 0.0849 - acc: 0.2882 - val_loss: 0.0847 - val_acc: 0.2917\n",
      "Training on batch 1650000 to 1700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 374us/step - loss: 0.0860 - acc: 0.2896 - val_loss: 0.0794 - val_acc: 0.2902\n",
      "Training on batch 1700000 to 1750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0844 - acc: 0.2899 - val_loss: 0.0819 - val_acc: 0.2903\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1750000 to 1800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 375us/step - loss: 0.0844 - acc: 0.2892 - val_loss: 0.0857 - val_acc: 0.2902\n",
      "Training on batch 1800000 to 1850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 373us/step - loss: 0.0806 - acc: 0.2912 - val_loss: 0.0788 - val_acc: 0.2912\n",
      "Training on batch 1850000 to 1900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 0.0802 - acc: 0.2903 - val_loss: 0.0801 - val_acc: 0.2916\n",
      "Training on batch 1900000 to 1950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0796 - acc: 0.2908 - val_loss: 0.0789 - val_acc: 0.2917\n",
      "Training on batch 1950000 to 2000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.0787 - acc: 0.2917 - val_loss: 0.0845 - val_acc: 0.2929\n",
      "Training on batch 2000000 to 2050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.0772 - acc: 0.2912 - val_loss: 0.0818 - val_acc: 0.2922\n",
      "Training on batch 2050000 to 2100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 0.0773 - acc: 0.2911 - val_loss: 0.0827 - val_acc: 0.2896\n",
      "Training on batch 2100000 to 2150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0785 - acc: 0.2914 - val_loss: 0.0818 - val_acc: 0.2921\n",
      "Training on batch 2150000 to 2200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 399us/step - loss: 0.0787 - acc: 0.2917 - val_loss: 0.0759 - val_acc: 0.2921\n",
      "Training on batch 2200000 to 2250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 381us/step - loss: 0.0778 - acc: 0.2918 - val_loss: 0.0756 - val_acc: 0.2928\n",
      "Training on batch 2250000 to 2300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 380us/step - loss: 0.0754 - acc: 0.2919 - val_loss: 0.0794 - val_acc: 0.2920\n",
      "Training on batch 2300000 to 2350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 380us/step - loss: 0.0745 - acc: 0.2919 - val_loss: 0.0732 - val_acc: 0.2922\n",
      "Training on batch 2350000 to 2400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0744 - acc: 0.2929 - val_loss: 0.0755 - val_acc: 0.2896\n",
      "Training on batch 2400000 to 2450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0760 - acc: 0.2929 - val_loss: 0.0738 - val_acc: 0.2929\n",
      "Training on batch 2450000 to 2500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0736 - acc: 0.2925 - val_loss: 0.0712 - val_acc: 0.2936\n",
      "Training on batch 2500000 to 2550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0758 - acc: 0.2923 - val_loss: 0.0736 - val_acc: 0.2927\n",
      "Training on batch 2550000 to 2600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 0.0739 - acc: 0.2928 - val_loss: 0.0715 - val_acc: 0.2928\n",
      "Training on batch 2600000 to 2650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0739 - acc: 0.2925 - val_loss: 0.0721 - val_acc: 0.2917\n",
      "Training on batch 2650000 to 2700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 0.0732 - acc: 0.2934 - val_loss: 0.0691 - val_acc: 0.2946\n",
      "Training on batch 2700000 to 2750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0723 - acc: 0.2929 - val_loss: 0.0727 - val_acc: 0.2921\n",
      "Training on batch 2750000 to 2800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0712 - acc: 0.2927 - val_loss: 0.0757 - val_acc: 0.2918\n",
      "Training on batch 2800000 to 2850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0743 - acc: 0.2927 - val_loss: 0.0690 - val_acc: 0.2947\n",
      "Training on batch 2850000 to 2900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0704 - acc: 0.2936 - val_loss: 0.0719 - val_acc: 0.2942\n",
      "Training on batch 2900000 to 2950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.0706 - acc: 0.2931 - val_loss: 0.0716 - val_acc: 0.2915\n",
      "Training on batch 2950000 to 3000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0699 - acc: 0.2931 - val_loss: 0.0702 - val_acc: 0.2924\n",
      "Training on batch 3000000 to 3050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0709 - acc: 0.2932 - val_loss: 0.0714 - val_acc: 0.2940\n",
      "Training on batch 3050000 to 3100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0702 - acc: 0.2938 - val_loss: 0.0695 - val_acc: 0.2936\n",
      "Training on batch 3100000 to 3150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0729 - acc: 0.2930 - val_loss: 0.0716 - val_acc: 0.2955\n",
      "Training on batch 3150000 to 3200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0682 - acc: 0.2945 - val_loss: 0.0659 - val_acc: 0.2936\n",
      "Training on batch 3200000 to 3250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0679 - acc: 0.2940 - val_loss: 0.0668 - val_acc: 0.2954\n",
      "Training on batch 3250000 to 3300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0686 - acc: 0.2935 - val_loss: 0.0732 - val_acc: 0.2944\n",
      "Training on batch 3300000 to 3350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s 410us/step - loss: 0.0680 - acc: 0.2946 - val_loss: 0.0690 - val_acc: 0.2943\n",
      "Training on batch 3350000 to 3400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 398us/step - loss: 0.0692 - acc: 0.2942 - val_loss: 0.0675 - val_acc: 0.2950\n",
      "Training on batch 3400000 to 3450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0685 - acc: 0.2938 - val_loss: 0.0667 - val_acc: 0.2920\n",
      "Training on batch 3450000 to 3500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0664 - acc: 0.2951 - val_loss: 0.0704 - val_acc: 0.2948\n",
      "Training on batch 3500000 to 3550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0660 - acc: 0.2944 - val_loss: 0.0688 - val_acc: 0.2928\n",
      "Training on batch 3550000 to 3600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0662 - acc: 0.2941 - val_loss: 0.0657 - val_acc: 0.2964\n",
      "Training on batch 3600000 to 3650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0665 - acc: 0.2930 - val_loss: 0.0693 - val_acc: 0.2920\n",
      "Training on batch 3650000 to 3700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 408us/step - loss: 0.0670 - acc: 0.2940 - val_loss: 0.0634 - val_acc: 0.2966\n",
      "Training on batch 3700000 to 3750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0657 - acc: 0.2937 - val_loss: 0.0653 - val_acc: 0.2930\n",
      "Training on batch 3750000 to 3800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0648 - acc: 0.2953 - val_loss: 0.0635 - val_acc: 0.2958\n",
      "Training on batch 3800000 to 3850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0646 - acc: 0.2939 - val_loss: 0.0690 - val_acc: 0.2933\n",
      "Training on batch 3850000 to 3900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0666 - acc: 0.2947 - val_loss: 0.0686 - val_acc: 0.2945\n",
      "Training on batch 3900000 to 3950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0643 - acc: 0.2945 - val_loss: 0.0661 - val_acc: 0.2969\n",
      "Training on batch 3950000 to 4000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0643 - acc: 0.2947 - val_loss: 0.0630 - val_acc: 0.2943\n",
      "Training on batch 4000000 to 4050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0663 - acc: 0.2959 - val_loss: 0.0640 - val_acc: 0.2944\n",
      "Training on batch 4050000 to 4100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0628 - acc: 0.2951 - val_loss: 0.0642 - val_acc: 0.2961\n",
      "Training on batch 4100000 to 4150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0645 - acc: 0.2949 - val_loss: 0.0620 - val_acc: 0.2945\n",
      "Training on batch 4150000 to 4200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0622 - acc: 0.2952 - val_loss: 0.0621 - val_acc: 0.2946\n",
      "Training on batch 4200000 to 4250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0613 - acc: 0.2962 - val_loss: 0.0627 - val_acc: 0.2959\n",
      "Training on batch 4250000 to 4300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 0.0645 - acc: 0.2959 - val_loss: 0.0665 - val_acc: 0.2967\n",
      "Training on batch 4300000 to 4350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0639 - acc: 0.2947 - val_loss: 0.0610 - val_acc: 0.2973\n",
      "Training on batch 4350000 to 4400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.0629 - acc: 0.2959 - val_loss: 0.0653 - val_acc: 0.2957\n",
      "Training on batch 4400000 to 4450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0640 - acc: 0.2963 - val_loss: 0.0620 - val_acc: 0.2974\n",
      "Training on batch 4450000 to 4500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0620 - acc: 0.2952 - val_loss: 0.0604 - val_acc: 0.2961\n",
      "Training on batch 4500000 to 4550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0647 - acc: 0.2956 - val_loss: 0.0651 - val_acc: 0.2962\n",
      "Training on batch 4550000 to 4600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0606 - acc: 0.2966 - val_loss: 0.0615 - val_acc: 0.2947\n",
      "Training on batch 4600000 to 4650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0631 - acc: 0.2955 - val_loss: 0.0609 - val_acc: 0.2957\n",
      "Training on batch 4650000 to 4700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0631 - acc: 0.2951 - val_loss: 0.0632 - val_acc: 0.2947\n",
      "Training on batch 4700000 to 4750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0631 - acc: 0.2953 - val_loss: 0.0599 - val_acc: 0.2947\n",
      "Training on batch 4750000 to 4800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0604 - acc: 0.2965 - val_loss: 0.0652 - val_acc: 0.2976\n",
      "Training on batch 4800000 to 4850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0624 - acc: 0.2943 - val_loss: 0.0654 - val_acc: 0.2961\n",
      "Training on batch 4850000 to 4900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0634 - acc: 0.2956 - val_loss: 0.0608 - val_acc: 0.2954\n",
      "Training on batch 4900000 to 4950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0619 - acc: 0.2969 - val_loss: 0.0597 - val_acc: 0.2938\n",
      "Training on batch 4950000 to 5000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0625 - acc: 0.2959 - val_loss: 0.0627 - val_acc: 0.2938\n",
      "Training on batch 5000000 to 5001036 of 5001036\n",
      "Train on 1036 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "1036/1036 [==============================] - 0s 467us/step - loss: 0.0579 - acc: 0.2885 - val_loss: 0.0420 - val_acc: 0.2942\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c6c627c18>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_s2s.train()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "Training on batch 4950000 to 5000000 of 5001036\n",
    "Train on 50000 samples, validate on 12500 samples\n",
    "Epoch 1/1\n",
    "50000/50000 [==============================] - 20s 392us/step - loss: 0.0625 - acc: 0.2959 - val_loss: 0.0627 - val_acc: 0.2938\n",
    "```\n",
    "\n",
    "Now we need to look at what this is generating!\n",
    "\n",
    "It is noted that the accuracy is only 30% - it would be interested to see how this is manifesting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Model:\n",
      "\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "DecoderInputs (InputLayer)      (None, None, 29)     0                                            \n",
      "__________________________________________________________________________________________________\n",
      "EncodedState (InputLayer)       (None, 100)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Decoder (GRU)                   [(None, None, 100),  39000       DecoderInputs[0][0]              \n",
      "                                                                 EncodedState[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "VocabProjection (Dense)         (None, None, 29)     2929        Decoder[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 41,929\n",
      "Trainable params: 41,929\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "char_s2s.print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training for epoch 0\n",
      "Training on batch 0 to 50000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0599 - acc: 0.2965 - val_loss: 0.0595 - val_acc: 0.2963\n",
      "Training on batch 50000 to 100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0610 - acc: 0.2957 - val_loss: 0.0595 - val_acc: 0.2956\n",
      "Training on batch 100000 to 150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0630 - acc: 0.2945 - val_loss: 0.0650 - val_acc: 0.2967\n",
      "Training on batch 150000 to 200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0632 - acc: 0.2965 - val_loss: 0.0595 - val_acc: 0.2960\n",
      "Training on batch 200000 to 250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0608 - acc: 0.2958 - val_loss: 0.0609 - val_acc: 0.2961\n",
      "Training on batch 250000 to 300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 0.0602 - acc: 0.2964 - val_loss: 0.0567 - val_acc: 0.2958\n",
      "Training on batch 300000 to 350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0601 - acc: 0.2968 - val_loss: 0.0600 - val_acc: 0.2997\n",
      "Training on batch 350000 to 400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0602 - acc: 0.2954 - val_loss: 0.0606 - val_acc: 0.2989\n",
      "Training on batch 400000 to 450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0608 - acc: 0.2977 - val_loss: 0.0597 - val_acc: 0.2949\n",
      "Training on batch 450000 to 500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0604 - acc: 0.2974 - val_loss: 0.0592 - val_acc: 0.2959\n",
      "Training on batch 500000 to 550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0609 - acc: 0.2949 - val_loss: 0.0631 - val_acc: 0.2976\n",
      "Training on batch 550000 to 600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.0613 - acc: 0.2952 - val_loss: 0.0592 - val_acc: 0.2956\n",
      "Training on batch 600000 to 650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0598 - acc: 0.2961 - val_loss: 0.0608 - val_acc: 0.2929\n",
      "Training on batch 650000 to 700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0604 - acc: 0.2975 - val_loss: 0.0581 - val_acc: 0.2981\n",
      "Training on batch 700000 to 750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0596 - acc: 0.2976 - val_loss: 0.0595 - val_acc: 0.2984\n",
      "Training on batch 750000 to 800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0583 - acc: 0.2950 - val_loss: 0.0585 - val_acc: 0.2980\n",
      "Training on batch 800000 to 850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0608 - acc: 0.2963 - val_loss: 0.0629 - val_acc: 0.2967\n",
      "Training on batch 850000 to 900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0588 - acc: 0.2960 - val_loss: 0.0601 - val_acc: 0.2955\n",
      "Training on batch 900000 to 950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 0.0583 - acc: 0.2961 - val_loss: 0.0584 - val_acc: 0.2964\n",
      "Training on batch 950000 to 1000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 390us/step - loss: 0.0587 - acc: 0.2956 - val_loss: 0.0603 - val_acc: 0.2956\n",
      "Training on batch 1000000 to 1050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0591 - acc: 0.2953 - val_loss: 0.0556 - val_acc: 0.2963\n",
      "Training on batch 1050000 to 1100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0594 - acc: 0.2946 - val_loss: 0.0555 - val_acc: 0.2976\n",
      "Training on batch 1100000 to 1150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0568 - acc: 0.2965 - val_loss: 0.0585 - val_acc: 0.2940\n",
      "Training on batch 1150000 to 1200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0598 - acc: 0.2970 - val_loss: 0.0598 - val_acc: 0.2959\n",
      "Training on batch 1200000 to 1250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0591 - acc: 0.2971 - val_loss: 0.0613 - val_acc: 0.2966\n",
      "Training on batch 1250000 to 1300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0575 - acc: 0.2969 - val_loss: 0.0570 - val_acc: 0.2972\n",
      "Training on batch 1300000 to 1350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0575 - acc: 0.2974 - val_loss: 0.0543 - val_acc: 0.2968\n",
      "Training on batch 1350000 to 1400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0591 - acc: 0.2955 - val_loss: 0.0607 - val_acc: 0.2975\n",
      "Training on batch 1400000 to 1450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0576 - acc: 0.2961 - val_loss: 0.0589 - val_acc: 0.2967\n",
      "Training on batch 1450000 to 1500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0581 - acc: 0.2966 - val_loss: 0.0597 - val_acc: 0.2953\n",
      "Training on batch 1500000 to 1550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.0589 - acc: 0.2956 - val_loss: 0.0585 - val_acc: 0.2971\n",
      "Training on batch 1550000 to 1600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0581 - acc: 0.2978 - val_loss: 0.0577 - val_acc: 0.2955\n",
      "Training on batch 1600000 to 1650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0565 - acc: 0.2959 - val_loss: 0.0567 - val_acc: 0.2992\n",
      "Training on batch 1650000 to 1700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0591 - acc: 0.2969 - val_loss: 0.0529 - val_acc: 0.2975\n",
      "Training on batch 1700000 to 1750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0575 - acc: 0.2972 - val_loss: 0.0559 - val_acc: 0.2972\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training on batch 1750000 to 1800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 0.0588 - acc: 0.2964 - val_loss: 0.0599 - val_acc: 0.2971\n",
      "Training on batch 1800000 to 1850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0577 - acc: 0.2974 - val_loss: 0.0571 - val_acc: 0.2971\n",
      "Training on batch 1850000 to 1900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0577 - acc: 0.2963 - val_loss: 0.0571 - val_acc: 0.2984\n",
      "Training on batch 1900000 to 1950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0554 - acc: 0.2973 - val_loss: 0.0561 - val_acc: 0.2978\n",
      "Training on batch 1950000 to 2000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0568 - acc: 0.2976 - val_loss: 0.0630 - val_acc: 0.2990\n",
      "Training on batch 2000000 to 2050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 382us/step - loss: 0.0565 - acc: 0.2966 - val_loss: 0.0584 - val_acc: 0.2981\n",
      "Training on batch 2050000 to 2100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 383us/step - loss: 0.0559 - acc: 0.2968 - val_loss: 0.0599 - val_acc: 0.2958\n",
      "Training on batch 2100000 to 2150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0569 - acc: 0.2971 - val_loss: 0.0594 - val_acc: 0.2985\n",
      "Training on batch 2150000 to 2200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0583 - acc: 0.2972 - val_loss: 0.0563 - val_acc: 0.2977\n",
      "Training on batch 2200000 to 2250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0580 - acc: 0.2971 - val_loss: 0.0557 - val_acc: 0.2980\n",
      "Training on batch 2250000 to 2300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0555 - acc: 0.2971 - val_loss: 0.0604 - val_acc: 0.2968\n",
      "Training on batch 2300000 to 2350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0564 - acc: 0.2967 - val_loss: 0.0604 - val_acc: 0.2956\n",
      "Training on batch 2350000 to 2400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0579 - acc: 0.2971 - val_loss: 0.0559 - val_acc: 0.2947\n",
      "Training on batch 2400000 to 2450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0565 - acc: 0.2978 - val_loss: 0.0558 - val_acc: 0.2978\n",
      "Training on batch 2450000 to 2500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0555 - acc: 0.2973 - val_loss: 0.0531 - val_acc: 0.2983\n",
      "Training on batch 2500000 to 2550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0578 - acc: 0.2972 - val_loss: 0.0560 - val_acc: 0.2974\n",
      "Training on batch 2550000 to 2600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0563 - acc: 0.2975 - val_loss: 0.0551 - val_acc: 0.2971\n",
      "Training on batch 2600000 to 2650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0563 - acc: 0.2972 - val_loss: 0.0557 - val_acc: 0.2959\n",
      "Training on batch 2650000 to 2700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0574 - acc: 0.2978 - val_loss: 0.0533 - val_acc: 0.2988\n",
      "Training on batch 2700000 to 2750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0579 - acc: 0.2967 - val_loss: 0.0582 - val_acc: 0.2960\n",
      "Training on batch 2750000 to 2800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0565 - acc: 0.2967 - val_loss: 0.0618 - val_acc: 0.2957\n",
      "Training on batch 2800000 to 2850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 407us/step - loss: 0.0586 - acc: 0.2969 - val_loss: 0.0536 - val_acc: 0.2989\n",
      "Training on batch 2850000 to 2900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0546 - acc: 0.2979 - val_loss: 0.0573 - val_acc: 0.2984\n",
      "Training on batch 2900000 to 2950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0553 - acc: 0.2973 - val_loss: 0.0564 - val_acc: 0.2952\n",
      "Training on batch 2950000 to 3000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 384us/step - loss: 0.0566 - acc: 0.2966 - val_loss: 0.0576 - val_acc: 0.2961\n",
      "Training on batch 3000000 to 3050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0566 - acc: 0.2970 - val_loss: 0.0583 - val_acc: 0.2974\n",
      "Training on batch 3050000 to 3100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0552 - acc: 0.2978 - val_loss: 0.0552 - val_acc: 0.2974\n",
      "Training on batch 3100000 to 3150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0575 - acc: 0.2971 - val_loss: 0.0589 - val_acc: 0.2987\n",
      "Training on batch 3150000 to 3200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 378us/step - loss: 0.0563 - acc: 0.2976 - val_loss: 0.0547 - val_acc: 0.2964\n",
      "Training on batch 3200000 to 3250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.0554 - acc: 0.2973 - val_loss: 0.0545 - val_acc: 0.2984\n",
      "Training on batch 3250000 to 3300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 378us/step - loss: 0.0554 - acc: 0.2970 - val_loss: 0.0585 - val_acc: 0.2984\n",
      "Training on batch 3300000 to 3350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 377us/step - loss: 0.0542 - acc: 0.2982 - val_loss: 0.0585 - val_acc: 0.2969\n",
      "Training on batch 3350000 to 3400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 379us/step - loss: 0.0566 - acc: 0.2975 - val_loss: 0.0551 - val_acc: 0.2982\n",
      "Training on batch 3400000 to 3450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 376us/step - loss: 0.0566 - acc: 0.2970 - val_loss: 0.0553 - val_acc: 0.2951\n",
      "Training on batch 3450000 to 3500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50000/50000 [==============================] - 19s 377us/step - loss: 0.0546 - acc: 0.2983 - val_loss: 0.0582 - val_acc: 0.2980\n",
      "Training on batch 3500000 to 3550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0539 - acc: 0.2977 - val_loss: 0.0576 - val_acc: 0.2960\n",
      "Training on batch 3550000 to 3600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0551 - acc: 0.2970 - val_loss: 0.0555 - val_acc: 0.2992\n",
      "Training on batch 3600000 to 3650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0548 - acc: 0.2960 - val_loss: 0.0589 - val_acc: 0.2950\n",
      "Training on batch 3650000 to 3700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0565 - acc: 0.2968 - val_loss: 0.0519 - val_acc: 0.2998\n",
      "Training on batch 3700000 to 3750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0546 - acc: 0.2966 - val_loss: 0.0551 - val_acc: 0.2959\n",
      "Training on batch 3750000 to 3800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0541 - acc: 0.2981 - val_loss: 0.0537 - val_acc: 0.2981\n",
      "Training on batch 3800000 to 3850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0551 - acc: 0.2963 - val_loss: 0.0569 - val_acc: 0.2964\n",
      "Training on batch 3850000 to 3900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0551 - acc: 0.2978 - val_loss: 0.0572 - val_acc: 0.2972\n",
      "Training on batch 3900000 to 3950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0532 - acc: 0.2974 - val_loss: 0.0547 - val_acc: 0.2998\n",
      "Training on batch 3950000 to 4000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0531 - acc: 0.2977 - val_loss: 0.0519 - val_acc: 0.2970\n",
      "Training on batch 4000000 to 4050000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0563 - acc: 0.2984 - val_loss: 0.0531 - val_acc: 0.2974\n",
      "Training on batch 4050000 to 4100000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 385us/step - loss: 0.0540 - acc: 0.2975 - val_loss: 0.0535 - val_acc: 0.2990\n",
      "Training on batch 4100000 to 4150000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0548 - acc: 0.2976 - val_loss: 0.0533 - val_acc: 0.2968\n",
      "Training on batch 4150000 to 4200000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 387us/step - loss: 0.0541 - acc: 0.2973 - val_loss: 0.0552 - val_acc: 0.2962\n",
      "Training on batch 4200000 to 4250000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0539 - acc: 0.2981 - val_loss: 0.0554 - val_acc: 0.2982\n",
      "Training on batch 4250000 to 4300000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0559 - acc: 0.2981 - val_loss: 0.0594 - val_acc: 0.2987\n",
      "Training on batch 4300000 to 4350000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 388us/step - loss: 0.0550 - acc: 0.2972 - val_loss: 0.0518 - val_acc: 0.2998\n",
      "Training on batch 4350000 to 4400000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0528 - acc: 0.2987 - val_loss: 0.0547 - val_acc: 0.2988\n",
      "Training on batch 4400000 to 4450000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0545 - acc: 0.2988 - val_loss: 0.0531 - val_acc: 0.2997\n",
      "Training on batch 4450000 to 4500000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0538 - acc: 0.2973 - val_loss: 0.0540 - val_acc: 0.2978\n",
      "Training on batch 4500000 to 4550000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s 424us/step - loss: 0.0575 - acc: 0.2977 - val_loss: 0.0554 - val_acc: 0.2990\n",
      "Training on batch 4550000 to 4600000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 392us/step - loss: 0.0518 - acc: 0.2990 - val_loss: 0.0539 - val_acc: 0.2967\n",
      "Training on batch 4600000 to 4650000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s 411us/step - loss: 0.0539 - acc: 0.2980 - val_loss: 0.0532 - val_acc: 0.2978\n",
      "Training on batch 4650000 to 4700000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 396us/step - loss: 0.0548 - acc: 0.2973 - val_loss: 0.0545 - val_acc: 0.2970\n",
      "Training on batch 4700000 to 4750000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s 416us/step - loss: 0.0552 - acc: 0.2974 - val_loss: 0.0523 - val_acc: 0.2965\n",
      "Training on batch 4750000 to 4800000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 20s 391us/step - loss: 0.0526 - acc: 0.2985 - val_loss: 0.0566 - val_acc: 0.2995\n",
      "Training on batch 4800000 to 4850000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 389us/step - loss: 0.0545 - acc: 0.2964 - val_loss: 0.0607 - val_acc: 0.2974\n",
      "Training on batch 4850000 to 4900000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 21s 425us/step - loss: 0.0556 - acc: 0.2975 - val_loss: 0.0555 - val_acc: 0.2966\n",
      "Training on batch 4900000 to 4950000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 390us/step - loss: 0.0552 - acc: 0.2987 - val_loss: 0.0527 - val_acc: 0.2954\n",
      "Training on batch 4950000 to 5000000 of 5001036\n",
      "Train on 50000 samples, validate on 12500 samples\n",
      "Epoch 1/1\n",
      "50000/50000 [==============================] - 19s 386us/step - loss: 0.0537 - acc: 0.2984 - val_loss: 0.0531 - val_acc: 0.2967\n",
      "Training on batch 5000000 to 5001036 of 5001036\n",
      "Train on 1036 samples, validate on 260 samples\n",
      "Epoch 1/1\n",
      "1036/1036 [==============================] - 1s 533us/step - loss: 0.0512 - acc: 0.2910 - val_loss: 0.0382 - val_acc: 0.2958\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f2c6c626cf8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "char_s2s.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "------------------------------------------\n",
      "Predicted word is: a s \n",
      "Actual word is: a s  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: p r o c e s s i n g \n",
      "Actual word is: p r o c e s s i n g  \n",
      "---\n",
      "Predicted word is: m a n a g e m e n t \n",
      "Actual word is: m a n a g e m e n t  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: o t h e r \n",
      "Actual word is: o t h e r  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: m e n u r e t \n",
      "Actual word is: c o l l a t e r a l  \n",
      "---\n",
      "Predicted word is: o n \n",
      "Actual word is: o n  \n",
      "---\n",
      "Predicted word is: i n \n",
      "Actual word is: i n  \n",
      "---\n",
      "Predicted word is: m e m b e r s \n",
      "Actual word is: m e m b e r s  \n",
      "---\n",
      "Predicted word is: p r o t e c t i o n \n",
      "Actual word is: p r o t e c t i o n  \n",
      "---\n",
      "Predicted word is: r e c l i v e \n",
      "Actual word is: s u p p o r t i n g  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: p e r f o r m \n",
      "Actual word is: p e r f o r m  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: m o d e l \n",
      "Actual word is: m o d e l  \n",
      "---\n",
      "Predicted word is: d i s p l a y \n",
      "Actual word is: d i s p l a y  \n",
      "---\n",
      "Predicted word is: t o \n",
      "Actual word is: t o  \n",
      "---\n",
      "Predicted word is: o f \n",
      "Actual word is: o f  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: s a i d \n",
      "Actual word is: s a i d  \n",
      "---\n",
      "Predicted word is: s t o r e d \n",
      "Actual word is: s t o r e d  \n",
      "---\n",
      "Predicted word is: w i t h \n",
      "Actual word is: w i t h  \n",
      "---\n",
      "Predicted word is: o u t p u t \n",
      "Actual word is: o u t p u t  \n",
      "---\n",
      "Predicted word is: c o l l e c t i n g \n",
      "Actual word is: c o l l e c t i n g  \n",
      "---\n",
      "Predicted word is: m o r e \n",
      "Actual word is: m o r e  \n",
      "---\n",
      "Predicted word is: r e f e r e n c e \n",
      "Actual word is: r e f e r e n c e  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: d o c u m e n t \n",
      "Actual word is: d o c u m e n t  \n",
      "---\n",
      "Predicted word is: d a t a \n",
      "Actual word is: d a t a  \n",
      "---\n",
      "Predicted word is: a s s h o l e c t o r \n",
      "Actual word is: u n i t a r y  \n",
      "---\n",
      "Predicted word is: w h e r e \n",
      "Actual word is: w h e r e  \n",
      "---\n",
      "Predicted word is: p o s i t i o n \n",
      "Actual word is: p o s i t i o n  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: a n \n",
      "Actual word is: a n  \n",
      "---\n",
      "Predicted word is: s e t \n",
      "Actual word is: s e t  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: e d g a y \n",
      "Actual word is: b i t t i n g  \n",
      "---\n",
      "Predicted word is: i d e n t i f y i n g \n",
      "Actual word is: i d e n t i f y i n g  \n",
      "---\n",
      "Predicted word is: d i s p l a y e d \n",
      "Actual word is: d i s p l a y e d  \n",
      "---\n",
      "Predicted word is: r e s e r t e r \n",
      "Actual word is: c l a s s e s  \n",
      "---\n",
      "Predicted word is: r e s t o n c e \n",
      "Actual word is: d u r a t i o n  \n",
      "---\n",
      "Predicted word is: a n \n",
      "Actual word is: a n  \n",
      "---\n",
      "Predicted word is: d i g i t a l \n",
      "Actual word is: d i g i t a l  \n",
      "---\n",
      "Predicted word is: u n i t \n",
      "Actual word is: u n i t  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: p a r a m e t e r s \n",
      "Actual word is: p a r a m e t e r s  \n",
      "---\n",
      "Predicted word is: s o u r c e \n",
      "Actual word is: s o u r c e  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: m e m o r y \n",
      "Actual word is: m e m o r y  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: o n e \n",
      "Actual word is: o n e  \n",
      "---\n",
      "Predicted word is: c l o c k \n",
      "Actual word is: c l o c k  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: a t t r i b u t e \n",
      "Actual word is: a t t r i b u t e  \n",
      "---\n",
      "Predicted word is: t h r e e \n",
      "Actual word is: t h r e e  \n",
      "---\n",
      "Predicted word is: a u t o m a t i c \n",
      "Actual word is: a u t o m a t i c  \n",
      "---\n",
      "Predicted word is: f f s \n",
      "Actual word is: a f f i n e  \n",
      "---\n",
      "Predicted word is: o f \n",
      "Actual word is: o f  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: s y s t e m \n",
      "Actual word is: s y s t e m  \n",
      "---\n",
      "Predicted word is: t o \n",
      "Actual word is: t o  \n",
      "---\n",
      "Predicted word is: t h a r u \n",
      "Actual word is: s p e e d  \n",
      "---\n",
      "Predicted word is: d i s k \n",
      "Actual word is: d i s k  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: p a d a b i l i t y \n",
      "Actual word is: t e n t a t i v e  \n",
      "---\n",
      "Predicted word is: e x e c u t e s \n",
      "Actual word is: e x e c u t e s  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: c o n p e r t \n",
      "Actual word is: p r o j e c t e d  \n",
      "---\n",
      "Predicted word is: p r e s e t a l \n",
      "Actual word is: c o n s t r a i n t  \n",
      "---\n",
      "Predicted word is: t o \n",
      "Actual word is: t o  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: o f \n",
      "Actual word is: o f  \n",
      "---\n",
      "Predicted word is: v a l e r \n",
      "Actual word is: v a l u e  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: a c c o u n t \n",
      "Actual word is: a c c o u n t  \n",
      "---\n",
      "Predicted word is: o f \n",
      "Actual word is: o f  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: b y \n",
      "Actual word is: b y  \n",
      "---\n",
      "Predicted word is: a n d \n",
      "Actual word is: a n d  \n",
      "---\n",
      "Predicted word is: a t \n",
      "Actual word is: a t  \n",
      "---\n",
      "Predicted word is: c u r r e n t \n",
      "Actual word is: c u r r e n t  \n",
      "---\n",
      "Predicted word is: p r o c e s s i n g \n",
      "Actual word is: p r o c e s s i n g  \n",
      "---\n",
      "Predicted word is: f o r \n",
      "Actual word is: f o r  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: i n t o \n",
      "Actual word is: i n t o  \n",
      "---\n",
      "Predicted word is: r e l e v a n t \n",
      "Actual word is: r e l e v a n t  \n",
      "---\n",
      "Predicted word is: o f \n",
      "Actual word is: o f  \n",
      "---\n",
      "Predicted word is: d a t a \n",
      "Actual word is: d a t a  \n",
      "---\n",
      "Predicted word is: i f \n",
      "Actual word is: i f  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: t h e \n",
      "Actual word is: t h e  \n",
      "---\n",
      "Predicted word is: c o m p u t e r \n",
      "Actual word is: c o m p u t e r  \n",
      "---\n",
      "Predicted word is: a \n",
      "Actual word is: a  \n",
      "---\n",
      "Predicted word is: p l u r a l i t y \n",
      "Actual word is: p l u r a l i t y  \n",
      "---\n",
      "Predicted word is: o n e \n",
      "Actual word is: o n e  \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "char_s2s.example_output(100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 192,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from keras.utils.vis_utils import model_to_dot\n",
    "from IPython.display import Image\n",
    "Image(model_to_dot(self.model, show_shapes=True).create_png(prog='dot'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ideas for improving performan"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "class CharS2S_ext(CharS2S):\n",
    "    def _build_model(self):\n",
    "        \"\"\" Build the model. \"\"\"\n",
    "        print(\"Building model\")\n",
    "        encoded_state = Input(shape=(self.latent_dim,), name=\"EncodedState\")\n",
    "        decoder_inputs = Input(shape=(None, self.num_decoder_tokens), name=\"DecoderInputs\")\n",
    "        decoder_gru = GRU(self.latent_dim, return_sequences=True, return_state=True, name=\"Decoder\")\n",
    "        decoder_outputs, decoder_state = decoder_gru(decoder_inputs, initial_state=encoded_state)\n",
    "        decoder_dense = Dense(self.num_decoder_tokens, activation='softmax', name=\"VocabProjection\")\n",
    "        decoder_outputs = decoder_dense(decoder_outputs)\n",
    "        self.model = Model([encoded_state, decoder_inputs], decoder_outputs)\n",
    "\n",
    "        # We also need an inference model\n",
    "        self.infdec = Model(inputs=[encoded_state, decoder_inputs], outputs=[decoder_outputs, decoder_state])\n",
    "\n",
    "        self.model.compile(\n",
    "            optimizer='adam',\n",
    "            loss='categorical_crossentropy',\n",
    "            metrics=['acc']\n",
    "        )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
