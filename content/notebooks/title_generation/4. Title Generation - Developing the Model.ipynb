{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: 4. Title Generation - Developing the Model\n",
    "Tags: improving_results\n",
    "Authors: Ben Hoyle\n",
    "Summary: This post looks at developing our initial models to include state of the art features to improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Title Generation - Developing the Model\n",
    "\n",
    "This post looks at developing our initial models to include state of the art features to improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap:\n",
    "\n",
    "* We have two models: the Ludwig model and the Chollet/Brownlee model. \n",
    "* Performance so far has been fairly poor.\n",
    "* Each model had slightly different characteristics - the Ludwig model produced better formed output but seemed to simply memorise and repeat titles, the Chollet/Brownlee model had a lower loss and appeared to memorise less but produced more nonsensical outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our last post we identified a number of ways to improve our models:\n",
    "\n",
    "1. Use GloVe encodings and a shared embedding layer. \n",
    "2. Add attention.\n",
    "3. Add pointers / skip connections between our input and our output.\n",
    "4. Use a coverage measure.\n",
    "5. Use different word forms such as lemmas or stems.\n",
    "6. Use a GAN-style discriminator on the output.\n",
    "7. Improve our sampling by employing beam search.\n",
    "\n",
    "We will look at some of these in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Shared Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the glove embeddings text file from [here](http://nlp.stanford.edu/data/glove.6B.zip). This is to be placed in a `/glove` directory.\n",
    "\n",
    "Then we follow the steps from Ludwig's example to generate our embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"glove/\"\n",
    "\n",
    "embeddings_index = {}\n",
    "# For Python 3 tweaked to add 'rb'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), 'rb')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    # Tweaked to decode the binary text values\n",
    "    word = values[0].decode('utf-8')\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['irati',\n",
       " 'fotiou',\n",
       " '8-year',\n",
       " 'usagi',\n",
       " 'autobianchi',\n",
       " 'eldercare',\n",
       " 'puraskar',\n",
       " 'dench',\n",
       " 'ventrally',\n",
       " 'amsc']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index.get('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load and Tokenize Data\n",
    "\n",
    "Initially we load our data as before. As we are using shared embeddings we will train a common tokenizer on both the claim text and title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_decoder_tokens = 2500 # This is our output title vocabulary\n",
    "num_encoder_tokens = 2500 # This is our input claim vocabulary\n",
    "encoder_seq_length = 300 # This is our limit for our input claim length\n",
    "decoder_seq_length = 22 # This is our limit for our output title length - 20 + 2 for start/stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "30000 samples loaded\n",
      "\n",
      "\n",
      "Adding start and stop tokens to output\n",
      "\n",
      "\n",
      "An example title: startseq System and method for session restoration at geo-redundant gateways stopseq\n",
      "----\n",
      "An example claim: \n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PIK = \"claim_and_title.data\"\n",
    "\n",
    "if not os.path.isfile(PIK):\n",
    "    # Download file\n",
    "    !wget https://benhoyle.github.io/notebooks/title_generation/claim_and_title.data\n",
    "\n",
    "with open(PIK, \"rb\") as f:\n",
    "    print(\"Loading data\")\n",
    "    data = pickle.load(f)\n",
    "    print(\"{0} samples loaded\".format(len(data)))\n",
    "    \n",
    "print(\"\\n\\nAdding start and stop tokens to output\")\n",
    "data = [(c, \"startseq {0} stopseq\".format(t)) for c, t in data]\n",
    "                                      \n",
    "print(\"\\n\\nAn example title:\", data[0][1])\n",
    "print(\"----\")\n",
    "print(\"An example claim:\", data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "t_joint = text.Tokenizer(\n",
    "                num_words=num_encoder_tokens, \n",
    "                lower=True,\n",
    "                char_level=False,\n",
    "                oov_token=\"<UNK>\"\n",
    ")\n",
    "X_texts = [d[0] for d in data]\n",
    "Y_texts = [d[1] for d in data]\n",
    "total_texts = X_texts + Y_texts\n",
    "t_joint.fit_on_texts(total_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remapper',\n",
       " 'inactive',\n",
       " 'imposes',\n",
       " 'overestimates',\n",
       " 'roman',\n",
       " 'mitigating',\n",
       " \"location's\",\n",
       " '56a',\n",
       " 'buckle',\n",
       " 'billable']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t_joint.word_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input sequences (claims) have a max integer value of 2499\n",
      "Our output sequences (titles) have a vocabulary of 2499 words\n"
     ]
    }
   ],
   "source": [
    "X_seqs = t_joint.texts_to_sequences(X_texts)\n",
    "Y_seqs = t_joint.texts_to_sequences(Y_texts)\n",
    "print(\"Our input sequences (claims) have a max integer value of {0}\".format(max([max(x) for x in X_seqs])))\n",
    "print(\"Our output sequences (titles) have a max integer value of {0}\".format(max([max(y) for y in Y_seqs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = max([max(x + y) for x, y in zip(X_seqs, Y_seqs)]) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest input sequence is 300 tokens long.\n",
      "Our longest output sequence is 22 tokens long.\n"
     ]
    }
   ],
   "source": [
    "filtered_seqs = [(x, y) for x,y in zip(X_seqs, Y_seqs) if len(x) <= encoder_seq_length and len(y) <= decoder_seq_length]\n",
    "X_seqs = [x for x, _ in filtered_seqs]\n",
    "Y_seqs = [y for _, y in filtered_seqs]\n",
    "\n",
    "X_length = [len(x) for x in X_seqs]\n",
    "max_length = max(X_length)\n",
    "print(\"Our longest input sequence is {0} tokens long.\".format(max_length))\n",
    "\n",
    "Y_length = [len(y) for y in Y_seqs]\n",
    "max_length = max(Y_length)\n",
    "print(\"Our longest output sequence is {0} tokens long.\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word_embedding_size = 100 # As we are using the Glove 100d data\n",
    "print('Found {0} word vectors.'.format(len(embeddings_index)))\n",
    "embedding_matrix = np.zeros((vocab_size, word_embedding_size))\n",
    "\n",
    "# Filter our vocab to only the used items\n",
    "words = [(w, i) for w, i in t_joint.word_index.items() if int(i) < vocab_size]\n",
    "\n",
    "# This is from https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/      \n",
    "for word, i in words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: can I use the embedding matrix as the weights for a dense layer that is multiplied by the probabilities of the decoder output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      " [31, 2, 29, 8, 448, 2, 552, 91, 1047, 42, 19, 2, 397, 1, 29, 26, 1959, 51, 20, 1, 397, 14, 25, 2, 74, 3, 61, 352, 109, 28, 1, 96, 74, 3, 352, 109, 28, 58, 2214, 4, 782, 1, 552, 4, 1008, 4, 11, 142, 261, 24, 69, 11, 500, 352, 1510, 15, 1, 397, 60, 6, 2, 1672, 109, 5, 6, 75, 4, 2, 888, 3, 1, 397, 1, 552, 142, 3, 603, 685, 5, 937, 42, 19, 16, 397, 5, 252, 2, 9, 494, 1653, 2, 142, 261, 8, 32, 3, 16, 69, 11, 500, 352, 1510, 15, 1, 2193, 397, 4, 20, 1, 53, 5, 4, 1, 53, 18, 32, 957, 1, 4, 742, 2, 65, 19, 2, 65, 97, 4, 1, 118]\n",
      "startseq System and method for session restoration at geo-redundant gateways stopseq [34, 30, 5, 29, 8, 352, 14, 1836, 35]\n"
     ]
    }
   ],
   "source": [
    "print(X_texts[0], X_seqs[0])\n",
    "print(Y_texts[0], Y_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X data has shape (25632, 300) and our Y data has shape (25632, 22)\n"
     ]
    }
   ],
   "source": [
    "# Pad the data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(X_seqs, maxlen=encoder_seq_length)\n",
    "Y = pad_sequences(Y_seqs, maxlen=decoder_seq_length, padding='post')\n",
    "\n",
    "print(\"Our X data has shape {0} and our Y data has shape {1}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   30,    5,   29,    8,  352,   14, 1836,   35,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ludwig Model\n",
    "\n",
    "There are actually two models described by Oswaldo. A first introductory model and a second model that uses an additional adversarial network. The first model is easier to understand so we will start with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.layers import concatenate\n",
    "\n",
    "y_vocab_len = num_decoder_tokens # This is our output title vocabulary\n",
    "X_vocab_len = num_encoder_tokens # This is our input claim vocabulary\n",
    "X_max_len = encoder_seq_length # This is our limit for our input claim length\n",
    "y_max_len = decoder_seq_length # This is our limit for our output title length - 20 + 2 for start/stop\n",
    "\n",
    "# source text input model\n",
    "inputs1 = Input(shape=(X_max_len,))\n",
    "#am1 = Embedding(X_vocab_len, 128)(inputs1)\n",
    "Shared_Embedding = Embedding(\n",
    "    output_dim=word_embedding_size, \n",
    "    input_dim=vocab_size, \n",
    "    weights=[embedding_matrix], \n",
    "    input_length=X_vocab_len\n",
    ")\n",
    "am1 = Shared_Embedding(inputs1)\n",
    "am2 = LSTM(128)(am1)\n",
    "# summary input model\n",
    "inputs2 = Input(shape=(y_max_len,))\n",
    "sm1 = Shared_Embedding(inputs2)\n",
    "sm2 = LSTM(128)(sm1)\n",
    "# decoder output model\n",
    "decoder1 = concatenate([am2, sm2])\n",
    "outputs = Dense(y_vocab_len, activation='softmax')(decoder1)\n",
    "# tie it together [article, summary] [word]\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 2500, 100)    250000      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 128)          117248      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 128)          117248      embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           lstm_5[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2500)         642500      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,126,996\n",
      "Trainable params: 1,126,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the embedding is shared by both LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   30,    5,   29,    8,  352,   14, 1836,   35,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_set(X, Y, i_end, i):\n",
    "    \"\"\" Generate the data for training/validation from X and Y.\n",
    "    i_end is the end of the set, i is the start.\"\"\"\n",
    "    set_size = 0\n",
    "    limit_list = list()\n",
    "    for sent in Y[i:i_end]:\n",
    "        # Edited below to use integer value of EOS symbol\n",
    "        limit = np.where(sent==t_joint.word_index[\"stopseq\"])[0][0]  #  the position of the symbol EOS\n",
    "        set_size += limit + 1\n",
    "        limit_list.append(limit)\n",
    "   \n",
    "    # We need to change this bit to set our array size based on the limit values\n",
    "    # Generate blank arrays for the set\n",
    "    I_1 = np.zeros((set_size, X_max_len))\n",
    "    I_2 = np.zeros((set_size, y_max_len))\n",
    "    # This below is a big array\n",
    "    Y_set = np.zeros((set_size, y_vocab_len))\n",
    "    count = 0\n",
    "    # Now we want to create, for each sample, a set of examples for each word in the title\n",
    "    # Have we just been training on 0 to 100?!?!\n",
    "    for l in range(0, (i_end - i)):\n",
    "        # for each X and y in set of NB_SET \n",
    "            \n",
    "        # We need to build the input for the second encoder for the next word in y\n",
    "        # I.e. for word 3 in the title the input2 consists of words 1 and 2 (using teacher forcing)\n",
    "            \n",
    "        # Get length of current title - i.e. where the integer = 2 = stopseq\n",
    "        limit = limit_list[l]\n",
    "            \n",
    "        # We only need to create examples up to the length of the title \n",
    "        for m in range(1, limit+1):\n",
    "                \n",
    "            # Generate our one-hot y out\n",
    "            one_hot_out = np.zeros((1, y_vocab_len))\n",
    "            # This builds our one-hot generation into our training loop\n",
    "            # The l and m respectively iterate through the samples and the output sequence elements\n",
    "            one_hot_out[0, Y[l+i][m]] = 1\n",
    "                \n",
    "            # Create a blank row/array for a partial input for our summary model - this is fed into the decoder\n",
    "            # It is of the same size as our title\n",
    "            partial_input = np.zeros((1, y_max_len))\n",
    "            # Don't we also need to set partial input [0] to startseq as well? - no that's taken care of\n",
    "            # by m starting at one but our range below starting at 0\n",
    "            \n",
    "            # Because we are zero padding add words up to m to end - DOES THIS STILL WORK IF WE ZERO PAD\n",
    "            # AT THE END? - Yes but we just feed the words with zeros first?\n",
    "            # What happens if we change this to 0:m?! - if we have [1, 2, 3, 4] this will generate\n",
    "            # [0,0,0,1], [0,0,1,2], [0,1, 2, 3]\n",
    "            # Our zero padding is at the end though so our seqs looks like [1,2,3,0,0,0], \n",
    "            # But I know you want the data need the end of the input seq to prevent forgetting\n",
    "            partial_input[0, -m:] = Y[l+i][0:m]\n",
    "            \n",
    "            # This fills in each sample of the training data, i.e. count increments up to set size\n",
    "            I_1[count, :] = X[l+i]\n",
    "            I_2[count, :] = partial_input\n",
    "            Y_set[count, :] = one_hot_out\n",
    "            count += 1\n",
    "                \n",
    "        # Shuffle the I_1, I_2 and Y_set vectors for better training - trick from RL\n",
    "        # - see here - np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X);\n",
    "        indices = np.random.permutation(I_1.shape[0])\n",
    "        np.take(I_1, indices, axis=0, out=I_1)\n",
    "        np.take(I_2, indices, axis=0, out=I_2)\n",
    "        np.take(Y_set, indices, axis=0, out=Y_set)\n",
    "    return I_1, I_2, Y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved weights found, loading...\n"
     ]
    }
   ],
   "source": [
    "# Basing training in sets code on here - https://github.com/ChunML/seq2seq/blob/master/seq2seq.py\n",
    "\n",
    "# Function to look for saved weights file\n",
    "def find_checkpoint_file(folder):\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'v2_kerascheckpoint' in f]\n",
    "    if len(checkpoint_file) == 0:\n",
    "        return []\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "# Finding trained weights of previous epoch if any\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "\n",
    "k_start = 1\n",
    "\n",
    "# If any trained weight was found, then load them into the model\n",
    "if len(saved_weights) != 0:\n",
    "    print('[INFO] Saved weights found, loading...')\n",
    "    epoch = saved_weights[saved_weights.rfind('_')+1:saved_weights.rfind('.')]\n",
    "    model.load_weights(saved_weights)\n",
    "    k_start = int(epoch) + 1\n",
    "\n",
    "# So instead of X we have [inputs1, inputs2] - this is where we need to fold in \n",
    "# - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py\n",
    "\n",
    "# So we have inputs2 that build up - we have a set of inputs2 up to the length of inputs2\n",
    "\n",
    "# We need to refactor some of the loops below as functions - we can then apply to test data to generate a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh - a problem with using embeddings is that our start and stop tokens are no longer 1 and 2!\n",
    "\n",
    "*** Fixed above ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For now we can just change 2 to the variable below - in future it is probably better to build our our tokenizer that\n",
    "# reserves control characters\n",
    "t_joint.word_index[\"stopseq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "BATCH_SIZE = 32 # Depends on GPU - most values are around this 32-128 \n",
    "NB_EPOCH = 20\n",
    "# Number of examples to group together in a set - 100 is fast / 1000 is too much on an 8-core i7 laptop\n",
    "# I think 100 is good - 250 takes a time to generate the sets of test data\n",
    "NB_SET = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_end = 0\n",
    "num_examples = len(X_train)\n",
    "num_test = len(X_test)\n",
    "# Initialise history of accuracy\n",
    "train_loss = list()\n",
    "val_loss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 2 - 0/20505 samples\n",
      "Train on 2534 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 22s 9ms/step - loss: 2.2101 - val_loss: 2.3826\n",
      "[INFO] Training model: epoch 2 - 250/20505 samples\n",
      "Train on 2464 samples, validate on 677 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 22s 9ms/step - loss: 2.1098 - val_loss: 2.2632\n",
      "[INFO] Training model: epoch 2 - 500/20505 samples\n",
      "Train on 2404 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 21s 9ms/step - loss: 2.1046 - val_loss: 2.4288\n",
      "[INFO] Training model: epoch 2 - 750/20505 samples\n",
      "Train on 2516 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 22s 9ms/step - loss: 2.1949 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 2 - 1000/20505 samples\n",
      "Train on 2510 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 22s 9ms/step - loss: 2.2015 - val_loss: 2.3367\n",
      "[INFO] Training model: epoch 2 - 1250/20505 samples\n",
      "Train on 2521 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 23s 9ms/step - loss: 2.2629 - val_loss: 2.2410\n",
      "[INFO] Training model: epoch 2 - 1500/20505 samples\n",
      "Train on 2492 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 2.1124 - val_loss: 2.3247\n",
      "[INFO] Training model: epoch 2 - 1750/20505 samples\n",
      "Train on 2545 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 24s 9ms/step - loss: 2.0176 - val_loss: 2.2035\n",
      "[INFO] Training model: epoch 2 - 2000/20505 samples\n",
      "Train on 2484 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.1958 - val_loss: 2.6558\n",
      "[INFO] Training model: epoch 2 - 2250/20505 samples\n",
      "Train on 2391 samples, validate on 683 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 23s 9ms/step - loss: 2.1795 - val_loss: 2.4181\n",
      "[INFO] Training model: epoch 2 - 2500/20505 samples\n",
      "Train on 2521 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 24s 9ms/step - loss: 2.1711 - val_loss: 2.1677\n",
      "[INFO] Training model: epoch 2 - 2750/20505 samples\n",
      "Train on 2522 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 2.2412 - val_loss: 2.3920\n",
      "[INFO] Training model: epoch 2 - 3000/20505 samples\n",
      "Train on 2455 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 2.1552 - val_loss: 2.3904\n",
      "[INFO] Training model: epoch 2 - 3250/20505 samples\n",
      "Train on 2538 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 24s 9ms/step - loss: 2.1931 - val_loss: 2.3230\n",
      "[INFO] Training model: epoch 2 - 3500/20505 samples\n",
      "Train on 2464 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.2429 - val_loss: 2.1672\n",
      "[INFO] Training model: epoch 2 - 3750/20505 samples\n",
      "Train on 2484 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.1411 - val_loss: 2.5224\n",
      "[INFO] Training model: epoch 2 - 4000/20505 samples\n",
      "Train on 2547 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 23s 9ms/step - loss: 2.2104 - val_loss: 2.3912\n",
      "[INFO] Training model: epoch 2 - 4250/20505 samples\n",
      "Train on 2364 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 2.1683 - val_loss: 2.2343\n",
      "[INFO] Training model: epoch 2 - 4500/20505 samples\n",
      "Train on 2351 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 2.1008 - val_loss: 2.3659\n",
      "[INFO] Training model: epoch 2 - 4750/20505 samples\n",
      "Train on 2436 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 2.0879 - val_loss: 2.2916\n",
      "[INFO] Training model: epoch 2 - 5000/20505 samples\n",
      "Train on 2338 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 22s 9ms/step - loss: 2.1865 - val_loss: 2.2310\n",
      "[INFO] Training model: epoch 2 - 5250/20505 samples\n",
      "Train on 2424 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 10ms/step - loss: 2.1551 - val_loss: 2.1450\n",
      "[INFO] Training model: epoch 2 - 5500/20505 samples\n",
      "Train on 2508 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 23s 9ms/step - loss: 2.1111 - val_loss: 2.5732\n",
      "[INFO] Training model: epoch 2 - 5750/20505 samples\n",
      "Train on 2428 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 2.2642 - val_loss: 2.5461\n",
      "[INFO] Training model: epoch 2 - 6000/20505 samples\n",
      "Train on 2412 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 2.2155 - val_loss: 2.5289\n",
      "[INFO] Training model: epoch 2 - 6250/20505 samples\n",
      "Train on 2469 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 2.2668 - val_loss: 2.2134\n",
      "[INFO] Training model: epoch 2 - 6500/20505 samples\n",
      "Train on 2513 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 2.2224 - val_loss: 2.3273\n",
      "[INFO] Training model: epoch 2 - 6750/20505 samples\n",
      "Train on 2509 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 22s 9ms/step - loss: 2.2078 - val_loss: 2.4643\n",
      "[INFO] Training model: epoch 2 - 7000/20505 samples\n",
      "Train on 2428 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 2.1056 - val_loss: 2.5365\n",
      "[INFO] Training model: epoch 2 - 7250/20505 samples\n",
      "Train on 2482 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 2.1171 - val_loss: 2.4198\n",
      "[INFO] Training model: epoch 2 - 7500/20505 samples\n",
      "Train on 2505 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 2.0969 - val_loss: 2.2209\n",
      "[INFO] Training model: epoch 2 - 7750/20505 samples\n",
      "Train on 2506 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 2.1823 - val_loss: 2.3450\n",
      "[INFO] Training model: epoch 2 - 8000/20505 samples\n",
      "Train on 2442 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 2.1400 - val_loss: 2.1909\n",
      "[INFO] Training model: epoch 2 - 8250/20505 samples\n",
      "Train on 2535 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 24s 9ms/step - loss: 2.2119 - val_loss: 2.3661\n",
      "[INFO] Training model: epoch 2 - 8500/20505 samples\n",
      "Train on 2531 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 2.1308 - val_loss: 2.2979\n",
      "[INFO] Training model: epoch 2 - 8750/20505 samples\n",
      "Train on 2525 samples, validate on 543 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 2.0999 - val_loss: 2.5126\n",
      "[INFO] Training model: epoch 2 - 9000/20505 samples\n",
      "Train on 2559 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 2.1101 - val_loss: 2.2551\n",
      "[INFO] Training model: epoch 2 - 9250/20505 samples\n",
      "Train on 2337 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 21s 9ms/step - loss: 2.2555 - val_loss: 2.3273\n",
      "[INFO] Training model: epoch 2 - 9500/20505 samples\n",
      "Train on 2572 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 24s 9ms/step - loss: 2.1376 - val_loss: 2.3022\n",
      "[INFO] Training model: epoch 2 - 9750/20505 samples\n",
      "Train on 2491 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 2.2172 - val_loss: 2.4557\n",
      "[INFO] Training model: epoch 2 - 10000/20505 samples\n",
      "Train on 2390 samples, validate on 659 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2390/2390 [==============================] - 22s 9ms/step - loss: 2.2061 - val_loss: 2.6325\n",
      "[INFO] Training model: epoch 2 - 10250/20505 samples\n",
      "Train on 2453 samples, validate on 702 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 2.0870 - val_loss: 2.3913\n",
      "[INFO] Training model: epoch 2 - 10500/20505 samples\n",
      "Train on 2484 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.2218 - val_loss: 2.2163\n",
      "[INFO] Training model: epoch 2 - 10750/20505 samples\n",
      "Train on 2424 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 9ms/step - loss: 2.1853 - val_loss: 2.4196\n",
      "[INFO] Training model: epoch 2 - 11000/20505 samples\n",
      "Train on 2435 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 2.2041 - val_loss: 2.3025\n",
      "[INFO] Training model: epoch 2 - 11250/20505 samples\n",
      "Train on 2503 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 2.0272 - val_loss: 2.2923\n",
      "[INFO] Training model: epoch 2 - 11500/20505 samples\n",
      "Train on 2381 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 22s 9ms/step - loss: 2.1969 - val_loss: 2.4107\n",
      "[INFO] Training model: epoch 2 - 11750/20505 samples\n",
      "Train on 2492 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 2.2025 - val_loss: 2.3053\n",
      "[INFO] Training model: epoch 2 - 12000/20505 samples\n",
      "Train on 2516 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 2.2331 - val_loss: 2.1163\n",
      "[INFO] Training model: epoch 2 - 12250/20505 samples\n",
      "Train on 2383 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 21s 9ms/step - loss: 2.2062 - val_loss: 2.2637\n",
      "[INFO] Training model: epoch 2 - 12500/20505 samples\n",
      "Train on 2491 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 2.1532 - val_loss: 2.5704\n",
      "[INFO] Training model: epoch 2 - 12750/20505 samples\n",
      "Train on 2446 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 24s 10ms/step - loss: 2.0985 - val_loss: 2.2835\n",
      "[INFO] Training model: epoch 2 - 13000/20505 samples\n",
      "Train on 2440 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 2.1408 - val_loss: 2.2730\n",
      "[INFO] Training model: epoch 2 - 13250/20505 samples\n",
      "Train on 2444 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 2.1590 - val_loss: 2.3108\n",
      "[INFO] Training model: epoch 2 - 13500/20505 samples\n",
      "Train on 2397 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 9ms/step - loss: 2.1229 - val_loss: 2.2442\n",
      "[INFO] Training model: epoch 2 - 13750/20505 samples\n",
      "Train on 2319 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 2.0592 - val_loss: 2.5376\n",
      "[INFO] Training model: epoch 2 - 14000/20505 samples\n",
      "Train on 2504 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 23s 9ms/step - loss: 2.2372 - val_loss: 2.1988\n",
      "[INFO] Training model: epoch 2 - 14250/20505 samples\n",
      "Train on 2421 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 21s 9ms/step - loss: 2.2013 - val_loss: 2.4810\n",
      "[INFO] Training model: epoch 2 - 14500/20505 samples\n",
      "Train on 2463 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 21s 9ms/step - loss: 2.2323 - val_loss: 2.2700\n",
      "[INFO] Training model: epoch 2 - 14750/20505 samples\n",
      "Train on 2405 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 2.1686 - val_loss: 2.3067\n",
      "[INFO] Training model: epoch 2 - 15000/20505 samples\n",
      "Train on 2405 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 2.2542 - val_loss: 2.4856\n",
      "[INFO] Training model: epoch 2 - 15250/20505 samples\n",
      "Train on 2373 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 21s 9ms/step - loss: 2.0537 - val_loss: 2.3686\n",
      "[INFO] Training model: epoch 2 - 15500/20505 samples\n",
      "Train on 2425 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 2.1881 - val_loss: 2.4565\n",
      "[INFO] Training model: epoch 2 - 15750/20505 samples\n",
      "Train on 2437 samples, validate on 533 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 2.1347 - val_loss: 2.5169\n",
      "[INFO] Training model: epoch 2 - 16000/20505 samples\n",
      "Train on 2443 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 2.1617 - val_loss: 2.3260\n",
      "[INFO] Training model: epoch 2 - 16250/20505 samples\n",
      "Train on 2362 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 2.2975 - val_loss: 2.3707\n",
      "[INFO] Training model: epoch 2 - 16500/20505 samples\n",
      "Train on 2464 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.1335 - val_loss: 2.2904\n",
      "[INFO] Training model: epoch 2 - 16750/20505 samples\n",
      "Train on 2375 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 2.0726 - val_loss: 2.1677\n",
      "[INFO] Training model: epoch 2 - 17000/20505 samples\n",
      "Train on 2511 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 2.2338 - val_loss: 2.2962\n",
      "[INFO] Training model: epoch 2 - 17250/20505 samples\n",
      "Train on 2428 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 2.2274 - val_loss: 2.4144\n",
      "[INFO] Training model: epoch 2 - 17500/20505 samples\n",
      "Train on 2414 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 2.2584 - val_loss: 2.1193\n",
      "[INFO] Training model: epoch 2 - 17750/20505 samples\n",
      "Train on 2463 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 2.0694 - val_loss: 2.3732\n",
      "[INFO] Training model: epoch 2 - 18000/20505 samples\n",
      "Train on 2418 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 2.1459 - val_loss: 2.1653\n",
      "[INFO] Training model: epoch 2 - 18250/20505 samples\n",
      "Train on 2431 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 2.1444 - val_loss: 2.3524\n",
      "[INFO] Training model: epoch 2 - 18500/20505 samples\n",
      "Train on 2440 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 2.1563 - val_loss: 2.3204\n",
      "[INFO] Training model: epoch 2 - 18750/20505 samples\n",
      "Train on 2431 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 2.1367 - val_loss: 2.2359\n",
      "[INFO] Training model: epoch 2 - 19000/20505 samples\n",
      "Train on 2421 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 2.1752 - val_loss: 2.2166\n",
      "[INFO] Training model: epoch 2 - 19250/20505 samples\n",
      "Train on 2464 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.1737 - val_loss: 2.5509\n",
      "[INFO] Training model: epoch 2 - 19500/20505 samples\n",
      "Train on 2419 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 2.1663 - val_loss: 2.3102\n",
      "[INFO] Training model: epoch 2 - 19750/20505 samples\n",
      "Train on 2508 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 24s 9ms/step - loss: 2.1191 - val_loss: 2.1213\n",
      "[INFO] Training model: epoch 2 - 20000/20505 samples\n",
      "Train on 2462 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 2.1453 - val_loss: 2.2773\n",
      "[INFO] Training model: epoch 2 - 20250/20505 samples\n",
      "Train on 2478 samples, validate on 686 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478/2478 [==============================] - 23s 9ms/step - loss: 2.1018 - val_loss: 2.4592\n",
      "[INFO] Training model: epoch 2 - 20500/20505 samples\n",
      "Train on 36 samples, validate on 12 samples\n",
      "Epoch 1/1\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 2.5730 - val_loss: 3.4734\n",
      "[INFO] Training model: epoch 3 - 0/20505 samples\n",
      "Train on 2446 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.9679 - val_loss: 2.3590\n",
      "[INFO] Training model: epoch 3 - 250/20505 samples\n",
      "Train on 2541 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 2.0008 - val_loss: 2.3540\n",
      "[INFO] Training model: epoch 3 - 500/20505 samples\n",
      "Train on 2429 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.9819 - val_loss: 2.1722\n",
      "[INFO] Training model: epoch 3 - 750/20505 samples\n",
      "Train on 2416 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.9458 - val_loss: 2.3659\n",
      "[INFO] Training model: epoch 3 - 1000/20505 samples\n",
      "Train on 2368 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 2.0201 - val_loss: 2.5634\n",
      "[INFO] Training model: epoch 3 - 1250/20505 samples\n",
      "Train on 2473 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.9461 - val_loss: 2.4993\n",
      "[INFO] Training model: epoch 3 - 1500/20505 samples\n",
      "Train on 2454 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.9743 - val_loss: 2.3521\n",
      "[INFO] Training model: epoch 3 - 1750/20505 samples\n",
      "Train on 2509 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 23s 9ms/step - loss: 2.0200 - val_loss: 2.3583\n",
      "[INFO] Training model: epoch 3 - 2000/20505 samples\n",
      "Train on 2377 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.8921 - val_loss: 2.4193\n",
      "[INFO] Training model: epoch 3 - 2250/20505 samples\n",
      "Train on 2531 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 1.9906 - val_loss: 2.1544\n",
      "[INFO] Training model: epoch 3 - 2500/20505 samples\n",
      "Train on 2447 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 22s 9ms/step - loss: 1.9864 - val_loss: 2.3306\n",
      "[INFO] Training model: epoch 3 - 2750/20505 samples\n",
      "Train on 2589 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 24s 9ms/step - loss: 2.0430 - val_loss: 2.1839\n",
      "[INFO] Training model: epoch 3 - 3000/20505 samples\n",
      "Train on 2386 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 23s 10ms/step - loss: 1.9785 - val_loss: 2.2455\n",
      "[INFO] Training model: epoch 3 - 3250/20505 samples\n",
      "Train on 2379 samples, validate on 693 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 22s 9ms/step - loss: 2.1022 - val_loss: 2.3693\n",
      "[INFO] Training model: epoch 3 - 3500/20505 samples\n",
      "Train on 2433 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.9631 - val_loss: 2.2237\n",
      "[INFO] Training model: epoch 3 - 3750/20505 samples\n",
      "Train on 2464 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.9817 - val_loss: 2.2259\n",
      "[INFO] Training model: epoch 3 - 4000/20505 samples\n",
      "Train on 2452 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.9195 - val_loss: 2.3822\n",
      "[INFO] Training model: epoch 3 - 4250/20505 samples\n",
      "Train on 2532 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.9579 - val_loss: 2.2244\n",
      "[INFO] Training model: epoch 3 - 4500/20505 samples\n",
      "Train on 2411 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 2.0331 - val_loss: 2.1242\n",
      "[INFO] Training model: epoch 3 - 4750/20505 samples\n",
      "Train on 2389 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 21s 9ms/step - loss: 2.0033 - val_loss: 2.4065\n",
      "[INFO] Training model: epoch 3 - 5000/20505 samples\n",
      "Train on 2463 samples, validate on 713 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9559 - val_loss: 2.3578\n",
      "[INFO] Training model: epoch 3 - 5250/20505 samples\n",
      "Train on 2548 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.9676 - val_loss: 2.3423\n",
      "[INFO] Training model: epoch 3 - 5500/20505 samples\n",
      "Train on 2471 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 2.0121 - val_loss: 2.3606\n",
      "[INFO] Training model: epoch 3 - 5750/20505 samples\n",
      "Train on 2463 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9974 - val_loss: 2.2110\n",
      "[INFO] Training model: epoch 3 - 6000/20505 samples\n",
      "Train on 2472 samples, validate on 533 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 2.0287 - val_loss: 2.2368\n",
      "[INFO] Training model: epoch 3 - 6250/20505 samples\n",
      "Train on 2460 samples, validate on 681 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.9816 - val_loss: 2.5111\n",
      "[INFO] Training model: epoch 3 - 6500/20505 samples\n",
      "Train on 2488 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 2.0163 - val_loss: 2.3491\n",
      "[INFO] Training model: epoch 3 - 6750/20505 samples\n",
      "Train on 2435 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.9731 - val_loss: 2.2698\n",
      "[INFO] Training model: epoch 3 - 7000/20505 samples\n",
      "Train on 2384 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 21s 9ms/step - loss: 2.0065 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 3 - 7250/20505 samples\n",
      "Train on 2562 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 24s 9ms/step - loss: 2.0366 - val_loss: 2.1553\n",
      "[INFO] Training model: epoch 3 - 7500/20505 samples\n",
      "Train on 2468 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 2.0321 - val_loss: 2.4310\n",
      "[INFO] Training model: epoch 3 - 7750/20505 samples\n",
      "Train on 2531 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 2.0115 - val_loss: 2.2900\n",
      "[INFO] Training model: epoch 3 - 8000/20505 samples\n",
      "Train on 2526 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 2.0067 - val_loss: 2.3143\n",
      "[INFO] Training model: epoch 3 - 8250/20505 samples\n",
      "Train on 2443 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.9194 - val_loss: 2.2773\n",
      "[INFO] Training model: epoch 3 - 8500/20505 samples\n",
      "Train on 2426 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.9174 - val_loss: 2.1635\n",
      "[INFO] Training model: epoch 3 - 8750/20505 samples\n",
      "Train on 2361 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 22s 9ms/step - loss: 2.0461 - val_loss: 2.1081\n",
      "[INFO] Training model: epoch 3 - 9000/20505 samples\n",
      "Train on 2386 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 2.0540 - val_loss: 2.4666\n",
      "[INFO] Training model: epoch 3 - 9250/20505 samples\n",
      "Train on 2498 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 23s 9ms/step - loss: 2.1164 - val_loss: 2.5101\n",
      "[INFO] Training model: epoch 3 - 9500/20505 samples\n",
      "Train on 2576 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.9519 - val_loss: 2.4530\n",
      "[INFO] Training model: epoch 3 - 9750/20505 samples\n",
      "Train on 2401 samples, validate on 654 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401/2401 [==============================] - 21s 9ms/step - loss: 2.0529 - val_loss: 2.2487\n",
      "[INFO] Training model: epoch 3 - 10000/20505 samples\n",
      "Train on 2424 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 9ms/step - loss: 2.0596 - val_loss: 2.2842\n",
      "[INFO] Training model: epoch 3 - 10250/20505 samples\n",
      "Train on 2402 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 22s 9ms/step - loss: 2.0181 - val_loss: 2.2941\n",
      "[INFO] Training model: epoch 3 - 10500/20505 samples\n",
      "Train on 2485 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 21s 9ms/step - loss: 1.9160 - val_loss: 2.2243\n",
      "[INFO] Training model: epoch 3 - 10750/20505 samples\n",
      "Train on 2408 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 2.0305 - val_loss: 2.3228\n",
      "[INFO] Training model: epoch 3 - 11000/20505 samples\n",
      "Train on 2464 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 21s 9ms/step - loss: 2.0048 - val_loss: 2.2965\n",
      "[INFO] Training model: epoch 3 - 11250/20505 samples\n",
      "Train on 2496 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 24s 9ms/step - loss: 2.0008 - val_loss: 2.1904\n",
      "[INFO] Training model: epoch 3 - 11500/20505 samples\n",
      "Train on 2520 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 23s 9ms/step - loss: 2.1009 - val_loss: 2.2523\n",
      "[INFO] Training model: epoch 3 - 11750/20505 samples\n",
      "Train on 2346 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 20s 9ms/step - loss: 1.9924 - val_loss: 2.2339\n",
      "[INFO] Training model: epoch 3 - 12000/20505 samples\n",
      "Train on 2419 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 2.0396 - val_loss: 2.2959\n",
      "[INFO] Training model: epoch 3 - 12250/20505 samples\n",
      "Train on 2516 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.9296 - val_loss: 2.3050\n",
      "[INFO] Training model: epoch 3 - 12500/20505 samples\n",
      "Train on 2475 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 21s 9ms/step - loss: 2.1503 - val_loss: 2.2433\n",
      "[INFO] Training model: epoch 3 - 12750/20505 samples\n",
      "Train on 2481 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 24s 10ms/step - loss: 1.9820 - val_loss: 2.4081\n",
      "[INFO] Training model: epoch 3 - 13000/20505 samples\n",
      "Train on 2463 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 2.0926 - val_loss: 2.1198\n",
      "[INFO] Training model: epoch 3 - 13250/20505 samples\n",
      "Train on 2469 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 21s 9ms/step - loss: 2.0258 - val_loss: 2.0723\n",
      "[INFO] Training model: epoch 3 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 2.0368 - val_loss: 2.2888\n",
      "[INFO] Training model: epoch 3 - 13750/20505 samples\n",
      "Train on 2506 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 22s 9ms/step - loss: 2.0438 - val_loss: 2.1098\n",
      "[INFO] Training model: epoch 3 - 14000/20505 samples\n",
      "Train on 2398 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9774 - val_loss: 2.2850\n",
      "[INFO] Training model: epoch 3 - 14250/20505 samples\n",
      "Train on 2559 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 22s 9ms/step - loss: 1.9961 - val_loss: 2.3942\n",
      "[INFO] Training model: epoch 3 - 14500/20505 samples\n",
      "Train on 2401 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 9ms/step - loss: 2.1028 - val_loss: 2.3458\n",
      "[INFO] Training model: epoch 3 - 14750/20505 samples\n",
      "Train on 2477 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.9652 - val_loss: 2.2911\n",
      "[INFO] Training model: epoch 3 - 15000/20505 samples\n",
      "Train on 2463 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9934 - val_loss: 2.0781\n",
      "[INFO] Training model: epoch 3 - 15250/20505 samples\n",
      "Train on 2476 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 2.0802 - val_loss: 1.9587\n",
      "[INFO] Training model: epoch 3 - 15500/20505 samples\n",
      "Train on 2538 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 2.0145 - val_loss: 2.3855\n",
      "[INFO] Training model: epoch 3 - 15750/20505 samples\n",
      "Train on 2478 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 2.0595 - val_loss: 2.3195\n",
      "[INFO] Training model: epoch 3 - 16000/20505 samples\n",
      "Train on 2488 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.9409 - val_loss: 2.3646\n",
      "[INFO] Training model: epoch 3 - 16250/20505 samples\n",
      "Train on 2452 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 2.0128 - val_loss: 2.2983\n",
      "[INFO] Training model: epoch 3 - 16500/20505 samples\n",
      "Train on 2462 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 2.0187 - val_loss: 2.3817\n",
      "[INFO] Training model: epoch 3 - 16750/20505 samples\n",
      "Train on 2379 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 23s 10ms/step - loss: 2.0363 - val_loss: 2.3836\n",
      "[INFO] Training model: epoch 3 - 17000/20505 samples\n",
      "Train on 2343 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 22s 9ms/step - loss: 2.0317 - val_loss: 2.3947\n",
      "[INFO] Training model: epoch 3 - 17250/20505 samples\n",
      "Train on 2443 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 2.0213 - val_loss: 2.2759\n",
      "[INFO] Training model: epoch 3 - 17500/20505 samples\n",
      "Train on 2490 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.9697 - val_loss: 2.0411\n",
      "[INFO] Training model: epoch 3 - 17750/20505 samples\n",
      "Train on 2514 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 23s 9ms/step - loss: 2.0143 - val_loss: 2.2918\n",
      "[INFO] Training model: epoch 3 - 18000/20505 samples\n",
      "Train on 2395 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 2.0279 - val_loss: 2.0990\n",
      "[INFO] Training model: epoch 3 - 18250/20505 samples\n",
      "Train on 2389 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 9ms/step - loss: 2.0216 - val_loss: 2.3590\n",
      "[INFO] Training model: epoch 3 - 18500/20505 samples\n",
      "Train on 2359 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 2.0521 - val_loss: 2.4699\n",
      "[INFO] Training model: epoch 3 - 18750/20505 samples\n",
      "Train on 2454 samples, validate on 689 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 21s 9ms/step - loss: 2.1109 - val_loss: 2.4121\n",
      "[INFO] Training model: epoch 3 - 19000/20505 samples\n",
      "Train on 2439 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 2.0431 - val_loss: 2.2133\n",
      "[INFO] Training model: epoch 3 - 19250/20505 samples\n",
      "Train on 2574 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 23s 9ms/step - loss: 1.9156 - val_loss: 2.4480\n",
      "[INFO] Training model: epoch 3 - 19500/20505 samples\n",
      "Train on 2440 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 2.1311 - val_loss: 2.3291\n",
      "[INFO] Training model: epoch 3 - 19750/20505 samples\n",
      "Train on 2398 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9641 - val_loss: 2.2112\n",
      "[INFO] Training model: epoch 3 - 20000/20505 samples\n",
      "Train on 2449 samples, validate on 578 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2449/2449 [==============================] - 23s 9ms/step - loss: 2.0629 - val_loss: 2.1767\n",
      "[INFO] Training model: epoch 3 - 20250/20505 samples\n",
      "Train on 2452 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 2.0039 - val_loss: 2.3421\n",
      "[INFO] Training model: epoch 3 - 20500/20505 samples\n",
      "Train on 29 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.6708 - val_loss: 2.6099\n",
      "[INFO] Training model: epoch 4 - 0/20505 samples\n",
      "Train on 2575 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 22s 9ms/step - loss: 1.8181 - val_loss: 2.2501\n",
      "[INFO] Training model: epoch 4 - 250/20505 samples\n",
      "Train on 2533 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 1.8656 - val_loss: 2.3783\n",
      "[INFO] Training model: epoch 4 - 500/20505 samples\n",
      "Train on 2433 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.8740 - val_loss: 2.1100\n",
      "[INFO] Training model: epoch 4 - 750/20505 samples\n",
      "Train on 2436 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 1.7889 - val_loss: 2.2762\n",
      "[INFO] Training model: epoch 4 - 1000/20505 samples\n",
      "Train on 2589 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 1.7799 - val_loss: 2.2828\n",
      "[INFO] Training model: epoch 4 - 1250/20505 samples\n",
      "Train on 2502 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.8035 - val_loss: 2.5056\n",
      "[INFO] Training model: epoch 4 - 1500/20505 samples\n",
      "Train on 2426 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.7970 - val_loss: 2.4859\n",
      "[INFO] Training model: epoch 4 - 1750/20505 samples\n",
      "Train on 2458 samples, validate on 729 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 22s 9ms/step - loss: 1.8281 - val_loss: 2.2225\n",
      "[INFO] Training model: epoch 4 - 2000/20505 samples\n",
      "Train on 2419 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.8978 - val_loss: 2.6084\n",
      "[INFO] Training model: epoch 4 - 2250/20505 samples\n",
      "Train on 2408 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.7764 - val_loss: 2.1812\n",
      "[INFO] Training model: epoch 4 - 2500/20505 samples\n",
      "Train on 2425 samples, validate on 541 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.8684 - val_loss: 2.3981\n",
      "[INFO] Training model: epoch 4 - 2750/20505 samples\n",
      "Train on 2499 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.8258 - val_loss: 2.2930\n",
      "[INFO] Training model: epoch 4 - 3000/20505 samples\n",
      "Train on 2391 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.8925 - val_loss: 2.3727\n",
      "[INFO] Training model: epoch 4 - 3250/20505 samples\n",
      "Train on 2409 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.9352 - val_loss: 2.0798\n",
      "[INFO] Training model: epoch 4 - 3500/20505 samples\n",
      "Train on 2444 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.8653 - val_loss: 2.2631\n",
      "[INFO] Training model: epoch 4 - 3750/20505 samples\n",
      "Train on 2441 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 22s 9ms/step - loss: 1.7744 - val_loss: 2.2752\n",
      "[INFO] Training model: epoch 4 - 4000/20505 samples\n",
      "Train on 2419 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.8486 - val_loss: 2.1110\n",
      "[INFO] Training model: epoch 4 - 4250/20505 samples\n",
      "Train on 2410 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 9ms/step - loss: 1.8916 - val_loss: 2.3372\n",
      "[INFO] Training model: epoch 4 - 4500/20505 samples\n",
      "Train on 2445 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.9269 - val_loss: 2.1406\n",
      "[INFO] Training model: epoch 4 - 4750/20505 samples\n",
      "Train on 2412 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.9610 - val_loss: 2.3072\n",
      "[INFO] Training model: epoch 4 - 5000/20505 samples\n",
      "Train on 2408 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 21s 9ms/step - loss: 1.9144 - val_loss: 2.3452\n",
      "[INFO] Training model: epoch 4 - 5250/20505 samples\n",
      "Train on 2500 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.9601 - val_loss: 2.3606\n",
      "[INFO] Training model: epoch 4 - 5500/20505 samples\n",
      "Train on 2502 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.8823 - val_loss: 2.1988\n",
      "[INFO] Training model: epoch 4 - 5750/20505 samples\n",
      "Train on 2505 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.8329 - val_loss: 2.5443\n",
      "[INFO] Training model: epoch 4 - 6000/20505 samples\n",
      "Train on 2461 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.8096 - val_loss: 2.5711\n",
      "[INFO] Training model: epoch 4 - 6250/20505 samples\n",
      "Train on 2577 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 24s 9ms/step - loss: 1.9175 - val_loss: 2.2794\n",
      "[INFO] Training model: epoch 4 - 6500/20505 samples\n",
      "Train on 2476 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.9378 - val_loss: 2.4024\n",
      "[INFO] Training model: epoch 4 - 6750/20505 samples\n",
      "Train on 2439 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.8879 - val_loss: 2.2973\n",
      "[INFO] Training model: epoch 4 - 7000/20505 samples\n",
      "Train on 2499 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.8480 - val_loss: 2.2510\n",
      "[INFO] Training model: epoch 4 - 7250/20505 samples\n",
      "Train on 2373 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.8927 - val_loss: 2.1244\n",
      "[INFO] Training model: epoch 4 - 7500/20505 samples\n",
      "Train on 2422 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 1.8590 - val_loss: 2.2889\n",
      "[INFO] Training model: epoch 4 - 7750/20505 samples\n",
      "Train on 2450 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.8794 - val_loss: 2.3608\n",
      "[INFO] Training model: epoch 4 - 8000/20505 samples\n",
      "Train on 2412 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.8209 - val_loss: 2.2805\n",
      "[INFO] Training model: epoch 4 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.9515 - val_loss: 2.2631\n",
      "[INFO] Training model: epoch 4 - 8500/20505 samples\n",
      "Train on 2445 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.8774 - val_loss: 2.2549\n",
      "[INFO] Training model: epoch 4 - 8750/20505 samples\n",
      "Train on 2421 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.8524 - val_loss: 2.3661\n",
      "[INFO] Training model: epoch 4 - 9000/20505 samples\n",
      "Train on 2426 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.8206 - val_loss: 2.5110\n",
      "[INFO] Training model: epoch 4 - 9250/20505 samples\n",
      "Train on 2479 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.8867 - val_loss: 2.3695\n",
      "[INFO] Training model: epoch 4 - 9500/20505 samples\n",
      "Train on 2618 samples, validate on 603 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2618/2618 [==============================] - 24s 9ms/step - loss: 1.8837 - val_loss: 2.1510\n",
      "[INFO] Training model: epoch 4 - 9750/20505 samples\n",
      "Train on 2466 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.8331 - val_loss: 2.1895\n",
      "[INFO] Training model: epoch 4 - 10000/20505 samples\n",
      "Train on 2588 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2588/2588 [==============================] - 24s 9ms/step - loss: 1.9080 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 4 - 10250/20505 samples\n",
      "Train on 2361 samples, validate on 679 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 21s 9ms/step - loss: 1.9049 - val_loss: 2.2427\n",
      "[INFO] Training model: epoch 4 - 10500/20505 samples\n",
      "Train on 2474 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.9174 - val_loss: 2.2741\n",
      "[INFO] Training model: epoch 4 - 10750/20505 samples\n",
      "Train on 2365 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.9266 - val_loss: 2.2804\n",
      "[INFO] Training model: epoch 4 - 11000/20505 samples\n",
      "Train on 2443 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.8663 - val_loss: 2.5425\n",
      "[INFO] Training model: epoch 4 - 11250/20505 samples\n",
      "Train on 2515 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.9228 - val_loss: 2.4609\n",
      "[INFO] Training model: epoch 4 - 11500/20505 samples\n",
      "Train on 2480 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.9351 - val_loss: 2.1128\n",
      "[INFO] Training model: epoch 4 - 11750/20505 samples\n",
      "Train on 2399 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.9186 - val_loss: 2.1957\n",
      "[INFO] Training model: epoch 4 - 12000/20505 samples\n",
      "Train on 2488 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 22s 9ms/step - loss: 1.9209 - val_loss: 2.2131\n",
      "[INFO] Training model: epoch 4 - 12250/20505 samples\n",
      "Train on 2470 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 22s 9ms/step - loss: 1.9218 - val_loss: 2.2256\n",
      "[INFO] Training model: epoch 4 - 12500/20505 samples\n",
      "Train on 2459 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.8631 - val_loss: 2.1819\n",
      "[INFO] Training model: epoch 4 - 12750/20505 samples\n",
      "Train on 2529 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.8885 - val_loss: 2.1035\n",
      "[INFO] Training model: epoch 4 - 13000/20505 samples\n",
      "Train on 2332 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2332/2332 [==============================] - 20s 9ms/step - loss: 1.9453 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 4 - 13250/20505 samples\n",
      "Train on 2377 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 21s 9ms/step - loss: 1.9469 - val_loss: 2.4771\n",
      "[INFO] Training model: epoch 4 - 13500/20505 samples\n",
      "Train on 2544 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2544/2544 [==============================] - 23s 9ms/step - loss: 1.8625 - val_loss: 2.1636\n",
      "[INFO] Training model: epoch 4 - 13750/20505 samples\n",
      "Train on 2449 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.8517 - val_loss: 2.1139\n",
      "[INFO] Training model: epoch 4 - 14000/20505 samples\n",
      "Train on 2447 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.8558 - val_loss: 2.0986\n",
      "[INFO] Training model: epoch 4 - 14250/20505 samples\n",
      "Train on 2389 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 10ms/step - loss: 1.8420 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 4 - 14500/20505 samples\n",
      "Train on 2447 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.9212 - val_loss: 2.3392\n",
      "[INFO] Training model: epoch 4 - 14750/20505 samples\n",
      "Train on 2448 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 2.0031 - val_loss: 2.2180\n",
      "[INFO] Training model: epoch 4 - 15000/20505 samples\n",
      "Train on 2374 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.8841 - val_loss: 2.4357\n",
      "[INFO] Training model: epoch 4 - 15250/20505 samples\n",
      "Train on 2358 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2358/2358 [==============================] - 22s 9ms/step - loss: 1.8365 - val_loss: 2.1272\n",
      "[INFO] Training model: epoch 4 - 15500/20505 samples\n",
      "Train on 2546 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 23s 9ms/step - loss: 1.8368 - val_loss: 2.4724\n",
      "[INFO] Training model: epoch 4 - 15750/20505 samples\n",
      "Train on 2360 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 20s 9ms/step - loss: 1.9465 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 4 - 16000/20505 samples\n",
      "Train on 2526 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.8555 - val_loss: 2.4807\n",
      "[INFO] Training model: epoch 4 - 16250/20505 samples\n",
      "Train on 2452 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 21s 9ms/step - loss: 1.8927 - val_loss: 2.2656\n",
      "[INFO] Training model: epoch 4 - 16500/20505 samples\n",
      "Train on 2549 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 24s 9ms/step - loss: 1.9135 - val_loss: 2.2410\n",
      "[INFO] Training model: epoch 4 - 16750/20505 samples\n",
      "Train on 2430 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.9829 - val_loss: 2.4204\n",
      "[INFO] Training model: epoch 4 - 17000/20505 samples\n",
      "Train on 2443 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 2.0419 - val_loss: 2.4511\n",
      "[INFO] Training model: epoch 4 - 17250/20505 samples\n",
      "Train on 2577 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 24s 9ms/step - loss: 1.9187 - val_loss: 2.3724\n",
      "[INFO] Training model: epoch 4 - 17500/20505 samples\n",
      "Train on 2380 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.9575 - val_loss: 2.4231\n",
      "[INFO] Training model: epoch 4 - 17750/20505 samples\n",
      "Train on 2398 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9364 - val_loss: 2.1313\n",
      "[INFO] Training model: epoch 4 - 18000/20505 samples\n",
      "Train on 2418 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 21s 9ms/step - loss: 1.9309 - val_loss: 2.1786\n",
      "[INFO] Training model: epoch 4 - 18250/20505 samples\n",
      "Train on 2332 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2332/2332 [==============================] - 22s 9ms/step - loss: 1.9019 - val_loss: 2.4738\n",
      "[INFO] Training model: epoch 4 - 18500/20505 samples\n",
      "Train on 2443 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.8825 - val_loss: 2.1931\n",
      "[INFO] Training model: epoch 4 - 18750/20505 samples\n",
      "Train on 2513 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 1.9521 - val_loss: 2.2412\n",
      "[INFO] Training model: epoch 4 - 19000/20505 samples\n",
      "Train on 2409 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 21s 9ms/step - loss: 1.8999 - val_loss: 2.2668\n",
      "[INFO] Training model: epoch 4 - 19250/20505 samples\n",
      "Train on 2449 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.9619 - val_loss: 2.0539\n",
      "[INFO] Training model: epoch 4 - 19500/20505 samples\n",
      "Train on 2323 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2323/2323 [==============================] - 20s 9ms/step - loss: 1.9228 - val_loss: 2.3549\n",
      "[INFO] Training model: epoch 4 - 19750/20505 samples\n",
      "Train on 2472 samples, validate on 645 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.9326 - val_loss: 2.2581\n",
      "[INFO] Training model: epoch 4 - 20000/20505 samples\n",
      "Train on 2673 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2673/2673 [==============================] - 25s 9ms/step - loss: 1.8769 - val_loss: 2.1921\n",
      "[INFO] Training model: epoch 4 - 20250/20505 samples\n",
      "Train on 2570 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 24s 9ms/step - loss: 1.9859 - val_loss: 2.5148\n",
      "[INFO] Training model: epoch 4 - 20500/20505 samples\n",
      "Train on 48 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7381 - val_loss: 1.6902\n",
      "[INFO] Training model: epoch 5 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.6588 - val_loss: 2.1795\n",
      "[INFO] Training model: epoch 5 - 250/20505 samples\n",
      "Train on 2528 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.7280 - val_loss: 2.5894\n",
      "[INFO] Training model: epoch 5 - 500/20505 samples\n",
      "Train on 2448 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.6344 - val_loss: 2.3779\n",
      "[INFO] Training model: epoch 5 - 750/20505 samples\n",
      "Train on 2480 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.7078 - val_loss: 2.4007\n",
      "[INFO] Training model: epoch 5 - 1000/20505 samples\n",
      "Train on 2373 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.7302 - val_loss: 2.2991\n",
      "[INFO] Training model: epoch 5 - 1250/20505 samples\n",
      "Train on 2621 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2621/2621 [==============================] - 24s 9ms/step - loss: 1.7348 - val_loss: 2.2687\n",
      "[INFO] Training model: epoch 5 - 1500/20505 samples\n",
      "Train on 2563 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 22s 9ms/step - loss: 1.7571 - val_loss: 2.3786\n",
      "[INFO] Training model: epoch 5 - 1750/20505 samples\n",
      "Train on 2496 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.6953 - val_loss: 2.0289\n",
      "[INFO] Training model: epoch 5 - 2000/20505 samples\n",
      "Train on 2488 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.6804 - val_loss: 2.2218\n",
      "[INFO] Training model: epoch 5 - 2250/20505 samples\n",
      "Train on 2384 samples, validate on 701 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.7762 - val_loss: 2.3217\n",
      "[INFO] Training model: epoch 5 - 2500/20505 samples\n",
      "Train on 2479 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 21s 9ms/step - loss: 1.7130 - val_loss: 2.1191\n",
      "[INFO] Training model: epoch 5 - 2750/20505 samples\n",
      "Train on 2586 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 24s 9ms/step - loss: 1.7713 - val_loss: 2.2365\n",
      "[INFO] Training model: epoch 5 - 3000/20505 samples\n",
      "Train on 2406 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 22s 9ms/step - loss: 1.7563 - val_loss: 2.4710\n",
      "[INFO] Training model: epoch 5 - 3250/20505 samples\n",
      "Train on 2446 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.6794 - val_loss: 2.1599\n",
      "[INFO] Training model: epoch 5 - 3500/20505 samples\n",
      "Train on 2398 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.7460 - val_loss: 2.1127\n",
      "[INFO] Training model: epoch 5 - 3750/20505 samples\n",
      "Train on 2412 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.7539 - val_loss: 2.4862\n",
      "[INFO] Training model: epoch 5 - 4000/20505 samples\n",
      "Train on 2507 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.6685 - val_loss: 2.2009\n",
      "[INFO] Training model: epoch 5 - 4250/20505 samples\n",
      "Train on 2438 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.8401 - val_loss: 2.3447\n",
      "[INFO] Training model: epoch 5 - 4500/20505 samples\n",
      "Train on 2497 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 22s 9ms/step - loss: 1.7904 - val_loss: 2.3172\n",
      "[INFO] Training model: epoch 5 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.7795 - val_loss: 2.4117\n",
      "[INFO] Training model: epoch 5 - 5000/20505 samples\n",
      "Train on 2446 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.7072 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 5 - 5250/20505 samples\n",
      "Train on 2455 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 22s 9ms/step - loss: 1.6254 - val_loss: 2.2444\n",
      "[INFO] Training model: epoch 5 - 5500/20505 samples\n",
      "Train on 2346 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 22s 9ms/step - loss: 1.6726 - val_loss: 2.5422\n",
      "[INFO] Training model: epoch 5 - 5750/20505 samples\n",
      "Train on 2512 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 9ms/step - loss: 1.7776 - val_loss: 2.3551\n",
      "[INFO] Training model: epoch 5 - 6000/20505 samples\n",
      "Train on 2541 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.8737 - val_loss: 2.4247\n",
      "[INFO] Training model: epoch 5 - 6250/20505 samples\n",
      "Train on 2477 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.7692 - val_loss: 2.3936\n",
      "[INFO] Training model: epoch 5 - 6500/20505 samples\n",
      "Train on 2494 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.6913 - val_loss: 2.3650\n",
      "[INFO] Training model: epoch 5 - 6750/20505 samples\n",
      "Train on 2392 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.7650 - val_loss: 2.0583\n",
      "[INFO] Training model: epoch 5 - 7000/20505 samples\n",
      "Train on 2315 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 21s 9ms/step - loss: 1.7746 - val_loss: 2.2880\n",
      "[INFO] Training model: epoch 5 - 7250/20505 samples\n",
      "Train on 2451 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.7709 - val_loss: 2.2970\n",
      "[INFO] Training model: epoch 5 - 7500/20505 samples\n",
      "Train on 2522 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.7517 - val_loss: 2.3807\n",
      "[INFO] Training model: epoch 5 - 7750/20505 samples\n",
      "Train on 2445 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 10ms/step - loss: 1.8237 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 5 - 8000/20505 samples\n",
      "Train on 2438 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.7687 - val_loss: 2.2626\n",
      "[INFO] Training model: epoch 5 - 8250/20505 samples\n",
      "Train on 2395 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 23s 9ms/step - loss: 1.7875 - val_loss: 2.2748\n",
      "[INFO] Training model: epoch 5 - 8500/20505 samples\n",
      "Train on 2409 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.8377 - val_loss: 2.3619\n",
      "[INFO] Training model: epoch 5 - 8750/20505 samples\n",
      "Train on 2425 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.7089 - val_loss: 2.4154\n",
      "[INFO] Training model: epoch 5 - 9000/20505 samples\n",
      "Train on 2518 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.7544 - val_loss: 2.2951\n",
      "[INFO] Training model: epoch 5 - 9250/20505 samples\n",
      "Train on 2531 samples, validate on 595 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.7499 - val_loss: 2.5523\n",
      "[INFO] Training model: epoch 5 - 9500/20505 samples\n",
      "Train on 2451 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 21s 9ms/step - loss: 1.7993 - val_loss: 2.5333\n",
      "[INFO] Training model: epoch 5 - 9750/20505 samples\n",
      "Train on 2461 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.7712 - val_loss: 2.2353\n",
      "[INFO] Training model: epoch 5 - 10000/20505 samples\n",
      "Train on 2493 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 22s 9ms/step - loss: 1.8271 - val_loss: 2.3032\n",
      "[INFO] Training model: epoch 5 - 10250/20505 samples\n",
      "Train on 2477 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.7321 - val_loss: 2.5237\n",
      "[INFO] Training model: epoch 5 - 10500/20505 samples\n",
      "Train on 2462 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 21s 9ms/step - loss: 1.8266 - val_loss: 2.3225\n",
      "[INFO] Training model: epoch 5 - 10750/20505 samples\n",
      "Train on 2399 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.7260 - val_loss: 2.2284\n",
      "[INFO] Training model: epoch 5 - 11000/20505 samples\n",
      "Train on 2473 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.8306 - val_loss: 2.2246\n",
      "[INFO] Training model: epoch 5 - 11250/20505 samples\n",
      "Train on 2445 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.8767 - val_loss: 2.0386\n",
      "[INFO] Training model: epoch 5 - 11500/20505 samples\n",
      "Train on 2470 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 21s 9ms/step - loss: 1.8679 - val_loss: 2.3615\n",
      "[INFO] Training model: epoch 5 - 11750/20505 samples\n",
      "Train on 2529 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 23s 9ms/step - loss: 1.8508 - val_loss: 2.1514\n",
      "[INFO] Training model: epoch 5 - 12000/20505 samples\n",
      "Train on 2396 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.8328 - val_loss: 2.5286\n",
      "[INFO] Training model: epoch 5 - 12250/20505 samples\n",
      "Train on 2339 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 22s 9ms/step - loss: 1.7740 - val_loss: 2.5101\n",
      "[INFO] Training model: epoch 5 - 12500/20505 samples\n",
      "Train on 2424 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.8361 - val_loss: 2.3302\n",
      "[INFO] Training model: epoch 5 - 12750/20505 samples\n",
      "Train on 2415 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.8605 - val_loss: 2.4586\n",
      "[INFO] Training model: epoch 5 - 13000/20505 samples\n",
      "Train on 2519 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.7856 - val_loss: 2.3343\n",
      "[INFO] Training model: epoch 5 - 13250/20505 samples\n",
      "Train on 2476 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.8638 - val_loss: 2.2934\n",
      "[INFO] Training model: epoch 5 - 13500/20505 samples\n",
      "Train on 2586 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 22s 9ms/step - loss: 1.7022 - val_loss: 2.2078\n",
      "[INFO] Training model: epoch 5 - 13750/20505 samples\n",
      "Train on 2411 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 23s 9ms/step - loss: 1.8114 - val_loss: 2.3719\n",
      "[INFO] Training model: epoch 5 - 14000/20505 samples\n",
      "Train on 2540 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.8806 - val_loss: 2.2540\n",
      "[INFO] Training model: epoch 5 - 14250/20505 samples\n",
      "Train on 2432 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.9148 - val_loss: 2.0796\n",
      "[INFO] Training model: epoch 5 - 14500/20505 samples\n",
      "Train on 2393 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.7767 - val_loss: 2.3064\n",
      "[INFO] Training model: epoch 5 - 14750/20505 samples\n",
      "Train on 2497 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.7721 - val_loss: 2.4710\n",
      "[INFO] Training model: epoch 5 - 15000/20505 samples\n",
      "Train on 2442 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.8235 - val_loss: 2.3506\n",
      "[INFO] Training model: epoch 5 - 15250/20505 samples\n",
      "Train on 2486 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.8534 - val_loss: 2.3857\n",
      "[INFO] Training model: epoch 5 - 15500/20505 samples\n",
      "Train on 2381 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 21s 9ms/step - loss: 1.8651 - val_loss: 2.5534\n",
      "[INFO] Training model: epoch 5 - 15750/20505 samples\n",
      "Train on 2362 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 1.7420 - val_loss: 2.5371\n",
      "[INFO] Training model: epoch 5 - 16000/20505 samples\n",
      "Train on 2430 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.8132 - val_loss: 2.5304\n",
      "[INFO] Training model: epoch 5 - 16250/20505 samples\n",
      "Train on 2425 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.7712 - val_loss: 2.2208\n",
      "[INFO] Training model: epoch 5 - 16500/20505 samples\n",
      "Train on 2371 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.7880 - val_loss: 2.2664\n",
      "[INFO] Training model: epoch 5 - 16750/20505 samples\n",
      "Train on 2435 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.8680 - val_loss: 2.4669\n",
      "[INFO] Training model: epoch 5 - 17000/20505 samples\n",
      "Train on 2440 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.8582 - val_loss: 2.4023\n",
      "[INFO] Training model: epoch 5 - 17250/20505 samples\n",
      "Train on 2473 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.7905 - val_loss: 2.2635\n",
      "[INFO] Training model: epoch 5 - 17500/20505 samples\n",
      "Train on 2396 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.7842 - val_loss: 2.1404\n",
      "[INFO] Training model: epoch 5 - 17750/20505 samples\n",
      "Train on 2482 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.8415 - val_loss: 2.1168\n",
      "[INFO] Training model: epoch 5 - 18000/20505 samples\n",
      "Train on 2350 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 22s 9ms/step - loss: 1.8460 - val_loss: 2.5834\n",
      "[INFO] Training model: epoch 5 - 18250/20505 samples\n",
      "Train on 2489 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 22s 9ms/step - loss: 1.8516 - val_loss: 2.0430\n",
      "[INFO] Training model: epoch 5 - 18500/20505 samples\n",
      "Train on 2575 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 24s 9ms/step - loss: 1.7680 - val_loss: 2.3112\n",
      "[INFO] Training model: epoch 5 - 18750/20505 samples\n",
      "Train on 2357 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 20s 9ms/step - loss: 1.8306 - val_loss: 2.2618\n",
      "[INFO] Training model: epoch 5 - 19000/20505 samples\n",
      "Train on 2486 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.8506 - val_loss: 2.3207\n",
      "[INFO] Training model: epoch 5 - 19250/20505 samples\n",
      "Train on 2561 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 22s 9ms/step - loss: 1.7900 - val_loss: 2.1994\n",
      "[INFO] Training model: epoch 5 - 19500/20505 samples\n",
      "Train on 2447 samples, validate on 633 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.8832 - val_loss: 2.1714\n",
      "[INFO] Training model: epoch 5 - 19750/20505 samples\n",
      "Train on 2476 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.7426 - val_loss: 2.5985\n",
      "[INFO] Training model: epoch 5 - 20000/20505 samples\n",
      "Train on 2446 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.8426 - val_loss: 2.3097\n",
      "[INFO] Training model: epoch 5 - 20250/20505 samples\n",
      "Train on 2414 samples, validate on 673 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.7997 - val_loss: 2.2960\n",
      "[INFO] Training model: epoch 5 - 20500/20505 samples\n",
      "Train on 58 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 1.6416 - val_loss: 3.4273\n",
      "[INFO] Training model: epoch 6 - 0/20505 samples\n",
      "Train on 2421 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.6970 - val_loss: 2.4960\n",
      "[INFO] Training model: epoch 6 - 250/20505 samples\n",
      "Train on 2495 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.6130 - val_loss: 2.2849\n",
      "[INFO] Training model: epoch 6 - 500/20505 samples\n",
      "Train on 2512 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 23s 9ms/step - loss: 1.5883 - val_loss: 2.3773\n",
      "[INFO] Training model: epoch 6 - 750/20505 samples\n",
      "Train on 2433 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 21s 9ms/step - loss: 1.6403 - val_loss: 2.2587\n",
      "[INFO] Training model: epoch 6 - 1000/20505 samples\n",
      "Train on 2507 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.6721 - val_loss: 2.0345\n",
      "[INFO] Training model: epoch 6 - 1250/20505 samples\n",
      "Train on 2429 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.6330 - val_loss: 2.4260\n",
      "[INFO] Training model: epoch 6 - 1500/20505 samples\n",
      "Train on 2474 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.6099 - val_loss: 2.3333\n",
      "[INFO] Training model: epoch 6 - 1750/20505 samples\n",
      "Train on 2524 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.6078 - val_loss: 2.1451\n",
      "[INFO] Training model: epoch 6 - 2000/20505 samples\n",
      "Train on 2427 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.6317 - val_loss: 2.4242\n",
      "[INFO] Training model: epoch 6 - 2250/20505 samples\n",
      "Train on 2426 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.6050 - val_loss: 2.2428\n",
      "[INFO] Training model: epoch 6 - 2500/20505 samples\n",
      "Train on 2335 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 22s 9ms/step - loss: 1.6385 - val_loss: 2.2996\n",
      "[INFO] Training model: epoch 6 - 2750/20505 samples\n",
      "Train on 2536 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 22s 9ms/step - loss: 1.6037 - val_loss: 2.3593\n",
      "[INFO] Training model: epoch 6 - 3000/20505 samples\n",
      "Train on 2480 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.6541 - val_loss: 2.2419\n",
      "[INFO] Training model: epoch 6 - 3250/20505 samples\n",
      "Train on 2513 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 22s 9ms/step - loss: 1.6458 - val_loss: 2.2877\n",
      "[INFO] Training model: epoch 6 - 3500/20505 samples\n",
      "Train on 2426 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.5270 - val_loss: 2.1816\n",
      "[INFO] Training model: epoch 6 - 3750/20505 samples\n",
      "Train on 2467 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.6266 - val_loss: 2.2949\n",
      "[INFO] Training model: epoch 6 - 4000/20505 samples\n",
      "Train on 2384 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.7333 - val_loss: 2.2862\n",
      "[INFO] Training model: epoch 6 - 4250/20505 samples\n",
      "Train on 2461 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.6214 - val_loss: 2.6528\n",
      "[INFO] Training model: epoch 6 - 4500/20505 samples\n",
      "Train on 2435 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.6428 - val_loss: 2.6257\n",
      "[INFO] Training model: epoch 6 - 4750/20505 samples\n",
      "Train on 2580 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 23s 9ms/step - loss: 1.6013 - val_loss: 2.4786\n",
      "[INFO] Training model: epoch 6 - 5000/20505 samples\n",
      "Train on 2373 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.6726 - val_loss: 2.0889\n",
      "[INFO] Training model: epoch 6 - 5250/20505 samples\n",
      "Train on 2420 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 21s 9ms/step - loss: 1.5415 - val_loss: 2.4912\n",
      "[INFO] Training model: epoch 6 - 5500/20505 samples\n",
      "Train on 2460 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.6232 - val_loss: 2.2377\n",
      "[INFO] Training model: epoch 6 - 5750/20505 samples\n",
      "Train on 2436 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 1.6815 - val_loss: 2.5921\n",
      "[INFO] Training model: epoch 6 - 6000/20505 samples\n",
      "Train on 2461 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.6216 - val_loss: 2.3263\n",
      "[INFO] Training model: epoch 6 - 6250/20505 samples\n",
      "Train on 2424 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.6932 - val_loss: 2.1140\n",
      "[INFO] Training model: epoch 6 - 6500/20505 samples\n",
      "Train on 2421 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.6109 - val_loss: 2.3272\n",
      "[INFO] Training model: epoch 6 - 6750/20505 samples\n",
      "Train on 2408 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.6297 - val_loss: 2.3727\n",
      "[INFO] Training model: epoch 6 - 7000/20505 samples\n",
      "Train on 2421 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.6129 - val_loss: 2.5436\n",
      "[INFO] Training model: epoch 6 - 7250/20505 samples\n",
      "Train on 2473 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.6869 - val_loss: 2.4687\n",
      "[INFO] Training model: epoch 6 - 7500/20505 samples\n",
      "Train on 2464 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.6035 - val_loss: 2.0970\n",
      "[INFO] Training model: epoch 6 - 7750/20505 samples\n",
      "Train on 2477 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.7168 - val_loss: 2.0737\n",
      "[INFO] Training model: epoch 6 - 8000/20505 samples\n",
      "Train on 2444 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.7218 - val_loss: 2.4107\n",
      "[INFO] Training model: epoch 6 - 8250/20505 samples\n",
      "Train on 2465 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.7547 - val_loss: 2.5391\n",
      "[INFO] Training model: epoch 6 - 8500/20505 samples\n",
      "Train on 2529 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.6680 - val_loss: 2.2534\n",
      "[INFO] Training model: epoch 6 - 8750/20505 samples\n",
      "Train on 2465 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.6374 - val_loss: 2.2134\n",
      "[INFO] Training model: epoch 6 - 9000/20505 samples\n",
      "Train on 2425 samples, validate on 566 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.6890 - val_loss: 2.2453\n",
      "[INFO] Training model: epoch 6 - 9250/20505 samples\n",
      "Train on 2443 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.7445 - val_loss: 2.1644\n",
      "[INFO] Training model: epoch 6 - 9500/20505 samples\n",
      "Train on 2543 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 24s 9ms/step - loss: 1.7439 - val_loss: 2.5242\n",
      "[INFO] Training model: epoch 6 - 9750/20505 samples\n",
      "Train on 2472 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.6768 - val_loss: 2.3641\n",
      "[INFO] Training model: epoch 6 - 10000/20505 samples\n",
      "Train on 2438 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.7202 - val_loss: 2.2866\n",
      "[INFO] Training model: epoch 6 - 10250/20505 samples\n",
      "Train on 2510 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 23s 9ms/step - loss: 1.6588 - val_loss: 2.4374\n",
      "[INFO] Training model: epoch 6 - 10500/20505 samples\n",
      "Train on 2416 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.6831 - val_loss: 2.3973\n",
      "[INFO] Training model: epoch 6 - 10750/20505 samples\n",
      "Train on 2518 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.6286 - val_loss: 2.3987\n",
      "[INFO] Training model: epoch 6 - 11000/20505 samples\n",
      "Train on 2462 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.6979 - val_loss: 2.5231\n",
      "[INFO] Training model: epoch 6 - 11250/20505 samples\n",
      "Train on 2452 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.7115 - val_loss: 2.3102\n",
      "[INFO] Training model: epoch 6 - 11500/20505 samples\n",
      "Train on 2476 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.6436 - val_loss: 2.4744\n",
      "[INFO] Training model: epoch 6 - 11750/20505 samples\n",
      "Train on 2431 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.7299 - val_loss: 2.3264\n",
      "[INFO] Training model: epoch 6 - 12000/20505 samples\n",
      "Train on 2475 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.6288 - val_loss: 2.4985\n",
      "[INFO] Training model: epoch 6 - 12250/20505 samples\n",
      "Train on 2558 samples, validate on 686 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.7051 - val_loss: 2.3350\n",
      "[INFO] Training model: epoch 6 - 12500/20505 samples\n",
      "Train on 2429 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.7141 - val_loss: 2.0375\n",
      "[INFO] Training model: epoch 6 - 12750/20505 samples\n",
      "Train on 2440 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.7222 - val_loss: 2.5432\n",
      "[INFO] Training model: epoch 6 - 13000/20505 samples\n",
      "Train on 2413 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.7120 - val_loss: 2.2495\n",
      "[INFO] Training model: epoch 6 - 13250/20505 samples\n",
      "Train on 2609 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 24s 9ms/step - loss: 1.6765 - val_loss: 2.5382\n",
      "[INFO] Training model: epoch 6 - 13500/20505 samples\n",
      "Train on 2483 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.7931 - val_loss: 2.1695\n",
      "[INFO] Training model: epoch 6 - 13750/20505 samples\n",
      "Train on 2518 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.6132 - val_loss: 2.3552\n",
      "[INFO] Training model: epoch 6 - 14000/20505 samples\n",
      "Train on 2485 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.7079 - val_loss: 2.4400\n",
      "[INFO] Training model: epoch 6 - 14250/20505 samples\n",
      "Train on 2338 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 22s 9ms/step - loss: 1.7291 - val_loss: 2.3762\n",
      "[INFO] Training model: epoch 6 - 14500/20505 samples\n",
      "Train on 2376 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 21s 9ms/step - loss: 1.7457 - val_loss: 2.4927\n",
      "[INFO] Training model: epoch 6 - 14750/20505 samples\n",
      "Train on 2474 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.6840 - val_loss: 2.4033\n",
      "[INFO] Training model: epoch 6 - 15000/20505 samples\n",
      "Train on 2540 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.7175 - val_loss: 2.5282\n",
      "[INFO] Training model: epoch 6 - 15250/20505 samples\n",
      "Train on 2365 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.6456 - val_loss: 2.3759\n",
      "[INFO] Training model: epoch 6 - 15500/20505 samples\n",
      "Train on 2454 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.6197 - val_loss: 2.2829\n",
      "[INFO] Training model: epoch 6 - 15750/20505 samples\n",
      "Train on 2514 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 22s 9ms/step - loss: 1.7261 - val_loss: 2.5984\n",
      "[INFO] Training model: epoch 6 - 16000/20505 samples\n",
      "Train on 2359 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 1.6230 - val_loss: 2.3596\n",
      "[INFO] Training model: epoch 6 - 16250/20505 samples\n",
      "Train on 2459 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 21s 9ms/step - loss: 1.7241 - val_loss: 2.3302\n",
      "[INFO] Training model: epoch 6 - 16500/20505 samples\n",
      "Train on 2456 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.7264 - val_loss: 2.6006\n",
      "[INFO] Training model: epoch 6 - 16750/20505 samples\n",
      "Train on 2529 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 23s 9ms/step - loss: 1.7672 - val_loss: 2.2009\n",
      "[INFO] Training model: epoch 6 - 17000/20505 samples\n",
      "Train on 2500 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.7326 - val_loss: 2.2105\n",
      "[INFO] Training model: epoch 6 - 17250/20505 samples\n",
      "Train on 2430 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.7581 - val_loss: 2.2474\n",
      "[INFO] Training model: epoch 6 - 17500/20505 samples\n",
      "Train on 2465 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.7938 - val_loss: 2.3136\n",
      "[INFO] Training model: epoch 6 - 17750/20505 samples\n",
      "Train on 2414 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.7278 - val_loss: 2.1119\n",
      "[INFO] Training model: epoch 6 - 18000/20505 samples\n",
      "Train on 2450 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 22s 9ms/step - loss: 1.7657 - val_loss: 2.2828\n",
      "[INFO] Training model: epoch 6 - 18250/20505 samples\n",
      "Train on 2376 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 21s 9ms/step - loss: 1.7093 - val_loss: 2.3104\n",
      "[INFO] Training model: epoch 6 - 18500/20505 samples\n",
      "Train on 2521 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 22s 9ms/step - loss: 1.7807 - val_loss: 2.3583\n",
      "[INFO] Training model: epoch 6 - 18750/20505 samples\n",
      "Train on 2371 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 21s 9ms/step - loss: 1.7420 - val_loss: 2.1900\n",
      "[INFO] Training model: epoch 6 - 19000/20505 samples\n",
      "Train on 2432 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.7618 - val_loss: 2.2859\n",
      "[INFO] Training model: epoch 6 - 19250/20505 samples\n",
      "Train on 2343 samples, validate on 600 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 21s 9ms/step - loss: 1.6982 - val_loss: 2.4171\n",
      "[INFO] Training model: epoch 6 - 19500/20505 samples\n",
      "Train on 2420 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.7421 - val_loss: 2.5573\n",
      "[INFO] Training model: epoch 6 - 19750/20505 samples\n",
      "Train on 2570 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 23s 9ms/step - loss: 1.7655 - val_loss: 2.4473\n",
      "[INFO] Training model: epoch 6 - 20000/20505 samples\n",
      "Train on 2404 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 22s 9ms/step - loss: 1.7779 - val_loss: 2.5735\n",
      "[INFO] Training model: epoch 6 - 20250/20505 samples\n",
      "Train on 2450 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 21s 9ms/step - loss: 1.6975 - val_loss: 2.5984\n",
      "[INFO] Training model: epoch 6 - 20500/20505 samples\n",
      "Train on 44 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.3004 - val_loss: 3.0366\n",
      "[INFO] Training model: epoch 7 - 0/20505 samples\n",
      "Train on 2488 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.4763 - val_loss: 2.2780\n",
      "[INFO] Training model: epoch 7 - 250/20505 samples\n",
      "Train on 2443 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.4953 - val_loss: 2.1234\n",
      "[INFO] Training model: epoch 7 - 500/20505 samples\n",
      "Train on 2385 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.5771 - val_loss: 2.2463\n",
      "[INFO] Training model: epoch 7 - 750/20505 samples\n",
      "Train on 2476 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.5056 - val_loss: 2.1917\n",
      "[INFO] Training model: epoch 7 - 1000/20505 samples\n",
      "Train on 2392 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.4971 - val_loss: 2.4398\n",
      "[INFO] Training model: epoch 7 - 1250/20505 samples\n",
      "Train on 2457 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.5337 - val_loss: 2.2988\n",
      "[INFO] Training model: epoch 7 - 1500/20505 samples\n",
      "Train on 2492 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 22s 9ms/step - loss: 1.5026 - val_loss: 2.3642\n",
      "[INFO] Training model: epoch 7 - 1750/20505 samples\n",
      "Train on 2578 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.5229 - val_loss: 2.6030\n",
      "[INFO] Training model: epoch 7 - 2000/20505 samples\n",
      "Train on 2437 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.5252 - val_loss: 2.0496\n",
      "[INFO] Training model: epoch 7 - 2250/20505 samples\n",
      "Train on 2413 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.5389 - val_loss: 2.3118\n",
      "[INFO] Training model: epoch 7 - 2500/20505 samples\n",
      "Train on 2421 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 21s 9ms/step - loss: 1.4964 - val_loss: 2.0663\n",
      "[INFO] Training model: epoch 7 - 2750/20505 samples\n",
      "Train on 2533 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 23s 9ms/step - loss: 1.5114 - val_loss: 2.2290\n",
      "[INFO] Training model: epoch 7 - 3000/20505 samples\n",
      "Train on 2394 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5039 - val_loss: 2.4504\n",
      "[INFO] Training model: epoch 7 - 3250/20505 samples\n",
      "Train on 2511 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.5438 - val_loss: 2.4028\n",
      "[INFO] Training model: epoch 7 - 3500/20505 samples\n",
      "Train on 2459 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.5891 - val_loss: 2.1991\n",
      "[INFO] Training model: epoch 7 - 3750/20505 samples\n",
      "Train on 2428 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.6195 - val_loss: 2.5187\n",
      "[INFO] Training model: epoch 7 - 4000/20505 samples\n",
      "Train on 2394 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5502 - val_loss: 2.4556\n",
      "[INFO] Training model: epoch 7 - 4250/20505 samples\n",
      "Train on 2430 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.6266 - val_loss: 2.3376\n",
      "[INFO] Training model: epoch 7 - 4500/20505 samples\n",
      "Train on 2454 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 22s 9ms/step - loss: 1.5222 - val_loss: 2.3722\n",
      "[INFO] Training model: epoch 7 - 4750/20505 samples\n",
      "Train on 2412 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.5967 - val_loss: 2.2392\n",
      "[INFO] Training model: epoch 7 - 5000/20505 samples\n",
      "Train on 2414 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 1.5900 - val_loss: 2.4648\n",
      "[INFO] Training model: epoch 7 - 5250/20505 samples\n",
      "Train on 2486 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.5873 - val_loss: 2.4198\n",
      "[INFO] Training model: epoch 7 - 5500/20505 samples\n",
      "Train on 2507 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 24s 9ms/step - loss: 1.5875 - val_loss: 2.1348\n",
      "[INFO] Training model: epoch 7 - 5750/20505 samples\n",
      "Train on 2370 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 21s 9ms/step - loss: 1.6221 - val_loss: 2.2851\n",
      "[INFO] Training model: epoch 7 - 6000/20505 samples\n",
      "Train on 2437 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 1.5326 - val_loss: 2.2213\n",
      "[INFO] Training model: epoch 7 - 6250/20505 samples\n",
      "Train on 2524 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 22s 9ms/step - loss: 1.5721 - val_loss: 2.3666\n",
      "[INFO] Training model: epoch 7 - 6500/20505 samples\n",
      "Train on 2364 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.4773 - val_loss: 2.4268\n",
      "[INFO] Training model: epoch 7 - 6750/20505 samples\n",
      "Train on 2499 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.5269 - val_loss: 2.2204\n",
      "[INFO] Training model: epoch 7 - 7000/20505 samples\n",
      "Train on 2382 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.6021 - val_loss: 2.4607\n",
      "[INFO] Training model: epoch 7 - 7250/20505 samples\n",
      "Train on 2531 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.5950 - val_loss: 2.7721\n",
      "[INFO] Training model: epoch 7 - 7500/20505 samples\n",
      "Train on 2489 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.5564 - val_loss: 2.2557\n",
      "[INFO] Training model: epoch 7 - 7750/20505 samples\n",
      "Train on 2431 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 23s 9ms/step - loss: 1.6196 - val_loss: 2.3948\n",
      "[INFO] Training model: epoch 7 - 8000/20505 samples\n",
      "Train on 2468 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 21s 9ms/step - loss: 1.5953 - val_loss: 2.5672\n",
      "[INFO] Training model: epoch 7 - 8250/20505 samples\n",
      "Train on 2433 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.6247 - val_loss: 2.3639\n",
      "[INFO] Training model: epoch 7 - 8500/20505 samples\n",
      "Train on 2480 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.5937 - val_loss: 2.4006\n",
      "[INFO] Training model: epoch 7 - 8750/20505 samples\n",
      "Train on 2449 samples, validate on 665 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.6109 - val_loss: 2.3355\n",
      "[INFO] Training model: epoch 7 - 9000/20505 samples\n",
      "Train on 2572 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 22s 9ms/step - loss: 1.6855 - val_loss: 2.5221\n",
      "[INFO] Training model: epoch 7 - 9250/20505 samples\n",
      "Train on 2472 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.5566 - val_loss: 2.3681\n",
      "[INFO] Training model: epoch 7 - 9500/20505 samples\n",
      "Train on 2567 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 22s 9ms/step - loss: 1.5753 - val_loss: 2.3222\n",
      "[INFO] Training model: epoch 7 - 9750/20505 samples\n",
      "Train on 2523 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 22s 9ms/step - loss: 1.5586 - val_loss: 2.5310\n",
      "[INFO] Training model: epoch 7 - 10000/20505 samples\n",
      "Train on 2434 samples, validate on 554 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 21s 9ms/step - loss: 1.6161 - val_loss: 2.1261\n",
      "[INFO] Training model: epoch 7 - 10250/20505 samples\n",
      "Train on 2453 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 22s 9ms/step - loss: 1.5927 - val_loss: 2.2858\n",
      "[INFO] Training model: epoch 7 - 10500/20505 samples\n",
      "Train on 2560 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 24s 9ms/step - loss: 1.6111 - val_loss: 2.4876\n",
      "[INFO] Training model: epoch 7 - 10750/20505 samples\n",
      "Train on 2445 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.5732 - val_loss: 2.2471\n",
      "[INFO] Training model: epoch 7 - 11000/20505 samples\n",
      "Train on 2336 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2336/2336 [==============================] - 21s 9ms/step - loss: 1.5799 - val_loss: 2.2332\n",
      "[INFO] Training model: epoch 7 - 11250/20505 samples\n",
      "Train on 2562 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 22s 9ms/step - loss: 1.5524 - val_loss: 2.3192\n",
      "[INFO] Training model: epoch 7 - 11500/20505 samples\n",
      "Train on 2364 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.6110 - val_loss: 2.6067\n",
      "[INFO] Training model: epoch 7 - 11750/20505 samples\n",
      "Train on 2504 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 23s 9ms/step - loss: 1.6525 - val_loss: 2.4365\n",
      "[INFO] Training model: epoch 7 - 12000/20505 samples\n",
      "Train on 2462 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 22s 9ms/step - loss: 1.5801 - val_loss: 2.2681\n",
      "[INFO] Training model: epoch 7 - 12250/20505 samples\n",
      "Train on 2477 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.6111 - val_loss: 2.4492\n",
      "[INFO] Training model: epoch 7 - 12500/20505 samples\n",
      "Train on 2449 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 21s 9ms/step - loss: 1.5695 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 7 - 12750/20505 samples\n",
      "Train on 2586 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 24s 9ms/step - loss: 1.7065 - val_loss: 2.3356\n",
      "[INFO] Training model: epoch 7 - 13000/20505 samples\n",
      "Train on 2406 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 21s 9ms/step - loss: 1.6430 - val_loss: 2.2652\n",
      "[INFO] Training model: epoch 7 - 13250/20505 samples\n",
      "Train on 2443 samples, validate on 684 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.6526 - val_loss: 2.0837\n",
      "[INFO] Training model: epoch 7 - 13500/20505 samples\n",
      "Train on 2506 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 1.6170 - val_loss: 2.2738\n",
      "[INFO] Training model: epoch 7 - 13750/20505 samples\n",
      "Train on 2474 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.5978 - val_loss: 2.3005\n",
      "[INFO] Training model: epoch 7 - 14000/20505 samples\n",
      "Train on 2391 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.5105 - val_loss: 2.4274\n",
      "[INFO] Training model: epoch 7 - 14250/20505 samples\n",
      "Train on 2429 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5688 - val_loss: 2.4713\n",
      "[INFO] Training model: epoch 7 - 14500/20505 samples\n",
      "Train on 2429 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5981 - val_loss: 2.5741\n",
      "[INFO] Training model: epoch 7 - 14750/20505 samples\n",
      "Train on 2422 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 21s 9ms/step - loss: 1.6252 - val_loss: 2.5238\n",
      "[INFO] Training model: epoch 7 - 15000/20505 samples\n",
      "Train on 2446 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.5523 - val_loss: 2.5058\n",
      "[INFO] Training model: epoch 7 - 15250/20505 samples\n",
      "Train on 2418 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.6368 - val_loss: 2.3573\n",
      "[INFO] Training model: epoch 7 - 15500/20505 samples\n",
      "Train on 2431 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.5739 - val_loss: 2.2895\n",
      "[INFO] Training model: epoch 7 - 15750/20505 samples\n",
      "Train on 2458 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.6645 - val_loss: 2.5678\n",
      "[INFO] Training model: epoch 7 - 16000/20505 samples\n",
      "Train on 2425 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.6505 - val_loss: 2.5744\n",
      "[INFO] Training model: epoch 7 - 16250/20505 samples\n",
      "Train on 2518 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.7050 - val_loss: 2.5486\n",
      "[INFO] Training model: epoch 7 - 16500/20505 samples\n",
      "Train on 2455 samples, validate on 555 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 21s 9ms/step - loss: 1.8237 - val_loss: 2.6175\n",
      "[INFO] Training model: epoch 7 - 16750/20505 samples\n",
      "Train on 2493 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.6548 - val_loss: 2.3380\n",
      "[INFO] Training model: epoch 7 - 17000/20505 samples\n",
      "Train on 2262 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2262/2262 [==============================] - 21s 9ms/step - loss: 1.7339 - val_loss: 2.1764\n",
      "[INFO] Training model: epoch 7 - 17250/20505 samples\n",
      "Train on 2570 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 23s 9ms/step - loss: 1.6821 - val_loss: 2.2011\n",
      "[INFO] Training model: epoch 7 - 17500/20505 samples\n",
      "Train on 2498 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 22s 9ms/step - loss: 1.5465 - val_loss: 2.3249\n",
      "[INFO] Training model: epoch 7 - 17750/20505 samples\n",
      "Train on 2409 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.6616 - val_loss: 2.5293\n",
      "[INFO] Training model: epoch 7 - 18000/20505 samples\n",
      "Train on 2377 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.6448 - val_loss: 2.5505\n",
      "[INFO] Training model: epoch 7 - 18250/20505 samples\n",
      "Train on 2443 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.6520 - val_loss: 2.3775\n",
      "[INFO] Training model: epoch 7 - 18500/20505 samples\n",
      "Train on 2499 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 24s 9ms/step - loss: 1.6862 - val_loss: 2.2862\n",
      "[INFO] Training model: epoch 7 - 18750/20505 samples\n",
      "Train on 2343 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 20s 9ms/step - loss: 1.6297 - val_loss: 2.3813\n",
      "[INFO] Training model: epoch 7 - 19000/20505 samples\n",
      "Train on 2364 samples, validate on 652 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.6269 - val_loss: 1.9372\n",
      "[INFO] Training model: epoch 7 - 19250/20505 samples\n",
      "Train on 2603 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 22s 9ms/step - loss: 1.6554 - val_loss: 2.5579\n",
      "[INFO] Training model: epoch 7 - 19500/20505 samples\n",
      "Train on 2489 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.7127 - val_loss: 2.4204\n",
      "[INFO] Training model: epoch 7 - 19750/20505 samples\n",
      "Train on 2465 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 22s 9ms/step - loss: 1.7281 - val_loss: 2.1974\n",
      "[INFO] Training model: epoch 7 - 20000/20505 samples\n",
      "Train on 2533 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 23s 9ms/step - loss: 1.6051 - val_loss: 2.6490\n",
      "[INFO] Training model: epoch 7 - 20250/20505 samples\n",
      "Train on 2380 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 21s 9ms/step - loss: 1.7321 - val_loss: 2.3327\n",
      "[INFO] Training model: epoch 7 - 20500/20505 samples\n",
      "Train on 50 samples, validate on 28 samples\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1.7676 - val_loss: 2.3740\n",
      "[INFO] Training model: epoch 8 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.4254 - val_loss: 2.2604\n",
      "[INFO] Training model: epoch 8 - 250/20505 samples\n",
      "Train on 2357 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.4702 - val_loss: 2.2392\n",
      "[INFO] Training model: epoch 8 - 500/20505 samples\n",
      "Train on 2440 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.4585 - val_loss: 2.5810\n",
      "[INFO] Training model: epoch 8 - 750/20505 samples\n",
      "Train on 2387 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 22s 9ms/step - loss: 1.4499 - val_loss: 2.1828\n",
      "[INFO] Training model: epoch 8 - 1000/20505 samples\n",
      "Train on 2484 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 22s 9ms/step - loss: 1.5182 - val_loss: 2.1674\n",
      "[INFO] Training model: epoch 8 - 1250/20505 samples\n",
      "Train on 2485 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 22s 9ms/step - loss: 1.4507 - val_loss: 2.3934\n",
      "[INFO] Training model: epoch 8 - 1500/20505 samples\n",
      "Train on 2499 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.4543 - val_loss: 2.5001\n",
      "[INFO] Training model: epoch 8 - 1750/20505 samples\n",
      "Train on 2442 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 22s 9ms/step - loss: 1.4923 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 8 - 2000/20505 samples\n",
      "Train on 2531 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.4511 - val_loss: 2.4506\n",
      "[INFO] Training model: epoch 8 - 2250/20505 samples\n",
      "Train on 2399 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.4636 - val_loss: 2.4071\n",
      "[INFO] Training model: epoch 8 - 2500/20505 samples\n",
      "Train on 2478 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 21s 9ms/step - loss: 1.4292 - val_loss: 2.2661\n",
      "[INFO] Training model: epoch 8 - 2750/20505 samples\n",
      "Train on 2516 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 23s 9ms/step - loss: 1.5255 - val_loss: 2.3535\n",
      "[INFO] Training model: epoch 8 - 3000/20505 samples\n",
      "Train on 2429 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5200 - val_loss: 2.2941\n",
      "[INFO] Training model: epoch 8 - 3250/20505 samples\n",
      "Train on 2471 samples, validate on 555 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.4237 - val_loss: 2.6849\n",
      "[INFO] Training model: epoch 8 - 3500/20505 samples\n",
      "Train on 2439 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4980 - val_loss: 2.3344\n",
      "[INFO] Training model: epoch 8 - 3750/20505 samples\n",
      "Train on 2472 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.4265 - val_loss: 2.3935\n",
      "[INFO] Training model: epoch 8 - 4000/20505 samples\n",
      "Train on 2411 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 21s 9ms/step - loss: 1.4608 - val_loss: 2.4303\n",
      "[INFO] Training model: epoch 8 - 4250/20505 samples\n",
      "Train on 2567 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 24s 9ms/step - loss: 1.4338 - val_loss: 2.5292\n",
      "[INFO] Training model: epoch 8 - 4500/20505 samples\n",
      "Train on 2393 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 21s 9ms/step - loss: 1.4894 - val_loss: 2.5774\n",
      "[INFO] Training model: epoch 8 - 4750/20505 samples\n",
      "Train on 2585 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2585/2585 [==============================] - 24s 9ms/step - loss: 1.5106 - val_loss: 2.4945\n",
      "[INFO] Training model: epoch 8 - 5000/20505 samples\n",
      "Train on 2458 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 21s 9ms/step - loss: 1.4196 - val_loss: 2.4547\n",
      "[INFO] Training model: epoch 8 - 5250/20505 samples\n",
      "Train on 2474 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.4336 - val_loss: 2.3045\n",
      "[INFO] Training model: epoch 8 - 5500/20505 samples\n",
      "Train on 2483 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.4292 - val_loss: 2.3462\n",
      "[INFO] Training model: epoch 8 - 5750/20505 samples\n",
      "Train on 2487 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.5076 - val_loss: 2.2881\n",
      "[INFO] Training model: epoch 8 - 6000/20505 samples\n",
      "Train on 2426 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.5588 - val_loss: 2.3620\n",
      "[INFO] Training model: epoch 8 - 6250/20505 samples\n",
      "Train on 2495 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.4925 - val_loss: 2.2900\n",
      "[INFO] Training model: epoch 8 - 6500/20505 samples\n",
      "Train on 2379 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 21s 9ms/step - loss: 1.4613 - val_loss: 2.4415\n",
      "[INFO] Training model: epoch 8 - 6750/20505 samples\n",
      "Train on 2390 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.4836 - val_loss: 2.3037\n",
      "[INFO] Training model: epoch 8 - 7000/20505 samples\n",
      "Train on 2519 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.4802 - val_loss: 2.2517\n",
      "[INFO] Training model: epoch 8 - 7250/20505 samples\n",
      "Train on 2411 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.5662 - val_loss: 2.4529\n",
      "[INFO] Training model: epoch 8 - 7500/20505 samples\n",
      "Train on 2538 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.4339 - val_loss: 2.2519\n",
      "[INFO] Training model: epoch 8 - 7750/20505 samples\n",
      "Train on 2465 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.5983 - val_loss: 2.5384\n",
      "[INFO] Training model: epoch 8 - 8000/20505 samples\n",
      "Train on 2475 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.5479 - val_loss: 2.2322\n",
      "[INFO] Training model: epoch 8 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.4310 - val_loss: 2.2282\n",
      "[INFO] Training model: epoch 8 - 8500/20505 samples\n",
      "Train on 2368 samples, validate on 587 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 22s 9ms/step - loss: 1.5458 - val_loss: 2.3485\n",
      "[INFO] Training model: epoch 8 - 8750/20505 samples\n",
      "Train on 2467 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 21s 9ms/step - loss: 1.4903 - val_loss: 2.4145\n",
      "[INFO] Training model: epoch 8 - 9000/20505 samples\n",
      "Train on 2421 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.4592 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 8 - 9250/20505 samples\n",
      "Train on 2442 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.5260 - val_loss: 2.3786\n",
      "[INFO] Training model: epoch 8 - 9500/20505 samples\n",
      "Train on 2467 samples, validate on 564 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 21s 9ms/step - loss: 1.5346 - val_loss: 2.4670\n",
      "[INFO] Training model: epoch 8 - 9750/20505 samples\n",
      "Train on 2496 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.5529 - val_loss: 2.5700\n",
      "[INFO] Training model: epoch 8 - 10000/20505 samples\n",
      "Train on 2458 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.5413 - val_loss: 2.4237\n",
      "[INFO] Training model: epoch 8 - 10250/20505 samples\n",
      "Train on 2446 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.5506 - val_loss: 2.5202\n",
      "[INFO] Training model: epoch 8 - 10500/20505 samples\n",
      "Train on 2513 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.5282 - val_loss: 2.4706\n",
      "[INFO] Training model: epoch 8 - 10750/20505 samples\n",
      "Train on 2458 samples, validate on 690 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.5982 - val_loss: 2.4331\n",
      "[INFO] Training model: epoch 8 - 11000/20505 samples\n",
      "Train on 2465 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 21s 9ms/step - loss: 1.4890 - val_loss: 2.5478\n",
      "[INFO] Training model: epoch 8 - 11250/20505 samples\n",
      "Train on 2484 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.5896 - val_loss: 2.2726\n",
      "[INFO] Training model: epoch 8 - 11500/20505 samples\n",
      "Train on 2515 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 22s 9ms/step - loss: 1.4795 - val_loss: 2.6344\n",
      "[INFO] Training model: epoch 8 - 11750/20505 samples\n",
      "Train on 2510 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 22s 9ms/step - loss: 1.5080 - val_loss: 2.4703\n",
      "[INFO] Training model: epoch 8 - 12000/20505 samples\n",
      "Train on 2394 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5328 - val_loss: 2.1728\n",
      "[INFO] Training model: epoch 8 - 12250/20505 samples\n",
      "Train on 2388 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.5352 - val_loss: 2.4339\n",
      "[INFO] Training model: epoch 8 - 12500/20505 samples\n",
      "Train on 2501 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.5268 - val_loss: 2.5951\n",
      "[INFO] Training model: epoch 8 - 12750/20505 samples\n",
      "Train on 2524 samples, validate on 714 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 1.5869 - val_loss: 2.4815\n",
      "[INFO] Training model: epoch 8 - 13000/20505 samples\n",
      "Train on 2456 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 22s 9ms/step - loss: 1.5443 - val_loss: 2.2870\n",
      "[INFO] Training model: epoch 8 - 13250/20505 samples\n",
      "Train on 2386 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.5590 - val_loss: 2.3811\n",
      "[INFO] Training model: epoch 8 - 13500/20505 samples\n",
      "Train on 2377 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.6301 - val_loss: 2.3500\n",
      "[INFO] Training model: epoch 8 - 13750/20505 samples\n",
      "Train on 2374 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.5277 - val_loss: 2.4277\n",
      "[INFO] Training model: epoch 8 - 14000/20505 samples\n",
      "Train on 2377 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.4668 - val_loss: 2.6192\n",
      "[INFO] Training model: epoch 8 - 14250/20505 samples\n",
      "Train on 2521 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 23s 9ms/step - loss: 1.5401 - val_loss: 2.4191\n",
      "[INFO] Training model: epoch 8 - 14500/20505 samples\n",
      "Train on 2526 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.5665 - val_loss: 2.4617\n",
      "[INFO] Training model: epoch 8 - 14750/20505 samples\n",
      "Train on 2365 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.4607 - val_loss: 2.6013\n",
      "[INFO] Training model: epoch 8 - 15000/20505 samples\n",
      "Train on 2502 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 23s 9ms/step - loss: 1.5806 - val_loss: 2.3278\n",
      "[INFO] Training model: epoch 8 - 15250/20505 samples\n",
      "Train on 2357 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.5798 - val_loss: 2.5623\n",
      "[INFO] Training model: epoch 8 - 15500/20505 samples\n",
      "Train on 2511 samples, validate on 541 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.5130 - val_loss: 2.5665\n",
      "[INFO] Training model: epoch 8 - 15750/20505 samples\n",
      "Train on 2457 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.5821 - val_loss: 2.1772\n",
      "[INFO] Training model: epoch 8 - 16000/20505 samples\n",
      "Train on 2435 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.6315 - val_loss: 2.3547\n",
      "[INFO] Training model: epoch 8 - 16250/20505 samples\n",
      "Train on 2349 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 9ms/step - loss: 1.5623 - val_loss: 2.3017\n",
      "[INFO] Training model: epoch 8 - 16500/20505 samples\n",
      "Train on 2283 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2283/2283 [==============================] - 21s 9ms/step - loss: 1.6112 - val_loss: 2.2483\n",
      "[INFO] Training model: epoch 8 - 16750/20505 samples\n",
      "Train on 2401 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.5802 - val_loss: 2.2122\n",
      "[INFO] Training model: epoch 8 - 17000/20505 samples\n",
      "Train on 2349 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 9ms/step - loss: 1.5594 - val_loss: 2.3625\n",
      "[INFO] Training model: epoch 8 - 17250/20505 samples\n",
      "Train on 2501 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.6021 - val_loss: 2.4631\n",
      "[INFO] Training model: epoch 8 - 17500/20505 samples\n",
      "Train on 2470 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.5539 - val_loss: 2.4974\n",
      "[INFO] Training model: epoch 8 - 17750/20505 samples\n",
      "Train on 2472 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 21s 9ms/step - loss: 1.5754 - val_loss: 2.4237\n",
      "[INFO] Training model: epoch 8 - 18000/20505 samples\n",
      "Train on 2449 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.5953 - val_loss: 2.3047\n",
      "[INFO] Training model: epoch 8 - 18250/20505 samples\n",
      "Train on 2518 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.4867 - val_loss: 2.6699\n",
      "[INFO] Training model: epoch 8 - 18500/20505 samples\n",
      "Train on 2600 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2600/2600 [==============================] - 24s 9ms/step - loss: 1.6077 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 8 - 18750/20505 samples\n",
      "Train on 2429 samples, validate on 655 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429/2429 [==============================] - 23s 9ms/step - loss: 1.5625 - val_loss: 2.4025\n",
      "[INFO] Training model: epoch 8 - 19000/20505 samples\n",
      "Train on 2542 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 23s 9ms/step - loss: 1.5899 - val_loss: 2.2500\n",
      "[INFO] Training model: epoch 8 - 19250/20505 samples\n",
      "Train on 2461 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.5829 - val_loss: 2.3534\n",
      "[INFO] Training model: epoch 8 - 19500/20505 samples\n",
      "Train on 2433 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.5422 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 8 - 19750/20505 samples\n",
      "Train on 2535 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 23s 9ms/step - loss: 1.5532 - val_loss: 2.3387\n",
      "[INFO] Training model: epoch 8 - 20000/20505 samples\n",
      "Train on 2458 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 22s 9ms/step - loss: 1.6201 - val_loss: 2.4505\n",
      "[INFO] Training model: epoch 8 - 20250/20505 samples\n",
      "Train on 2493 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.4899 - val_loss: 2.3800\n",
      "[INFO] Training model: epoch 8 - 20500/20505 samples\n",
      "Train on 62 samples, validate on 37 samples\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3269 - val_loss: 3.3216\n",
      "[INFO] Training model: epoch 9 - 0/20505 samples\n",
      "Train on 2507 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.2494 - val_loss: 2.3022\n",
      "[INFO] Training model: epoch 9 - 250/20505 samples\n",
      "Train on 2478 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 22s 9ms/step - loss: 1.2654 - val_loss: 2.2845\n",
      "[INFO] Training model: epoch 9 - 500/20505 samples\n",
      "Train on 2490 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 22s 9ms/step - loss: 1.3792 - val_loss: 2.5207\n",
      "[INFO] Training model: epoch 9 - 750/20505 samples\n",
      "Train on 2411 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 23s 9ms/step - loss: 1.3050 - val_loss: 2.3013\n",
      "[INFO] Training model: epoch 9 - 1000/20505 samples\n",
      "Train on 2556 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2556/2556 [==============================] - 24s 9ms/step - loss: 1.3251 - val_loss: 2.7311\n",
      "[INFO] Training model: epoch 9 - 1250/20505 samples\n",
      "Train on 2461 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.3897 - val_loss: 2.4335\n",
      "[INFO] Training model: epoch 9 - 1500/20505 samples\n",
      "Train on 2464 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.4240 - val_loss: 2.5491\n",
      "[INFO] Training model: epoch 9 - 1750/20505 samples\n",
      "Train on 2441 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.3969 - val_loss: 2.4459\n",
      "[INFO] Training model: epoch 9 - 2000/20505 samples\n",
      "Train on 2422 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 22s 9ms/step - loss: 1.3862 - val_loss: 2.6346\n",
      "[INFO] Training model: epoch 9 - 2250/20505 samples\n",
      "Train on 2531 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 1.4287 - val_loss: 2.4100\n",
      "[INFO] Training model: epoch 9 - 2500/20505 samples\n",
      "Train on 2479 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 22s 9ms/step - loss: 1.4320 - val_loss: 2.4232\n",
      "[INFO] Training model: epoch 9 - 2750/20505 samples\n",
      "Train on 2489 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.3846 - val_loss: 2.4463\n",
      "[INFO] Training model: epoch 9 - 3000/20505 samples\n",
      "Train on 2348 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 21s 9ms/step - loss: 1.3995 - val_loss: 2.5715\n",
      "[INFO] Training model: epoch 9 - 3250/20505 samples\n",
      "Train on 2473 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.3809 - val_loss: 2.2969\n",
      "[INFO] Training model: epoch 9 - 3500/20505 samples\n",
      "Train on 2485 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.4185 - val_loss: 2.1848\n",
      "[INFO] Training model: epoch 9 - 3750/20505 samples\n",
      "Train on 2528 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.3111 - val_loss: 2.5029\n",
      "[INFO] Training model: epoch 9 - 4000/20505 samples\n",
      "Train on 2420 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.5147 - val_loss: 2.3917\n",
      "[INFO] Training model: epoch 9 - 4250/20505 samples\n",
      "Train on 2451 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.3961 - val_loss: 2.5064\n",
      "[INFO] Training model: epoch 9 - 4500/20505 samples\n",
      "Train on 2489 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.4747 - val_loss: 2.3963\n",
      "[INFO] Training model: epoch 9 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.4757 - val_loss: 2.6546\n",
      "[INFO] Training model: epoch 9 - 5000/20505 samples\n",
      "Train on 2419 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 21s 9ms/step - loss: 1.4721 - val_loss: 2.4276\n",
      "[INFO] Training model: epoch 9 - 5250/20505 samples\n",
      "Train on 2374 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.4015 - val_loss: 2.3351\n",
      "[INFO] Training model: epoch 9 - 5500/20505 samples\n",
      "Train on 2466 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 21s 9ms/step - loss: 1.4323 - val_loss: 2.3597\n",
      "[INFO] Training model: epoch 9 - 5750/20505 samples\n",
      "Train on 2448 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.4114 - val_loss: 2.3271\n",
      "[INFO] Training model: epoch 9 - 6000/20505 samples\n",
      "Train on 2394 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.4814 - val_loss: 2.4957\n",
      "[INFO] Training model: epoch 9 - 6250/20505 samples\n",
      "Train on 2385 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.3888 - val_loss: 2.6494\n",
      "[INFO] Training model: epoch 9 - 6500/20505 samples\n",
      "Train on 2439 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.3862 - val_loss: 2.5470\n",
      "[INFO] Training model: epoch 9 - 6750/20505 samples\n",
      "Train on 2555 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2555/2555 [==============================] - 22s 9ms/step - loss: 1.4329 - val_loss: 2.4876\n",
      "[INFO] Training model: epoch 9 - 7000/20505 samples\n",
      "Train on 2482 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.4097 - val_loss: 2.4222\n",
      "[INFO] Training model: epoch 9 - 7250/20505 samples\n",
      "Train on 2507 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 23s 9ms/step - loss: 1.4090 - val_loss: 2.3161\n",
      "[INFO] Training model: epoch 9 - 7500/20505 samples\n",
      "Train on 2405 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 1.3927 - val_loss: 2.5329\n",
      "[INFO] Training model: epoch 9 - 7750/20505 samples\n",
      "Train on 2562 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 24s 9ms/step - loss: 1.5146 - val_loss: 2.1525\n",
      "[INFO] Training model: epoch 9 - 8000/20505 samples\n",
      "Train on 2459 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.4617 - val_loss: 2.5031\n",
      "[INFO] Training model: epoch 9 - 8250/20505 samples\n",
      "Train on 2408 samples, validate on 596 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.4500 - val_loss: 2.5077\n",
      "[INFO] Training model: epoch 9 - 8500/20505 samples\n",
      "Train on 2373 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 21s 9ms/step - loss: 1.4290 - val_loss: 2.3043\n",
      "[INFO] Training model: epoch 9 - 8750/20505 samples\n",
      "Train on 2446 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.4198 - val_loss: 2.3607\n",
      "[INFO] Training model: epoch 9 - 9000/20505 samples\n",
      "Train on 2522 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.4920 - val_loss: 2.5335\n",
      "[INFO] Training model: epoch 9 - 9250/20505 samples\n",
      "Train on 2440 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.4412 - val_loss: 2.0988\n",
      "[INFO] Training model: epoch 9 - 9500/20505 samples\n",
      "Train on 2433 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.4807 - val_loss: 2.2379\n",
      "[INFO] Training model: epoch 9 - 9750/20505 samples\n",
      "Train on 2410 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.4218 - val_loss: 2.5125\n",
      "[INFO] Training model: epoch 9 - 10000/20505 samples\n",
      "Train on 2457 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.4569 - val_loss: 2.4772\n",
      "[INFO] Training model: epoch 9 - 10250/20505 samples\n",
      "Train on 2518 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 24s 9ms/step - loss: 1.3941 - val_loss: 2.6484\n",
      "[INFO] Training model: epoch 9 - 10500/20505 samples\n",
      "Train on 2460 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 21s 9ms/step - loss: 1.4324 - val_loss: 2.4306\n",
      "[INFO] Training model: epoch 9 - 10750/20505 samples\n",
      "Train on 2316 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 21s 9ms/step - loss: 1.5087 - val_loss: 2.2779\n",
      "[INFO] Training model: epoch 9 - 11000/20505 samples\n",
      "Train on 2347 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 9ms/step - loss: 1.4858 - val_loss: 2.3544\n",
      "[INFO] Training model: epoch 9 - 11250/20505 samples\n",
      "Train on 2440 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 1.4716 - val_loss: 2.4179\n",
      "[INFO] Training model: epoch 9 - 11500/20505 samples\n",
      "Train on 2405 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.4988 - val_loss: 2.4062\n",
      "[INFO] Training model: epoch 9 - 11750/20505 samples\n",
      "Train on 2423 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.4550 - val_loss: 2.2950\n",
      "[INFO] Training model: epoch 9 - 12000/20505 samples\n",
      "Train on 2536 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 22s 9ms/step - loss: 1.5277 - val_loss: 2.3984\n",
      "[INFO] Training model: epoch 9 - 12250/20505 samples\n",
      "Train on 2495 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.4774 - val_loss: 2.4728\n",
      "[INFO] Training model: epoch 9 - 12500/20505 samples\n",
      "Train on 2446 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.5677 - val_loss: 2.3705\n",
      "[INFO] Training model: epoch 9 - 12750/20505 samples\n",
      "Train on 2377 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.4511 - val_loss: 2.4314\n",
      "[INFO] Training model: epoch 9 - 13000/20505 samples\n",
      "Train on 2460 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.4524 - val_loss: 2.5302\n",
      "[INFO] Training model: epoch 9 - 13250/20505 samples\n",
      "Train on 2473 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 22s 9ms/step - loss: 1.4904 - val_loss: 2.3268\n",
      "[INFO] Training model: epoch 9 - 13500/20505 samples\n",
      "Train on 2403 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 22s 9ms/step - loss: 1.4029 - val_loss: 2.3485\n",
      "[INFO] Training model: epoch 9 - 13750/20505 samples\n",
      "Train on 2399 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.5397 - val_loss: 2.6131\n",
      "[INFO] Training model: epoch 9 - 14000/20505 samples\n",
      "Train on 2321 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2321/2321 [==============================] - 22s 9ms/step - loss: 1.3923 - val_loss: 2.5680\n",
      "[INFO] Training model: epoch 9 - 14250/20505 samples\n",
      "Train on 2371 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.4947 - val_loss: 2.2011\n",
      "[INFO] Training model: epoch 9 - 14500/20505 samples\n",
      "Train on 2511 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.4852 - val_loss: 2.6161\n",
      "[INFO] Training model: epoch 9 - 14750/20505 samples\n",
      "Train on 2603 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 23s 9ms/step - loss: 1.4086 - val_loss: 2.4499\n",
      "[INFO] Training model: epoch 9 - 15000/20505 samples\n",
      "Train on 2578 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.4114 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 9 - 15250/20505 samples\n",
      "Train on 2535 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 23s 9ms/step - loss: 1.4417 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 9 - 15500/20505 samples\n",
      "Train on 2494 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.4749 - val_loss: 2.4858\n",
      "[INFO] Training model: epoch 9 - 15750/20505 samples\n",
      "Train on 2480 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 24s 9ms/step - loss: 1.5163 - val_loss: 2.5709\n",
      "[INFO] Training model: epoch 9 - 16000/20505 samples\n",
      "Train on 2508 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 22s 9ms/step - loss: 1.4481 - val_loss: 2.5664\n",
      "[INFO] Training model: epoch 9 - 16250/20505 samples\n",
      "Train on 2347 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 9ms/step - loss: 1.4775 - val_loss: 2.6308\n",
      "[INFO] Training model: epoch 9 - 16500/20505 samples\n",
      "Train on 2299 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2299/2299 [==============================] - 21s 9ms/step - loss: 1.5214 - val_loss: 2.5229\n",
      "[INFO] Training model: epoch 9 - 16750/20505 samples\n",
      "Train on 2504 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 22s 9ms/step - loss: 1.4966 - val_loss: 2.3708\n",
      "[INFO] Training model: epoch 9 - 17000/20505 samples\n",
      "Train on 2399 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 23s 9ms/step - loss: 1.5044 - val_loss: 2.3872\n",
      "[INFO] Training model: epoch 9 - 17250/20505 samples\n",
      "Train on 2470 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 21s 9ms/step - loss: 1.5059 - val_loss: 2.5252\n",
      "[INFO] Training model: epoch 9 - 17500/20505 samples\n",
      "Train on 2592 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 22s 9ms/step - loss: 1.5426 - val_loss: 2.4145\n",
      "[INFO] Training model: epoch 9 - 17750/20505 samples\n",
      "Train on 2383 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.4442 - val_loss: 2.3948\n",
      "[INFO] Training model: epoch 9 - 18000/20505 samples\n",
      "Train on 2569 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 22s 9ms/step - loss: 1.4572 - val_loss: 2.4517\n",
      "[INFO] Training model: epoch 9 - 18250/20505 samples\n",
      "Train on 2446 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.4634 - val_loss: 2.1839\n",
      "[INFO] Training model: epoch 9 - 18500/20505 samples\n",
      "Train on 2369 samples, validate on 665 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2369/2369 [==============================] - 22s 9ms/step - loss: 1.4268 - val_loss: 2.4147\n",
      "[INFO] Training model: epoch 9 - 18750/20505 samples\n",
      "Train on 2497 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.5895 - val_loss: 2.5063\n",
      "[INFO] Training model: epoch 9 - 19000/20505 samples\n",
      "Train on 2480 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.5036 - val_loss: 2.5566\n",
      "[INFO] Training model: epoch 9 - 19250/20505 samples\n",
      "Train on 2538 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.5389 - val_loss: 2.6828\n",
      "[INFO] Training model: epoch 9 - 19500/20505 samples\n",
      "Train on 2425 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.5731 - val_loss: 2.3701\n",
      "[INFO] Training model: epoch 9 - 19750/20505 samples\n",
      "Train on 2419 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.5797 - val_loss: 2.4151\n",
      "[INFO] Training model: epoch 9 - 20000/20505 samples\n",
      "Train on 2557 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 24s 9ms/step - loss: 1.5699 - val_loss: 2.4112\n",
      "[INFO] Training model: epoch 9 - 20250/20505 samples\n",
      "Train on 2427 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.5866 - val_loss: 2.3979\n",
      "[INFO] Training model: epoch 9 - 20500/20505 samples\n",
      "Train on 54 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 1.3256 - val_loss: 3.8678\n",
      "[INFO] Training model: epoch 10 - 0/20505 samples\n",
      "Train on 2477 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.2813 - val_loss: 2.5783\n",
      "[INFO] Training model: epoch 10 - 250/20505 samples\n",
      "Train on 2480 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.2865 - val_loss: 2.4034\n",
      "[INFO] Training model: epoch 10 - 500/20505 samples\n",
      "Train on 2385 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.3301 - val_loss: 2.5189\n",
      "[INFO] Training model: epoch 10 - 750/20505 samples\n",
      "Train on 2480 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.2654 - val_loss: 2.3832\n",
      "[INFO] Training model: epoch 10 - 1000/20505 samples\n",
      "Train on 2421 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.2587 - val_loss: 2.3226\n",
      "[INFO] Training model: epoch 10 - 1250/20505 samples\n",
      "Train on 2525 samples, validate on 684 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.3854 - val_loss: 2.5774\n",
      "[INFO] Training model: epoch 10 - 1500/20505 samples\n",
      "Train on 2450 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.3582 - val_loss: 2.4658\n",
      "[INFO] Training model: epoch 10 - 1750/20505 samples\n",
      "Train on 2563 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 23s 9ms/step - loss: 1.3821 - val_loss: 2.3121\n",
      "[INFO] Training model: epoch 10 - 2000/20505 samples\n",
      "Train on 2462 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 22s 9ms/step - loss: 1.2983 - val_loss: 2.2430\n",
      "[INFO] Training model: epoch 10 - 2250/20505 samples\n",
      "Train on 2362 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 1.2991 - val_loss: 2.4158\n",
      "[INFO] Training model: epoch 10 - 2500/20505 samples\n",
      "Train on 2488 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 22s 9ms/step - loss: 1.3255 - val_loss: 2.3827\n",
      "[INFO] Training model: epoch 10 - 2750/20505 samples\n",
      "Train on 2427 samples, validate on 720 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.3067 - val_loss: 2.5710\n",
      "[INFO] Training model: epoch 10 - 3000/20505 samples\n",
      "Train on 2528 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 22s 9ms/step - loss: 1.3662 - val_loss: 2.2393\n",
      "[INFO] Training model: epoch 10 - 3250/20505 samples\n",
      "Train on 2495 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.3305 - val_loss: 2.2888\n",
      "[INFO] Training model: epoch 10 - 3500/20505 samples\n",
      "Train on 2456 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.3233 - val_loss: 2.3604\n",
      "[INFO] Training model: epoch 10 - 3750/20505 samples\n",
      "Train on 2392 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.3297 - val_loss: 2.4217\n",
      "[INFO] Training model: epoch 10 - 4000/20505 samples\n",
      "Train on 2527 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 23s 9ms/step - loss: 1.3286 - val_loss: 2.3171\n",
      "[INFO] Training model: epoch 10 - 4250/20505 samples\n",
      "Train on 2452 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.3810 - val_loss: 2.3649\n",
      "[INFO] Training model: epoch 10 - 4500/20505 samples\n",
      "Train on 2375 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 1.3607 - val_loss: 2.4770\n",
      "[INFO] Training model: epoch 10 - 4750/20505 samples\n",
      "Train on 2381 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 21s 9ms/step - loss: 1.3526 - val_loss: 2.2170\n",
      "[INFO] Training model: epoch 10 - 5000/20505 samples\n",
      "Train on 2430 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.3711 - val_loss: 2.5644\n",
      "[INFO] Training model: epoch 10 - 5250/20505 samples\n",
      "Train on 2511 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.2857 - val_loss: 2.3252\n",
      "[INFO] Training model: epoch 10 - 5500/20505 samples\n",
      "Train on 2636 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 25s 9ms/step - loss: 1.4415 - val_loss: 2.4390\n",
      "[INFO] Training model: epoch 10 - 5750/20505 samples\n",
      "Train on 2460 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.3645 - val_loss: 2.8236\n",
      "[INFO] Training model: epoch 10 - 6000/20505 samples\n",
      "Train on 2513 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.3189 - val_loss: 2.5506\n",
      "[INFO] Training model: epoch 10 - 6250/20505 samples\n",
      "Train on 2477 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.3864 - val_loss: 2.5477\n",
      "[INFO] Training model: epoch 10 - 6500/20505 samples\n",
      "Train on 2459 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.3168 - val_loss: 2.6463\n",
      "[INFO] Training model: epoch 10 - 6750/20505 samples\n",
      "Train on 2430 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.3488 - val_loss: 2.7052\n",
      "[INFO] Training model: epoch 10 - 7000/20505 samples\n",
      "Train on 2436 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 22s 9ms/step - loss: 1.3153 - val_loss: 2.6865\n",
      "[INFO] Training model: epoch 10 - 7250/20505 samples\n",
      "Train on 2487 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.4553 - val_loss: 2.3880\n",
      "[INFO] Training model: epoch 10 - 7500/20505 samples\n",
      "Train on 2636 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 24s 9ms/step - loss: 1.4411 - val_loss: 2.6852\n",
      "[INFO] Training model: epoch 10 - 7750/20505 samples\n",
      "Train on 2500 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.4265 - val_loss: 2.5388\n",
      "[INFO] Training model: epoch 10 - 8000/20505 samples\n",
      "Train on 2380 samples, validate on 606 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.3947 - val_loss: 2.6676\n",
      "[INFO] Training model: epoch 10 - 8250/20505 samples\n",
      "Train on 2464 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.4110 - val_loss: 2.7268\n",
      "[INFO] Training model: epoch 10 - 8500/20505 samples\n",
      "Train on 2365 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.3895 - val_loss: 2.3469\n",
      "[INFO] Training model: epoch 10 - 8750/20505 samples\n",
      "Train on 2410 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.4229 - val_loss: 2.4641\n",
      "[INFO] Training model: epoch 10 - 9000/20505 samples\n",
      "Train on 2468 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.4841 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 10 - 9250/20505 samples\n",
      "Train on 2445 samples, validate on 687 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 22s 9ms/step - loss: 1.3823 - val_loss: 2.5592\n",
      "[INFO] Training model: epoch 10 - 9500/20505 samples\n",
      "Train on 2428 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.3235 - val_loss: 2.4626\n",
      "[INFO] Training model: epoch 10 - 9750/20505 samples\n",
      "Train on 2476 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.3637 - val_loss: 2.5549\n",
      "[INFO] Training model: epoch 10 - 10000/20505 samples\n",
      "Train on 2461 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.2935 - val_loss: 2.5553\n",
      "[INFO] Training model: epoch 10 - 10250/20505 samples\n",
      "Train on 2414 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 1.4189 - val_loss: 2.3249\n",
      "[INFO] Training model: epoch 10 - 10500/20505 samples\n",
      "Train on 2389 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.3648 - val_loss: 2.4715\n",
      "[INFO] Training model: epoch 10 - 10750/20505 samples\n",
      "Train on 2395 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 1.4253 - val_loss: 2.3489\n",
      "[INFO] Training model: epoch 10 - 11000/20505 samples\n",
      "Train on 2473 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.4304 - val_loss: 2.5243\n",
      "[INFO] Training model: epoch 10 - 11250/20505 samples\n",
      "Train on 2348 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 21s 9ms/step - loss: 1.4773 - val_loss: 2.3848\n",
      "[INFO] Training model: epoch 10 - 11500/20505 samples\n",
      "Train on 2405 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.3192 - val_loss: 2.8990\n",
      "[INFO] Training model: epoch 10 - 11750/20505 samples\n",
      "Train on 2394 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.3400 - val_loss: 2.1565\n",
      "[INFO] Training model: epoch 10 - 12000/20505 samples\n",
      "Train on 2367 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 21s 9ms/step - loss: 1.4235 - val_loss: 2.5791\n",
      "[INFO] Training model: epoch 10 - 12250/20505 samples\n",
      "Train on 2399 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 21s 9ms/step - loss: 1.4320 - val_loss: 2.4136\n",
      "[INFO] Training model: epoch 10 - 12500/20505 samples\n",
      "Train on 2565 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 23s 9ms/step - loss: 1.4080 - val_loss: 2.4983\n",
      "[INFO] Training model: epoch 10 - 12750/20505 samples\n",
      "Train on 2537 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 23s 9ms/step - loss: 1.3766 - val_loss: 2.5732\n",
      "[INFO] Training model: epoch 10 - 13000/20505 samples\n",
      "Train on 2515 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 22s 9ms/step - loss: 1.4405 - val_loss: 2.5322\n",
      "[INFO] Training model: epoch 10 - 13250/20505 samples\n",
      "Train on 2391 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.3882 - val_loss: 2.5887\n",
      "[INFO] Training model: epoch 10 - 13500/20505 samples\n",
      "Train on 2517 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 22s 9ms/step - loss: 1.3980 - val_loss: 2.6533\n",
      "[INFO] Training model: epoch 10 - 13750/20505 samples\n",
      "Train on 2445 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.3992 - val_loss: 2.4517\n",
      "[INFO] Training model: epoch 10 - 14000/20505 samples\n",
      "Train on 2448 samples, validate on 551 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.4529 - val_loss: 2.3358\n",
      "[INFO] Training model: epoch 10 - 14250/20505 samples\n",
      "Train on 2536 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 24s 9ms/step - loss: 1.3809 - val_loss: 2.4419\n",
      "[INFO] Training model: epoch 10 - 14500/20505 samples\n",
      "Train on 2456 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.3710 - val_loss: 2.5289\n",
      "[INFO] Training model: epoch 10 - 14750/20505 samples\n",
      "Train on 2420 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 23s 9ms/step - loss: 1.4500 - val_loss: 2.3588\n",
      "[INFO] Training model: epoch 10 - 15000/20505 samples\n",
      "Train on 2373 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.4255 - val_loss: 2.4434\n",
      "[INFO] Training model: epoch 10 - 15250/20505 samples\n",
      "Train on 2411 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.4036 - val_loss: 2.3656\n",
      "[INFO] Training model: epoch 10 - 15500/20505 samples\n",
      "Train on 2440 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.3787 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 10 - 15750/20505 samples\n",
      "Train on 2522 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.4314 - val_loss: 2.1885\n",
      "[INFO] Training model: epoch 10 - 16000/20505 samples\n",
      "Train on 2439 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4104 - val_loss: 2.4741\n",
      "[INFO] Training model: epoch 10 - 16250/20505 samples\n",
      "Train on 2417 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 22s 9ms/step - loss: 1.4709 - val_loss: 2.4638\n",
      "[INFO] Training model: epoch 10 - 16500/20505 samples\n",
      "Train on 2352 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2352/2352 [==============================] - 22s 9ms/step - loss: 1.4960 - val_loss: 2.6431\n",
      "[INFO] Training model: epoch 10 - 16750/20505 samples\n",
      "Train on 2471 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.4400 - val_loss: 2.5334\n",
      "[INFO] Training model: epoch 10 - 17000/20505 samples\n",
      "Train on 2490 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.4389 - val_loss: 2.4421\n",
      "[INFO] Training model: epoch 10 - 17250/20505 samples\n",
      "Train on 2445 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.4755 - val_loss: 2.5807\n",
      "[INFO] Training model: epoch 10 - 17500/20505 samples\n",
      "Train on 2409 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.4552 - val_loss: 2.3073\n",
      "[INFO] Training model: epoch 10 - 17750/20505 samples\n",
      "Train on 2537 samples, validate on 545 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 9ms/step - loss: 1.4278 - val_loss: 2.2083\n",
      "[INFO] Training model: epoch 10 - 18000/20505 samples\n",
      "Train on 2519 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.4099 - val_loss: 2.5587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 10 - 18250/20505 samples\n",
      "Train on 2419 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.4591 - val_loss: 2.4607\n",
      "[INFO] Training model: epoch 10 - 18500/20505 samples\n",
      "Train on 2459 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 1.4149 - val_loss: 2.2507\n",
      "[INFO] Training model: epoch 10 - 18750/20505 samples\n",
      "Train on 2304 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 20s 9ms/step - loss: 1.4548 - val_loss: 2.1973\n",
      "[INFO] Training model: epoch 10 - 19000/20505 samples\n",
      "Train on 2501 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.5338 - val_loss: 2.5324\n",
      "[INFO] Training model: epoch 10 - 19250/20505 samples\n",
      "Train on 2519 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.3824 - val_loss: 2.7397\n",
      "[INFO] Training model: epoch 10 - 19500/20505 samples\n",
      "Train on 2510 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 23s 9ms/step - loss: 1.5166 - val_loss: 2.2992\n",
      "[INFO] Training model: epoch 10 - 19750/20505 samples\n",
      "Train on 2351 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 1.4894 - val_loss: 2.3523\n",
      "[INFO] Training model: epoch 10 - 20000/20505 samples\n",
      "Train on 2612 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2612/2612 [==============================] - 24s 9ms/step - loss: 1.5049 - val_loss: 2.3938\n",
      "[INFO] Training model: epoch 10 - 20250/20505 samples\n",
      "Train on 2474 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.5264 - val_loss: 2.4127\n",
      "[INFO] Training model: epoch 10 - 20500/20505 samples\n",
      "Train on 70 samples, validate on 21 samples\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 1.4037 - val_loss: 2.9908\n",
      "[INFO] Training model: epoch 11 - 0/20505 samples\n",
      "Train on 2370 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 21s 9ms/step - loss: 1.2309 - val_loss: 2.5357\n",
      "[INFO] Training model: epoch 11 - 250/20505 samples\n",
      "Train on 2382 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.1821 - val_loss: 2.5691\n",
      "[INFO] Training model: epoch 11 - 500/20505 samples\n",
      "Train on 2352 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2352/2352 [==============================] - 22s 9ms/step - loss: 1.1994 - val_loss: 2.5280\n",
      "[INFO] Training model: epoch 11 - 750/20505 samples\n",
      "Train on 2494 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.2412 - val_loss: 2.4799\n",
      "[INFO] Training model: epoch 11 - 1000/20505 samples\n",
      "Train on 2416 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 21s 9ms/step - loss: 1.2701 - val_loss: 2.9312\n",
      "[INFO] Training model: epoch 11 - 1250/20505 samples\n",
      "Train on 2401 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2047 - val_loss: 2.4645\n",
      "[INFO] Training model: epoch 11 - 1500/20505 samples\n",
      "Train on 2473 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2480 - val_loss: 2.6627\n",
      "[INFO] Training model: epoch 11 - 1750/20505 samples\n",
      "Train on 2426 samples, validate on 542 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.2830 - val_loss: 2.5884\n",
      "[INFO] Training model: epoch 11 - 2000/20505 samples\n",
      "Train on 2410 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2945 - val_loss: 2.4347\n",
      "[INFO] Training model: epoch 11 - 2250/20505 samples\n",
      "Train on 2541 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.2395 - val_loss: 2.4725\n",
      "[INFO] Training model: epoch 11 - 2500/20505 samples\n",
      "Train on 2473 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2596 - val_loss: 2.7029\n",
      "[INFO] Training model: epoch 11 - 2750/20505 samples\n",
      "Train on 2443 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.2199 - val_loss: 2.7177\n",
      "[INFO] Training model: epoch 11 - 3000/20505 samples\n",
      "Train on 2445 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 21s 9ms/step - loss: 1.2165 - val_loss: 2.1850\n",
      "[INFO] Training model: epoch 11 - 3250/20505 samples\n",
      "Train on 2469 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 22s 9ms/step - loss: 1.3073 - val_loss: 2.3856\n",
      "[INFO] Training model: epoch 11 - 3500/20505 samples\n",
      "Train on 2497 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 24s 10ms/step - loss: 1.1882 - val_loss: 2.3857\n",
      "[INFO] Training model: epoch 11 - 3750/20505 samples\n",
      "Train on 2471 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.2442 - val_loss: 2.5019\n",
      "[INFO] Training model: epoch 11 - 4000/20505 samples\n",
      "Train on 2477 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 22s 9ms/step - loss: 1.2202 - val_loss: 2.4028\n",
      "[INFO] Training model: epoch 11 - 4250/20505 samples\n",
      "Train on 2464 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.2981 - val_loss: 2.6262\n",
      "[INFO] Training model: epoch 11 - 4500/20505 samples\n",
      "Train on 2421 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.2153 - val_loss: 2.5997\n",
      "[INFO] Training model: epoch 11 - 4750/20505 samples\n",
      "Train on 2477 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.2472 - val_loss: 2.7452\n",
      "[INFO] Training model: epoch 11 - 5000/20505 samples\n",
      "Train on 2454 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 21s 9ms/step - loss: 1.2551 - val_loss: 2.3677\n",
      "[INFO] Training model: epoch 11 - 5250/20505 samples\n",
      "Train on 2536 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 23s 9ms/step - loss: 1.2775 - val_loss: 2.4986\n",
      "[INFO] Training model: epoch 11 - 5500/20505 samples\n",
      "Train on 2485 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.3082 - val_loss: 2.3396\n",
      "[INFO] Training model: epoch 11 - 5750/20505 samples\n",
      "Train on 2440 samples, validate on 561 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.3467 - val_loss: 2.5025\n",
      "[INFO] Training model: epoch 11 - 6000/20505 samples\n",
      "Train on 2347 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 21s 9ms/step - loss: 1.3810 - val_loss: 2.3751\n",
      "[INFO] Training model: epoch 11 - 6250/20505 samples\n",
      "Train on 2464 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 21s 9ms/step - loss: 1.3652 - val_loss: 2.7571\n",
      "[INFO] Training model: epoch 11 - 6500/20505 samples\n",
      "Train on 2495 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 21s 9ms/step - loss: 1.3482 - val_loss: 2.4914\n",
      "[INFO] Training model: epoch 11 - 6750/20505 samples\n",
      "Train on 2494 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.2669 - val_loss: 2.7112\n",
      "[INFO] Training model: epoch 11 - 7000/20505 samples\n",
      "Train on 2593 samples, validate on 686 samples\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 25s 9ms/step - loss: 1.2989 - val_loss: 2.6193\n",
      "[INFO] Training model: epoch 11 - 7250/20505 samples\n",
      "Train on 2449 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.2783 - val_loss: 2.5531\n",
      "[INFO] Training model: epoch 11 - 7500/20505 samples\n",
      "Train on 2417 samples, validate on 637 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417/2417 [==============================] - 22s 9ms/step - loss: 1.2918 - val_loss: 2.8132\n",
      "[INFO] Training model: epoch 11 - 7750/20505 samples\n",
      "Train on 2437 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 21s 9ms/step - loss: 1.3941 - val_loss: 2.4988\n",
      "[INFO] Training model: epoch 11 - 8000/20505 samples\n",
      "Train on 2367 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 20s 9ms/step - loss: 1.3292 - val_loss: 2.3259\n",
      "[INFO] Training model: epoch 11 - 8250/20505 samples\n",
      "Train on 2479 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.2917 - val_loss: 2.6790\n",
      "[INFO] Training model: epoch 11 - 8500/20505 samples\n",
      "Train on 2437 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 1.3568 - val_loss: 2.6854\n",
      "[INFO] Training model: epoch 11 - 8750/20505 samples\n",
      "Train on 2438 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.3525 - val_loss: 2.4817\n",
      "[INFO] Training model: epoch 11 - 9000/20505 samples\n",
      "Train on 2390 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 21s 9ms/step - loss: 1.2992 - val_loss: 2.7257\n",
      "[INFO] Training model: epoch 11 - 9250/20505 samples\n",
      "Train on 2463 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 22s 9ms/step - loss: 1.3064 - val_loss: 2.8056\n",
      "[INFO] Training model: epoch 11 - 9500/20505 samples\n",
      "Train on 2497 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.3276 - val_loss: 2.8389\n",
      "[INFO] Training model: epoch 11 - 9750/20505 samples\n",
      "Train on 2442 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.3576 - val_loss: 2.1876\n",
      "[INFO] Training model: epoch 11 - 10000/20505 samples\n",
      "Train on 2505 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.3888 - val_loss: 2.5828\n",
      "[INFO] Training model: epoch 11 - 10250/20505 samples\n",
      "Train on 2439 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.3151 - val_loss: 2.6247\n",
      "[INFO] Training model: epoch 11 - 10500/20505 samples\n",
      "Train on 2443 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.2393 - val_loss: 2.7560\n",
      "[INFO] Training model: epoch 11 - 10750/20505 samples\n",
      "Train on 2418 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 9ms/step - loss: 1.3563 - val_loss: 2.6090\n",
      "[INFO] Training model: epoch 11 - 11000/20505 samples\n",
      "Train on 2425 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.4039 - val_loss: 2.6096\n",
      "[INFO] Training model: epoch 11 - 11250/20505 samples\n",
      "Train on 2360 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 20s 9ms/step - loss: 1.4179 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 11 - 11500/20505 samples\n",
      "Train on 2507 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.3092 - val_loss: 2.6899\n",
      "[INFO] Training model: epoch 11 - 11750/20505 samples\n",
      "Train on 2467 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.3841 - val_loss: 2.4422\n",
      "[INFO] Training model: epoch 11 - 12000/20505 samples\n",
      "Train on 2395 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 1.3591 - val_loss: 2.4199\n",
      "[INFO] Training model: epoch 11 - 12250/20505 samples\n",
      "Train on 2491 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 21s 9ms/step - loss: 1.3581 - val_loss: 2.6334\n",
      "[INFO] Training model: epoch 11 - 12500/20505 samples\n",
      "Train on 2483 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.3397 - val_loss: 2.6833\n",
      "[INFO] Training model: epoch 11 - 12750/20505 samples\n",
      "Train on 2387 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 21s 9ms/step - loss: 1.3226 - val_loss: 2.1283\n",
      "[INFO] Training model: epoch 11 - 13000/20505 samples\n",
      "Train on 2482 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 24s 9ms/step - loss: 1.3582 - val_loss: 2.4333\n",
      "[INFO] Training model: epoch 11 - 13250/20505 samples\n",
      "Train on 2419 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.3824 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 11 - 13500/20505 samples\n",
      "Train on 2545 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 23s 9ms/step - loss: 1.3950 - val_loss: 2.7967\n",
      "[INFO] Training model: epoch 11 - 13750/20505 samples\n",
      "Train on 2474 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.2810 - val_loss: 2.3460\n",
      "[INFO] Training model: epoch 11 - 14000/20505 samples\n",
      "Train on 2547 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.3375 - val_loss: 2.3385\n",
      "[INFO] Training model: epoch 11 - 14250/20505 samples\n",
      "Train on 2526 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.3521 - val_loss: 2.1959\n",
      "[INFO] Training model: epoch 11 - 14500/20505 samples\n",
      "Train on 2548 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.4120 - val_loss: 2.5015\n",
      "[INFO] Training model: epoch 11 - 14750/20505 samples\n",
      "Train on 2442 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.3917 - val_loss: 2.6781\n",
      "[INFO] Training model: epoch 11 - 15000/20505 samples\n",
      "Train on 2445 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 21s 9ms/step - loss: 1.3617 - val_loss: 2.4649\n",
      "[INFO] Training model: epoch 11 - 15250/20505 samples\n",
      "Train on 2392 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.4431 - val_loss: 2.4181\n",
      "[INFO] Training model: epoch 11 - 15500/20505 samples\n",
      "Train on 2339 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 22s 9ms/step - loss: 1.4015 - val_loss: 2.7118\n",
      "[INFO] Training model: epoch 11 - 15750/20505 samples\n",
      "Train on 2445 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.4225 - val_loss: 2.5225\n",
      "[INFO] Training model: epoch 11 - 16000/20505 samples\n",
      "Train on 2519 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 22s 9ms/step - loss: 1.3761 - val_loss: 2.6158\n",
      "[INFO] Training model: epoch 11 - 16250/20505 samples\n",
      "Train on 2664 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2664/2664 [==============================] - 25s 9ms/step - loss: 1.3578 - val_loss: 2.8205\n",
      "[INFO] Training model: epoch 11 - 16500/20505 samples\n",
      "Train on 2485 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.3746 - val_loss: 2.4532\n",
      "[INFO] Training model: epoch 11 - 16750/20505 samples\n",
      "Train on 2453 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.3805 - val_loss: 2.5250\n",
      "[INFO] Training model: epoch 11 - 17000/20505 samples\n",
      "Train on 2559 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 1.3940 - val_loss: 2.3491\n",
      "[INFO] Training model: epoch 11 - 17250/20505 samples\n",
      "Train on 2456 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.3744 - val_loss: 2.4802\n",
      "[INFO] Training model: epoch 11 - 17500/20505 samples\n",
      "Train on 2393 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.4325 - val_loss: 2.2792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 11 - 17750/20505 samples\n",
      "Train on 2530 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 22s 9ms/step - loss: 1.3477 - val_loss: 2.2779\n",
      "[INFO] Training model: epoch 11 - 18000/20505 samples\n",
      "Train on 2461 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.4718 - val_loss: 2.1462\n",
      "[INFO] Training model: epoch 11 - 18250/20505 samples\n",
      "Train on 2399 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.3591 - val_loss: 2.6600\n",
      "[INFO] Training model: epoch 11 - 18500/20505 samples\n",
      "Train on 2401 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.3993 - val_loss: 2.2315\n",
      "[INFO] Training model: epoch 11 - 18750/20505 samples\n",
      "Train on 2481 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 21s 9ms/step - loss: 1.3960 - val_loss: 2.4870\n",
      "[INFO] Training model: epoch 11 - 19000/20505 samples\n",
      "Train on 2480 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.3786 - val_loss: 2.4056\n",
      "[INFO] Training model: epoch 11 - 19250/20505 samples\n",
      "Train on 2451 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 22s 9ms/step - loss: 1.4008 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 11 - 19500/20505 samples\n",
      "Train on 2441 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 21s 9ms/step - loss: 1.4363 - val_loss: 2.4583\n",
      "[INFO] Training model: epoch 11 - 19750/20505 samples\n",
      "Train on 2364 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.3617 - val_loss: 2.4458\n",
      "[INFO] Training model: epoch 11 - 20000/20505 samples\n",
      "Train on 2467 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 22s 9ms/step - loss: 1.4323 - val_loss: 2.5759\n",
      "[INFO] Training model: epoch 11 - 20250/20505 samples\n",
      "Train on 2439 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4116 - val_loss: 2.2876\n",
      "[INFO] Training model: epoch 11 - 20500/20505 samples\n",
      "Train on 63 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.5614 - val_loss: 2.4370\n",
      "[INFO] Training model: epoch 12 - 0/20505 samples\n",
      "Train on 2546 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 24s 9ms/step - loss: 1.1884 - val_loss: 2.4317\n",
      "[INFO] Training model: epoch 12 - 250/20505 samples\n",
      "Train on 2376 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 22s 9ms/step - loss: 1.1951 - val_loss: 2.6852\n",
      "[INFO] Training model: epoch 12 - 500/20505 samples\n",
      "Train on 2474 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.1750 - val_loss: 2.4667\n",
      "[INFO] Training model: epoch 12 - 750/20505 samples\n",
      "Train on 2415 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.2445 - val_loss: 2.3990\n",
      "[INFO] Training model: epoch 12 - 1000/20505 samples\n",
      "Train on 2455 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 1.1705 - val_loss: 2.1942\n",
      "[INFO] Training model: epoch 12 - 1250/20505 samples\n",
      "Train on 2430 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.2072 - val_loss: 2.7040\n",
      "[INFO] Training model: epoch 12 - 1500/20505 samples\n",
      "Train on 2509 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 22s 9ms/step - loss: 1.2525 - val_loss: 2.6146\n",
      "[INFO] Training model: epoch 12 - 1750/20505 samples\n",
      "Train on 2413 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 9ms/step - loss: 1.2572 - val_loss: 2.5434\n",
      "[INFO] Training model: epoch 12 - 2000/20505 samples\n",
      "Train on 2518 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.1916 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 12 - 2250/20505 samples\n",
      "Train on 2388 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.1610 - val_loss: 2.6454\n",
      "[INFO] Training model: epoch 12 - 2500/20505 samples\n",
      "Train on 2457 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.2348 - val_loss: 2.3086\n",
      "[INFO] Training model: epoch 12 - 2750/20505 samples\n",
      "Train on 2378 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 22s 9ms/step - loss: 1.1515 - val_loss: 2.8354\n",
      "[INFO] Training model: epoch 12 - 3000/20505 samples\n",
      "Train on 2485 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 21s 9ms/step - loss: 1.1734 - val_loss: 2.7399\n",
      "[INFO] Training model: epoch 12 - 3250/20505 samples\n",
      "Train on 2381 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 22s 9ms/step - loss: 1.2248 - val_loss: 2.5669\n",
      "[INFO] Training model: epoch 12 - 3500/20505 samples\n",
      "Train on 2511 samples, validate on 699 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.1919 - val_loss: 2.4787\n",
      "[INFO] Training model: epoch 12 - 3750/20505 samples\n",
      "Train on 2438 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 21s 9ms/step - loss: 1.1791 - val_loss: 2.7310\n",
      "[INFO] Training model: epoch 12 - 4000/20505 samples\n",
      "Train on 2456 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.2101 - val_loss: 2.4553\n",
      "[INFO] Training model: epoch 12 - 4250/20505 samples\n",
      "Train on 2472 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.2134 - val_loss: 2.5999\n",
      "[INFO] Training model: epoch 12 - 4500/20505 samples\n",
      "Train on 2433 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.3086 - val_loss: 2.6614\n",
      "[INFO] Training model: epoch 12 - 4750/20505 samples\n",
      "Train on 2444 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.1838 - val_loss: 2.4374\n",
      "[INFO] Training model: epoch 12 - 5000/20505 samples\n",
      "Train on 2505 samples, validate on 532 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.3045 - val_loss: 2.5985\n",
      "[INFO] Training model: epoch 12 - 5250/20505 samples\n",
      "Train on 2409 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.2956 - val_loss: 2.5598\n",
      "[INFO] Training model: epoch 12 - 5500/20505 samples\n",
      "Train on 2447 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 21s 9ms/step - loss: 1.2475 - val_loss: 2.2821\n",
      "[INFO] Training model: epoch 12 - 5750/20505 samples\n",
      "Train on 2472 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 22s 9ms/step - loss: 1.2803 - val_loss: 2.6148\n",
      "[INFO] Training model: epoch 12 - 6000/20505 samples\n",
      "Train on 2575 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 25s 10ms/step - loss: 1.2526 - val_loss: 2.6842\n",
      "[INFO] Training model: epoch 12 - 6250/20505 samples\n",
      "Train on 2399 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.2647 - val_loss: 2.7982\n",
      "[INFO] Training model: epoch 12 - 6500/20505 samples\n",
      "Train on 2547 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 22s 9ms/step - loss: 1.2216 - val_loss: 2.6313\n",
      "[INFO] Training model: epoch 12 - 6750/20505 samples\n",
      "Train on 2464 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.2585 - val_loss: 2.5686\n",
      "[INFO] Training model: epoch 12 - 7000/20505 samples\n",
      "Train on 2489 samples, validate on 578 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.2773 - val_loss: 2.4639\n",
      "[INFO] Training model: epoch 12 - 7250/20505 samples\n",
      "Train on 2472 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 21s 9ms/step - loss: 1.2424 - val_loss: 2.8239\n",
      "[INFO] Training model: epoch 12 - 7500/20505 samples\n",
      "Train on 2386 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.2487 - val_loss: 2.3500\n",
      "[INFO] Training model: epoch 12 - 7750/20505 samples\n",
      "Train on 2459 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.2780 - val_loss: 2.5432\n",
      "[INFO] Training model: epoch 12 - 8000/20505 samples\n",
      "Train on 2350 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 21s 9ms/step - loss: 1.2250 - val_loss: 2.8511\n",
      "[INFO] Training model: epoch 12 - 8250/20505 samples\n",
      "Train on 2375 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 21s 9ms/step - loss: 1.2869 - val_loss: 2.7251\n",
      "[INFO] Training model: epoch 12 - 8500/20505 samples\n",
      "Train on 2387 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 22s 9ms/step - loss: 1.2107 - val_loss: 2.5376\n",
      "[INFO] Training model: epoch 12 - 8750/20505 samples\n",
      "Train on 2401 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 21s 9ms/step - loss: 1.2918 - val_loss: 2.5749\n",
      "[INFO] Training model: epoch 12 - 9000/20505 samples\n",
      "Train on 2399 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.2866 - val_loss: 2.4616\n",
      "[INFO] Training model: epoch 12 - 9250/20505 samples\n",
      "Train on 2576 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.2929 - val_loss: 2.5945\n",
      "[INFO] Training model: epoch 12 - 9500/20505 samples\n",
      "Train on 2401 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2458 - val_loss: 2.5714\n",
      "[INFO] Training model: epoch 12 - 9750/20505 samples\n",
      "Train on 2440 samples, validate on 702 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 1.2527 - val_loss: 2.7648\n",
      "[INFO] Training model: epoch 12 - 10000/20505 samples\n",
      "Train on 2410 samples, validate on 664 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2470 - val_loss: 2.8064\n",
      "[INFO] Training model: epoch 12 - 10250/20505 samples\n",
      "Train on 2487 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 21s 9ms/step - loss: 1.2552 - val_loss: 2.6279\n",
      "[INFO] Training model: epoch 12 - 10500/20505 samples\n",
      "Train on 2530 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 23s 9ms/step - loss: 1.3237 - val_loss: 2.4501\n",
      "[INFO] Training model: epoch 12 - 10750/20505 samples\n",
      "Train on 2435 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 21s 9ms/step - loss: 1.2626 - val_loss: 2.7013\n",
      "[INFO] Training model: epoch 12 - 11000/20505 samples\n",
      "Train on 2409 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 21s 9ms/step - loss: 1.3134 - val_loss: 2.6058\n",
      "[INFO] Training model: epoch 12 - 11250/20505 samples\n",
      "Train on 2372 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2372/2372 [==============================] - 22s 9ms/step - loss: 1.3281 - val_loss: 2.2159\n",
      "[INFO] Training model: epoch 12 - 11500/20505 samples\n",
      "Train on 2540 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.3469 - val_loss: 2.4681\n",
      "[INFO] Training model: epoch 12 - 11750/20505 samples\n",
      "Train on 2528 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.2769 - val_loss: 2.3153\n",
      "[INFO] Training model: epoch 12 - 12000/20505 samples\n",
      "Train on 2448 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 22s 9ms/step - loss: 1.3128 - val_loss: 2.4284\n",
      "[INFO] Training model: epoch 12 - 12250/20505 samples\n",
      "Train on 2452 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.2495 - val_loss: 2.6827\n",
      "[INFO] Training model: epoch 12 - 12500/20505 samples\n",
      "Train on 2465 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 21s 9ms/step - loss: 1.3633 - val_loss: 2.4817\n",
      "[INFO] Training model: epoch 12 - 12750/20505 samples\n",
      "Train on 2395 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 21s 9ms/step - loss: 1.3170 - val_loss: 2.6730\n",
      "[INFO] Training model: epoch 12 - 13000/20505 samples\n",
      "Train on 2453 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.3228 - val_loss: 2.3821\n",
      "[INFO] Training model: epoch 12 - 13250/20505 samples\n",
      "Train on 2669 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2669/2669 [==============================] - 25s 9ms/step - loss: 1.3146 - val_loss: 2.9244\n",
      "[INFO] Training model: epoch 12 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 22s 9ms/step - loss: 1.2955 - val_loss: 2.3359\n",
      "[INFO] Training model: epoch 12 - 13750/20505 samples\n",
      "Train on 2589 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 1.3506 - val_loss: 2.5390\n",
      "[INFO] Training model: epoch 12 - 14000/20505 samples\n",
      "Train on 2606 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2606/2606 [==============================] - 24s 9ms/step - loss: 1.2537 - val_loss: 2.3006\n",
      "[INFO] Training model: epoch 12 - 14250/20505 samples\n",
      "Train on 2435 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 21s 9ms/step - loss: 1.3256 - val_loss: 2.0831\n",
      "[INFO] Training model: epoch 12 - 14500/20505 samples\n",
      "Train on 2563 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 22s 9ms/step - loss: 1.3042 - val_loss: 2.6325\n",
      "[INFO] Training model: epoch 12 - 14750/20505 samples\n",
      "Train on 2383 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.4048 - val_loss: 2.4628\n",
      "[INFO] Training model: epoch 12 - 15000/20505 samples\n",
      "Train on 2528 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.3683 - val_loss: 2.9727\n",
      "[INFO] Training model: epoch 12 - 15250/20505 samples\n",
      "Train on 2500 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.3268 - val_loss: 2.7967\n",
      "[INFO] Training model: epoch 12 - 15500/20505 samples\n",
      "Train on 2433 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 10ms/step - loss: 1.3061 - val_loss: 2.5433\n",
      "[INFO] Training model: epoch 12 - 15750/20505 samples\n",
      "Train on 2477 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.2813 - val_loss: 2.4719\n",
      "[INFO] Training model: epoch 12 - 16000/20505 samples\n",
      "Train on 2400 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 22s 9ms/step - loss: 1.3419 - val_loss: 2.3366\n",
      "[INFO] Training model: epoch 12 - 16250/20505 samples\n",
      "Train on 2277 samples, validate on 703 samples\n",
      "Epoch 1/1\n",
      "2277/2277 [==============================] - 21s 9ms/step - loss: 1.3264 - val_loss: 2.5151\n",
      "[INFO] Training model: epoch 12 - 16500/20505 samples\n",
      "Train on 2523 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 23s 9ms/step - loss: 1.3371 - val_loss: 2.5685\n",
      "[INFO] Training model: epoch 12 - 16750/20505 samples\n",
      "Train on 2392 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 21s 9ms/step - loss: 1.3229 - val_loss: 2.6889\n",
      "[INFO] Training model: epoch 12 - 17000/20505 samples\n",
      "Train on 2502 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 23s 9ms/step - loss: 1.3510 - val_loss: 2.5016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 12 - 17250/20505 samples\n",
      "Train on 2394 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 21s 9ms/step - loss: 1.3551 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 12 - 17500/20505 samples\n",
      "Train on 2444 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.3190 - val_loss: 2.3521\n",
      "[INFO] Training model: epoch 12 - 17750/20505 samples\n",
      "Train on 2476 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.3401 - val_loss: 2.5740\n",
      "[INFO] Training model: epoch 12 - 18000/20505 samples\n",
      "Train on 2444 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 21s 9ms/step - loss: 1.3549 - val_loss: 2.6335\n",
      "[INFO] Training model: epoch 12 - 18250/20505 samples\n",
      "Train on 2491 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2908 - val_loss: 2.4421\n",
      "[INFO] Training model: epoch 12 - 18500/20505 samples\n",
      "Train on 2326 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2326/2326 [==============================] - 21s 9ms/step - loss: 1.3129 - val_loss: 2.6949\n",
      "[INFO] Training model: epoch 12 - 18750/20505 samples\n",
      "Train on 2497 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.3302 - val_loss: 2.4779\n",
      "[INFO] Training model: epoch 12 - 19000/20505 samples\n",
      "Train on 2566 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2566/2566 [==============================] - 22s 9ms/step - loss: 1.3780 - val_loss: 2.5958\n",
      "[INFO] Training model: epoch 12 - 19250/20505 samples\n",
      "Train on 2425 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.2921 - val_loss: 2.5769\n",
      "[INFO] Training model: epoch 12 - 19500/20505 samples\n",
      "Train on 2415 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 23s 9ms/step - loss: 1.3342 - val_loss: 2.5212\n",
      "[INFO] Training model: epoch 12 - 19750/20505 samples\n",
      "Train on 2508 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 23s 9ms/step - loss: 1.3358 - val_loss: 2.5891\n",
      "[INFO] Training model: epoch 12 - 20000/20505 samples\n",
      "Train on 2380 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.2774 - val_loss: 2.5000\n",
      "[INFO] Training model: epoch 12 - 20250/20505 samples\n",
      "Train on 2450 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 21s 9ms/step - loss: 1.4014 - val_loss: 2.5701\n",
      "[INFO] Training model: epoch 12 - 20500/20505 samples\n",
      "Train on 52 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 2.1503 - val_loss: 1.2227\n",
      "[INFO] Training model: epoch 13 - 0/20505 samples\n",
      "Train on 2394 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1681 - val_loss: 2.2861\n",
      "[INFO] Training model: epoch 13 - 250/20505 samples\n",
      "Train on 2433 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.1308 - val_loss: 2.3463\n",
      "[INFO] Training model: epoch 13 - 500/20505 samples\n",
      "Train on 2389 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.1554 - val_loss: 2.1439\n",
      "[INFO] Training model: epoch 13 - 750/20505 samples\n",
      "Train on 2405 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.1226 - val_loss: 2.4390\n",
      "[INFO] Training model: epoch 13 - 1000/20505 samples\n",
      "Train on 2385 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1484 - val_loss: 2.1855\n",
      "[INFO] Training model: epoch 13 - 1250/20505 samples\n",
      "Train on 2451 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 21s 9ms/step - loss: 1.2039 - val_loss: 2.8291\n",
      "[INFO] Training model: epoch 13 - 1500/20505 samples\n",
      "Train on 2374 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 23s 10ms/step - loss: 1.1345 - val_loss: 2.7188\n",
      "[INFO] Training model: epoch 13 - 1750/20505 samples\n",
      "Train on 2375 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 1.1465 - val_loss: 2.4266\n",
      "[INFO] Training model: epoch 13 - 2000/20505 samples\n",
      "Train on 2487 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 22s 9ms/step - loss: 1.1350 - val_loss: 2.5639\n",
      "[INFO] Training model: epoch 13 - 2250/20505 samples\n",
      "Train on 2389 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.1659 - val_loss: 2.7454\n",
      "[INFO] Training model: epoch 13 - 2500/20505 samples\n",
      "Train on 2569 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 24s 9ms/step - loss: 1.1579 - val_loss: 2.6287\n",
      "[INFO] Training model: epoch 13 - 2750/20505 samples\n",
      "Train on 2416 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.1136 - val_loss: 2.7806\n",
      "[INFO] Training model: epoch 13 - 3000/20505 samples\n",
      "Train on 2476 samples, validate on 525 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.1667 - val_loss: 2.7894\n",
      "[INFO] Training model: epoch 13 - 3250/20505 samples\n",
      "Train on 2495 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 1.1847 - val_loss: 2.3461\n",
      "[INFO] Training model: epoch 13 - 3500/20505 samples\n",
      "Train on 2532 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.1381 - val_loss: 2.6230\n",
      "[INFO] Training model: epoch 13 - 3750/20505 samples\n",
      "Train on 2486 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 22s 9ms/step - loss: 1.1969 - val_loss: 2.5509\n",
      "[INFO] Training model: epoch 13 - 4000/20505 samples\n",
      "Train on 2547 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.1586 - val_loss: 2.5952\n",
      "[INFO] Training model: epoch 13 - 4250/20505 samples\n",
      "Train on 2482 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.2058 - val_loss: 2.6656\n",
      "[INFO] Training model: epoch 13 - 4500/20505 samples\n",
      "Train on 2503 samples, validate on 673 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 22s 9ms/step - loss: 1.1188 - val_loss: 2.7083\n",
      "[INFO] Training model: epoch 13 - 4750/20505 samples\n",
      "Train on 2374 samples, validate on 725 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.2142 - val_loss: 2.7237\n",
      "[INFO] Training model: epoch 13 - 5000/20505 samples\n",
      "Train on 2348 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 20s 9ms/step - loss: 1.2338 - val_loss: 2.6558\n",
      "[INFO] Training model: epoch 13 - 5250/20505 samples\n",
      "Train on 2360 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 22s 9ms/step - loss: 1.2276 - val_loss: 2.2035\n",
      "[INFO] Training model: epoch 13 - 5500/20505 samples\n",
      "Train on 2382 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.1619 - val_loss: 2.6144\n",
      "[INFO] Training model: epoch 13 - 5750/20505 samples\n",
      "Train on 2463 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.1542 - val_loss: 2.4655\n",
      "[INFO] Training model: epoch 13 - 6000/20505 samples\n",
      "Train on 2456 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 22s 9ms/step - loss: 1.2435 - val_loss: 2.7665\n",
      "[INFO] Training model: epoch 13 - 6250/20505 samples\n",
      "Train on 2516 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.2016 - val_loss: 2.5575\n",
      "[INFO] Training model: epoch 13 - 6500/20505 samples\n",
      "Train on 2481 samples, validate on 604 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.2674 - val_loss: 2.6208\n",
      "[INFO] Training model: epoch 13 - 6750/20505 samples\n",
      "Train on 2575 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 23s 9ms/step - loss: 1.1781 - val_loss: 2.4991\n",
      "[INFO] Training model: epoch 13 - 7000/20505 samples\n",
      "Train on 2571 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2571/2571 [==============================] - 24s 9ms/step - loss: 1.2175 - val_loss: 2.7427\n",
      "[INFO] Training model: epoch 13 - 7250/20505 samples\n",
      "Train on 2423 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.0938 - val_loss: 2.4453\n",
      "[INFO] Training model: epoch 13 - 7500/20505 samples\n",
      "Train on 2475 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.1944 - val_loss: 2.4015\n",
      "[INFO] Training model: epoch 13 - 7750/20505 samples\n",
      "Train on 2513 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 22s 9ms/step - loss: 1.2082 - val_loss: 2.6704\n",
      "[INFO] Training model: epoch 13 - 8000/20505 samples\n",
      "Train on 2383 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.1868 - val_loss: 2.8137\n",
      "[INFO] Training model: epoch 13 - 8250/20505 samples\n",
      "Train on 2357 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.2685 - val_loss: 2.6211\n",
      "[INFO] Training model: epoch 13 - 8500/20505 samples\n",
      "Train on 2406 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 10ms/step - loss: 1.2111 - val_loss: 2.5712\n",
      "[INFO] Training model: epoch 13 - 8750/20505 samples\n",
      "Train on 2345 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2345/2345 [==============================] - 22s 9ms/step - loss: 1.1781 - val_loss: 2.6281\n",
      "[INFO] Training model: epoch 13 - 9000/20505 samples\n",
      "Train on 2438 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.2099 - val_loss: 2.3352\n",
      "[INFO] Training model: epoch 13 - 9250/20505 samples\n",
      "Train on 2479 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.1469 - val_loss: 2.7611\n",
      "[INFO] Training model: epoch 13 - 9500/20505 samples\n",
      "Train on 2433 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.2217 - val_loss: 2.6948\n",
      "[INFO] Training model: epoch 13 - 9750/20505 samples\n",
      "Train on 2419 samples, validate on 664 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 21s 9ms/step - loss: 1.1979 - val_loss: 2.7193\n",
      "[INFO] Training model: epoch 13 - 10000/20505 samples\n",
      "Train on 2492 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 1.2902 - val_loss: 2.4032\n",
      "[INFO] Training model: epoch 13 - 10250/20505 samples\n",
      "Train on 2475 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 22s 9ms/step - loss: 1.2068 - val_loss: 2.7705\n",
      "[INFO] Training model: epoch 13 - 10500/20505 samples\n",
      "Train on 2494 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.2008 - val_loss: 2.6127\n",
      "[INFO] Training model: epoch 13 - 10750/20505 samples\n",
      "Train on 2482 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 21s 9ms/step - loss: 1.2692 - val_loss: 2.2856\n",
      "[INFO] Training model: epoch 13 - 11000/20505 samples\n",
      "Train on 2416 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.2081 - val_loss: 2.4837\n",
      "[INFO] Training model: epoch 13 - 11250/20505 samples\n",
      "Train on 2445 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.2761 - val_loss: 2.3846\n",
      "[INFO] Training model: epoch 13 - 11500/20505 samples\n",
      "Train on 2525 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.2181 - val_loss: 2.5468\n",
      "[INFO] Training model: epoch 13 - 11750/20505 samples\n",
      "Train on 2463 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.2889 - val_loss: 2.5805\n",
      "[INFO] Training model: epoch 13 - 12000/20505 samples\n",
      "Train on 2452 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.3121 - val_loss: 2.8777\n",
      "[INFO] Training model: epoch 13 - 12250/20505 samples\n",
      "Train on 2570 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 24s 9ms/step - loss: 1.2860 - val_loss: 2.4413\n",
      "[INFO] Training model: epoch 13 - 12500/20505 samples\n",
      "Train on 2378 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 25s 10ms/step - loss: 1.2392 - val_loss: 2.4371\n",
      "[INFO] Training model: epoch 13 - 12750/20505 samples\n",
      "Train on 2428 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 24s 10ms/step - loss: 1.2632 - val_loss: 2.3211\n",
      "[INFO] Training model: epoch 13 - 13000/20505 samples\n",
      "Train on 2482 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 30s 12ms/step - loss: 1.2634 - val_loss: 2.6472\n",
      "[INFO] Training model: epoch 13 - 13250/20505 samples\n",
      "Train on 2474 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 28s 11ms/step - loss: 1.2644 - val_loss: 2.6802\n",
      "[INFO] Training model: epoch 13 - 13500/20505 samples\n",
      "Train on 2481 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.2862 - val_loss: 2.4489\n",
      "[INFO] Training model: epoch 13 - 13750/20505 samples\n",
      "Train on 2457 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 10ms/step - loss: 1.2377 - val_loss: 2.5902\n",
      "[INFO] Training model: epoch 13 - 14000/20505 samples\n",
      "Train on 2431 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.2907 - val_loss: 2.6848\n",
      "[INFO] Training model: epoch 13 - 14250/20505 samples\n",
      "Train on 2607 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 24s 9ms/step - loss: 1.2425 - val_loss: 2.7250\n",
      "[INFO] Training model: epoch 13 - 14500/20505 samples\n",
      "Train on 2463 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 1.2485 - val_loss: 2.3472\n",
      "[INFO] Training model: epoch 13 - 14750/20505 samples\n",
      "Train on 2541 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 1.2776 - val_loss: 2.5587\n",
      "[INFO] Training model: epoch 13 - 15000/20505 samples\n",
      "Train on 2537 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 9ms/step - loss: 1.2785 - val_loss: 2.6488\n",
      "[INFO] Training model: epoch 13 - 15250/20505 samples\n",
      "Train on 2404 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 23s 9ms/step - loss: 1.3118 - val_loss: 2.6508\n",
      "[INFO] Training model: epoch 13 - 15500/20505 samples\n",
      "Train on 2460 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.2495 - val_loss: 2.4094\n",
      "[INFO] Training model: epoch 13 - 15750/20505 samples\n",
      "Train on 2476 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.2591 - val_loss: 2.5843\n",
      "[INFO] Training model: epoch 13 - 16000/20505 samples\n",
      "Train on 2388 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 10ms/step - loss: 1.2660 - val_loss: 2.8181\n",
      "[INFO] Training model: epoch 13 - 16250/20505 samples\n",
      "Train on 2373 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.2892 - val_loss: 2.8678\n",
      "[INFO] Training model: epoch 13 - 16500/20505 samples\n",
      "Train on 2410 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2527 - val_loss: 2.5705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 13 - 16750/20505 samples\n",
      "Train on 2462 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.3198 - val_loss: 2.3820\n",
      "[INFO] Training model: epoch 13 - 17000/20505 samples\n",
      "Train on 2414 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 23s 9ms/step - loss: 1.2549 - val_loss: 2.6669\n",
      "[INFO] Training model: epoch 13 - 17250/20505 samples\n",
      "Train on 2402 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 24s 10ms/step - loss: 1.2253 - val_loss: 2.6443\n",
      "[INFO] Training model: epoch 13 - 17500/20505 samples\n",
      "Train on 2445 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.3274 - val_loss: 2.5191\n",
      "[INFO] Training model: epoch 13 - 17750/20505 samples\n",
      "Train on 2432 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.2943 - val_loss: 2.5945\n",
      "[INFO] Training model: epoch 13 - 18000/20505 samples\n",
      "Train on 2462 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 21s 9ms/step - loss: 1.3899 - val_loss: 2.3965\n",
      "[INFO] Training model: epoch 13 - 18250/20505 samples\n",
      "Train on 2474 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.3381 - val_loss: 2.5519\n",
      "[INFO] Training model: epoch 13 - 18500/20505 samples\n",
      "Train on 2551 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 23s 9ms/step - loss: 1.2981 - val_loss: 2.7234\n",
      "[INFO] Training model: epoch 13 - 18750/20505 samples\n",
      "Train on 2498 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.2994 - val_loss: 2.4684\n",
      "[INFO] Training model: epoch 13 - 19000/20505 samples\n",
      "Train on 2519 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.3448 - val_loss: 2.5957\n",
      "[INFO] Training model: epoch 13 - 19250/20505 samples\n",
      "Train on 2480 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 24s 9ms/step - loss: 1.2890 - val_loss: 2.5116\n",
      "[INFO] Training model: epoch 13 - 19500/20505 samples\n",
      "Train on 2548 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.2763 - val_loss: 2.5991\n",
      "[INFO] Training model: epoch 13 - 19750/20505 samples\n",
      "Train on 2468 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 24s 10ms/step - loss: 1.2964 - val_loss: 2.5093\n",
      "[INFO] Training model: epoch 13 - 20000/20505 samples\n",
      "Train on 2380 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 21s 9ms/step - loss: 1.3566 - val_loss: 2.2832\n",
      "[INFO] Training model: epoch 13 - 20250/20505 samples\n",
      "Train on 2491 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2711 - val_loss: 2.5337\n",
      "[INFO] Training model: epoch 13 - 20500/20505 samples\n",
      "Train on 41 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.4036 - val_loss: 2.7953\n",
      "[INFO] Training model: epoch 14 - 0/20505 samples\n",
      "Train on 2443 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.0526 - val_loss: 2.9585\n",
      "[INFO] Training model: epoch 14 - 250/20505 samples\n",
      "Train on 2439 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.0797 - val_loss: 2.9356\n",
      "[INFO] Training model: epoch 14 - 500/20505 samples\n",
      "Train on 2487 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.1280 - val_loss: 2.9764\n",
      "[INFO] Training model: epoch 14 - 750/20505 samples\n",
      "Train on 2464 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.1282 - val_loss: 2.5604\n",
      "[INFO] Training model: epoch 14 - 1000/20505 samples\n",
      "Train on 2524 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0790 - val_loss: 2.3977\n",
      "[INFO] Training model: epoch 14 - 1250/20505 samples\n",
      "Train on 2354 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 22s 9ms/step - loss: 1.0573 - val_loss: 2.9022\n",
      "[INFO] Training model: epoch 14 - 1500/20505 samples\n",
      "Train on 2432 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.0340 - val_loss: 2.6100\n",
      "[INFO] Training model: epoch 14 - 1750/20505 samples\n",
      "Train on 2458 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.0817 - val_loss: 2.7535\n",
      "[INFO] Training model: epoch 14 - 2000/20505 samples\n",
      "Train on 2447 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.1494 - val_loss: 2.8183\n",
      "[INFO] Training model: epoch 14 - 2250/20505 samples\n",
      "Train on 2446 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.1104 - val_loss: 2.2876\n",
      "[INFO] Training model: epoch 14 - 2500/20505 samples\n",
      "Train on 2467 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.1198 - val_loss: 2.5077\n",
      "[INFO] Training model: epoch 14 - 2750/20505 samples\n",
      "Train on 2475 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.1595 - val_loss: 2.2208\n",
      "[INFO] Training model: epoch 14 - 3000/20505 samples\n",
      "Train on 2364 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 20s 9ms/step - loss: 1.1147 - val_loss: 2.5708\n",
      "[INFO] Training model: epoch 14 - 3250/20505 samples\n",
      "Train on 2526 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 1.1760 - val_loss: 2.7828\n",
      "[INFO] Training model: epoch 14 - 3500/20505 samples\n",
      "Train on 2371 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.1518 - val_loss: 2.5813\n",
      "[INFO] Training model: epoch 14 - 3750/20505 samples\n",
      "Train on 2500 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.0834 - val_loss: 2.7539\n",
      "[INFO] Training model: epoch 14 - 4000/20505 samples\n",
      "Train on 2515 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 24s 9ms/step - loss: 1.1497 - val_loss: 2.8131\n",
      "[INFO] Training model: epoch 14 - 4250/20505 samples\n",
      "Train on 2435 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.1599 - val_loss: 2.7319\n",
      "[INFO] Training model: epoch 14 - 4500/20505 samples\n",
      "Train on 2432 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.1219 - val_loss: 2.3819\n",
      "[INFO] Training model: epoch 14 - 4750/20505 samples\n",
      "Train on 2403 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 21s 9ms/step - loss: 1.1484 - val_loss: 2.8080\n",
      "[INFO] Training model: epoch 14 - 5000/20505 samples\n",
      "Train on 2420 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 23s 9ms/step - loss: 1.1608 - val_loss: 2.6976\n",
      "[INFO] Training model: epoch 14 - 5250/20505 samples\n",
      "Train on 2435 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.1181 - val_loss: 2.5411\n",
      "[INFO] Training model: epoch 14 - 5500/20505 samples\n",
      "Train on 2435 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 22s 9ms/step - loss: 1.2306 - val_loss: 2.9144\n",
      "[INFO] Training model: epoch 14 - 5750/20505 samples\n",
      "Train on 2462 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.1817 - val_loss: 2.4831\n",
      "[INFO] Training model: epoch 14 - 6000/20505 samples\n",
      "Train on 2541 samples, validate on 611 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.0866 - val_loss: 2.6962\n",
      "[INFO] Training model: epoch 14 - 6250/20505 samples\n",
      "Train on 2369 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2369/2369 [==============================] - 22s 9ms/step - loss: 1.1899 - val_loss: 2.6757\n",
      "[INFO] Training model: epoch 14 - 6500/20505 samples\n",
      "Train on 2423 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.1987 - val_loss: 2.8957\n",
      "[INFO] Training model: epoch 14 - 6750/20505 samples\n",
      "Train on 2459 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.1641 - val_loss: 2.5555\n",
      "[INFO] Training model: epoch 14 - 7000/20505 samples\n",
      "Train on 2442 samples, validate on 507 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 22s 9ms/step - loss: 1.1629 - val_loss: 2.6858\n",
      "[INFO] Training model: epoch 14 - 7250/20505 samples\n",
      "Train on 2361 samples, validate on 540 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 23s 10ms/step - loss: 1.1715 - val_loss: 2.7752\n",
      "[INFO] Training model: epoch 14 - 7500/20505 samples\n",
      "Train on 2357 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 22s 9ms/step - loss: 1.1519 - val_loss: 2.6262\n",
      "[INFO] Training model: epoch 14 - 7750/20505 samples\n",
      "Train on 2402 samples, validate on 727 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1504 - val_loss: 2.7175\n",
      "[INFO] Training model: epoch 14 - 8000/20505 samples\n",
      "Train on 2466 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 21s 9ms/step - loss: 1.1636 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 14 - 8250/20505 samples\n",
      "Train on 2430 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.1933 - val_loss: 2.4823\n",
      "[INFO] Training model: epoch 14 - 8500/20505 samples\n",
      "Train on 2452 samples, validate on 692 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1515 - val_loss: 2.3191\n",
      "[INFO] Training model: epoch 14 - 8750/20505 samples\n",
      "Train on 2615 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 24s 9ms/step - loss: 1.2396 - val_loss: 2.5740\n",
      "[INFO] Training model: epoch 14 - 9000/20505 samples\n",
      "Train on 2465 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.1939 - val_loss: 2.4041\n",
      "[INFO] Training model: epoch 14 - 9250/20505 samples\n",
      "Train on 2438 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 22s 9ms/step - loss: 1.1828 - val_loss: 2.9110\n",
      "[INFO] Training model: epoch 14 - 9500/20505 samples\n",
      "Train on 2466 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.1729 - val_loss: 2.5145\n",
      "[INFO] Training model: epoch 14 - 9750/20505 samples\n",
      "Train on 2446 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.1608 - val_loss: 2.2801\n",
      "[INFO] Training model: epoch 14 - 10000/20505 samples\n",
      "Train on 2428 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 1.1831 - val_loss: 2.5697\n",
      "[INFO] Training model: epoch 14 - 10250/20505 samples\n",
      "Train on 2513 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 1.2424 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 14 - 10500/20505 samples\n",
      "Train on 2469 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.1988 - val_loss: 2.6358\n",
      "[INFO] Training model: epoch 14 - 10750/20505 samples\n",
      "Train on 2441 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.2172 - val_loss: 3.0045\n",
      "[INFO] Training model: epoch 14 - 11000/20505 samples\n",
      "Train on 2503 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 1.1385 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 14 - 11250/20505 samples\n",
      "Train on 2521 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 24s 9ms/step - loss: 1.2008 - val_loss: 2.4104\n",
      "[INFO] Training model: epoch 14 - 11500/20505 samples\n",
      "Train on 2558 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 23s 9ms/step - loss: 1.1940 - val_loss: 2.9328\n",
      "[INFO] Training model: epoch 14 - 11750/20505 samples\n",
      "Train on 2514 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 22s 9ms/step - loss: 1.2445 - val_loss: 2.5280\n",
      "[INFO] Training model: epoch 14 - 12000/20505 samples\n",
      "Train on 2418 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.1794 - val_loss: 2.3512\n",
      "[INFO] Training model: epoch 14 - 12250/20505 samples\n",
      "Train on 2547 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.1824 - val_loss: 2.5754\n",
      "[INFO] Training model: epoch 14 - 12500/20505 samples\n",
      "Train on 2444 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.1919 - val_loss: 2.6997\n",
      "[INFO] Training model: epoch 14 - 12750/20505 samples\n",
      "Train on 2495 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 1.2771 - val_loss: 2.4880\n",
      "[INFO] Training model: epoch 14 - 13000/20505 samples\n",
      "Train on 2416 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.2313 - val_loss: 2.4450\n",
      "[INFO] Training model: epoch 14 - 13250/20505 samples\n",
      "Train on 2518 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.2359 - val_loss: 2.3428\n",
      "[INFO] Training model: epoch 14 - 13500/20505 samples\n",
      "Train on 2459 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.2364 - val_loss: 2.5417\n",
      "[INFO] Training model: epoch 14 - 13750/20505 samples\n",
      "Train on 2413 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.3127 - val_loss: 2.6574\n",
      "[INFO] Training model: epoch 14 - 14000/20505 samples\n",
      "Train on 2481 samples, validate on 710 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 1.1633 - val_loss: 2.6111\n",
      "[INFO] Training model: epoch 14 - 14250/20505 samples\n",
      "Train on 2467 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.2198 - val_loss: 2.3812\n",
      "[INFO] Training model: epoch 14 - 14500/20505 samples\n",
      "Train on 2405 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.2593 - val_loss: 2.5718\n",
      "[INFO] Training model: epoch 14 - 14750/20505 samples\n",
      "Train on 2411 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.2435 - val_loss: 2.4176\n",
      "[INFO] Training model: epoch 14 - 15000/20505 samples\n",
      "Train on 2432 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.2552 - val_loss: 2.5886\n",
      "[INFO] Training model: epoch 14 - 15250/20505 samples\n",
      "Train on 2459 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 1.2295 - val_loss: 2.4746\n",
      "[INFO] Training model: epoch 14 - 15500/20505 samples\n",
      "Train on 2424 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.1866 - val_loss: 2.8634\n",
      "[INFO] Training model: epoch 14 - 15750/20505 samples\n",
      "Train on 2493 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.2274 - val_loss: 2.9647\n",
      "[INFO] Training model: epoch 14 - 16000/20505 samples\n",
      "Train on 2401 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2048 - val_loss: 2.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 14 - 16250/20505 samples\n",
      "Train on 2473 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2532 - val_loss: 2.3116\n",
      "[INFO] Training model: epoch 14 - 16500/20505 samples\n",
      "Train on 2499 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1839 - val_loss: 2.7059\n",
      "[INFO] Training model: epoch 14 - 16750/20505 samples\n",
      "Train on 2484 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.2256 - val_loss: 2.5901\n",
      "[INFO] Training model: epoch 14 - 17000/20505 samples\n",
      "Train on 2441 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.2346 - val_loss: 2.6685\n",
      "[INFO] Training model: epoch 14 - 17250/20505 samples\n",
      "Train on 2401 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2021 - val_loss: 2.7811\n",
      "[INFO] Training model: epoch 14 - 17500/20505 samples\n",
      "Train on 2547 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 23s 9ms/step - loss: 1.2543 - val_loss: 2.5712\n",
      "[INFO] Training model: epoch 14 - 17750/20505 samples\n",
      "Train on 2557 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 23s 9ms/step - loss: 1.2095 - val_loss: 2.7230\n",
      "[INFO] Training model: epoch 14 - 18000/20505 samples\n",
      "Train on 2507 samples, validate on 676 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 24s 9ms/step - loss: 1.1946 - val_loss: 2.4608\n",
      "[INFO] Training model: epoch 14 - 18250/20505 samples\n",
      "Train on 2468 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.2261 - val_loss: 2.4564\n",
      "[INFO] Training model: epoch 14 - 18500/20505 samples\n",
      "Train on 2405 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.2453 - val_loss: 2.6626\n",
      "[INFO] Training model: epoch 14 - 18750/20505 samples\n",
      "Train on 2539 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 9ms/step - loss: 1.2307 - val_loss: 2.6883\n",
      "[INFO] Training model: epoch 14 - 19000/20505 samples\n",
      "Train on 2473 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2462 - val_loss: 2.6410\n",
      "[INFO] Training model: epoch 14 - 19250/20505 samples\n",
      "Train on 2309 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2309/2309 [==============================] - 21s 9ms/step - loss: 1.2278 - val_loss: 2.6431\n",
      "[INFO] Training model: epoch 14 - 19500/20505 samples\n",
      "Train on 2489 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 21s 9ms/step - loss: 1.2471 - val_loss: 2.4865\n",
      "[INFO] Training model: epoch 14 - 19750/20505 samples\n",
      "Train on 2491 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2789 - val_loss: 2.6601\n",
      "[INFO] Training model: epoch 14 - 20000/20505 samples\n",
      "Train on 2392 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 23s 9ms/step - loss: 1.2030 - val_loss: 2.5679\n",
      "[INFO] Training model: epoch 14 - 20250/20505 samples\n",
      "Train on 2407 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 10ms/step - loss: 1.3407 - val_loss: 2.8099\n",
      "[INFO] Training model: epoch 14 - 20500/20505 samples\n",
      "Train on 78 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 1.2407 - val_loss: 3.1446\n",
      "[INFO] Training model: epoch 15 - 0/20505 samples\n",
      "Train on 2331 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 22s 9ms/step - loss: 1.1331 - val_loss: 2.9295\n",
      "[INFO] Training model: epoch 15 - 250/20505 samples\n",
      "Train on 2518 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 24s 9ms/step - loss: 1.0381 - val_loss: 2.6519\n",
      "[INFO] Training model: epoch 15 - 500/20505 samples\n",
      "Train on 2354 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 22s 9ms/step - loss: 1.0688 - val_loss: 3.0876\n",
      "[INFO] Training model: epoch 15 - 750/20505 samples\n",
      "Train on 2499 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1073 - val_loss: 2.5800\n",
      "[INFO] Training model: epoch 15 - 1000/20505 samples\n",
      "Train on 2429 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.0695 - val_loss: 2.8064\n",
      "[INFO] Training model: epoch 15 - 1250/20505 samples\n",
      "Train on 2470 samples, validate on 681 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 24s 10ms/step - loss: 1.0238 - val_loss: 2.6690\n",
      "[INFO] Training model: epoch 15 - 1500/20505 samples\n",
      "Train on 2441 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.0588 - val_loss: 2.7763\n",
      "[INFO] Training model: epoch 15 - 1750/20505 samples\n",
      "Train on 2399 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 23s 10ms/step - loss: 1.0339 - val_loss: 2.5999\n",
      "[INFO] Training model: epoch 15 - 2000/20505 samples\n",
      "Train on 2315 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 22s 9ms/step - loss: 1.0842 - val_loss: 2.6414\n",
      "[INFO] Training model: epoch 15 - 2250/20505 samples\n",
      "Train on 2450 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.1063 - val_loss: 2.8094\n",
      "[INFO] Training model: epoch 15 - 2500/20505 samples\n",
      "Train on 2453 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 1.0391 - val_loss: 2.5060\n",
      "[INFO] Training model: epoch 15 - 2750/20505 samples\n",
      "Train on 2520 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 23s 9ms/step - loss: 1.0579 - val_loss: 2.4260\n",
      "[INFO] Training model: epoch 15 - 3000/20505 samples\n",
      "Train on 2529 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.1151 - val_loss: 2.5902\n",
      "[INFO] Training model: epoch 15 - 3250/20505 samples\n",
      "Train on 2458 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.0946 - val_loss: 2.9541\n",
      "[INFO] Training model: epoch 15 - 3500/20505 samples\n",
      "Train on 2388 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 9ms/step - loss: 1.0853 - val_loss: 2.8799\n",
      "[INFO] Training model: epoch 15 - 3750/20505 samples\n",
      "Train on 2412 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.0967 - val_loss: 2.3592\n",
      "[INFO] Training model: epoch 15 - 4000/20505 samples\n",
      "Train on 2415 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.1337 - val_loss: 2.5667\n",
      "[INFO] Training model: epoch 15 - 4250/20505 samples\n",
      "Train on 2379 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 22s 9ms/step - loss: 1.0970 - val_loss: 2.4808\n",
      "[INFO] Training model: epoch 15 - 4500/20505 samples\n",
      "Train on 2457 samples, validate on 561 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 22s 9ms/step - loss: 1.0490 - val_loss: 2.7659\n",
      "[INFO] Training model: epoch 15 - 4750/20505 samples\n",
      "Train on 2408 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.0856 - val_loss: 2.5832\n",
      "[INFO] Training model: epoch 15 - 5000/20505 samples\n",
      "Train on 2470 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.0941 - val_loss: 2.7505\n",
      "[INFO] Training model: epoch 15 - 5250/20505 samples\n",
      "Train on 2534 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 23s 9ms/step - loss: 1.1479 - val_loss: 2.7339\n",
      "[INFO] Training model: epoch 15 - 5500/20505 samples\n",
      "Train on 2392 samples, validate on 639 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392/2392 [==============================] - 21s 9ms/step - loss: 1.1235 - val_loss: 2.4902\n",
      "[INFO] Training model: epoch 15 - 5750/20505 samples\n",
      "Train on 2576 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.0981 - val_loss: 2.7348\n",
      "[INFO] Training model: epoch 15 - 6000/20505 samples\n",
      "Train on 2441 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.1493 - val_loss: 2.9630\n",
      "[INFO] Training model: epoch 15 - 6250/20505 samples\n",
      "Train on 2442 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.0885 - val_loss: 3.0562\n",
      "[INFO] Training model: epoch 15 - 6500/20505 samples\n",
      "Train on 2340 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 22s 10ms/step - loss: 1.1056 - val_loss: 2.3974\n",
      "[INFO] Training model: epoch 15 - 6750/20505 samples\n",
      "Train on 2449 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.0739 - val_loss: 2.5867\n",
      "[INFO] Training model: epoch 15 - 7000/20505 samples\n",
      "Train on 2472 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.1090 - val_loss: 2.5161\n",
      "[INFO] Training model: epoch 15 - 7250/20505 samples\n",
      "Train on 2402 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1223 - val_loss: 2.4847\n",
      "[INFO] Training model: epoch 15 - 7500/20505 samples\n",
      "Train on 2451 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 24s 10ms/step - loss: 1.1270 - val_loss: 2.4395\n",
      "[INFO] Training model: epoch 15 - 7750/20505 samples\n",
      "Train on 2434 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 25s 10ms/step - loss: 1.0877 - val_loss: 2.8560\n",
      "[INFO] Training model: epoch 15 - 8000/20505 samples\n",
      "Train on 2471 samples, validate on 676 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.0647 - val_loss: 2.5131\n",
      "[INFO] Training model: epoch 15 - 8250/20505 samples\n",
      "Train on 2541 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 10ms/step - loss: 1.1874 - val_loss: 2.7540\n",
      "[INFO] Training model: epoch 15 - 8500/20505 samples\n",
      "Train on 2381 samples, validate on 551 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 23s 10ms/step - loss: 1.1156 - val_loss: 2.6978\n",
      "[INFO] Training model: epoch 15 - 8750/20505 samples\n",
      "Train on 2475 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.1583 - val_loss: 2.6210\n",
      "[INFO] Training model: epoch 15 - 9000/20505 samples\n",
      "Train on 2347 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 10ms/step - loss: 1.1305 - val_loss: 2.4200\n",
      "[INFO] Training model: epoch 15 - 9250/20505 samples\n",
      "Train on 2501 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 24s 10ms/step - loss: 1.1533 - val_loss: 2.7463\n",
      "[INFO] Training model: epoch 15 - 9500/20505 samples\n",
      "Train on 2485 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 24s 10ms/step - loss: 1.1980 - val_loss: 2.6791\n",
      "[INFO] Training model: epoch 15 - 9750/20505 samples\n",
      "Train on 2389 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 9ms/step - loss: 1.1991 - val_loss: 2.7248\n",
      "[INFO] Training model: epoch 15 - 10000/20505 samples\n",
      "Train on 2374 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.1210 - val_loss: 2.6510\n",
      "[INFO] Training model: epoch 15 - 10250/20505 samples\n",
      "Train on 2558 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.2004 - val_loss: 2.6337\n",
      "[INFO] Training model: epoch 15 - 10500/20505 samples\n",
      "Train on 2413 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 1.0770 - val_loss: 2.6536\n",
      "[INFO] Training model: epoch 15 - 10750/20505 samples\n",
      "Train on 2475 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.1151 - val_loss: 2.7780\n",
      "[INFO] Training model: epoch 15 - 11000/20505 samples\n",
      "Train on 2509 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 24s 9ms/step - loss: 1.1291 - val_loss: 2.7472\n",
      "[INFO] Training model: epoch 15 - 11250/20505 samples\n",
      "Train on 2432 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.1479 - val_loss: 2.5829\n",
      "[INFO] Training model: epoch 15 - 11500/20505 samples\n",
      "Train on 2397 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 10ms/step - loss: 1.1320 - val_loss: 2.9159\n",
      "[INFO] Training model: epoch 15 - 11750/20505 samples\n",
      "Train on 2360 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 23s 10ms/step - loss: 1.1171 - val_loss: 2.5413\n",
      "[INFO] Training model: epoch 15 - 12000/20505 samples\n",
      "Train on 2526 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.1114 - val_loss: 2.4176\n",
      "[INFO] Training model: epoch 15 - 12250/20505 samples\n",
      "Train on 2404 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 24s 10ms/step - loss: 1.1859 - val_loss: 2.7987\n",
      "[INFO] Training model: epoch 15 - 12500/20505 samples\n",
      "Train on 2406 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 9ms/step - loss: 1.2046 - val_loss: 2.5153\n",
      "[INFO] Training model: epoch 15 - 12750/20505 samples\n",
      "Train on 2506 samples, validate on 552 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1929 - val_loss: 2.6046\n",
      "[INFO] Training model: epoch 15 - 13000/20505 samples\n",
      "Train on 2498 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 9ms/step - loss: 1.1683 - val_loss: 2.6654\n",
      "[INFO] Training model: epoch 15 - 13250/20505 samples\n",
      "Train on 2511 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 22s 9ms/step - loss: 1.2345 - val_loss: 2.9101\n",
      "[INFO] Training model: epoch 15 - 13500/20505 samples\n",
      "Train on 2437 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.1747 - val_loss: 2.5648\n",
      "[INFO] Training model: epoch 15 - 13750/20505 samples\n",
      "Train on 2418 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 24s 10ms/step - loss: 1.1908 - val_loss: 2.8365\n",
      "[INFO] Training model: epoch 15 - 14000/20505 samples\n",
      "Train on 2450 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 24s 10ms/step - loss: 1.1300 - val_loss: 2.5605\n",
      "[INFO] Training model: epoch 15 - 14250/20505 samples\n",
      "Train on 2506 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 9ms/step - loss: 1.1920 - val_loss: 2.5458\n",
      "[INFO] Training model: epoch 15 - 14500/20505 samples\n",
      "Train on 2517 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 24s 9ms/step - loss: 1.1624 - val_loss: 2.8510\n",
      "[INFO] Training model: epoch 15 - 14750/20505 samples\n",
      "Train on 2524 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 1.2065 - val_loss: 2.7859\n",
      "[INFO] Training model: epoch 15 - 15000/20505 samples\n",
      "Train on 2455 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 10ms/step - loss: 1.2362 - val_loss: 2.4933\n",
      "[INFO] Training model: epoch 15 - 15250/20505 samples\n",
      "Train on 2547 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 25s 10ms/step - loss: 1.2009 - val_loss: 2.8018\n",
      "[INFO] Training model: epoch 15 - 15500/20505 samples\n",
      "Train on 2492 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.2984 - val_loss: 2.5872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 15 - 15750/20505 samples\n",
      "Train on 2458 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.2579 - val_loss: 2.7299\n",
      "[INFO] Training model: epoch 15 - 16000/20505 samples\n",
      "Train on 2423 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.1368 - val_loss: 2.4889\n",
      "[INFO] Training model: epoch 15 - 16250/20505 samples\n",
      "Train on 2481 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 24s 10ms/step - loss: 1.2146 - val_loss: 2.9762\n",
      "[INFO] Training model: epoch 15 - 16500/20505 samples\n",
      "Train on 2448 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 23s 9ms/step - loss: 1.2419 - val_loss: 2.7460\n",
      "[INFO] Training model: epoch 15 - 16750/20505 samples\n",
      "Train on 2537 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 10ms/step - loss: 1.2492 - val_loss: 2.7059\n",
      "[INFO] Training model: epoch 15 - 17000/20505 samples\n",
      "Train on 2488 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 24s 10ms/step - loss: 1.2518 - val_loss: 2.5754\n",
      "[INFO] Training model: epoch 15 - 17250/20505 samples\n",
      "Train on 2478 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 24s 10ms/step - loss: 1.2247 - val_loss: 2.6553\n",
      "[INFO] Training model: epoch 15 - 17500/20505 samples\n",
      "Train on 2498 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.1885 - val_loss: 2.7258\n",
      "[INFO] Training model: epoch 15 - 17750/20505 samples\n",
      "Train on 2374 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 23s 10ms/step - loss: 1.1766 - val_loss: 2.5925\n",
      "[INFO] Training model: epoch 15 - 18000/20505 samples\n",
      "Train on 2559 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 1.2059 - val_loss: 2.7214\n",
      "[INFO] Training model: epoch 15 - 18250/20505 samples\n",
      "Train on 2558 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.3310 - val_loss: 2.3532\n",
      "[INFO] Training model: epoch 15 - 18500/20505 samples\n",
      "Train on 2463 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 1.1660 - val_loss: 2.5401\n",
      "[INFO] Training model: epoch 15 - 18750/20505 samples\n",
      "Train on 2410 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 10ms/step - loss: 1.2774 - val_loss: 2.6960\n",
      "[INFO] Training model: epoch 15 - 19000/20505 samples\n",
      "Train on 2550 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 24s 9ms/step - loss: 1.2430 - val_loss: 2.8580\n",
      "[INFO] Training model: epoch 15 - 19250/20505 samples\n",
      "Train on 2496 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.2518 - val_loss: 2.7315\n",
      "[INFO] Training model: epoch 15 - 19500/20505 samples\n",
      "Train on 2498 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.1718 - val_loss: 2.6074\n",
      "[INFO] Training model: epoch 15 - 19750/20505 samples\n",
      "Train on 2378 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 23s 10ms/step - loss: 1.2462 - val_loss: 2.4960\n",
      "[INFO] Training model: epoch 15 - 20000/20505 samples\n",
      "Train on 2510 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 24s 9ms/step - loss: 1.3002 - val_loss: 2.9654\n",
      "[INFO] Training model: epoch 15 - 20250/20505 samples\n",
      "Train on 2469 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.2027 - val_loss: 2.4907\n",
      "[INFO] Training model: epoch 15 - 20500/20505 samples\n",
      "Train on 47 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 1.5079 - val_loss: 1.6176\n",
      "[INFO] Training model: epoch 16 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 0.9983 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 16 - 250/20505 samples\n",
      "Train on 2407 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 9ms/step - loss: 0.9501 - val_loss: 2.9764\n",
      "[INFO] Training model: epoch 16 - 500/20505 samples\n",
      "Train on 2491 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 24s 10ms/step - loss: 1.0341 - val_loss: 2.7407\n",
      "[INFO] Training model: epoch 16 - 750/20505 samples\n",
      "Train on 2516 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.0242 - val_loss: 2.4131\n",
      "[INFO] Training model: epoch 16 - 1000/20505 samples\n",
      "Train on 2453 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 24s 10ms/step - loss: 1.0159 - val_loss: 2.6177\n",
      "[INFO] Training model: epoch 16 - 1250/20505 samples\n",
      "Train on 2465 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 24s 10ms/step - loss: 1.0454 - val_loss: 2.5644\n",
      "[INFO] Training model: epoch 16 - 1500/20505 samples\n",
      "Train on 2469 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.0215 - val_loss: 2.7709\n",
      "[INFO] Training model: epoch 16 - 1750/20505 samples\n",
      "Train on 2444 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 10ms/step - loss: 1.0894 - val_loss: 2.7102\n",
      "[INFO] Training model: epoch 16 - 2000/20505 samples\n",
      "Train on 2484 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.0157 - val_loss: 2.8553\n",
      "[INFO] Training model: epoch 16 - 2250/20505 samples\n",
      "Train on 2378 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 22s 9ms/step - loss: 0.9970 - val_loss: 2.8719\n",
      "[INFO] Training model: epoch 16 - 2500/20505 samples\n",
      "Train on 2390 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 23s 10ms/step - loss: 1.0443 - val_loss: 2.9657\n",
      "[INFO] Training model: epoch 16 - 2750/20505 samples\n",
      "Train on 2489 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 24s 10ms/step - loss: 1.0189 - val_loss: 2.6347\n",
      "[INFO] Training model: epoch 16 - 3000/20505 samples\n",
      "Train on 2477 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 24s 10ms/step - loss: 1.0143 - val_loss: 2.8704\n",
      "[INFO] Training model: epoch 16 - 3250/20505 samples\n",
      "Train on 2469 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.0132 - val_loss: 2.8750\n",
      "[INFO] Training model: epoch 16 - 3500/20505 samples\n",
      "Train on 2492 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.0481 - val_loss: 2.6044\n",
      "[INFO] Training model: epoch 16 - 3750/20505 samples\n",
      "Train on 2395 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 23s 10ms/step - loss: 1.1016 - val_loss: 2.9041\n",
      "[INFO] Training model: epoch 16 - 4000/20505 samples\n",
      "Train on 2500 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 9ms/step - loss: 1.0904 - val_loss: 2.6777\n",
      "[INFO] Training model: epoch 16 - 4250/20505 samples\n",
      "Train on 2440 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 24s 10ms/step - loss: 1.0469 - val_loss: 2.9893\n",
      "[INFO] Training model: epoch 16 - 4500/20505 samples\n",
      "Train on 2531 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 10ms/step - loss: 1.1035 - val_loss: 2.8099\n",
      "[INFO] Training model: epoch 16 - 4750/20505 samples\n",
      "Train on 2461 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.0165 - val_loss: 2.7785\n",
      "[INFO] Training model: epoch 16 - 5000/20505 samples\n",
      "Train on 2500 samples, validate on 560 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.0688 - val_loss: 2.6050\n",
      "[INFO] Training model: epoch 16 - 5250/20505 samples\n",
      "Train on 2428 samples, validate on 696 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 24s 10ms/step - loss: 1.0508 - val_loss: 2.8019\n",
      "[INFO] Training model: epoch 16 - 5500/20505 samples\n",
      "Train on 2388 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.0622 - val_loss: 2.8949\n",
      "[INFO] Training model: epoch 16 - 5750/20505 samples\n",
      "Train on 2484 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 24s 10ms/step - loss: 1.1655 - val_loss: 2.7134\n",
      "[INFO] Training model: epoch 16 - 6000/20505 samples\n",
      "Train on 2473 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.1333 - val_loss: 2.8752\n",
      "[INFO] Training model: epoch 16 - 6250/20505 samples\n",
      "Train on 2354 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 23s 10ms/step - loss: 1.0938 - val_loss: 2.5080\n",
      "[INFO] Training model: epoch 16 - 6500/20505 samples\n",
      "Train on 2485 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 24s 10ms/step - loss: 1.0767 - val_loss: 2.4303\n",
      "[INFO] Training model: epoch 16 - 6750/20505 samples\n",
      "Train on 2485 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.1094 - val_loss: 2.6812\n",
      "[INFO] Training model: epoch 16 - 7000/20505 samples\n",
      "Train on 2436 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 10ms/step - loss: 1.0820 - val_loss: 2.6339\n",
      "[INFO] Training model: epoch 16 - 7250/20505 samples\n",
      "Train on 2337 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 22s 9ms/step - loss: 1.0910 - val_loss: 2.4352\n",
      "[INFO] Training model: epoch 16 - 7500/20505 samples\n",
      "Train on 2474 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.1137 - val_loss: 2.7438\n",
      "[INFO] Training model: epoch 16 - 7750/20505 samples\n",
      "Train on 2478 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 1.1322 - val_loss: 2.4278\n",
      "[INFO] Training model: epoch 16 - 8000/20505 samples\n",
      "Train on 2502 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.0313 - val_loss: 2.5378\n",
      "[INFO] Training model: epoch 16 - 8250/20505 samples\n",
      "Train on 2386 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.1094 - val_loss: 2.4691\n",
      "[INFO] Training model: epoch 16 - 8500/20505 samples\n",
      "Train on 2422 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 1.1337 - val_loss: 2.7323\n",
      "[INFO] Training model: epoch 16 - 8750/20505 samples\n",
      "Train on 2406 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 22s 9ms/step - loss: 1.1031 - val_loss: 2.5611\n",
      "[INFO] Training model: epoch 16 - 9000/20505 samples\n",
      "Train on 2482 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.0771 - val_loss: 2.7091\n",
      "[INFO] Training model: epoch 16 - 9250/20505 samples\n",
      "Train on 2451 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 24s 10ms/step - loss: 1.0644 - val_loss: 2.7200\n",
      "[INFO] Training model: epoch 16 - 9500/20505 samples\n",
      "Train on 2513 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.0869 - val_loss: 2.7013\n",
      "[INFO] Training model: epoch 16 - 9750/20505 samples\n",
      "Train on 2472 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.0944 - val_loss: 2.6165\n",
      "[INFO] Training model: epoch 16 - 10000/20505 samples\n",
      "Train on 2452 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.1097 - val_loss: 2.7837\n",
      "[INFO] Training model: epoch 16 - 10250/20505 samples\n",
      "Train on 2480 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.0722 - val_loss: 2.9084\n",
      "[INFO] Training model: epoch 16 - 10500/20505 samples\n",
      "Train on 2503 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 1.1793 - val_loss: 2.6631\n",
      "[INFO] Training model: epoch 16 - 10750/20505 samples\n",
      "Train on 2394 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1578 - val_loss: 2.6566\n",
      "[INFO] Training model: epoch 16 - 11000/20505 samples\n",
      "Train on 2426 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.1017 - val_loss: 2.7182\n",
      "[INFO] Training model: epoch 16 - 11250/20505 samples\n",
      "Train on 2446 samples, validate on 543 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.1649 - val_loss: 2.4252\n",
      "[INFO] Training model: epoch 16 - 11500/20505 samples\n",
      "Train on 2590 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2590/2590 [==============================] - 22s 9ms/step - loss: 1.0900 - val_loss: 2.6227\n",
      "[INFO] Training model: epoch 16 - 11750/20505 samples\n",
      "Train on 2489 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.1183 - val_loss: 2.6726\n",
      "[INFO] Training model: epoch 16 - 12000/20505 samples\n",
      "Train on 2411 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.1546 - val_loss: 2.8114\n",
      "[INFO] Training model: epoch 16 - 12250/20505 samples\n",
      "Train on 2481 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.1160 - val_loss: 2.8245\n",
      "[INFO] Training model: epoch 16 - 12500/20505 samples\n",
      "Train on 2421 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.1357 - val_loss: 2.8259\n",
      "[INFO] Training model: epoch 16 - 12750/20505 samples\n",
      "Train on 2533 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 1.1177 - val_loss: 2.6389\n",
      "[INFO] Training model: epoch 16 - 13000/20505 samples\n",
      "Train on 2411 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 21s 9ms/step - loss: 1.1377 - val_loss: 2.8588\n",
      "[INFO] Training model: epoch 16 - 13250/20505 samples\n",
      "Train on 2409 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.2043 - val_loss: 2.5796\n",
      "[INFO] Training model: epoch 16 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 1.1689 - val_loss: 2.6230\n",
      "[INFO] Training model: epoch 16 - 13750/20505 samples\n",
      "Train on 2419 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.1453 - val_loss: 2.9169\n",
      "[INFO] Training model: epoch 16 - 14000/20505 samples\n",
      "Train on 2396 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.1187 - val_loss: 2.7596\n",
      "[INFO] Training model: epoch 16 - 14250/20505 samples\n",
      "Train on 2516 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 23s 9ms/step - loss: 1.1450 - val_loss: 2.8539\n",
      "[INFO] Training model: epoch 16 - 14500/20505 samples\n",
      "Train on 2349 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 10ms/step - loss: 1.1809 - val_loss: 2.9646\n",
      "[INFO] Training model: epoch 16 - 14750/20505 samples\n",
      "Train on 2505 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 22s 9ms/step - loss: 1.0939 - val_loss: 2.5317\n",
      "[INFO] Training model: epoch 16 - 15000/20505 samples\n",
      "Train on 2480 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.1239 - val_loss: 2.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 16 - 15250/20505 samples\n",
      "Train on 2376 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 22s 9ms/step - loss: 1.1672 - val_loss: 2.8551\n",
      "[INFO] Training model: epoch 16 - 15500/20505 samples\n",
      "Train on 2557 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 23s 9ms/step - loss: 1.1876 - val_loss: 2.6456\n",
      "[INFO] Training model: epoch 16 - 15750/20505 samples\n",
      "Train on 2380 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.1035 - val_loss: 2.5155\n",
      "[INFO] Training model: epoch 16 - 16000/20505 samples\n",
      "Train on 2477 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 22s 9ms/step - loss: 1.0815 - val_loss: 2.6339\n",
      "[INFO] Training model: epoch 16 - 16250/20505 samples\n",
      "Train on 2518 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.1643 - val_loss: 2.6151\n",
      "[INFO] Training model: epoch 16 - 16500/20505 samples\n",
      "Train on 2445 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.1738 - val_loss: 2.9454\n",
      "[INFO] Training model: epoch 16 - 16750/20505 samples\n",
      "Train on 2543 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 23s 9ms/step - loss: 1.2228 - val_loss: 2.6314\n",
      "[INFO] Training model: epoch 16 - 17000/20505 samples\n",
      "Train on 2429 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 23s 10ms/step - loss: 1.1839 - val_loss: 2.7489\n",
      "[INFO] Training model: epoch 16 - 17250/20505 samples\n",
      "Train on 2430 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.2367 - val_loss: 2.3456\n",
      "[INFO] Training model: epoch 16 - 17500/20505 samples\n",
      "Train on 2471 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.1852 - val_loss: 2.7800\n",
      "[INFO] Training model: epoch 16 - 17750/20505 samples\n",
      "Train on 2414 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.1961 - val_loss: 2.4988\n",
      "[INFO] Training model: epoch 16 - 18000/20505 samples\n",
      "Train on 2416 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.1739 - val_loss: 2.8059\n",
      "[INFO] Training model: epoch 16 - 18250/20505 samples\n",
      "Train on 2524 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 22s 9ms/step - loss: 1.2073 - val_loss: 2.5295\n",
      "[INFO] Training model: epoch 16 - 18500/20505 samples\n",
      "Train on 2444 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.2064 - val_loss: 2.5997\n",
      "[INFO] Training model: epoch 16 - 18750/20505 samples\n",
      "Train on 2388 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 10ms/step - loss: 1.1778 - val_loss: 2.6540\n",
      "[INFO] Training model: epoch 16 - 19000/20505 samples\n",
      "Train on 2469 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.2310 - val_loss: 2.8563\n",
      "[INFO] Training model: epoch 16 - 19250/20505 samples\n",
      "Train on 2512 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 10ms/step - loss: 1.1143 - val_loss: 2.6969\n",
      "[INFO] Training model: epoch 16 - 19500/20505 samples\n",
      "Train on 2539 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 9ms/step - loss: 1.2172 - val_loss: 2.8458\n",
      "[INFO] Training model: epoch 16 - 19750/20505 samples\n",
      "Train on 2451 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.1893 - val_loss: 2.3518\n",
      "[INFO] Training model: epoch 16 - 20000/20505 samples\n",
      "Train on 2497 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 24s 9ms/step - loss: 1.2013 - val_loss: 2.6247\n",
      "[INFO] Training model: epoch 16 - 20250/20505 samples\n",
      "Train on 2408 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.1041 - val_loss: 2.7736\n",
      "[INFO] Training model: epoch 16 - 20500/20505 samples\n",
      "Train on 46 samples, validate on 17 samples\n",
      "Epoch 1/1\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.8807 - val_loss: 2.5004\n",
      "[INFO] Training model: epoch 17 - 0/20505 samples\n",
      "Train on 2419 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 24s 10ms/step - loss: 1.0017 - val_loss: 2.7597\n",
      "[INFO] Training model: epoch 17 - 250/20505 samples\n",
      "Train on 2397 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 9ms/step - loss: 1.0012 - val_loss: 2.9054\n",
      "[INFO] Training model: epoch 17 - 500/20505 samples\n",
      "Train on 2394 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 23s 10ms/step - loss: 0.9167 - val_loss: 2.8373\n",
      "[INFO] Training model: epoch 17 - 750/20505 samples\n",
      "Train on 2377 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 21s 9ms/step - loss: 0.9693 - val_loss: 2.6920\n",
      "[INFO] Training model: epoch 17 - 1000/20505 samples\n",
      "Train on 2487 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 0.9938 - val_loss: 2.6396\n",
      "[INFO] Training model: epoch 17 - 1250/20505 samples\n",
      "Train on 2448 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 22s 9ms/step - loss: 0.9835 - val_loss: 2.8758\n",
      "[INFO] Training model: epoch 17 - 1500/20505 samples\n",
      "Train on 2329 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 22s 9ms/step - loss: 1.0472 - val_loss: 2.8908\n",
      "[INFO] Training model: epoch 17 - 1750/20505 samples\n",
      "Train on 2592 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 24s 9ms/step - loss: 0.9826 - val_loss: 2.8343\n",
      "[INFO] Training model: epoch 17 - 2000/20505 samples\n",
      "Train on 2515 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 24s 10ms/step - loss: 1.0178 - val_loss: 2.7633\n",
      "[INFO] Training model: epoch 17 - 2250/20505 samples\n",
      "Train on 2473 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 0.9895 - val_loss: 2.7203\n",
      "[INFO] Training model: epoch 17 - 2500/20505 samples\n",
      "Train on 2551 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 23s 9ms/step - loss: 0.9872 - val_loss: 2.8223\n",
      "[INFO] Training model: epoch 17 - 2750/20505 samples\n",
      "Train on 2418 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 10ms/step - loss: 1.0305 - val_loss: 2.7459\n",
      "[INFO] Training model: epoch 17 - 3000/20505 samples\n",
      "Train on 2486 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 0.9566 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 3250/20505 samples\n",
      "Train on 2511 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 0.9859 - val_loss: 2.5696\n",
      "[INFO] Training model: epoch 17 - 3500/20505 samples\n",
      "Train on 2524 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 0.9989 - val_loss: 2.8635\n",
      "[INFO] Training model: epoch 17 - 3750/20505 samples\n",
      "Train on 2432 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 10ms/step - loss: 1.0931 - val_loss: 2.8016\n",
      "[INFO] Training model: epoch 17 - 4000/20505 samples\n",
      "Train on 2496 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 24s 10ms/step - loss: 1.0310 - val_loss: 2.5127\n",
      "[INFO] Training model: epoch 17 - 4250/20505 samples\n",
      "Train on 2460 samples, validate on 689 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 24s 10ms/step - loss: 1.0273 - val_loss: 2.7648\n",
      "[INFO] Training model: epoch 17 - 4500/20505 samples\n",
      "Train on 2473 samples, validate on 570 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.0124 - val_loss: 2.8310\n",
      "[INFO] Training model: epoch 17 - 4750/20505 samples\n",
      "Train on 2492 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 1.0560 - val_loss: 2.5926\n",
      "[INFO] Training model: epoch 17 - 5000/20505 samples\n",
      "Train on 2431 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 23s 10ms/step - loss: 1.0501 - val_loss: 2.8781\n",
      "[INFO] Training model: epoch 17 - 5250/20505 samples\n",
      "Train on 2541 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 1.0259 - val_loss: 3.0532\n",
      "[INFO] Training model: epoch 17 - 5500/20505 samples\n",
      "Train on 2506 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.0523 - val_loss: 2.5453\n",
      "[INFO] Training model: epoch 17 - 5750/20505 samples\n",
      "Train on 2468 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 24s 10ms/step - loss: 1.0446 - val_loss: 2.9264\n",
      "[INFO] Training model: epoch 17 - 6000/20505 samples\n",
      "Train on 2462 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 10ms/step - loss: 1.0265 - val_loss: 2.6951\n",
      "[INFO] Training model: epoch 17 - 6250/20505 samples\n",
      "Train on 2447 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.0243 - val_loss: 2.6062\n",
      "[INFO] Training model: epoch 17 - 6500/20505 samples\n",
      "Train on 2442 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.0276 - val_loss: 2.4541\n",
      "[INFO] Training model: epoch 17 - 6750/20505 samples\n",
      "Train on 2480 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.0952 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 7000/20505 samples\n",
      "Train on 2474 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.0354 - val_loss: 2.8625\n",
      "[INFO] Training model: epoch 17 - 7250/20505 samples\n",
      "Train on 2487 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 1.0581 - val_loss: 2.5959\n",
      "[INFO] Training model: epoch 17 - 7500/20505 samples\n",
      "Train on 2448 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 23s 10ms/step - loss: 1.0141 - val_loss: 2.9285\n",
      "[INFO] Training model: epoch 17 - 7750/20505 samples\n",
      "Train on 2396 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 23s 9ms/step - loss: 1.1087 - val_loss: 2.1447\n",
      "[INFO] Training model: epoch 17 - 8000/20505 samples\n",
      "Train on 2436 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 10ms/step - loss: 1.0189 - val_loss: 2.7016\n",
      "[INFO] Training model: epoch 17 - 8250/20505 samples\n",
      "Train on 2511 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 1.0544 - val_loss: 2.7902\n",
      "[INFO] Training model: epoch 17 - 8500/20505 samples\n",
      "Train on 2432 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 24s 10ms/step - loss: 1.0913 - val_loss: 3.0249\n",
      "[INFO] Training model: epoch 17 - 8750/20505 samples\n",
      "Train on 2563 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 25s 10ms/step - loss: 1.1346 - val_loss: 2.7360\n",
      "[INFO] Training model: epoch 17 - 9000/20505 samples\n",
      "Train on 2310 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2310/2310 [==============================] - 23s 10ms/step - loss: 1.0845 - val_loss: 2.4522\n",
      "[INFO] Training model: epoch 17 - 9250/20505 samples\n",
      "Train on 2426 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 10ms/step - loss: 1.0874 - val_loss: 2.4807\n",
      "[INFO] Training model: epoch 17 - 9500/20505 samples\n",
      "Train on 2439 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.1209 - val_loss: 2.7332\n",
      "[INFO] Training model: epoch 17 - 9750/20505 samples\n",
      "Train on 2410 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 9ms/step - loss: 1.1525 - val_loss: 2.3952\n",
      "[INFO] Training model: epoch 17 - 10000/20505 samples\n",
      "Train on 2542 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 24s 9ms/step - loss: 1.0238 - val_loss: 2.8738\n",
      "[INFO] Training model: epoch 17 - 10250/20505 samples\n",
      "Train on 2413 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 1.0568 - val_loss: 2.7993\n",
      "[INFO] Training model: epoch 17 - 10500/20505 samples\n",
      "Train on 2511 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 1.0314 - val_loss: 2.7383\n",
      "[INFO] Training model: epoch 17 - 10750/20505 samples\n",
      "Train on 2385 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1645 - val_loss: 2.9513\n",
      "[INFO] Training model: epoch 17 - 11000/20505 samples\n",
      "Train on 2439 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 10ms/step - loss: 1.0990 - val_loss: 2.7914\n",
      "[INFO] Training model: epoch 17 - 11250/20505 samples\n",
      "Train on 2458 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.1120 - val_loss: 2.7903\n",
      "[INFO] Training model: epoch 17 - 11500/20505 samples\n",
      "Train on 2517 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 23s 9ms/step - loss: 1.0835 - val_loss: 2.6622\n",
      "[INFO] Training model: epoch 17 - 11750/20505 samples\n",
      "Train on 2666 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 25s 9ms/step - loss: 1.0112 - val_loss: 2.7902\n",
      "[INFO] Training model: epoch 17 - 12000/20505 samples\n",
      "Train on 2474 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 24s 10ms/step - loss: 1.1217 - val_loss: 2.7922\n",
      "[INFO] Training model: epoch 17 - 12250/20505 samples\n",
      "Train on 2460 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.0967 - val_loss: 2.6633\n",
      "[INFO] Training model: epoch 17 - 12500/20505 samples\n",
      "Train on 2441 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 10ms/step - loss: 1.0969 - val_loss: 2.5391\n",
      "[INFO] Training model: epoch 17 - 12750/20505 samples\n",
      "Train on 2384 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.1017 - val_loss: 2.6273\n",
      "[INFO] Training model: epoch 17 - 13000/20505 samples\n",
      "Train on 2454 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 22s 9ms/step - loss: 1.0918 - val_loss: 2.8309\n",
      "[INFO] Training model: epoch 17 - 13250/20505 samples\n",
      "Train on 2489 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.1318 - val_loss: 2.4994\n",
      "[INFO] Training model: epoch 17 - 13500/20505 samples\n",
      "Train on 2538 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.0943 - val_loss: 2.7106\n",
      "[INFO] Training model: epoch 17 - 13750/20505 samples\n",
      "Train on 2483 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.1202 - val_loss: 2.8043\n",
      "[INFO] Training model: epoch 17 - 14000/20505 samples\n",
      "Train on 2325 samples, validate on 687 samples\n",
      "Epoch 1/1\n",
      "2325/2325 [==============================] - 22s 10ms/step - loss: 1.1483 - val_loss: 2.7629\n",
      "[INFO] Training model: epoch 17 - 14250/20505 samples\n",
      "Train on 2416 samples, validate on 546 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.0924 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 17 - 14500/20505 samples\n",
      "Train on 2433 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.1171 - val_loss: 2.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 17 - 14750/20505 samples\n",
      "Train on 2418 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.1694 - val_loss: 2.5151\n",
      "[INFO] Training model: epoch 17 - 15000/20505 samples\n",
      "Train on 2328 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 20s 9ms/step - loss: 1.0865 - val_loss: 2.4355\n",
      "[INFO] Training model: epoch 17 - 15250/20505 samples\n",
      "Train on 2545 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 24s 9ms/step - loss: 1.0970 - val_loss: 2.3715\n",
      "[INFO] Training model: epoch 17 - 15500/20505 samples\n",
      "Train on 2344 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 22s 9ms/step - loss: 1.0990 - val_loss: 2.6788\n",
      "[INFO] Training model: epoch 17 - 15750/20505 samples\n",
      "Train on 2390 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 23s 9ms/step - loss: 1.1033 - val_loss: 2.7593\n",
      "[INFO] Training model: epoch 17 - 16000/20505 samples\n",
      "Train on 2425 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.1782 - val_loss: 2.9337\n",
      "[INFO] Training model: epoch 17 - 16250/20505 samples\n",
      "Train on 2498 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 23s 9ms/step - loss: 1.1287 - val_loss: 2.4064\n",
      "[INFO] Training model: epoch 17 - 16500/20505 samples\n",
      "Train on 2365 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.1559 - val_loss: 2.4488\n",
      "[INFO] Training model: epoch 17 - 16750/20505 samples\n",
      "Train on 2491 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 22s 9ms/step - loss: 1.1277 - val_loss: 2.6632\n",
      "[INFO] Training model: epoch 17 - 17000/20505 samples\n",
      "Train on 2428 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 1.1324 - val_loss: 2.7551\n",
      "[INFO] Training model: epoch 17 - 17250/20505 samples\n",
      "Train on 2524 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.1615 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 17 - 17500/20505 samples\n",
      "Train on 2574 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 24s 9ms/step - loss: 1.1741 - val_loss: 3.2363\n",
      "[INFO] Training model: epoch 17 - 17750/20505 samples\n",
      "Train on 2515 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.1676 - val_loss: 3.0051\n",
      "[INFO] Training model: epoch 17 - 18000/20505 samples\n",
      "Train on 2430 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.1260 - val_loss: 2.7207\n",
      "[INFO] Training model: epoch 17 - 18250/20505 samples\n",
      "Train on 2476 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.1031 - val_loss: 2.7186\n",
      "[INFO] Training model: epoch 17 - 18500/20505 samples\n",
      "Train on 2394 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1297 - val_loss: 2.8500\n",
      "[INFO] Training model: epoch 17 - 18750/20505 samples\n",
      "Train on 2304 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 22s 10ms/step - loss: 1.1580 - val_loss: 2.4239\n",
      "[INFO] Training model: epoch 17 - 19000/20505 samples\n",
      "Train on 2428 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.1718 - val_loss: 2.5803\n",
      "[INFO] Training model: epoch 17 - 19250/20505 samples\n",
      "Train on 2499 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1715 - val_loss: 2.7985\n",
      "[INFO] Training model: epoch 17 - 19500/20505 samples\n",
      "Train on 2513 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.1181 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 19750/20505 samples\n",
      "Train on 2402 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1569 - val_loss: 2.8702\n",
      "[INFO] Training model: epoch 17 - 20000/20505 samples\n",
      "Train on 2420 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.1346 - val_loss: 2.8192\n",
      "[INFO] Training model: epoch 17 - 20250/20505 samples\n",
      "Train on 2463 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.0940 - val_loss: 2.6720\n",
      "[INFO] Training model: epoch 17 - 20500/20505 samples\n",
      "Train on 71 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.0095 - val_loss: 4.2551\n",
      "[INFO] Training model: epoch 18 - 0/20505 samples\n",
      "Train on 2468 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 0.9432 - val_loss: 2.7818\n",
      "[INFO] Training model: epoch 18 - 250/20505 samples\n",
      "Train on 2486 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 0.9197 - val_loss: 2.7538\n",
      "[INFO] Training model: epoch 18 - 500/20505 samples\n",
      "Train on 2431 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 0.9541 - val_loss: 2.8043\n",
      "[INFO] Training model: epoch 18 - 750/20505 samples\n",
      "Train on 2540 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 0.9200 - val_loss: 2.8726\n",
      "[INFO] Training model: epoch 18 - 1000/20505 samples\n",
      "Train on 2443 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 0.9293 - val_loss: 2.7009\n",
      "[INFO] Training model: epoch 18 - 1250/20505 samples\n",
      "Train on 2526 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 0.9791 - val_loss: 2.8556\n",
      "[INFO] Training model: epoch 18 - 1500/20505 samples\n",
      "Train on 2399 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 0.9893 - val_loss: 2.7956\n",
      "[INFO] Training model: epoch 18 - 1750/20505 samples\n",
      "Train on 2419 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 0.9367 - val_loss: 3.0318\n",
      "[INFO] Training model: epoch 18 - 2000/20505 samples\n",
      "Train on 2342 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2342/2342 [==============================] - 22s 10ms/step - loss: 0.9534 - val_loss: 2.7286\n",
      "[INFO] Training model: epoch 18 - 2250/20505 samples\n",
      "Train on 2445 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 0.9583 - val_loss: 2.4451\n",
      "[INFO] Training model: epoch 18 - 2500/20505 samples\n",
      "Train on 2499 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 22s 9ms/step - loss: 0.9184 - val_loss: 2.7506\n",
      "[INFO] Training model: epoch 18 - 2750/20505 samples\n",
      "Train on 2421 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 0.9276 - val_loss: 2.7725\n",
      "[INFO] Training model: epoch 18 - 3000/20505 samples\n",
      "Train on 2469 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 0.9909 - val_loss: 2.5665\n",
      "[INFO] Training model: epoch 18 - 3250/20505 samples\n",
      "Train on 2434 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 23s 9ms/step - loss: 1.0166 - val_loss: 2.8835\n",
      "[INFO] Training model: epoch 18 - 3500/20505 samples\n",
      "Train on 2413 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 0.9707 - val_loss: 2.6490\n",
      "[INFO] Training model: epoch 18 - 3750/20505 samples\n",
      "Train on 2430 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 10ms/step - loss: 1.0240 - val_loss: 2.7994\n",
      "[INFO] Training model: epoch 18 - 4000/20505 samples\n",
      "Train on 2397 samples, validate on 670 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397/2397 [==============================] - 22s 9ms/step - loss: 0.9866 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 18 - 4250/20505 samples\n",
      "Train on 2486 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.0078 - val_loss: 2.6311\n",
      "[INFO] Training model: epoch 18 - 4500/20505 samples\n",
      "Train on 2548 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 24s 9ms/step - loss: 0.9312 - val_loss: 2.8432\n",
      "[INFO] Training model: epoch 18 - 4750/20505 samples\n",
      "Train on 2411 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 0.9752 - val_loss: 2.6434\n",
      "[INFO] Training model: epoch 18 - 5000/20505 samples\n",
      "Train on 2531 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 0.9718 - val_loss: 3.0324\n",
      "[INFO] Training model: epoch 18 - 5250/20505 samples\n",
      "Train on 2414 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.0249 - val_loss: 2.7234\n",
      "[INFO] Training model: epoch 18 - 5500/20505 samples\n",
      "Train on 2525 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.0700 - val_loss: 2.5666\n",
      "[INFO] Training model: epoch 18 - 5750/20505 samples\n",
      "Train on 2383 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.0236 - val_loss: 2.7478\n",
      "[INFO] Training model: epoch 18 - 6000/20505 samples\n",
      "Train on 2423 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 0.9926 - val_loss: 2.7383\n",
      "[INFO] Training model: epoch 18 - 6250/20505 samples\n",
      "Train on 2443 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.0206 - val_loss: 2.8369\n",
      "[INFO] Training model: epoch 18 - 6500/20505 samples\n",
      "Train on 2528 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.0120 - val_loss: 2.6608\n",
      "[INFO] Training model: epoch 18 - 6750/20505 samples\n",
      "Train on 2374 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 0.9914 - val_loss: 2.7737\n",
      "[INFO] Training model: epoch 18 - 7000/20505 samples\n",
      "Train on 2530 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 23s 9ms/step - loss: 0.9630 - val_loss: 2.8892\n",
      "[INFO] Training model: epoch 18 - 7250/20505 samples\n",
      "Train on 2466 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.0281 - val_loss: 2.7736\n",
      "[INFO] Training model: epoch 18 - 7500/20505 samples\n",
      "Train on 2390 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.0465 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 18 - 7750/20505 samples\n",
      "Train on 2468 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.0300 - val_loss: 2.6032\n",
      "[INFO] Training model: epoch 18 - 8000/20505 samples\n",
      "Train on 2401 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 9ms/step - loss: 1.0728 - val_loss: 2.8673\n",
      "[INFO] Training model: epoch 18 - 8250/20505 samples\n",
      "Train on 2473 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.0917 - val_loss: 2.5969\n",
      "[INFO] Training model: epoch 18 - 8500/20505 samples\n",
      "Train on 2476 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.0823 - val_loss: 2.4519\n",
      "[INFO] Training model: epoch 18 - 8750/20505 samples\n",
      "Train on 2423 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 21s 9ms/step - loss: 1.0260 - val_loss: 2.5291\n",
      "[INFO] Training model: epoch 18 - 9000/20505 samples\n",
      "Train on 2346 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 22s 10ms/step - loss: 1.0396 - val_loss: 3.0978\n",
      "[INFO] Training model: epoch 18 - 9250/20505 samples\n",
      "Train on 2524 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0258 - val_loss: 2.7623\n",
      "[INFO] Training model: epoch 18 - 9500/20505 samples\n",
      "Train on 2416 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 0.9630 - val_loss: 2.3985\n",
      "[INFO] Training model: epoch 18 - 9750/20505 samples\n",
      "Train on 2437 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.0564 - val_loss: 2.7762\n",
      "[INFO] Training model: epoch 18 - 10000/20505 samples\n",
      "Train on 2518 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.0274 - val_loss: 2.6226\n",
      "[INFO] Training model: epoch 18 - 10250/20505 samples\n",
      "Train on 2452 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.0672 - val_loss: 2.8824\n",
      "[INFO] Training model: epoch 18 - 10500/20505 samples\n",
      "Train on 2457 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.0273 - val_loss: 3.0981\n",
      "[INFO] Training model: epoch 18 - 10750/20505 samples\n",
      "Train on 2434 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 22s 9ms/step - loss: 1.0691 - val_loss: 2.8633\n",
      "[INFO] Training model: epoch 18 - 11000/20505 samples\n",
      "Train on 2494 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.1319 - val_loss: 2.7680\n",
      "[INFO] Training model: epoch 18 - 11250/20505 samples\n",
      "Train on 2502 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.0556 - val_loss: 2.9950\n",
      "[INFO] Training model: epoch 18 - 11500/20505 samples\n",
      "Train on 2393 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.0817 - val_loss: 2.6052\n",
      "[INFO] Training model: epoch 18 - 11750/20505 samples\n",
      "Train on 2602 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2602/2602 [==============================] - 24s 9ms/step - loss: 1.0657 - val_loss: 3.0729\n",
      "[INFO] Training model: epoch 18 - 12000/20505 samples\n",
      "Train on 2390 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.0750 - val_loss: 2.6785\n",
      "[INFO] Training model: epoch 18 - 12250/20505 samples\n",
      "Train on 2359 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 1.0819 - val_loss: 3.3371\n",
      "[INFO] Training model: epoch 18 - 12500/20505 samples\n",
      "Train on 2423 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.0705 - val_loss: 2.9523\n",
      "[INFO] Training model: epoch 18 - 12750/20505 samples\n",
      "Train on 2496 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.1152 - val_loss: 2.9089\n",
      "[INFO] Training model: epoch 18 - 13000/20505 samples\n",
      "Train on 2549 samples, validate on 553 samples\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 23s 9ms/step - loss: 1.0360 - val_loss: 2.9781\n",
      "[INFO] Training model: epoch 18 - 13250/20505 samples\n",
      "Train on 2468 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.0542 - val_loss: 2.5845\n",
      "[INFO] Training model: epoch 18 - 13500/20505 samples\n",
      "Train on 2420 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.1649 - val_loss: 2.7396\n",
      "[INFO] Training model: epoch 18 - 13750/20505 samples\n",
      "Train on 2454 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.1051 - val_loss: 2.8910\n",
      "[INFO] Training model: epoch 18 - 14000/20505 samples\n",
      "Train on 2392 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.0719 - val_loss: 2.6278\n",
      "[INFO] Training model: epoch 18 - 14250/20505 samples\n",
      "Train on 2601 samples, validate on 625 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601/2601 [==============================] - 24s 9ms/step - loss: 1.0618 - val_loss: 2.9545\n",
      "[INFO] Training model: epoch 18 - 14500/20505 samples\n",
      "Train on 2515 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.1398 - val_loss: 2.5537\n",
      "[INFO] Training model: epoch 18 - 14750/20505 samples\n",
      "Train on 2429 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.1956 - val_loss: 3.0650\n",
      "[INFO] Training model: epoch 18 - 15000/20505 samples\n",
      "Train on 2423 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.1139 - val_loss: 3.2373\n",
      "[INFO] Training model: epoch 18 - 15250/20505 samples\n",
      "Train on 2470 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.1225 - val_loss: 2.7245\n",
      "[INFO] Training model: epoch 18 - 15500/20505 samples\n",
      "Train on 2505 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 24s 9ms/step - loss: 1.0658 - val_loss: 2.7332\n",
      "[INFO] Training model: epoch 18 - 15750/20505 samples\n",
      "Train on 2396 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 21s 9ms/step - loss: 1.1214 - val_loss: 2.8891\n",
      "[INFO] Training model: epoch 18 - 16000/20505 samples\n",
      "Train on 2466 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.0915 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 18 - 16250/20505 samples\n",
      "Train on 2461 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 22s 9ms/step - loss: 1.0768 - val_loss: 2.6934\n",
      "[INFO] Training model: epoch 18 - 16500/20505 samples\n",
      "Train on 2451 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.1657 - val_loss: 3.1628\n",
      "[INFO] Training model: epoch 18 - 16750/20505 samples\n",
      "Train on 2385 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1427 - val_loss: 2.6621\n",
      "[INFO] Training model: epoch 18 - 17000/20505 samples\n",
      "Train on 2452 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.0555 - val_loss: 2.7870\n",
      "[INFO] Training model: epoch 18 - 17250/20505 samples\n",
      "Train on 2459 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.1140 - val_loss: 2.8887\n",
      "[INFO] Training model: epoch 18 - 17500/20505 samples\n",
      "Train on 2485 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.0537 - val_loss: 2.9955\n",
      "[INFO] Training model: epoch 18 - 17750/20505 samples\n",
      "Train on 2483 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.0585 - val_loss: 2.7522\n",
      "[INFO] Training model: epoch 18 - 18000/20505 samples\n",
      "Train on 2386 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.0394 - val_loss: 2.4840\n",
      "[INFO] Training model: epoch 18 - 18250/20505 samples\n",
      "Train on 2460 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.0950 - val_loss: 2.5444\n",
      "[INFO] Training model: epoch 18 - 18500/20505 samples\n",
      "Train on 2542 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 23s 9ms/step - loss: 1.1051 - val_loss: 2.7910\n",
      "[INFO] Training model: epoch 18 - 18750/20505 samples\n",
      "Train on 2482 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 22s 9ms/step - loss: 1.1232 - val_loss: 2.6184\n",
      "[INFO] Training model: epoch 18 - 19000/20505 samples\n",
      "Train on 2370 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 22s 9ms/step - loss: 1.1474 - val_loss: 2.9380\n",
      "[INFO] Training model: epoch 18 - 19250/20505 samples\n",
      "Train on 2457 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.1237 - val_loss: 3.0535\n",
      "[INFO] Training model: epoch 18 - 19500/20505 samples\n",
      "Train on 2523 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 22s 9ms/step - loss: 1.1631 - val_loss: 2.6603\n",
      "[INFO] Training model: epoch 18 - 19750/20505 samples\n",
      "Train on 2540 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 23s 9ms/step - loss: 1.0741 - val_loss: 2.7600\n",
      "[INFO] Training model: epoch 18 - 20000/20505 samples\n",
      "Train on 2464 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.1240 - val_loss: 2.5807\n",
      "[INFO] Training model: epoch 18 - 20250/20505 samples\n",
      "Train on 2426 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.1292 - val_loss: 2.8161\n",
      "[INFO] Training model: epoch 18 - 20500/20505 samples\n",
      "Train on 44 samples, validate on 28 samples\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3792 - val_loss: 4.8115\n",
      "[INFO] Training model: epoch 19 - 0/20505 samples\n",
      "Train on 2427 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 22s 9ms/step - loss: 0.9222 - val_loss: 2.7577\n",
      "[INFO] Training model: epoch 19 - 250/20505 samples\n",
      "Train on 2413 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 0.9591 - val_loss: 2.9073\n",
      "[INFO] Training model: epoch 19 - 500/20505 samples\n",
      "Train on 2520 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 22s 9ms/step - loss: 0.9091 - val_loss: 3.0033\n",
      "[INFO] Training model: epoch 19 - 750/20505 samples\n",
      "Train on 2459 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 0.9315 - val_loss: 2.8249\n",
      "[INFO] Training model: epoch 19 - 1000/20505 samples\n",
      "Train on 2395 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 0.9188 - val_loss: 2.6159\n",
      "[INFO] Training model: epoch 19 - 1250/20505 samples\n",
      "Train on 2316 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 22s 10ms/step - loss: 0.9730 - val_loss: 2.5742\n",
      "[INFO] Training model: epoch 19 - 1500/20505 samples\n",
      "Train on 2467 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 0.8922 - val_loss: 2.7719\n",
      "[INFO] Training model: epoch 19 - 1750/20505 samples\n",
      "Train on 2330 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2330/2330 [==============================] - 21s 9ms/step - loss: 0.9017 - val_loss: 2.6170\n",
      "[INFO] Training model: epoch 19 - 2000/20505 samples\n",
      "Train on 2322 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2322/2322 [==============================] - 22s 9ms/step - loss: 0.9265 - val_loss: 2.7872\n",
      "[INFO] Training model: epoch 19 - 2250/20505 samples\n",
      "Train on 2422 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 0.9825 - val_loss: 2.7195\n",
      "[INFO] Training model: epoch 19 - 2500/20505 samples\n",
      "Train on 2428 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 0.9926 - val_loss: 2.6763\n",
      "[INFO] Training model: epoch 19 - 2750/20505 samples\n",
      "Train on 2476 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 0.9291 - val_loss: 2.7136\n",
      "[INFO] Training model: epoch 19 - 3000/20505 samples\n",
      "Train on 2502 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 10ms/step - loss: 0.8985 - val_loss: 2.5489\n",
      "[INFO] Training model: epoch 19 - 3250/20505 samples\n",
      "Train on 2397 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 22s 9ms/step - loss: 0.9399 - val_loss: 2.9378\n",
      "[INFO] Training model: epoch 19 - 3500/20505 samples\n",
      "Train on 2591 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2591/2591 [==============================] - 25s 9ms/step - loss: 0.9191 - val_loss: 2.4402\n",
      "[INFO] Training model: epoch 19 - 3750/20505 samples\n",
      "Train on 2521 samples, validate on 614 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521/2521 [==============================] - 24s 9ms/step - loss: 0.9959 - val_loss: 2.9614\n",
      "[INFO] Training model: epoch 19 - 4000/20505 samples\n",
      "Train on 2321 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2321/2321 [==============================] - 22s 10ms/step - loss: 1.0236 - val_loss: 3.1506\n",
      "[INFO] Training model: epoch 19 - 4250/20505 samples\n",
      "Train on 2426 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 0.9928 - val_loss: 2.8356\n",
      "[INFO] Training model: epoch 19 - 4500/20505 samples\n",
      "Train on 2430 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9653 - val_loss: 3.2060\n",
      "[INFO] Training model: epoch 19 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.0055 - val_loss: 2.6078\n",
      "[INFO] Training model: epoch 19 - 5000/20505 samples\n",
      "Train on 2490 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.0002 - val_loss: 2.6924\n",
      "[INFO] Training model: epoch 19 - 5250/20505 samples\n",
      "Train on 2494 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 0.9418 - val_loss: 2.9382\n",
      "[INFO] Training model: epoch 19 - 5500/20505 samples\n",
      "Train on 2539 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 10ms/step - loss: 0.9957 - val_loss: 2.8705\n",
      "[INFO] Training model: epoch 19 - 5750/20505 samples\n",
      "Train on 2576 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 0.9907 - val_loss: 3.0956\n",
      "[INFO] Training model: epoch 19 - 6000/20505 samples\n",
      "Train on 2486 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 24s 10ms/step - loss: 0.9790 - val_loss: 2.8852\n",
      "[INFO] Training model: epoch 19 - 6250/20505 samples\n",
      "Train on 2482 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 0.9659 - val_loss: 2.8126\n",
      "[INFO] Training model: epoch 19 - 6500/20505 samples\n",
      "Train on 2393 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.0122 - val_loss: 2.7792\n",
      "[INFO] Training model: epoch 19 - 6750/20505 samples\n",
      "Train on 2409 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 0.9541 - val_loss: 3.0745\n",
      "[INFO] Training model: epoch 19 - 7000/20505 samples\n",
      "Train on 2506 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 0.9594 - val_loss: 2.8316\n",
      "[INFO] Training model: epoch 19 - 7250/20505 samples\n",
      "Train on 2426 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 10ms/step - loss: 0.9579 - val_loss: 3.0970\n",
      "[INFO] Training model: epoch 19 - 7500/20505 samples\n",
      "Train on 2439 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 0.9676 - val_loss: 3.1359\n",
      "[INFO] Training model: epoch 19 - 7750/20505 samples\n",
      "Train on 2503 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 24s 9ms/step - loss: 0.9924 - val_loss: 3.0336\n",
      "[INFO] Training model: epoch 19 - 8000/20505 samples\n",
      "Train on 2453 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 1.0063 - val_loss: 2.7270\n",
      "[INFO] Training model: epoch 19 - 8250/20505 samples\n",
      "Train on 2532 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.0022 - val_loss: 2.8855\n",
      "[INFO] Training model: epoch 19 - 8500/20505 samples\n",
      "Train on 2526 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 1.0056 - val_loss: 2.6776\n",
      "[INFO] Training model: epoch 19 - 8750/20505 samples\n",
      "Train on 2592 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 25s 10ms/step - loss: 0.9807 - val_loss: 2.3118\n",
      "[INFO] Training model: epoch 19 - 9000/20505 samples\n",
      "Train on 2439 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.0218 - val_loss: 3.0609\n",
      "[INFO] Training model: epoch 19 - 9250/20505 samples\n",
      "Train on 2498 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 9ms/step - loss: 1.0473 - val_loss: 2.8939\n",
      "[INFO] Training model: epoch 19 - 9500/20505 samples\n",
      "Train on 2268 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0087 - val_loss: 2.7694\n",
      "[INFO] Training model: epoch 19 - 9750/20505 samples\n",
      "Train on 2501 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 24s 9ms/step - loss: 1.0118 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 19 - 10000/20505 samples\n",
      "Train on 2363 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 22s 9ms/step - loss: 1.0402 - val_loss: 2.7114\n",
      "[INFO] Training model: epoch 19 - 10250/20505 samples\n",
      "Train on 2344 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 23s 10ms/step - loss: 1.0391 - val_loss: 2.6761\n",
      "[INFO] Training model: epoch 19 - 10500/20505 samples\n",
      "Train on 2603 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 25s 10ms/step - loss: 1.0738 - val_loss: 2.8809\n",
      "[INFO] Training model: epoch 19 - 10750/20505 samples\n",
      "Train on 2426 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 9ms/step - loss: 1.0309 - val_loss: 2.9924\n",
      "[INFO] Training model: epoch 19 - 11000/20505 samples\n",
      "Train on 2482 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 0.9618 - val_loss: 2.9536\n",
      "[INFO] Training model: epoch 19 - 11250/20505 samples\n",
      "Train on 2408 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.0816 - val_loss: 2.7447\n",
      "[INFO] Training model: epoch 19 - 11500/20505 samples\n",
      "Train on 2357 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 23s 10ms/step - loss: 1.0541 - val_loss: 2.8024\n",
      "[INFO] Training model: epoch 19 - 11750/20505 samples\n",
      "Train on 2453 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.0147 - val_loss: 2.8662\n",
      "[INFO] Training model: epoch 19 - 12000/20505 samples\n",
      "Train on 2367 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 23s 10ms/step - loss: 1.0537 - val_loss: 2.6470\n",
      "[INFO] Training model: epoch 19 - 12250/20505 samples\n",
      "Train on 2449 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 24s 10ms/step - loss: 1.0041 - val_loss: 2.2383\n",
      "[INFO] Training model: epoch 19 - 12500/20505 samples\n",
      "Train on 2499 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 26s 10ms/step - loss: 1.0798 - val_loss: 2.5349\n",
      "[INFO] Training model: epoch 19 - 12750/20505 samples\n",
      "Train on 2383 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 25s 10ms/step - loss: 1.0249 - val_loss: 3.0277\n",
      "[INFO] Training model: epoch 19 - 13000/20505 samples\n",
      "Train on 2343 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 23s 10ms/step - loss: 1.1097 - val_loss: 2.5419\n",
      "[INFO] Training model: epoch 19 - 13250/20505 samples\n",
      "Train on 2407 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 10ms/step - loss: 1.0463 - val_loss: 2.4872\n",
      "[INFO] Training model: epoch 19 - 13500/20505 samples\n",
      "Train on 2417 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 24s 10ms/step - loss: 1.0459 - val_loss: 3.1451\n",
      "[INFO] Training model: epoch 19 - 13750/20505 samples\n",
      "Train on 2480 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 0.9855 - val_loss: 2.6958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 19 - 14000/20505 samples\n",
      "Train on 2524 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 10ms/step - loss: 1.0499 - val_loss: 2.5189\n",
      "[INFO] Training model: epoch 19 - 14250/20505 samples\n",
      "Train on 2376 samples, validate on 564 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 23s 10ms/step - loss: 1.0014 - val_loss: 2.5998\n",
      "[INFO] Training model: epoch 19 - 14500/20505 samples\n",
      "Train on 2335 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 22s 9ms/step - loss: 1.0450 - val_loss: 3.0092\n",
      "[INFO] Training model: epoch 19 - 14750/20505 samples\n",
      "Train on 2593 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 24s 9ms/step - loss: 1.0362 - val_loss: 2.6478\n",
      "[INFO] Training model: epoch 19 - 15000/20505 samples\n",
      "Train on 2421 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.0505 - val_loss: 2.8659\n",
      "[INFO] Training model: epoch 19 - 15250/20505 samples\n",
      "Train on 2522 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 24s 9ms/step - loss: 1.0652 - val_loss: 2.6258\n",
      "[INFO] Training model: epoch 19 - 15500/20505 samples\n",
      "Train on 2449 samples, validate on 717 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 24s 10ms/step - loss: 1.0636 - val_loss: 2.9232\n",
      "[INFO] Training model: epoch 19 - 15750/20505 samples\n",
      "Train on 2403 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 23s 10ms/step - loss: 1.0571 - val_loss: 3.0399\n",
      "[INFO] Training model: epoch 19 - 16000/20505 samples\n",
      "Train on 2524 samples, validate on 675 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0083 - val_loss: 2.8676\n",
      "[INFO] Training model: epoch 19 - 16250/20505 samples\n",
      "Train on 2461 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 24s 10ms/step - loss: 0.9984 - val_loss: 2.5887\n",
      "[INFO] Training model: epoch 19 - 16500/20505 samples\n",
      "Train on 2434 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 23s 9ms/step - loss: 1.0308 - val_loss: 2.7769\n",
      "[INFO] Training model: epoch 19 - 16750/20505 samples\n",
      "Train on 2553 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2553/2553 [==============================] - 24s 9ms/step - loss: 1.0659 - val_loss: 2.7299\n",
      "[INFO] Training model: epoch 19 - 17000/20505 samples\n",
      "Train on 2473 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.0745 - val_loss: 3.0547\n",
      "[INFO] Training model: epoch 19 - 17250/20505 samples\n",
      "Train on 2510 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 24s 9ms/step - loss: 1.0764 - val_loss: 2.9385\n",
      "[INFO] Training model: epoch 19 - 17500/20505 samples\n",
      "Train on 2435 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 24s 10ms/step - loss: 1.1201 - val_loss: 2.9584\n",
      "[INFO] Training model: epoch 19 - 17750/20505 samples\n",
      "Train on 2464 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.0935 - val_loss: 3.0776\n",
      "[INFO] Training model: epoch 19 - 18000/20505 samples\n",
      "Train on 2401 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 10ms/step - loss: 1.1295 - val_loss: 2.8364\n",
      "[INFO] Training model: epoch 19 - 18250/20505 samples\n",
      "Train on 2578 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.0703 - val_loss: 2.7388\n",
      "[INFO] Training model: epoch 19 - 18500/20505 samples\n",
      "Train on 2528 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 24s 10ms/step - loss: 1.0585 - val_loss: 2.7927\n",
      "[INFO] Training model: epoch 19 - 18750/20505 samples\n",
      "Train on 2482 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.0888 - val_loss: 2.7047\n",
      "[INFO] Training model: epoch 19 - 19000/20505 samples\n",
      "Train on 2529 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.0695 - val_loss: 2.4776\n",
      "[INFO] Training model: epoch 19 - 19250/20505 samples\n",
      "Train on 2456 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.0996 - val_loss: 2.7192\n",
      "[INFO] Training model: epoch 19 - 19500/20505 samples\n",
      "Train on 2517 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 24s 10ms/step - loss: 1.1036 - val_loss: 2.8878\n",
      "[INFO] Training model: epoch 19 - 19750/20505 samples\n",
      "Train on 2550 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 25s 10ms/step - loss: 1.0740 - val_loss: 3.0209\n",
      "[INFO] Training model: epoch 19 - 20000/20505 samples\n",
      "Train on 2456 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.1257 - val_loss: 2.7437\n",
      "[INFO] Training model: epoch 19 - 20250/20505 samples\n",
      "Train on 2457 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 24s 10ms/step - loss: 1.1427 - val_loss: 3.0866\n",
      "[INFO] Training model: epoch 19 - 20500/20505 samples\n",
      "Train on 54 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.7647 - val_loss: 3.9848\n",
      "[INFO] Training model: epoch 20 - 0/20505 samples\n",
      "Train on 2466 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 0.8772 - val_loss: 2.8746\n",
      "[INFO] Training model: epoch 20 - 250/20505 samples\n",
      "Train on 2477 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 24s 10ms/step - loss: 0.8611 - val_loss: 2.7570\n",
      "[INFO] Training model: epoch 20 - 500/20505 samples\n",
      "Train on 2527 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 24s 10ms/step - loss: 0.8867 - val_loss: 3.0272\n",
      "[INFO] Training model: epoch 20 - 750/20505 samples\n",
      "Train on 2540 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 24s 10ms/step - loss: 0.8715 - val_loss: 2.4588\n",
      "[INFO] Training model: epoch 20 - 1000/20505 samples\n",
      "Train on 2527 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 24s 10ms/step - loss: 0.9176 - val_loss: 2.9459\n",
      "[INFO] Training model: epoch 20 - 1250/20505 samples\n",
      "Train on 2461 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 24s 10ms/step - loss: 0.9293 - val_loss: 2.6768\n",
      "[INFO] Training model: epoch 20 - 1500/20505 samples\n",
      "Train on 2429 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 23s 9ms/step - loss: 0.8735 - val_loss: 2.8972\n",
      "[INFO] Training model: epoch 20 - 1750/20505 samples\n",
      "Train on 2484 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 0.9053 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 20 - 2000/20505 samples\n",
      "Train on 2408 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 0.8652 - val_loss: 2.9732\n",
      "[INFO] Training model: epoch 20 - 2250/20505 samples\n",
      "Train on 2370 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 23s 10ms/step - loss: 0.9307 - val_loss: 2.8537\n",
      "[INFO] Training model: epoch 20 - 2500/20505 samples\n",
      "Train on 2472 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 24s 10ms/step - loss: 0.9756 - val_loss: 2.8670\n",
      "[INFO] Training model: epoch 20 - 2750/20505 samples\n",
      "Train on 2423 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 10ms/step - loss: 0.9644 - val_loss: 2.6924\n",
      "[INFO] Training model: epoch 20 - 3000/20505 samples\n",
      "Train on 2454 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 24s 10ms/step - loss: 0.9538 - val_loss: 2.9333\n",
      "[INFO] Training model: epoch 20 - 3250/20505 samples\n",
      "Train on 2446 samples, validate on 669 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2446/2446 [==============================] - 24s 10ms/step - loss: 0.9323 - val_loss: 2.7179\n",
      "[INFO] Training model: epoch 20 - 3500/20505 samples\n",
      "Train on 2406 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 10ms/step - loss: 0.9968 - val_loss: 2.7366\n",
      "[INFO] Training model: epoch 20 - 3750/20505 samples\n",
      "Train on 2356 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2356/2356 [==============================] - 23s 10ms/step - loss: 0.9795 - val_loss: 2.9514\n",
      "[INFO] Training model: epoch 20 - 4000/20505 samples\n",
      "Train on 2561 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 25s 10ms/step - loss: 0.9739 - val_loss: 2.7247\n",
      "[INFO] Training model: epoch 20 - 4250/20505 samples\n",
      "Train on 2412 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 23s 10ms/step - loss: 0.9360 - val_loss: 2.9094\n",
      "[INFO] Training model: epoch 20 - 4500/20505 samples\n",
      "Train on 2430 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9404 - val_loss: 3.0012\n",
      "[INFO] Training model: epoch 20 - 4750/20505 samples\n",
      "Train on 2456 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 0.9547 - val_loss: 3.2422\n",
      "[INFO] Training model: epoch 20 - 5000/20505 samples\n",
      "Train on 2458 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 24s 10ms/step - loss: 0.9714 - val_loss: 2.8212\n",
      "[INFO] Training model: epoch 20 - 5250/20505 samples\n",
      "Train on 2479 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 24s 10ms/step - loss: 0.9516 - val_loss: 2.5386\n",
      "[INFO] Training model: epoch 20 - 5500/20505 samples\n",
      "Train on 2413 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 9ms/step - loss: 0.8988 - val_loss: 3.0341\n",
      "[INFO] Training model: epoch 20 - 5750/20505 samples\n",
      "Train on 2461 samples, validate on 562 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 0.8881 - val_loss: 2.9847\n",
      "[INFO] Training model: epoch 20 - 6000/20505 samples\n",
      "Train on 2446 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 0.9611 - val_loss: 2.5921\n",
      "[INFO] Training model: epoch 20 - 6250/20505 samples\n",
      "Train on 2430 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9322 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 20 - 6500/20505 samples\n",
      "Train on 2413 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 0.9243 - val_loss: 2.8292\n",
      "[INFO] Training model: epoch 20 - 6750/20505 samples\n",
      "Train on 2547 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 0.9554 - val_loss: 2.8236\n",
      "[INFO] Training model: epoch 20 - 7000/20505 samples\n",
      "Train on 2522 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 0.9682 - val_loss: 3.2812\n",
      "[INFO] Training model: epoch 20 - 7250/20505 samples\n",
      "Train on 2483 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 24s 10ms/step - loss: 0.9026 - val_loss: 2.8475\n",
      "[INFO] Training model: epoch 20 - 7500/20505 samples\n",
      "Train on 2418 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 9ms/step - loss: 0.9574 - val_loss: 2.8752\n",
      "[INFO] Training model: epoch 20 - 7750/20505 samples\n",
      "Train on 2487 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 1.0249 - val_loss: 2.6443\n",
      "[INFO] Training model: epoch 20 - 8000/20505 samples\n",
      "Train on 2428 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 10ms/step - loss: 1.0199 - val_loss: 2.9591\n",
      "[INFO] Training model: epoch 20 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.0000 - val_loss: 2.7896\n",
      "[INFO] Training model: epoch 20 - 8500/20505 samples\n",
      "Train on 2417 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 23s 10ms/step - loss: 0.9377 - val_loss: 2.9389\n",
      "[INFO] Training model: epoch 20 - 8750/20505 samples\n",
      "Train on 2433 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 10ms/step - loss: 0.9886 - val_loss: 2.9208\n",
      "[INFO] Training model: epoch 20 - 9000/20505 samples\n",
      "Train on 2340 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 23s 10ms/step - loss: 0.9615 - val_loss: 2.9226\n",
      "[INFO] Training model: epoch 20 - 9250/20505 samples\n",
      "Train on 2580 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 24s 9ms/step - loss: 0.9418 - val_loss: 2.7592\n",
      "[INFO] Training model: epoch 20 - 9500/20505 samples\n",
      "Train on 2380 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.0275 - val_loss: 2.7439\n",
      "[INFO] Training model: epoch 20 - 9750/20505 samples\n",
      "Train on 2457 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 0.9699 - val_loss: 2.8970\n",
      "[INFO] Training model: epoch 20 - 10000/20505 samples\n",
      "Train on 2494 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 24s 10ms/step - loss: 1.0251 - val_loss: 3.3458\n",
      "[INFO] Training model: epoch 20 - 10250/20505 samples\n",
      "Train on 2471 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 24s 10ms/step - loss: 1.0047 - val_loss: 2.8272\n",
      "[INFO] Training model: epoch 20 - 10500/20505 samples\n",
      "Train on 2389 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.0217 - val_loss: 3.0992\n",
      "[INFO] Training model: epoch 20 - 10750/20505 samples\n",
      "Train on 2405 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 10ms/step - loss: 1.0618 - val_loss: 3.2234\n",
      "[INFO] Training model: epoch 20 - 11000/20505 samples\n",
      "Train on 2533 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 0.9685 - val_loss: 2.9900\n",
      "[INFO] Training model: epoch 20 - 11250/20505 samples\n",
      "Train on 2476 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 24s 10ms/step - loss: 1.0137 - val_loss: 2.9637\n",
      "[INFO] Training model: epoch 20 - 11500/20505 samples\n",
      "Train on 2389 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 0.9836 - val_loss: 2.8098\n",
      "[INFO] Training model: epoch 20 - 11750/20505 samples\n",
      "Train on 2477 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 0.9760 - val_loss: 3.0091\n",
      "[INFO] Training model: epoch 20 - 12000/20505 samples\n",
      "Train on 2456 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 24s 10ms/step - loss: 1.0020 - val_loss: 3.0511\n",
      "[INFO] Training model: epoch 20 - 12250/20505 samples\n",
      "Train on 2473 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.0514 - val_loss: 2.9545\n",
      "[INFO] Training model: epoch 20 - 12500/20505 samples\n",
      "Train on 2389 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.0055 - val_loss: 2.9810\n",
      "[INFO] Training model: epoch 20 - 12750/20505 samples\n",
      "Train on 2500 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 10ms/step - loss: 0.9591 - val_loss: 2.8290\n",
      "[INFO] Training model: epoch 20 - 13000/20505 samples\n",
      "Train on 2439 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.0339 - val_loss: 2.6524\n",
      "[INFO] Training model: epoch 20 - 13250/20505 samples\n",
      "Train on 2446 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 24s 10ms/step - loss: 1.0551 - val_loss: 2.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 20 - 13500/20505 samples\n",
      "Train on 2423 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 10ms/step - loss: 1.0256 - val_loss: 2.7173\n",
      "[INFO] Training model: epoch 20 - 13750/20505 samples\n",
      "Train on 2512 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 10ms/step - loss: 1.0480 - val_loss: 3.1636\n",
      "[INFO] Training model: epoch 20 - 14000/20505 samples\n",
      "Train on 2441 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 10ms/step - loss: 1.0378 - val_loss: 2.8572\n",
      "[INFO] Training model: epoch 20 - 14250/20505 samples\n",
      "Train on 2316 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 22s 10ms/step - loss: 1.0007 - val_loss: 2.7598\n",
      "[INFO] Training model: epoch 20 - 14500/20505 samples\n",
      "Train on 2519 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 24s 9ms/step - loss: 1.0588 - val_loss: 2.6922\n",
      "[INFO] Training model: epoch 20 - 14750/20505 samples\n",
      "Train on 2357 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 22s 9ms/step - loss: 1.0280 - val_loss: 2.8910\n",
      "[INFO] Training model: epoch 20 - 15000/20505 samples\n",
      "Train on 2475 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.0677 - val_loss: 3.1557\n",
      "[INFO] Training model: epoch 20 - 15250/20505 samples\n",
      "Train on 2609 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 25s 10ms/step - loss: 1.0872 - val_loss: 2.7097\n",
      "[INFO] Training model: epoch 20 - 15500/20505 samples\n",
      "Train on 2500 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 10ms/step - loss: 0.9392 - val_loss: 2.8872\n",
      "[INFO] Training model: epoch 20 - 15750/20505 samples\n",
      "Train on 2351 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 1.0663 - val_loss: 2.4584\n",
      "[INFO] Training model: epoch 20 - 16000/20505 samples\n",
      "Train on 2499 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 24s 10ms/step - loss: 1.0225 - val_loss: 2.6461\n",
      "[INFO] Training model: epoch 20 - 16250/20505 samples\n",
      "Train on 2469 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.0650 - val_loss: 3.0242\n",
      "[INFO] Training model: epoch 20 - 16500/20505 samples\n",
      "Train on 2454 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 24s 10ms/step - loss: 1.0914 - val_loss: 2.9343\n",
      "[INFO] Training model: epoch 20 - 16750/20505 samples\n",
      "Train on 2459 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 24s 10ms/step - loss: 1.1257 - val_loss: 2.6547\n",
      "[INFO] Training model: epoch 20 - 17000/20505 samples\n",
      "Train on 2529 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 10ms/step - loss: 1.0780 - val_loss: 2.7337\n",
      "[INFO] Training model: epoch 20 - 17250/20505 samples\n",
      "Train on 2400 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 23s 10ms/step - loss: 1.0419 - val_loss: 2.9985\n",
      "[INFO] Training model: epoch 20 - 17500/20505 samples\n",
      "Train on 2546 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 24s 9ms/step - loss: 1.0504 - val_loss: 2.9189\n",
      "[INFO] Training model: epoch 20 - 17750/20505 samples\n",
      "Train on 2478 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 1.0307 - val_loss: 2.5250\n",
      "[INFO] Training model: epoch 20 - 18000/20505 samples\n",
      "Train on 2369 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2369/2369 [==============================] - 23s 10ms/step - loss: 1.0685 - val_loss: 2.6356\n",
      "[INFO] Training model: epoch 20 - 18250/20505 samples\n",
      "Train on 2464 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 24s 10ms/step - loss: 1.0587 - val_loss: 2.7259\n",
      "[INFO] Training model: epoch 20 - 18500/20505 samples\n",
      "Train on 2440 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.0634 - val_loss: 3.1154\n",
      "[INFO] Training model: epoch 20 - 18750/20505 samples\n",
      "Train on 2492 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.0790 - val_loss: 2.7095\n",
      "[INFO] Training model: epoch 20 - 19000/20505 samples\n",
      "Train on 2520 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 24s 9ms/step - loss: 1.0600 - val_loss: 2.6155\n",
      "[INFO] Training model: epoch 20 - 19250/20505 samples\n",
      "Train on 2466 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 10ms/step - loss: 1.0733 - val_loss: 2.6178\n",
      "[INFO] Training model: epoch 20 - 19500/20505 samples\n",
      "Train on 2479 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 24s 10ms/step - loss: 1.0512 - val_loss: 2.6358\n",
      "[INFO] Training model: epoch 20 - 19750/20505 samples\n",
      "Train on 2402 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 24s 10ms/step - loss: 1.0468 - val_loss: 2.4997\n",
      "[INFO] Training model: epoch 20 - 20000/20505 samples\n",
      "Train on 2452 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1216 - val_loss: 2.6810\n",
      "[INFO] Training model: epoch 20 - 20250/20505 samples\n",
      "Train on 2506 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1131 - val_loss: 2.7156\n",
      "[INFO] Training model: epoch 20 - 20500/20505 samples\n",
      "Train on 39 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.8315 - val_loss: 3.1535\n"
     ]
    }
   ],
   "source": [
    "# Continue from loaded epoch number or new epoch if not loaded\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(num_examples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    Y_train = Y_train[indices]\n",
    "    indices = np.arange(num_test)\n",
    "    np.random.shuffle(indices)\n",
    "    X_test = X_test[indices]\n",
    "    Y_test = Y_test[indices]\n",
    "\n",
    "    # This for loop rotates through NB_SET samples at a time to avoid memory issues\n",
    "    # E.g. Training 100 sequences at a time\n",
    "    for i in range(0, num_examples, NB_SET):\n",
    "        if i + NB_SET >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + NB_SET\n",
    "        \n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "            \n",
    "        I_1_train, I_2_train, Y_set_train = generate_set(X_train, Y_train, i_end, i)\n",
    "        I_1_test, I_2_test, Y_set_test = generate_set(X_test, Y_test, i_test_end, i_test)\n",
    "              \n",
    "        print('[INFO] Training model: epoch {} - {}/{} samples'.format(k, i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size=BATCH_SIZE, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "        # Get history and apppend new data to running set here\n",
    "    model.save_weights('v2_kerascheckpoint_epoch_{}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "2462/2462 [==============================] - 23s 9ms/step - loss: 2.1453 - val_loss: 2.2773\n",
    "[INFO] Training model: epoch 2 - 20250/20505 samples\n",
    "Train on 2478 samples, validate on 686 samples\n",
    "Epoch 1/1\n",
    "\n",
    "2478/2478 [==============================] - 23s 9ms/step - loss: 2.1018 - val_loss: 2.4592\n",
    "[INFO] Training model: epoch 2 - 20500/20505 samples\n",
    "Train on 36 samples, validate on 12 samples\n",
    "Epoch 1/1\n",
    "36/36 [==============================] - 1s 15ms/step - loss: 2.5730 - val_loss: 3.4734\n",
    "\n",
    "[INFO] Training model: epoch 20 - 20000/20505 samples\n",
    "Train on 2452 samples, validate on 662 samples\n",
    "Epoch 1/1\n",
    "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1216 - val_loss: 2.6810\n",
    "[INFO] Training model: epoch 20 - 20250/20505 samples\n",
    "Train on 2506 samples, validate on 607 samples\n",
    "Epoch 1/1\n",
    "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1131 - val_loss: 2.7156\n",
    "[INFO] Training model: epoch 20 - 20500/20505 samples\n",
    "Train on 39 samples, validate on 22 samples\n",
    "Epoch 1/1\n",
    "39/39 [==============================] - 1s 13ms/step - loss: 0.8315 - val_loss: 3.1535\n",
    "```\n",
    "\n",
    "So using the shared embedding appears to provide a small advantage in reducing our loss function. It also lowers the number of parameters for our model, which is a good thing as it reduces over-fitting and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9416ff6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've trained our model we need some code to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: 1 a method of memory page de in a computer system comprising a plurality of virtual machine partitions managed by a hypervisor wherein each virtual machine is assigned a different dedicated memory par\n",
      "\n",
      "Predicted title is: virtual machine using virtual machine i o port  (with prob 0.00024153314510963288). \n",
      " Test title is: memory page de in a computer system that includes a plurality of virtual machines  \n",
      "---\n",
      "Sample of claim text: 1 a method for operating a server comprising a processor for automatically generating an end user interface for working with the data within a relational database defined within a relational whose dat\n",
      "\n",
      "Predicted title is: method and system for managing database objects in a database  (with prob 0.0003222082082124349). \n",
      " Test title is: system and method for generating automatic user interface for complex or large databases  \n",
      "---\n",
      "Sample of claim text: 1 a method of processing user input in a three dimensional coordinate system comprising receiving a user input of an origin reset for the three dimensional coordinate system responsive to receiving th\n",
      "\n",
      "Predicted title is: user interface based on user interaction surfaces type sources therein  (with prob 0.0009777329678170813). \n",
      " Test title is: three dimensional user input  \n",
      "---\n",
      "Sample of claim text: 1 a digital logic circuit comprising a programmable logic device configured to include a pipeline that comprises a matching stage and a downstream extension stage the matching stage being configured t\n",
      "\n",
      "Predicted title is: system and method for performing expression based on instruction time  (with prob 9.03439755326292e-05). \n",
      " Test title is: method and apparatus for performing similarity searching  \n",
      "---\n",
      "Sample of claim text: 1 a method for deriving information from a network that is used to model web traffic data the method comprising receiving by a web traffic analysis server web traffic data that is collected by a websi\n",
      "\n",
      "Predicted title is: method and system for determining the presence of a communication network information and method of the same  (with prob 0.00038204782414073336). \n",
      " Test title is: knowledge discovery from networks  \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Set up dictionary to translate indices to words\n",
    "y_dictionary = dict(\n",
    "            (i, char) for char, i in t_joint.word_index.items()\n",
    "        )\n",
    "\n",
    "x_dictionary = dict(\n",
    "            (i, char) for char, i in t_joint.word_index.items()\n",
    "        )\n",
    "\n",
    "def seq2text(seq, dictionary):\n",
    "    text = ''\n",
    "    for k in seq:\n",
    "        k = k.astype(int)\n",
    "        # Adapted to take account of different control integers\n",
    "        if k not in [t_joint.word_index[\"stopseq\"], t_joint.word_index[\"startseq\"], 0] and k < (len(dictionary)-1):\n",
    "            w = dictionary[k]\n",
    "            text = text + w + ' '\n",
    "    return text\n",
    "\n",
    "def greedy_decoder(X_seq):\n",
    "    # reformat input seq\n",
    "    input_seq = np.zeros((1, X_max_len))\n",
    "    input_seq[0, :] = X_seq\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1, y_max_len))\n",
    "    # Add start token integer to end of ans_partial input - initially [0,0,...BOS]\n",
    "    ans_partial[0, -1] = t_joint.word_index[\"startseq\"]  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(y_max_len - 1):\n",
    "        ye = model.predict([input_seq, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        # It is this line that sets how our training data should be arranged - need to change both\n",
    "        # the line below shifts the existing ans_partial by 1 to the left - [0, 0, ..., BOS, 0]\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        # This then adds the newly decoded word onto the end of ans_partial\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == t_joint.word_index[\"stopseq\"]:  #  the index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = seq2text(ans_partial[0], y_dictionary)\n",
    "    return(text, prob)\n",
    "\n",
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    text, prob = greedy_decoder(X_test[i])\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {} (with prob {}). \\n Test title is: {} \\n---\".format(text, prob, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Results\n",
    "\n",
    "From this training there now appears more of a link between the claim text and the predicted title. The model seems to be learning a few patterns such as - \"method and system for creating a [] method and system method\". \n",
    "\n",
    "This result seems close:\n",
    "```\n",
    "Sample of claim text: 1 an apparatus comprising a capacitive sense array and a processing device wherein the capacitive sense array is configured to detect a presence of a touch object or a stylus wherein the capacitive se\n",
    "\n",
    "Predicted title is: method and apparatus for displaying a touch screen method and apparatus for the same  (with prob 1.9565373226245597e-05). \n",
    " Test title is: capacitive sense array for detecting touch objects and an active stylus  \n",
    " ```\n",
    " \n",
    " Training still appears unstable. Some of this may be due to the shuffling for regularisation.\n",
    " \n",
    " The results appear an improvement though on the previous model. It is worth keeping this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options for Further Investigation\n",
    "\n",
    "It may be worth experimenting with different training parameters and not shuffling the data. Lowering the batch size might reduce some of the loss variance.\n",
    "\n",
    "\n",
    "Also adding some regularisation may help prevent overfitting. Maybe by adding some dropout (0.2?) to the LSTMs and by adding an L2 regulariser to the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chollet/Brownlee Model\n",
    "\n",
    "This is more of a true sequence-to-sequence model, and is thus slightly more involved.\n",
    "\n",
    "Our model consists of two portions - a portion for training and a portion for inference (i.e. for actually predicting new titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "def target_one_hot(input_seqs, seq_max_len, vocab_len):\n",
    "    \"\"\" Convert a sequence of integers to a one element shifted sequence of one-hot vectors.\"\"\"\n",
    "    one_hot_out = np.zeros((len(input_seqs), seq_max_len, vocab_len))\n",
    "    for i, sequence in enumerate(input_seqs):\n",
    "        for t, word_int in enumerate(sequence):\n",
    "            if t > 0:\n",
    "                # Shift decoder target get so it is one ahead\n",
    "                one_hot_out[i, t-1, word_int] = 1\n",
    "    return one_hot_out\n",
    "\n",
    "# We need to convert this for our present problem - this is similar to our generate dataset above\n",
    "# prepare data for the LSTM\n",
    "def get_dataset(X, Y, i, i_end, num_decoder_tokens):\n",
    "    \"\"\"Return encoder_input_data, decoder_input_data, and decoder_target_data, latter as one-hot\"\"\"\n",
    "    encoder_input_data = X[i:i_end]\n",
    "    decoder_input_data = Y[i:i_end]\n",
    "    decoder_target_data = target_one_hot(decoder_input_data, Y.shape[1], num_decoder_tokens)\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(vocab_size, latent_dim, embedding_matrix):\n",
    "    # define training encoder\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    Shared_Embedding = Embedding(\n",
    "        output_dim=latent_dim, \n",
    "        input_dim=vocab_size, \n",
    "        weights=[embedding_matrix]\n",
    "    )\n",
    "    encoder_embedding = Shared_Embedding(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    # Possibly share the embedding below\n",
    "    decoder_embedding = Shared_Embedding(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    # Need to adjust this line for the embedding\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def train_model(X_train, Y_train, X_test, Y_test, model, set_size, batch_size, num_decoder_tokens):\n",
    "    \"\"\" Code to train model in sets of set_size.\"\"\"\n",
    "    num_examples = len(X_train)\n",
    "    num_test = len(X_test)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    # Loop here to avoid memory issues with the target one hot vector\n",
    "    for i in range(0, num_examples, set_size):\n",
    "        if i + set_size >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + set_size\n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "        # Generate small sets of train and test data\n",
    "        I_1_train, I_2_train, Y_set_train = get_dataset(X_train, Y_train, i, i_end, num_decoder_tokens)\n",
    "        I_1_test, I_2_test, Y_set_test = get_dataset(X_test, Y_test, i_test, i_test_end, num_decoder_tokens)\n",
    "        print('[INFO] Training model: {}/{} samples'.format(i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size= batch_size, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "# define model\n",
    "train, infenc, infdec = define_models(vocab_size, word_embedding_size, embedding_matrix)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_14 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_13 (InputLayer)           (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_5 (Embedding)         (None, None, 100)    250000      input_13[0][0]                   \n",
      "                                                                 input_14[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lstm_9 (LSTM)                   [(None, 100), (None, 80400       embedding_5[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_10 (LSTM)                  [(None, None, 100),  80400       embedding_5[1][0]                \n",
      "                                                                 lstm_9[0][1]                     \n",
      "                                                                 lstm_9[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_5 (Dense)                 (None, None, 2500)   252500      lstm_10[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 663,300\n",
      "Trainable params: 663,300\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loss = []\n",
    "val_loss = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 34,  83,  87,   3, 644,  35,   0,   0,   0,   0,   0,   0,   0,\n",
       "         0,   0,   0,   0,   0,   0,   0,   0,   0], dtype=int32)"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_test[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,  302, 1116,  219,    6,  378,   78,   30,   35,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(34, 35)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t_joint.word_index[\"startseq\"], t_joint.word_index[\"stopseq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------\n",
      " Epoch -  0\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 77s 15ms/step - loss: 1.9163 - acc: 0.6911 - val_loss: 1.8874 - val_acc: 0.6925\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.8805 - acc: 0.6966 - val_loss: 1.9176 - val_acc: 0.6897\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.8370 - acc: 0.7020 - val_loss: 1.8404 - val_acc: 0.7031\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 1.8405 - acc: 0.7008 - val_loss: 1.7651 - val_acc: 0.7139\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 9s 18ms/step - loss: 1.8456 - acc: 0.7007 - val_loss: 2.0071 - val_acc: 0.6729\n",
      "\n",
      "--------\n",
      " Epoch -  1\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.7955 - acc: 0.7064 - val_loss: 1.7826 - val_acc: 0.7068\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.7731 - acc: 0.7086 - val_loss: 1.8238 - val_acc: 0.7022\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 1.7411 - acc: 0.7126 - val_loss: 1.7622 - val_acc: 0.7114\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.7553 - acc: 0.7087 - val_loss: 1.7029 - val_acc: 0.7206\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.7702 - acc: 0.7086 - val_loss: 1.9350 - val_acc: 0.6832\n",
      "\n",
      "--------\n",
      " Epoch -  2\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.7244 - acc: 0.7128 - val_loss: 1.7251 - val_acc: 0.7124\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 1.7078 - acc: 0.7152 - val_loss: 1.7720 - val_acc: 0.7087\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.6816 - acc: 0.7180 - val_loss: 1.7184 - val_acc: 0.7156\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.6988 - acc: 0.7138 - val_loss: 1.6630 - val_acc: 0.7235\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.7144 - acc: 0.7126 - val_loss: 1.8894 - val_acc: 0.6897\n",
      "\n",
      "--------\n",
      " Epoch -  3\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.6704 - acc: 0.7174 - val_loss: 1.6824 - val_acc: 0.7166\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.6544 - acc: 0.7191 - val_loss: 1.7325 - val_acc: 0.7125\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 1.6294 - acc: 0.7215 - val_loss: 1.6811 - val_acc: 0.7174\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.6454 - acc: 0.7180 - val_loss: 1.6243 - val_acc: 0.7275\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.6600 - acc: 0.7170 - val_loss: 1.8476 - val_acc: 0.6929\n",
      "\n",
      "--------\n",
      " Epoch -  4\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 1.6199 - acc: 0.7211 - val_loss: 1.6445 - val_acc: 0.7188\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.6057 - acc: 0.7227 - val_loss: 1.6938 - val_acc: 0.7151\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.5825 - acc: 0.7251 - val_loss: 1.6514 - val_acc: 0.7198\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 1.5993 - acc: 0.7212 - val_loss: 1.5952 - val_acc: 0.7300\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 10s 19ms/step - loss: 1.6141 - acc: 0.7199 - val_loss: 1.8181 - val_acc: 0.6933\n",
      "\n",
      "--------\n",
      " Epoch -  5\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 1.5780 - acc: 0.7242 - val_loss: 1.6171 - val_acc: 0.7219\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 1.5641 - acc: 0.7253 - val_loss: 1.6679 - val_acc: 0.7177\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.5419 - acc: 0.7278 - val_loss: 1.6236 - val_acc: 0.7231\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.5596 - acc: 0.7239 - val_loss: 1.5733 - val_acc: 0.7310\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.5751 - acc: 0.7213 - val_loss: 1.7973 - val_acc: 0.6961\n",
      "\n",
      "--------\n",
      " Epoch -  6\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.5385 - acc: 0.7277 - val_loss: 1.5934 - val_acc: 0.7256\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 1.5251 - acc: 0.7285 - val_loss: 1.6468 - val_acc: 0.7201\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.5044 - acc: 0.7314 - val_loss: 1.6046 - val_acc: 0.7244\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.5231 - acc: 0.7266 - val_loss: 1.5540 - val_acc: 0.7314\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.5399 - acc: 0.7249 - val_loss: 1.7775 - val_acc: 0.6983\n",
      "\n",
      "--------\n",
      " Epoch -  7\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.5044 - acc: 0.7305 - val_loss: 1.5740 - val_acc: 0.7269\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 1.4927 - acc: 0.7321 - val_loss: 1.6313 - val_acc: 0.7208\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 83s 17ms/step - loss: 1.4722 - acc: 0.7337 - val_loss: 1.5912 - val_acc: 0.7257\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4917 - acc: 0.7296 - val_loss: 1.5415 - val_acc: 0.7331\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.5047 - acc: 0.7276 - val_loss: 1.7628 - val_acc: 0.6997\n",
      "\n",
      "--------\n",
      " Epoch -  8\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4736 - acc: 0.7330 - val_loss: 1.5628 - val_acc: 0.7263\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4629 - acc: 0.7338 - val_loss: 1.6203 - val_acc: 0.7221\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4427 - acc: 0.7359 - val_loss: 1.5820 - val_acc: 0.7262\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4632 - acc: 0.7326 - val_loss: 1.5304 - val_acc: 0.7337\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 15ms/step - loss: 1.4776 - acc: 0.7293 - val_loss: 1.7544 - val_acc: 0.7015\n",
      "\n",
      "--------\n",
      " Epoch -  9\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4452 - acc: 0.7352 - val_loss: 1.5511 - val_acc: 0.7279\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4362 - acc: 0.7361 - val_loss: 1.6119 - val_acc: 0.7223\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 79s 16ms/step - loss: 1.4166 - acc: 0.7385 - val_loss: 1.5740 - val_acc: 0.7275\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4374 - acc: 0.7346 - val_loss: 1.5234 - val_acc: 0.7340\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.4496 - acc: 0.7321 - val_loss: 1.7466 - val_acc: 0.6994\n",
      "\n",
      "--------\n",
      " Epoch -  10\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4203 - acc: 0.7368 - val_loss: 1.5447 - val_acc: 0.7285\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 79s 16ms/step - loss: 1.4109 - acc: 0.7380 - val_loss: 1.6050 - val_acc: 0.7226\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3924 - acc: 0.7402 - val_loss: 1.5691 - val_acc: 0.7277\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.4132 - acc: 0.7367 - val_loss: 1.5189 - val_acc: 0.7348\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 16ms/step - loss: 1.4231 - acc: 0.7324 - val_loss: 1.7476 - val_acc: 0.7001\n",
      "\n",
      "--------\n",
      " Epoch -  11\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3959 - acc: 0.7391 - val_loss: 1.5382 - val_acc: 0.7300\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3878 - acc: 0.7395 - val_loss: 1.6024 - val_acc: 0.7238\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3700 - acc: 0.7424 - val_loss: 1.5668 - val_acc: 0.7291\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3910 - acc: 0.7383 - val_loss: 1.5160 - val_acc: 0.7364\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 15ms/step - loss: 1.4004 - acc: 0.7351 - val_loss: 1.7410 - val_acc: 0.7015\n",
      "\n",
      "--------\n",
      " Epoch -  12\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3733 - acc: 0.7413 - val_loss: 1.5367 - val_acc: 0.7296\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.3653 - acc: 0.7419 - val_loss: 1.6016 - val_acc: 0.7259\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 79s 16ms/step - loss: 1.3481 - acc: 0.7446 - val_loss: 1.5659 - val_acc: 0.7292\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3685 - acc: 0.7404 - val_loss: 1.5169 - val_acc: 0.7367\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 8s 17ms/step - loss: 1.3784 - acc: 0.7374 - val_loss: 1.7416 - val_acc: 0.6983\n",
      "\n",
      "--------\n",
      " Epoch -  13\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3520 - acc: 0.7432 - val_loss: 1.5350 - val_acc: 0.7292\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 80s 16ms/step - loss: 1.3447 - acc: 0.7440 - val_loss: 1.6017 - val_acc: 0.7240\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 81s 16ms/step - loss: 1.3269 - acc: 0.7467 - val_loss: 1.5640 - val_acc: 0.7291\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.3490 - acc: 0.7427 - val_loss: 1.5135 - val_acc: 0.7366\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 9s 17ms/step - loss: 1.3543 - acc: 0.7391 - val_loss: 1.7443 - val_acc: 0.7011\n",
      "\n",
      "--------\n",
      " Epoch -  14\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.3313 - acc: 0.7451 - val_loss: 1.5359 - val_acc: 0.7295\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000/5000 [==============================] - 118s 24ms/step - loss: 1.3247 - acc: 0.7461 - val_loss: 1.6028 - val_acc: 0.7251\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 122s 24ms/step - loss: 1.3075 - acc: 0.7483 - val_loss: 1.5648 - val_acc: 0.7285\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 119s 24ms/step - loss: 1.3289 - acc: 0.7444 - val_loss: 1.5176 - val_acc: 0.7366\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 13s 25ms/step - loss: 1.3358 - acc: 0.7423 - val_loss: 1.7427 - val_acc: 0.7011\n",
      "\n",
      "--------\n",
      " Epoch -  15\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 117s 23ms/step - loss: 1.3116 - acc: 0.7471 - val_loss: 1.5377 - val_acc: 0.7299\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 125s 25ms/step - loss: 1.3049 - acc: 0.7479 - val_loss: 1.6031 - val_acc: 0.7244\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 119s 24ms/step - loss: 1.2875 - acc: 0.7505 - val_loss: 1.5660 - val_acc: 0.7302\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 1.3095 - acc: 0.7464 - val_loss: 1.5178 - val_acc: 0.7367\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 13s 26ms/step - loss: 1.3166 - acc: 0.7428 - val_loss: 1.7445 - val_acc: 0.6990\n",
      "\n",
      "--------\n",
      " Epoch -  16\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 1.2919 - acc: 0.7494 - val_loss: 1.5387 - val_acc: 0.7297\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 119s 24ms/step - loss: 1.2855 - acc: 0.7498 - val_loss: 1.6071 - val_acc: 0.7241\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 1.2691 - acc: 0.7523 - val_loss: 1.5672 - val_acc: 0.7303\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 117s 23ms/step - loss: 1.2916 - acc: 0.7474 - val_loss: 1.5193 - val_acc: 0.7378\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 12s 24ms/step - loss: 1.2956 - acc: 0.7464 - val_loss: 1.7504 - val_acc: 0.6990\n",
      "\n",
      "--------\n",
      " Epoch -  17\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 118s 24ms/step - loss: 1.2731 - acc: 0.7513 - val_loss: 1.5425 - val_acc: 0.7304\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 117s 23ms/step - loss: 1.2671 - acc: 0.7515 - val_loss: 1.6094 - val_acc: 0.7249\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2508 - acc: 0.7542 - val_loss: 1.5749 - val_acc: 0.7299\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2731 - acc: 0.7502 - val_loss: 1.5233 - val_acc: 0.7373\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 13s 25ms/step - loss: 1.2802 - acc: 0.7473 - val_loss: 1.7515 - val_acc: 0.7008\n",
      "\n",
      "--------\n",
      " Epoch -  18\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2554 - acc: 0.7525 - val_loss: 1.5447 - val_acc: 0.7303\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 117s 23ms/step - loss: 1.2492 - acc: 0.7539 - val_loss: 1.6139 - val_acc: 0.7239\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 121s 24ms/step - loss: 1.2334 - acc: 0.7561 - val_loss: 1.5761 - val_acc: 0.7295\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 118s 24ms/step - loss: 1.2548 - acc: 0.7517 - val_loss: 1.5285 - val_acc: 0.7367\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 10s 21ms/step - loss: 1.2605 - acc: 0.7509 - val_loss: 1.7589 - val_acc: 0.6979\n",
      "\n",
      "--------\n",
      " Epoch -  19\n",
      "[INFO] Training model: 0/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 118s 24ms/step - loss: 1.2376 - acc: 0.7554 - val_loss: 1.5488 - val_acc: 0.7297\n",
      "[INFO] Training model: 5000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2313 - acc: 0.7557 - val_loss: 1.6187 - val_acc: 0.7252\n",
      "[INFO] Training model: 10000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2158 - acc: 0.7580 - val_loss: 1.5834 - val_acc: 0.7288\n",
      "[INFO] Training model: 15000/20505 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 118s 24ms/step - loss: 1.2380 - acc: 0.7529 - val_loss: 1.5333 - val_acc: 0.7379\n",
      "[INFO] Training model: 20000/20505 samples\n",
      "Train on 505 samples, validate on 127 samples\n",
      "Epoch 1/1\n",
      "505/505 [==============================] - 13s 25ms/step - loss: 1.2426 - acc: 0.7504 - val_loss: 1.7648 - val_acc: 0.6979\n"
     ]
    }
   ],
   "source": [
    "# setup variables\n",
    "epochs = 20\n",
    "batch_size = 32\n",
    "set_size = 5000\n",
    "\n",
    "for e in range(0, epochs):\n",
    "    print(\"\\n--------\\n Epoch - \", e)\n",
    "    train, tl, vl = train_model(X_train, Y_train, X_test, Y_test, train, set_size, batch_size, num_decoder_tokens)\n",
    "    train_loss += tl\n",
    "    val_loss += vl\n",
    "    model.save_weights(\"chollet_weights_v2.hdf5\", overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Again this seems to offer an improvement by lowering our loss.\n",
    "\n",
    "```\n",
    "[INFO] Training model: 15000/20505 samples\n",
    "Train on 5000 samples, validate on 1250 samples\n",
    "Epoch 1/1\n",
    "5000/5000 [==============================] - 70s 14ms/step - loss: 1.9611 - acc: 0.6856 - val_loss: 1.9311 - val_acc: 0.6896\n",
    "[INFO] Training model: 20000/20505 samples\n",
    "Train on 505 samples, validate on 127 samples\n",
    "Epoch 1/1\n",
    "505/505 [==============================] - 7s 14ms/step - loss: 1.9663 - acc: 0.6882 - val_loss: 1.9609 - val_acc: 0.6883\n",
    "```\n",
    "After 20 epochs.\n",
    "```\n",
    "[INFO] Training model: 10000/20505 samples\n",
    "Train on 5000 samples, validate on 1250 samples\n",
    "Epoch 1/1\n",
    "5000/5000 [==============================] - 116s 23ms/step - loss: 1.2158 - acc: 0.7580 - val_loss: 1.5834 - val_acc: 0.7288\n",
    "[INFO] Training model: 15000/20505 samples\n",
    "Train on 5000 samples, validate on 1250 samples\n",
    "Epoch 1/1\n",
    "5000/5000 [==============================] - 118s 24ms/step - loss: 1.2380 - acc: 0.7529 - val_loss: 1.5333 - val_acc: 0.7379\n",
    "[INFO] Training model: 20000/20505 samples\n",
    "Train on 505 samples, validate on 127 samples\n",
    "Epoch 1/1\n",
    "505/505 [==============================] - 13s 25ms/step - loss: 1.2426 - acc: 0.7504 - val_loss: 1.7648 - val_acc: 0.6979\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f940dfcb048>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our training and model loss end up lower and are slowly decreasing. This again suggests that the shared embedding is an improvement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, decoder_seq_length, temp=1.0):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([t_joint.word_index[\"startseq\"]])\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(decoder_seq_length):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence - this needs to be the argmax\n",
    "        next_int = sample(yhat[0, 0, :], temp)\n",
    "        output.append(next_int)\n",
    "        # It seems like we throw a lot of information away here - can we build in the probabilities?\n",
    "        target_seq = array([next_int])\n",
    "        # Check for stopping character\n",
    "        if next_int == t_joint.word_index[\"stopseq\"]:\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: 1 an audio playback system comprising a playback engine for playing audio data according to control information playback of the audio data a snapshot module comprising a memory for saving a plurality \n",
      "\n",
      "Predicted title is: party exclusive load sharing an iteration addition in a multi purpose computer . \n",
      " Test title is: music and audio playback system  \n",
      "---\n",
      "\n",
      "Sample of claim text: 1 a computer implemented method comprising receiving by a computing system a translation for content from a of the translation the content being associated with an item in an electronic providing the \n",
      "\n",
      "Predicted title is: necessary internal hybrid point to semiconductor apparatus . \n",
      " Test title is: techniques for translating content  \n",
      "---\n",
      "\n",
      "Sample of claim text: 1 a display device for installation in a comprising a detector that detects a touch operation an image associated with the display device that acquires at least two of a navigation image containing ma\n",
      "\n",
      "Predicted title is: placed microprocessor network sections size . \n",
      " Test title is: display device display program and display method  \n",
      "---\n",
      "\n",
      "Sample of claim text: 1 a method of using a computer to determine a of an object in a system comprising receiving from clients in the system the identifying an object detected at the clients determining a of the object on \n",
      "\n",
      "Predicted title is: stock coverage floating strings monitored applications . \n",
      " Test title is: using confidence about user in a system  \n",
      "---\n",
      "\n",
      "Sample of claim text: 1 a system comprising a processor an audio content registry component executable by the processor to register an audio content item wherein the audio content item has an insertion point at which to an\n",
      "\n",
      "Predicted title is: necessary causing computers space . \n",
      " Test title is: service to audio content with targeted audio advertising to users  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length, temp=0.8)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some saved examples:\n",
    "```\n",
    "Sample of claim text: 1 a decoding apparatus for decoding an encoded image signal the apparatus comprising a computer that executes a program that causes the apparatus to function as an entropy decoding unit that performs \n",
    "\n",
    "Predicted title is: substantially peripheral imaging source termination . \n",
    " Test title is: decoding apparatus and control method thereof  \n",
    "---\n",
    "\n",
    "Sample of claim text: 1 a computer implemented method for analyzing a scene in an input stream of video frames captured by a video camera the method comprising receiving a plurality of sequences wherein each sequence store\n",
    "\n",
    "Predicted title is: via respect images concerning device based storage . \n",
    " Test title is: adaptive for incremental segmentation of sequences with prediction in a video system \n",
    "```\n",
    "These titles still appear worse than those produced with the Ludwig model, despite a lower loss. The model almost appears to be guessing random words. This may be due to how the decoder is trained."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this post we have:\n",
    "* Constructed two sequence-to-sequence models.\n",
    "* Applied theses models to our patent claim and title data.\n",
    "* Looked at the performance of each model, including identifying strengths and weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
