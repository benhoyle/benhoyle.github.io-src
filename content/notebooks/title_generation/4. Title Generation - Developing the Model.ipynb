{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Title: 4. Title Generation - Developing the Model\n",
    "Tags: improving_results\n",
    "Authors: Ben Hoyle\n",
    "Summary: This post looks at developing our initial models to include state of the art features to improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Title Generation - Developing the Model\n",
    "\n",
    "This post looks at developing our initial models to include state of the art features to improve results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To recap:\n",
    "\n",
    "* We have two models: the Ludwig model and the Chollet/Brownlee model. \n",
    "* Performance so far has been fairly poor.\n",
    "* Each model had slightly different characteristics - the Ludwig model produced better formed output but seemed to simply memorise and repeat titles, the Chollet/Brownlee model had a lower loss and appeared to memorise less but produced more nonsensical outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In our last post we identified a number of ways to improve our models:\n",
    "\n",
    "1. Use GloVe encodings and a shared embedding layer. \n",
    "2. Add attention.\n",
    "3. Add pointers / skip connections between our input and our output.\n",
    "4. Use a coverage measure.\n",
    "5. Use different word forms such as lemmas or stems.\n",
    "6. Use a GAN-style discriminator on the output.\n",
    "7. Improve our sampling by employing beam search.\n",
    "\n",
    "We will look at some of these in this post."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports \n",
    "import numpy as np\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-trained Shared Embeddings "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First download the glove embeddings text file from [here](http://nlp.stanford.edu/data/glove.6B.zip). This is to be placed in a `/glove` directory.\n",
    "\n",
    "Then we follow the steps from Ludwig's example to generate our embedding matrix. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "GLOVE_DIR = \"glove/\"\n",
    "\n",
    "embeddings_index = {}\n",
    "# For Python 3 tweaked to add 'rb'\n",
    "f = open(os.path.join(GLOVE_DIR, 'glove.6B.100d.txt'), 'rb')\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    # Tweaked to decode the binary text values\n",
    "    word = values[0].decode('utf-8')\n",
    "    coefs = np.asarray(values[1:], dtype='float32')\n",
    "    embeddings_index[word] = coefs\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "400000"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(embeddings_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['irati',\n",
       " 'fotiou',\n",
       " '8-year',\n",
       " 'usagi',\n",
       " 'autobianchi',\n",
       " 'eldercare',\n",
       " 'puraskar',\n",
       " 'dench',\n",
       " 'ventrally',\n",
       " 'amsc']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(embeddings_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-0.038194, -0.24487 ,  0.72812 , -0.39961 ,  0.083172,  0.043953,\n",
       "       -0.39141 ,  0.3344  , -0.57545 ,  0.087459,  0.28787 , -0.06731 ,\n",
       "        0.30906 , -0.26384 , -0.13231 , -0.20757 ,  0.33395 , -0.33848 ,\n",
       "       -0.31743 , -0.48336 ,  0.1464  , -0.37304 ,  0.34577 ,  0.052041,\n",
       "        0.44946 , -0.46971 ,  0.02628 , -0.54155 , -0.15518 , -0.14107 ,\n",
       "       -0.039722,  0.28277 ,  0.14393 ,  0.23464 , -0.31021 ,  0.086173,\n",
       "        0.20397 ,  0.52624 ,  0.17164 , -0.082378, -0.71787 , -0.41531 ,\n",
       "        0.20335 , -0.12763 ,  0.41367 ,  0.55187 ,  0.57908 , -0.33477 ,\n",
       "       -0.36559 , -0.54857 , -0.062892,  0.26584 ,  0.30205 ,  0.99775 ,\n",
       "       -0.80481 , -3.0243  ,  0.01254 , -0.36942 ,  2.2167  ,  0.72201 ,\n",
       "       -0.24978 ,  0.92136 ,  0.034514,  0.46745 ,  1.1079  , -0.19358 ,\n",
       "       -0.074575,  0.23353 , -0.052062, -0.22044 ,  0.057162, -0.15806 ,\n",
       "       -0.30798 , -0.41625 ,  0.37972 ,  0.15006 , -0.53212 , -0.2055  ,\n",
       "       -1.2526  ,  0.071624,  0.70565 ,  0.49744 , -0.42063 ,  0.26148 ,\n",
       "       -1.538   , -0.30223 , -0.073438, -0.28312 ,  0.37104 , -0.25217 ,\n",
       "        0.016215, -0.017099, -0.38984 ,  0.87424 , -0.72569 , -0.51058 ,\n",
       "       -0.52028 , -0.1459  ,  0.8278  ,  0.27062 ], dtype=float32)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embeddings_index.get('the')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "#### Load and Tokenize Data\n",
    "\n",
    "Initially we load our data as before. As we are using shared embeddings we will train a common tokenizer on both the claim text and title."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set parameters\n",
    "num_decoder_tokens = 2500 # This is our output title vocabulary\n",
    "num_encoder_tokens = 2500 # This is our input claim vocabulary\n",
    "encoder_seq_length = 300 # This is our limit for our input claim length\n",
    "decoder_seq_length = 22 # This is our limit for our output title length - 20 + 2 for start/stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data\n",
      "30000 samples loaded\n",
      "\n",
      "\n",
      "Adding start and stop tokens to output\n",
      "\n",
      "\n",
      "An example title: startseq System and method for session restoration at geo-redundant gateways stopseq\n",
      "----\n",
      "An example claim: \n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import os\n",
    "\n",
    "PIK = \"claim_and_title.data\"\n",
    "\n",
    "if not os.path.isfile(PIK):\n",
    "    # Download file\n",
    "    !wget https://benhoyle.github.io/notebooks/title_generation/claim_and_title.data\n",
    "\n",
    "with open(PIK, \"rb\") as f:\n",
    "    print(\"Loading data\")\n",
    "    data = pickle.load(f)\n",
    "    print(\"{0} samples loaded\".format(len(data)))\n",
    "    \n",
    "print(\"\\n\\nAdding start and stop tokens to output\")\n",
    "data = [(c, \"startseq {0} stopseq\".format(t)) for c, t in data]\n",
    "                                      \n",
    "print(\"\\n\\nAn example title:\", data[0][1])\n",
    "print(\"----\")\n",
    "print(\"An example claim:\", data[0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/dist-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from keras.preprocessing import text\n",
    "t_joint = text.Tokenizer(\n",
    "                num_words=num_encoder_tokens, \n",
    "                lower=True,\n",
    "                char_level=False,\n",
    "                oov_token=\"<UNK>\"\n",
    ")\n",
    "X_texts = [d[0] for d in data]\n",
    "Y_texts = [d[1] for d in data]\n",
    "total_texts = X_texts + Y_texts\n",
    "t_joint.fit_on_texts(total_texts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['remapper',\n",
       " 'inactive',\n",
       " 'imposes',\n",
       " 'overestimates',\n",
       " 'roman',\n",
       " 'mitigating',\n",
       " \"location's\",\n",
       " '56a',\n",
       " 'buckle',\n",
       " 'billable']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(t_joint.word_index.keys())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our input sequences (claims) have a max integer value of 2499\n",
      "Our output sequences (titles) have a vocabulary of 2499 words\n"
     ]
    }
   ],
   "source": [
    "X_seqs = t_joint.texts_to_sequences(X_texts)\n",
    "Y_seqs = t_joint.texts_to_sequences(Y_texts)\n",
    "print(\"Our input sequences (claims) have a max integer value of {0}\".format(max([max(x) for x in X_seqs])))\n",
    "print(\"Our output sequences (titles) have a max integer value of {0}\".format(max([max(y) for y in Y_seqs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2500"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab_size = max([max(x + y) for x, y in zip(X_seqs, Y_seqs)]) + 1\n",
    "vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our longest input sequence is 300 tokens long.\n",
      "Our longest output sequence is 22 tokens long.\n"
     ]
    }
   ],
   "source": [
    "filtered_seqs = [(x, y) for x,y in zip(X_seqs, Y_seqs) if len(x) <= encoder_seq_length and len(y) <= decoder_seq_length]\n",
    "X_seqs = [x for x, _ in filtered_seqs]\n",
    "Y_seqs = [y for _, y in filtered_seqs]\n",
    "\n",
    "X_length = [len(x) for x in X_seqs]\n",
    "max_length = max(X_length)\n",
    "print(\"Our longest input sequence is {0} tokens long.\".format(max_length))\n",
    "\n",
    "Y_length = [len(y) for y in Y_seqs]\n",
    "max_length = max(Y_length)\n",
    "print(\"Our longest output sequence is {0} tokens long.\".format(max_length))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 400000 word vectors.\n"
     ]
    }
   ],
   "source": [
    "word_embedding_size = 100 # As we are using the Glove 100d data\n",
    "print('Found {0} word vectors.'.format(len(embeddings_index)))\n",
    "embedding_matrix = np.zeros((vocab_size, word_embedding_size))\n",
    "\n",
    "# Filter our vocab to only the used items\n",
    "words = [(w, i) for w, i in t_joint.word_index.items() if int(i) < vocab_size]\n",
    "\n",
    "# This is from https://machinelearningmastery.com/use-word-embedding-layers-deep-learning-keras/      \n",
    "for word, i in words:\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2500, 100)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "embedding_matrix.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Aside: can I use the embedding matrix as the weights for a dense layer that is multiplied by the probabilities of the decoder output?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "1. A method for managing a backup service gateway (SGW) associated with a primary SGW, the method comprising:\n",
      "periodically receiving from the primary SGW at least a portion of corresponding UE session state information, the received portion of session state information being sufficient to enable the backup SGW to indicate to an inquiring management entity that UEs having an active session supported by the primary SGW are in a live state; and\n",
      "in response to a failure of the primary SGW, the backup SGW assuming management of IP addresses and paths associated with said primary SGW and transmitting a Downlink Data Notification (DDN) toward a Mobility Management Entity (MME) for each of said UEs having an active session supported by the failed primary SGW to detach from the network and reattach to the network, wherein each DDN causes the MME to send a detach request with a reattach request code to the respective UE.\n",
      "\n",
      " [31, 2, 29, 8, 448, 2, 552, 91, 1047, 42, 19, 2, 397, 1, 29, 26, 1959, 51, 20, 1, 397, 14, 25, 2, 74, 3, 61, 352, 109, 28, 1, 96, 74, 3, 352, 109, 28, 58, 2214, 4, 782, 1, 552, 4, 1008, 4, 11, 142, 261, 24, 69, 11, 500, 352, 1510, 15, 1, 397, 60, 6, 2, 1672, 109, 5, 6, 75, 4, 2, 888, 3, 1, 397, 1, 552, 142, 3, 603, 685, 5, 937, 42, 19, 16, 397, 5, 252, 2, 9, 494, 1653, 2, 142, 261, 8, 32, 3, 16, 69, 11, 500, 352, 1510, 15, 1, 2193, 397, 4, 20, 1, 53, 5, 4, 1, 53, 18, 32, 957, 1, 4, 742, 2, 65, 19, 2, 65, 97, 4, 1, 118]\n",
      "startseq System and method for session restoration at geo-redundant gateways stopseq [34, 30, 5, 29, 8, 352, 14, 1836, 35]\n"
     ]
    }
   ],
   "source": [
    "print(X_texts[0], X_seqs[0])\n",
    "print(Y_texts[0], Y_seqs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Our X data has shape (25632, 300) and our Y data has shape (25632, 22)\n"
     ]
    }
   ],
   "source": [
    "# Pad the data\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "X = pad_sequences(X_seqs, maxlen=encoder_seq_length)\n",
    "Y = pad_sequences(Y_seqs, maxlen=decoder_seq_length, padding='post')\n",
    "\n",
    "print(\"Our X data has shape {0} and our Y data has shape {1}\".format(X.shape, Y.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   30,    5,   29,    8,  352,   14, 1836,   35,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ludwig Model\n",
    "\n",
    "There are actually two models described by Oswaldo. A first introductory model and a second model that uses an additional adversarial network. The first model is easier to understand so we will start with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "from keras.models import Model\n",
    "from keras.layers import Input, LSTM, Dense, Embedding\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "from keras.layers import concatenate\n",
    "\n",
    "y_vocab_len = num_decoder_tokens # This is our output title vocabulary\n",
    "X_vocab_len = num_encoder_tokens # This is our input claim vocabulary\n",
    "X_max_len = encoder_seq_length # This is our limit for our input claim length\n",
    "y_max_len = decoder_seq_length # This is our limit for our output title length - 20 + 2 for start/stop\n",
    "\n",
    "# source text input model\n",
    "inputs1 = Input(shape=(X_max_len,))\n",
    "#am1 = Embedding(X_vocab_len, 128)(inputs1)\n",
    "Shared_Embedding = Embedding(\n",
    "    output_dim=word_embedding_size, \n",
    "    input_dim=vocab_size, \n",
    "    weights=[embedding_matrix], \n",
    "    input_length=X_vocab_len\n",
    ")\n",
    "am1 = Shared_Embedding(inputs1)\n",
    "am2 = LSTM(128)(am1)\n",
    "# summary input model\n",
    "inputs2 = Input(shape=(y_max_len,))\n",
    "sm1 = Shared_Embedding(inputs2)\n",
    "sm2 = LSTM(128)(sm1)\n",
    "# decoder output model\n",
    "decoder1 = concatenate([am2, sm2])\n",
    "outputs = Dense(y_vocab_len, activation='softmax')(decoder1)\n",
    "# tie it together [article, summary] [word]\n",
    "model = Model(inputs=[inputs1, inputs2], outputs=outputs)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_7 (InputLayer)            (None, 300)          0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_8 (InputLayer)            (None, 22)           0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_3 (Embedding)         (None, 2500, 100)    250000      input_7[0][0]                    \n",
      "                                                                 input_8[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_5 (LSTM)                   (None, 128)          117248      embedding_3[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_6 (LSTM)                   (None, 128)          117248      embedding_3[1][0]                \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 256)          0           lstm_5[0][0]                     \n",
      "                                                                 lstm_6[0][0]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_3 (Dense)                 (None, 2500)         642500      concatenate_2[0][0]              \n",
      "==================================================================================================\n",
      "Total params: 1,126,996\n",
      "Trainable params: 1,126,996\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we see that the embedding is shared by both LSTMs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We need to split into train and test data\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# seed for reproducing same results\n",
    "seed = 9\n",
    "np.random.seed(seed)\n",
    "\n",
    "# split the data into training (80%) and testing (20%)\n",
    "(X_train, X_test, Y_train, Y_test) = train_test_split(X, Y, test_size=0.2, random_state=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  34,   30,    5,   29,    8,  352,   14, 1836,   35,    0,    0,\n",
       "          0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0],\n",
       "      dtype=int32)"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_set(X, Y, i_end, i):\n",
    "    \"\"\" Generate the data for training/validation from X and Y.\n",
    "    i_end is the end of the set, i is the start.\"\"\"\n",
    "    set_size = 0\n",
    "    limit_list = list()\n",
    "    for sent in Y[i:i_end]:\n",
    "        # Edited below to use integer value of EOS symbol\n",
    "        limit = np.where(sent==t_joint.word_index[\"stopseq\"])[0][0]  #  the position of the symbol EOS\n",
    "        set_size += limit + 1\n",
    "        limit_list.append(limit)\n",
    "   \n",
    "    # We need to change this bit to set our array size based on the limit values\n",
    "    # Generate blank arrays for the set\n",
    "    I_1 = np.zeros((set_size, X_max_len))\n",
    "    I_2 = np.zeros((set_size, y_max_len))\n",
    "    # This below is a big array\n",
    "    Y_set = np.zeros((set_size, y_vocab_len))\n",
    "    count = 0\n",
    "    # Now we want to create, for each sample, a set of examples for each word in the title\n",
    "    # Have we just been training on 0 to 100?!?!\n",
    "    for l in range(0, (i_end - i)):\n",
    "        # for each X and y in set of NB_SET \n",
    "            \n",
    "        # We need to build the input for the second encoder for the next word in y\n",
    "        # I.e. for word 3 in the title the input2 consists of words 1 and 2 (using teacher forcing)\n",
    "            \n",
    "        # Get length of current title - i.e. where the integer = 2 = stopseq\n",
    "        limit = limit_list[l]\n",
    "            \n",
    "        # We only need to create examples up to the length of the title \n",
    "        for m in range(1, limit+1):\n",
    "                \n",
    "            # Generate our one-hot y out\n",
    "            one_hot_out = np.zeros((1, y_vocab_len))\n",
    "            # This builds our one-hot generation into our training loop\n",
    "            # The l and m respectively iterate through the samples and the output sequence elements\n",
    "            one_hot_out[0, Y[l+i][m]] = 1\n",
    "                \n",
    "            # Create a blank row/array for a partial input for our summary model - this is fed into the decoder\n",
    "            # It is of the same size as our title\n",
    "            partial_input = np.zeros((1, y_max_len))\n",
    "            # Don't we also need to set partial input [0] to startseq as well? - no that's taken care of\n",
    "            # by m starting at one but our range below starting at 0\n",
    "            \n",
    "            # Because we are zero padding add words up to m to end - DOES THIS STILL WORK IF WE ZERO PAD\n",
    "            # AT THE END? - Yes but we just feed the words with zeros first?\n",
    "            # What happens if we change this to 0:m?! - if we have [1, 2, 3, 4] this will generate\n",
    "            # [0,0,0,1], [0,0,1,2], [0,1, 2, 3]\n",
    "            # Our zero padding is at the end though so our seqs looks like [1,2,3,0,0,0], \n",
    "            # But I know you want the data need the end of the input seq to prevent forgetting\n",
    "            partial_input[0, -m:] = Y[l+i][0:m]\n",
    "            \n",
    "            # This fills in each sample of the training data, i.e. count increments up to set size\n",
    "            I_1[count, :] = X[l+i]\n",
    "            I_2[count, :] = partial_input\n",
    "            Y_set[count, :] = one_hot_out\n",
    "            count += 1\n",
    "                \n",
    "        # Shuffle the I_1, I_2 and Y_set vectors for better training - trick from RL\n",
    "        # - see here - np.take(X,np.random.permutation(X.shape[0]),axis=0,out=X);\n",
    "        indices = np.random.permutation(I_1.shape[0])\n",
    "        np.take(I_1, indices, axis=0, out=I_1)\n",
    "        np.take(I_2, indices, axis=0, out=I_2)\n",
    "        np.take(Y_set, indices, axis=0, out=Y_set)\n",
    "    return I_1, I_2, Y_set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Saved weights found, loading...\n"
     ]
    }
   ],
   "source": [
    "# Basing training in sets code on here - https://github.com/ChunML/seq2seq/blob/master/seq2seq.py\n",
    "\n",
    "# Function to look for saved weights file\n",
    "def find_checkpoint_file(folder):\n",
    "    checkpoint_file = [f for f in os.listdir(folder) if 'v2_kerascheckpoint' in f]\n",
    "    if len(checkpoint_file) == 0:\n",
    "        return []\n",
    "    modified_time = [os.path.getmtime(f) for f in checkpoint_file]\n",
    "    return checkpoint_file[np.argmax(modified_time)]\n",
    "\n",
    "# Finding trained weights of previous epoch if any\n",
    "saved_weights = find_checkpoint_file('.')\n",
    "\n",
    "k_start = 1\n",
    "\n",
    "# If any trained weight was found, then load them into the model\n",
    "if len(saved_weights) != 0:\n",
    "    print('[INFO] Saved weights found, loading...')\n",
    "    epoch = saved_weights[saved_weights.rfind('_')+1:saved_weights.rfind('.')]\n",
    "    model.load_weights(saved_weights)\n",
    "    k_start = int(epoch) + 1\n",
    "\n",
    "# So instead of X we have [inputs1, inputs2] - this is where we need to fold in \n",
    "# - https://github.com/oswaldoludwig/Seq2seq-Chatbot-for-Keras/blob/master/train_bot.py\n",
    "\n",
    "# So we have inputs2 that build up - we have a set of inputs2 up to the length of inputs2\n",
    "\n",
    "# We need to refactor some of the loops below as functions - we can then apply to test data to generate a validation set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Uh oh - a problem with using embeddings is that our start and stop tokens are no longer 1 and 2!\n",
    "\n",
    "*** Fixed above ***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "35"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# For now we can just change 2 to the variable below - in future it is probably better to build our our tokenizer that\n",
    "# reserves control characters\n",
    "t_joint.word_index[\"stopseq\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "\n",
    "BATCH_SIZE = 32 # Depends on GPU - most values are around this 32-128 \n",
    "NB_EPOCH = 20\n",
    "# Number of examples to group together in a set - 100 is fast / 1000 is too much on an 8-core i7 laptop\n",
    "# I think 100 is good - 250 takes a time to generate the sets of test data\n",
    "NB_SET = 250"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "i_end = 0\n",
    "num_examples = len(X_train)\n",
    "num_test = len(X_test)\n",
    "# Initialise history of accuracy\n",
    "train_loss = list()\n",
    "val_loss = list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 2 - 0/20505 samples\n",
      "Train on 2534 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 22s 9ms/step - loss: 2.2101 - val_loss: 2.3826\n",
      "[INFO] Training model: epoch 2 - 250/20505 samples\n",
      "Train on 2464 samples, validate on 677 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 22s 9ms/step - loss: 2.1098 - val_loss: 2.2632\n",
      "[INFO] Training model: epoch 2 - 500/20505 samples\n",
      "Train on 2404 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 21s 9ms/step - loss: 2.1046 - val_loss: 2.4288\n",
      "[INFO] Training model: epoch 2 - 750/20505 samples\n",
      "Train on 2516 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 22s 9ms/step - loss: 2.1949 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 2 - 1000/20505 samples\n",
      "Train on 2510 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 22s 9ms/step - loss: 2.2015 - val_loss: 2.3367\n",
      "[INFO] Training model: epoch 2 - 1250/20505 samples\n",
      "Train on 2521 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 23s 9ms/step - loss: 2.2629 - val_loss: 2.2410\n",
      "[INFO] Training model: epoch 2 - 1500/20505 samples\n",
      "Train on 2492 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 2.1124 - val_loss: 2.3247\n",
      "[INFO] Training model: epoch 2 - 1750/20505 samples\n",
      "Train on 2545 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 24s 9ms/step - loss: 2.0176 - val_loss: 2.2035\n",
      "[INFO] Training model: epoch 2 - 2000/20505 samples\n",
      "Train on 2484 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.1958 - val_loss: 2.6558\n",
      "[INFO] Training model: epoch 2 - 2250/20505 samples\n",
      "Train on 2391 samples, validate on 683 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 23s 9ms/step - loss: 2.1795 - val_loss: 2.4181\n",
      "[INFO] Training model: epoch 2 - 2500/20505 samples\n",
      "Train on 2521 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 24s 9ms/step - loss: 2.1711 - val_loss: 2.1677\n",
      "[INFO] Training model: epoch 2 - 2750/20505 samples\n",
      "Train on 2522 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 2.2412 - val_loss: 2.3920\n",
      "[INFO] Training model: epoch 2 - 3000/20505 samples\n",
      "Train on 2455 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 2.1552 - val_loss: 2.3904\n",
      "[INFO] Training model: epoch 2 - 3250/20505 samples\n",
      "Train on 2538 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 24s 9ms/step - loss: 2.1931 - val_loss: 2.3230\n",
      "[INFO] Training model: epoch 2 - 3500/20505 samples\n",
      "Train on 2464 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.2429 - val_loss: 2.1672\n",
      "[INFO] Training model: epoch 2 - 3750/20505 samples\n",
      "Train on 2484 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.1411 - val_loss: 2.5224\n",
      "[INFO] Training model: epoch 2 - 4000/20505 samples\n",
      "Train on 2547 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 23s 9ms/step - loss: 2.2104 - val_loss: 2.3912\n",
      "[INFO] Training model: epoch 2 - 4250/20505 samples\n",
      "Train on 2364 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 2.1683 - val_loss: 2.2343\n",
      "[INFO] Training model: epoch 2 - 4500/20505 samples\n",
      "Train on 2351 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 2.1008 - val_loss: 2.3659\n",
      "[INFO] Training model: epoch 2 - 4750/20505 samples\n",
      "Train on 2436 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 2.0879 - val_loss: 2.2916\n",
      "[INFO] Training model: epoch 2 - 5000/20505 samples\n",
      "Train on 2338 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 22s 9ms/step - loss: 2.1865 - val_loss: 2.2310\n",
      "[INFO] Training model: epoch 2 - 5250/20505 samples\n",
      "Train on 2424 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 10ms/step - loss: 2.1551 - val_loss: 2.1450\n",
      "[INFO] Training model: epoch 2 - 5500/20505 samples\n",
      "Train on 2508 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 23s 9ms/step - loss: 2.1111 - val_loss: 2.5732\n",
      "[INFO] Training model: epoch 2 - 5750/20505 samples\n",
      "Train on 2428 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 2.2642 - val_loss: 2.5461\n",
      "[INFO] Training model: epoch 2 - 6000/20505 samples\n",
      "Train on 2412 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 2.2155 - val_loss: 2.5289\n",
      "[INFO] Training model: epoch 2 - 6250/20505 samples\n",
      "Train on 2469 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 2.2668 - val_loss: 2.2134\n",
      "[INFO] Training model: epoch 2 - 6500/20505 samples\n",
      "Train on 2513 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 2.2224 - val_loss: 2.3273\n",
      "[INFO] Training model: epoch 2 - 6750/20505 samples\n",
      "Train on 2509 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 22s 9ms/step - loss: 2.2078 - val_loss: 2.4643\n",
      "[INFO] Training model: epoch 2 - 7000/20505 samples\n",
      "Train on 2428 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 2.1056 - val_loss: 2.5365\n",
      "[INFO] Training model: epoch 2 - 7250/20505 samples\n",
      "Train on 2482 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 2.1171 - val_loss: 2.4198\n",
      "[INFO] Training model: epoch 2 - 7500/20505 samples\n",
      "Train on 2505 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 2.0969 - val_loss: 2.2209\n",
      "[INFO] Training model: epoch 2 - 7750/20505 samples\n",
      "Train on 2506 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 2.1823 - val_loss: 2.3450\n",
      "[INFO] Training model: epoch 2 - 8000/20505 samples\n",
      "Train on 2442 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 2.1400 - val_loss: 2.1909\n",
      "[INFO] Training model: epoch 2 - 8250/20505 samples\n",
      "Train on 2535 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 24s 9ms/step - loss: 2.2119 - val_loss: 2.3661\n",
      "[INFO] Training model: epoch 2 - 8500/20505 samples\n",
      "Train on 2531 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 2.1308 - val_loss: 2.2979\n",
      "[INFO] Training model: epoch 2 - 8750/20505 samples\n",
      "Train on 2525 samples, validate on 543 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 2.0999 - val_loss: 2.5126\n",
      "[INFO] Training model: epoch 2 - 9000/20505 samples\n",
      "Train on 2559 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 2.1101 - val_loss: 2.2551\n",
      "[INFO] Training model: epoch 2 - 9250/20505 samples\n",
      "Train on 2337 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 21s 9ms/step - loss: 2.2555 - val_loss: 2.3273\n",
      "[INFO] Training model: epoch 2 - 9500/20505 samples\n",
      "Train on 2572 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 24s 9ms/step - loss: 2.1376 - val_loss: 2.3022\n",
      "[INFO] Training model: epoch 2 - 9750/20505 samples\n",
      "Train on 2491 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 2.2172 - val_loss: 2.4557\n",
      "[INFO] Training model: epoch 2 - 10000/20505 samples\n",
      "Train on 2390 samples, validate on 659 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2390/2390 [==============================] - 22s 9ms/step - loss: 2.2061 - val_loss: 2.6325\n",
      "[INFO] Training model: epoch 2 - 10250/20505 samples\n",
      "Train on 2453 samples, validate on 702 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 2.0870 - val_loss: 2.3913\n",
      "[INFO] Training model: epoch 2 - 10500/20505 samples\n",
      "Train on 2484 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 2.2218 - val_loss: 2.2163\n",
      "[INFO] Training model: epoch 2 - 10750/20505 samples\n",
      "Train on 2424 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 9ms/step - loss: 2.1853 - val_loss: 2.4196\n",
      "[INFO] Training model: epoch 2 - 11000/20505 samples\n",
      "Train on 2435 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 2.2041 - val_loss: 2.3025\n",
      "[INFO] Training model: epoch 2 - 11250/20505 samples\n",
      "Train on 2503 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 2.0272 - val_loss: 2.2923\n",
      "[INFO] Training model: epoch 2 - 11500/20505 samples\n",
      "Train on 2381 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 22s 9ms/step - loss: 2.1969 - val_loss: 2.4107\n",
      "[INFO] Training model: epoch 2 - 11750/20505 samples\n",
      "Train on 2492 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 2.2025 - val_loss: 2.3053\n",
      "[INFO] Training model: epoch 2 - 12000/20505 samples\n",
      "Train on 2516 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 2.2331 - val_loss: 2.1163\n",
      "[INFO] Training model: epoch 2 - 12250/20505 samples\n",
      "Train on 2383 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 21s 9ms/step - loss: 2.2062 - val_loss: 2.2637\n",
      "[INFO] Training model: epoch 2 - 12500/20505 samples\n",
      "Train on 2491 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 2.1532 - val_loss: 2.5704\n",
      "[INFO] Training model: epoch 2 - 12750/20505 samples\n",
      "Train on 2446 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 24s 10ms/step - loss: 2.0985 - val_loss: 2.2835\n",
      "[INFO] Training model: epoch 2 - 13000/20505 samples\n",
      "Train on 2440 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 2.1408 - val_loss: 2.2730\n",
      "[INFO] Training model: epoch 2 - 13250/20505 samples\n",
      "Train on 2444 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 2.1590 - val_loss: 2.3108\n",
      "[INFO] Training model: epoch 2 - 13500/20505 samples\n",
      "Train on 2397 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 9ms/step - loss: 2.1229 - val_loss: 2.2442\n",
      "[INFO] Training model: epoch 2 - 13750/20505 samples\n",
      "Train on 2319 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2319/2319 [==============================] - 22s 9ms/step - loss: 2.0592 - val_loss: 2.5376\n",
      "[INFO] Training model: epoch 2 - 14000/20505 samples\n",
      "Train on 2504 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 23s 9ms/step - loss: 2.2372 - val_loss: 2.1988\n",
      "[INFO] Training model: epoch 2 - 14250/20505 samples\n",
      "Train on 2421 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 21s 9ms/step - loss: 2.2013 - val_loss: 2.4810\n",
      "[INFO] Training model: epoch 2 - 14500/20505 samples\n",
      "Train on 2463 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 21s 9ms/step - loss: 2.2323 - val_loss: 2.2700\n",
      "[INFO] Training model: epoch 2 - 14750/20505 samples\n",
      "Train on 2405 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 2.1686 - val_loss: 2.3067\n",
      "[INFO] Training model: epoch 2 - 15000/20505 samples\n",
      "Train on 2405 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 2.2542 - val_loss: 2.4856\n",
      "[INFO] Training model: epoch 2 - 15250/20505 samples\n",
      "Train on 2373 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 21s 9ms/step - loss: 2.0537 - val_loss: 2.3686\n",
      "[INFO] Training model: epoch 2 - 15500/20505 samples\n",
      "Train on 2425 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 2.1881 - val_loss: 2.4565\n",
      "[INFO] Training model: epoch 2 - 15750/20505 samples\n",
      "Train on 2437 samples, validate on 533 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 2.1347 - val_loss: 2.5169\n",
      "[INFO] Training model: epoch 2 - 16000/20505 samples\n",
      "Train on 2443 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 2.1617 - val_loss: 2.3260\n",
      "[INFO] Training model: epoch 2 - 16250/20505 samples\n",
      "Train on 2362 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 2.2975 - val_loss: 2.3707\n",
      "[INFO] Training model: epoch 2 - 16500/20505 samples\n",
      "Train on 2464 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.1335 - val_loss: 2.2904\n",
      "[INFO] Training model: epoch 2 - 16750/20505 samples\n",
      "Train on 2375 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 2.0726 - val_loss: 2.1677\n",
      "[INFO] Training model: epoch 2 - 17000/20505 samples\n",
      "Train on 2511 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 2.2338 - val_loss: 2.2962\n",
      "[INFO] Training model: epoch 2 - 17250/20505 samples\n",
      "Train on 2428 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 2.2274 - val_loss: 2.4144\n",
      "[INFO] Training model: epoch 2 - 17500/20505 samples\n",
      "Train on 2414 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 2.2584 - val_loss: 2.1193\n",
      "[INFO] Training model: epoch 2 - 17750/20505 samples\n",
      "Train on 2463 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 2.0694 - val_loss: 2.3732\n",
      "[INFO] Training model: epoch 2 - 18000/20505 samples\n",
      "Train on 2418 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 2.1459 - val_loss: 2.1653\n",
      "[INFO] Training model: epoch 2 - 18250/20505 samples\n",
      "Train on 2431 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 2.1444 - val_loss: 2.3524\n",
      "[INFO] Training model: epoch 2 - 18500/20505 samples\n",
      "Train on 2440 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 2.1563 - val_loss: 2.3204\n",
      "[INFO] Training model: epoch 2 - 18750/20505 samples\n",
      "Train on 2431 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 2.1367 - val_loss: 2.2359\n",
      "[INFO] Training model: epoch 2 - 19000/20505 samples\n",
      "Train on 2421 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 2.1752 - val_loss: 2.2166\n",
      "[INFO] Training model: epoch 2 - 19250/20505 samples\n",
      "Train on 2464 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 2.1737 - val_loss: 2.5509\n",
      "[INFO] Training model: epoch 2 - 19500/20505 samples\n",
      "Train on 2419 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 2.1663 - val_loss: 2.3102\n",
      "[INFO] Training model: epoch 2 - 19750/20505 samples\n",
      "Train on 2508 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 24s 9ms/step - loss: 2.1191 - val_loss: 2.1213\n",
      "[INFO] Training model: epoch 2 - 20000/20505 samples\n",
      "Train on 2462 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 2.1453 - val_loss: 2.2773\n",
      "[INFO] Training model: epoch 2 - 20250/20505 samples\n",
      "Train on 2478 samples, validate on 686 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2478/2478 [==============================] - 23s 9ms/step - loss: 2.1018 - val_loss: 2.4592\n",
      "[INFO] Training model: epoch 2 - 20500/20505 samples\n",
      "Train on 36 samples, validate on 12 samples\n",
      "Epoch 1/1\n",
      "36/36 [==============================] - 1s 15ms/step - loss: 2.5730 - val_loss: 3.4734\n",
      "[INFO] Training model: epoch 3 - 0/20505 samples\n",
      "Train on 2446 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.9679 - val_loss: 2.3590\n",
      "[INFO] Training model: epoch 3 - 250/20505 samples\n",
      "Train on 2541 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 2.0008 - val_loss: 2.3540\n",
      "[INFO] Training model: epoch 3 - 500/20505 samples\n",
      "Train on 2429 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.9819 - val_loss: 2.1722\n",
      "[INFO] Training model: epoch 3 - 750/20505 samples\n",
      "Train on 2416 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.9458 - val_loss: 2.3659\n",
      "[INFO] Training model: epoch 3 - 1000/20505 samples\n",
      "Train on 2368 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2368/2368 [==============================] - 22s 9ms/step - loss: 2.0201 - val_loss: 2.5634\n",
      "[INFO] Training model: epoch 3 - 1250/20505 samples\n",
      "Train on 2473 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.9461 - val_loss: 2.4993\n",
      "[INFO] Training model: epoch 3 - 1500/20505 samples\n",
      "Train on 2454 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.9743 - val_loss: 2.3521\n",
      "[INFO] Training model: epoch 3 - 1750/20505 samples\n",
      "Train on 2509 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 23s 9ms/step - loss: 2.0200 - val_loss: 2.3583\n",
      "[INFO] Training model: epoch 3 - 2000/20505 samples\n",
      "Train on 2377 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.8921 - val_loss: 2.4193\n",
      "[INFO] Training model: epoch 3 - 2250/20505 samples\n",
      "Train on 2531 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 1.9906 - val_loss: 2.1544\n",
      "[INFO] Training model: epoch 3 - 2500/20505 samples\n",
      "Train on 2447 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 22s 9ms/step - loss: 1.9864 - val_loss: 2.3306\n",
      "[INFO] Training model: epoch 3 - 2750/20505 samples\n",
      "Train on 2589 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 24s 9ms/step - loss: 2.0430 - val_loss: 2.1839\n",
      "[INFO] Training model: epoch 3 - 3000/20505 samples\n",
      "Train on 2386 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 23s 10ms/step - loss: 1.9785 - val_loss: 2.2455\n",
      "[INFO] Training model: epoch 3 - 3250/20505 samples\n",
      "Train on 2379 samples, validate on 693 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 22s 9ms/step - loss: 2.1022 - val_loss: 2.3693\n",
      "[INFO] Training model: epoch 3 - 3500/20505 samples\n",
      "Train on 2433 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.9631 - val_loss: 2.2237\n",
      "[INFO] Training model: epoch 3 - 3750/20505 samples\n",
      "Train on 2464 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.9817 - val_loss: 2.2259\n",
      "[INFO] Training model: epoch 3 - 4000/20505 samples\n",
      "Train on 2452 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.9195 - val_loss: 2.3822\n",
      "[INFO] Training model: epoch 3 - 4250/20505 samples\n",
      "Train on 2532 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.9579 - val_loss: 2.2244\n",
      "[INFO] Training model: epoch 3 - 4500/20505 samples\n",
      "Train on 2411 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 2.0331 - val_loss: 2.1242\n",
      "[INFO] Training model: epoch 3 - 4750/20505 samples\n",
      "Train on 2389 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 21s 9ms/step - loss: 2.0033 - val_loss: 2.4065\n",
      "[INFO] Training model: epoch 3 - 5000/20505 samples\n",
      "Train on 2463 samples, validate on 713 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9559 - val_loss: 2.3578\n",
      "[INFO] Training model: epoch 3 - 5250/20505 samples\n",
      "Train on 2548 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.9676 - val_loss: 2.3423\n",
      "[INFO] Training model: epoch 3 - 5500/20505 samples\n",
      "Train on 2471 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 2.0121 - val_loss: 2.3606\n",
      "[INFO] Training model: epoch 3 - 5750/20505 samples\n",
      "Train on 2463 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9974 - val_loss: 2.2110\n",
      "[INFO] Training model: epoch 3 - 6000/20505 samples\n",
      "Train on 2472 samples, validate on 533 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 2.0287 - val_loss: 2.2368\n",
      "[INFO] Training model: epoch 3 - 6250/20505 samples\n",
      "Train on 2460 samples, validate on 681 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.9816 - val_loss: 2.5111\n",
      "[INFO] Training model: epoch 3 - 6500/20505 samples\n",
      "Train on 2488 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 2.0163 - val_loss: 2.3491\n",
      "[INFO] Training model: epoch 3 - 6750/20505 samples\n",
      "Train on 2435 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.9731 - val_loss: 2.2698\n",
      "[INFO] Training model: epoch 3 - 7000/20505 samples\n",
      "Train on 2384 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 21s 9ms/step - loss: 2.0065 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 3 - 7250/20505 samples\n",
      "Train on 2562 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 24s 9ms/step - loss: 2.0366 - val_loss: 2.1553\n",
      "[INFO] Training model: epoch 3 - 7500/20505 samples\n",
      "Train on 2468 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 2.0321 - val_loss: 2.4310\n",
      "[INFO] Training model: epoch 3 - 7750/20505 samples\n",
      "Train on 2531 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 2.0115 - val_loss: 2.2900\n",
      "[INFO] Training model: epoch 3 - 8000/20505 samples\n",
      "Train on 2526 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 2.0067 - val_loss: 2.3143\n",
      "[INFO] Training model: epoch 3 - 8250/20505 samples\n",
      "Train on 2443 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.9194 - val_loss: 2.2773\n",
      "[INFO] Training model: epoch 3 - 8500/20505 samples\n",
      "Train on 2426 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.9174 - val_loss: 2.1635\n",
      "[INFO] Training model: epoch 3 - 8750/20505 samples\n",
      "Train on 2361 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 22s 9ms/step - loss: 2.0461 - val_loss: 2.1081\n",
      "[INFO] Training model: epoch 3 - 9000/20505 samples\n",
      "Train on 2386 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 2.0540 - val_loss: 2.4666\n",
      "[INFO] Training model: epoch 3 - 9250/20505 samples\n",
      "Train on 2498 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 23s 9ms/step - loss: 2.1164 - val_loss: 2.5101\n",
      "[INFO] Training model: epoch 3 - 9500/20505 samples\n",
      "Train on 2576 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.9519 - val_loss: 2.4530\n",
      "[INFO] Training model: epoch 3 - 9750/20505 samples\n",
      "Train on 2401 samples, validate on 654 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2401/2401 [==============================] - 21s 9ms/step - loss: 2.0529 - val_loss: 2.2487\n",
      "[INFO] Training model: epoch 3 - 10000/20505 samples\n",
      "Train on 2424 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 23s 9ms/step - loss: 2.0596 - val_loss: 2.2842\n",
      "[INFO] Training model: epoch 3 - 10250/20505 samples\n",
      "Train on 2402 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 22s 9ms/step - loss: 2.0181 - val_loss: 2.2941\n",
      "[INFO] Training model: epoch 3 - 10500/20505 samples\n",
      "Train on 2485 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 21s 9ms/step - loss: 1.9160 - val_loss: 2.2243\n",
      "[INFO] Training model: epoch 3 - 10750/20505 samples\n",
      "Train on 2408 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 2.0305 - val_loss: 2.3228\n",
      "[INFO] Training model: epoch 3 - 11000/20505 samples\n",
      "Train on 2464 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 21s 9ms/step - loss: 2.0048 - val_loss: 2.2965\n",
      "[INFO] Training model: epoch 3 - 11250/20505 samples\n",
      "Train on 2496 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 24s 9ms/step - loss: 2.0008 - val_loss: 2.1904\n",
      "[INFO] Training model: epoch 3 - 11500/20505 samples\n",
      "Train on 2520 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 23s 9ms/step - loss: 2.1009 - val_loss: 2.2523\n",
      "[INFO] Training model: epoch 3 - 11750/20505 samples\n",
      "Train on 2346 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 20s 9ms/step - loss: 1.9924 - val_loss: 2.2339\n",
      "[INFO] Training model: epoch 3 - 12000/20505 samples\n",
      "Train on 2419 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 2.0396 - val_loss: 2.2959\n",
      "[INFO] Training model: epoch 3 - 12250/20505 samples\n",
      "Train on 2516 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.9296 - val_loss: 2.3050\n",
      "[INFO] Training model: epoch 3 - 12500/20505 samples\n",
      "Train on 2475 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 21s 9ms/step - loss: 2.1503 - val_loss: 2.2433\n",
      "[INFO] Training model: epoch 3 - 12750/20505 samples\n",
      "Train on 2481 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 24s 10ms/step - loss: 1.9820 - val_loss: 2.4081\n",
      "[INFO] Training model: epoch 3 - 13000/20505 samples\n",
      "Train on 2463 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 2.0926 - val_loss: 2.1198\n",
      "[INFO] Training model: epoch 3 - 13250/20505 samples\n",
      "Train on 2469 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 21s 9ms/step - loss: 2.0258 - val_loss: 2.0723\n",
      "[INFO] Training model: epoch 3 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 2.0368 - val_loss: 2.2888\n",
      "[INFO] Training model: epoch 3 - 13750/20505 samples\n",
      "Train on 2506 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 22s 9ms/step - loss: 2.0438 - val_loss: 2.1098\n",
      "[INFO] Training model: epoch 3 - 14000/20505 samples\n",
      "Train on 2398 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9774 - val_loss: 2.2850\n",
      "[INFO] Training model: epoch 3 - 14250/20505 samples\n",
      "Train on 2559 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 22s 9ms/step - loss: 1.9961 - val_loss: 2.3942\n",
      "[INFO] Training model: epoch 3 - 14500/20505 samples\n",
      "Train on 2401 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 9ms/step - loss: 2.1028 - val_loss: 2.3458\n",
      "[INFO] Training model: epoch 3 - 14750/20505 samples\n",
      "Train on 2477 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.9652 - val_loss: 2.2911\n",
      "[INFO] Training model: epoch 3 - 15000/20505 samples\n",
      "Train on 2463 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.9934 - val_loss: 2.0781\n",
      "[INFO] Training model: epoch 3 - 15250/20505 samples\n",
      "Train on 2476 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 2.0802 - val_loss: 1.9587\n",
      "[INFO] Training model: epoch 3 - 15500/20505 samples\n",
      "Train on 2538 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 2.0145 - val_loss: 2.3855\n",
      "[INFO] Training model: epoch 3 - 15750/20505 samples\n",
      "Train on 2478 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 2.0595 - val_loss: 2.3195\n",
      "[INFO] Training model: epoch 3 - 16000/20505 samples\n",
      "Train on 2488 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.9409 - val_loss: 2.3646\n",
      "[INFO] Training model: epoch 3 - 16250/20505 samples\n",
      "Train on 2452 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 2.0128 - val_loss: 2.2983\n",
      "[INFO] Training model: epoch 3 - 16500/20505 samples\n",
      "Train on 2462 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 2.0187 - val_loss: 2.3817\n",
      "[INFO] Training model: epoch 3 - 16750/20505 samples\n",
      "Train on 2379 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 23s 10ms/step - loss: 2.0363 - val_loss: 2.3836\n",
      "[INFO] Training model: epoch 3 - 17000/20505 samples\n",
      "Train on 2343 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 22s 9ms/step - loss: 2.0317 - val_loss: 2.3947\n",
      "[INFO] Training model: epoch 3 - 17250/20505 samples\n",
      "Train on 2443 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 2.0213 - val_loss: 2.2759\n",
      "[INFO] Training model: epoch 3 - 17500/20505 samples\n",
      "Train on 2490 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.9697 - val_loss: 2.0411\n",
      "[INFO] Training model: epoch 3 - 17750/20505 samples\n",
      "Train on 2514 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 23s 9ms/step - loss: 2.0143 - val_loss: 2.2918\n",
      "[INFO] Training model: epoch 3 - 18000/20505 samples\n",
      "Train on 2395 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 2.0279 - val_loss: 2.0990\n",
      "[INFO] Training model: epoch 3 - 18250/20505 samples\n",
      "Train on 2389 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 9ms/step - loss: 2.0216 - val_loss: 2.3590\n",
      "[INFO] Training model: epoch 3 - 18500/20505 samples\n",
      "Train on 2359 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 2.0521 - val_loss: 2.4699\n",
      "[INFO] Training model: epoch 3 - 18750/20505 samples\n",
      "Train on 2454 samples, validate on 689 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 21s 9ms/step - loss: 2.1109 - val_loss: 2.4121\n",
      "[INFO] Training model: epoch 3 - 19000/20505 samples\n",
      "Train on 2439 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 2.0431 - val_loss: 2.2133\n",
      "[INFO] Training model: epoch 3 - 19250/20505 samples\n",
      "Train on 2574 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 23s 9ms/step - loss: 1.9156 - val_loss: 2.4480\n",
      "[INFO] Training model: epoch 3 - 19500/20505 samples\n",
      "Train on 2440 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 2.1311 - val_loss: 2.3291\n",
      "[INFO] Training model: epoch 3 - 19750/20505 samples\n",
      "Train on 2398 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9641 - val_loss: 2.2112\n",
      "[INFO] Training model: epoch 3 - 20000/20505 samples\n",
      "Train on 2449 samples, validate on 578 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2449/2449 [==============================] - 23s 9ms/step - loss: 2.0629 - val_loss: 2.1767\n",
      "[INFO] Training model: epoch 3 - 20250/20505 samples\n",
      "Train on 2452 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 2.0039 - val_loss: 2.3421\n",
      "[INFO] Training model: epoch 3 - 20500/20505 samples\n",
      "Train on 29 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "29/29 [==============================] - 0s 11ms/step - loss: 1.6708 - val_loss: 2.6099\n",
      "[INFO] Training model: epoch 4 - 0/20505 samples\n",
      "Train on 2575 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 22s 9ms/step - loss: 1.8181 - val_loss: 2.2501\n",
      "[INFO] Training model: epoch 4 - 250/20505 samples\n",
      "Train on 2533 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 1.8656 - val_loss: 2.3783\n",
      "[INFO] Training model: epoch 4 - 500/20505 samples\n",
      "Train on 2433 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.8740 - val_loss: 2.1100\n",
      "[INFO] Training model: epoch 4 - 750/20505 samples\n",
      "Train on 2436 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 1.7889 - val_loss: 2.2762\n",
      "[INFO] Training model: epoch 4 - 1000/20505 samples\n",
      "Train on 2589 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 23s 9ms/step - loss: 1.7799 - val_loss: 2.2828\n",
      "[INFO] Training model: epoch 4 - 1250/20505 samples\n",
      "Train on 2502 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.8035 - val_loss: 2.5056\n",
      "[INFO] Training model: epoch 4 - 1500/20505 samples\n",
      "Train on 2426 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.7970 - val_loss: 2.4859\n",
      "[INFO] Training model: epoch 4 - 1750/20505 samples\n",
      "Train on 2458 samples, validate on 729 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 22s 9ms/step - loss: 1.8281 - val_loss: 2.2225\n",
      "[INFO] Training model: epoch 4 - 2000/20505 samples\n",
      "Train on 2419 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.8978 - val_loss: 2.6084\n",
      "[INFO] Training model: epoch 4 - 2250/20505 samples\n",
      "Train on 2408 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.7764 - val_loss: 2.1812\n",
      "[INFO] Training model: epoch 4 - 2500/20505 samples\n",
      "Train on 2425 samples, validate on 541 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.8684 - val_loss: 2.3981\n",
      "[INFO] Training model: epoch 4 - 2750/20505 samples\n",
      "Train on 2499 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.8258 - val_loss: 2.2930\n",
      "[INFO] Training model: epoch 4 - 3000/20505 samples\n",
      "Train on 2391 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.8925 - val_loss: 2.3727\n",
      "[INFO] Training model: epoch 4 - 3250/20505 samples\n",
      "Train on 2409 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.9352 - val_loss: 2.0798\n",
      "[INFO] Training model: epoch 4 - 3500/20505 samples\n",
      "Train on 2444 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.8653 - val_loss: 2.2631\n",
      "[INFO] Training model: epoch 4 - 3750/20505 samples\n",
      "Train on 2441 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 22s 9ms/step - loss: 1.7744 - val_loss: 2.2752\n",
      "[INFO] Training model: epoch 4 - 4000/20505 samples\n",
      "Train on 2419 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.8486 - val_loss: 2.1110\n",
      "[INFO] Training model: epoch 4 - 4250/20505 samples\n",
      "Train on 2410 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 9ms/step - loss: 1.8916 - val_loss: 2.3372\n",
      "[INFO] Training model: epoch 4 - 4500/20505 samples\n",
      "Train on 2445 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.9269 - val_loss: 2.1406\n",
      "[INFO] Training model: epoch 4 - 4750/20505 samples\n",
      "Train on 2412 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.9610 - val_loss: 2.3072\n",
      "[INFO] Training model: epoch 4 - 5000/20505 samples\n",
      "Train on 2408 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 21s 9ms/step - loss: 1.9144 - val_loss: 2.3452\n",
      "[INFO] Training model: epoch 4 - 5250/20505 samples\n",
      "Train on 2500 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.9601 - val_loss: 2.3606\n",
      "[INFO] Training model: epoch 4 - 5500/20505 samples\n",
      "Train on 2502 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.8823 - val_loss: 2.1988\n",
      "[INFO] Training model: epoch 4 - 5750/20505 samples\n",
      "Train on 2505 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.8329 - val_loss: 2.5443\n",
      "[INFO] Training model: epoch 4 - 6000/20505 samples\n",
      "Train on 2461 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.8096 - val_loss: 2.5711\n",
      "[INFO] Training model: epoch 4 - 6250/20505 samples\n",
      "Train on 2577 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 24s 9ms/step - loss: 1.9175 - val_loss: 2.2794\n",
      "[INFO] Training model: epoch 4 - 6500/20505 samples\n",
      "Train on 2476 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.9378 - val_loss: 2.4024\n",
      "[INFO] Training model: epoch 4 - 6750/20505 samples\n",
      "Train on 2439 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.8879 - val_loss: 2.2973\n",
      "[INFO] Training model: epoch 4 - 7000/20505 samples\n",
      "Train on 2499 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.8480 - val_loss: 2.2510\n",
      "[INFO] Training model: epoch 4 - 7250/20505 samples\n",
      "Train on 2373 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.8927 - val_loss: 2.1244\n",
      "[INFO] Training model: epoch 4 - 7500/20505 samples\n",
      "Train on 2422 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 1.8590 - val_loss: 2.2889\n",
      "[INFO] Training model: epoch 4 - 7750/20505 samples\n",
      "Train on 2450 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.8794 - val_loss: 2.3608\n",
      "[INFO] Training model: epoch 4 - 8000/20505 samples\n",
      "Train on 2412 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.8209 - val_loss: 2.2805\n",
      "[INFO] Training model: epoch 4 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.9515 - val_loss: 2.2631\n",
      "[INFO] Training model: epoch 4 - 8500/20505 samples\n",
      "Train on 2445 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.8774 - val_loss: 2.2549\n",
      "[INFO] Training model: epoch 4 - 8750/20505 samples\n",
      "Train on 2421 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.8524 - val_loss: 2.3661\n",
      "[INFO] Training model: epoch 4 - 9000/20505 samples\n",
      "Train on 2426 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.8206 - val_loss: 2.5110\n",
      "[INFO] Training model: epoch 4 - 9250/20505 samples\n",
      "Train on 2479 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.8867 - val_loss: 2.3695\n",
      "[INFO] Training model: epoch 4 - 9500/20505 samples\n",
      "Train on 2618 samples, validate on 603 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2618/2618 [==============================] - 24s 9ms/step - loss: 1.8837 - val_loss: 2.1510\n",
      "[INFO] Training model: epoch 4 - 9750/20505 samples\n",
      "Train on 2466 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.8331 - val_loss: 2.1895\n",
      "[INFO] Training model: epoch 4 - 10000/20505 samples\n",
      "Train on 2588 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2588/2588 [==============================] - 24s 9ms/step - loss: 1.9080 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 4 - 10250/20505 samples\n",
      "Train on 2361 samples, validate on 679 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 21s 9ms/step - loss: 1.9049 - val_loss: 2.2427\n",
      "[INFO] Training model: epoch 4 - 10500/20505 samples\n",
      "Train on 2474 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.9174 - val_loss: 2.2741\n",
      "[INFO] Training model: epoch 4 - 10750/20505 samples\n",
      "Train on 2365 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.9266 - val_loss: 2.2804\n",
      "[INFO] Training model: epoch 4 - 11000/20505 samples\n",
      "Train on 2443 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.8663 - val_loss: 2.5425\n",
      "[INFO] Training model: epoch 4 - 11250/20505 samples\n",
      "Train on 2515 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.9228 - val_loss: 2.4609\n",
      "[INFO] Training model: epoch 4 - 11500/20505 samples\n",
      "Train on 2480 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.9351 - val_loss: 2.1128\n",
      "[INFO] Training model: epoch 4 - 11750/20505 samples\n",
      "Train on 2399 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.9186 - val_loss: 2.1957\n",
      "[INFO] Training model: epoch 4 - 12000/20505 samples\n",
      "Train on 2488 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 22s 9ms/step - loss: 1.9209 - val_loss: 2.2131\n",
      "[INFO] Training model: epoch 4 - 12250/20505 samples\n",
      "Train on 2470 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 22s 9ms/step - loss: 1.9218 - val_loss: 2.2256\n",
      "[INFO] Training model: epoch 4 - 12500/20505 samples\n",
      "Train on 2459 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.8631 - val_loss: 2.1819\n",
      "[INFO] Training model: epoch 4 - 12750/20505 samples\n",
      "Train on 2529 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.8885 - val_loss: 2.1035\n",
      "[INFO] Training model: epoch 4 - 13000/20505 samples\n",
      "Train on 2332 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2332/2332 [==============================] - 20s 9ms/step - loss: 1.9453 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 4 - 13250/20505 samples\n",
      "Train on 2377 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 21s 9ms/step - loss: 1.9469 - val_loss: 2.4771\n",
      "[INFO] Training model: epoch 4 - 13500/20505 samples\n",
      "Train on 2544 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2544/2544 [==============================] - 23s 9ms/step - loss: 1.8625 - val_loss: 2.1636\n",
      "[INFO] Training model: epoch 4 - 13750/20505 samples\n",
      "Train on 2449 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.8517 - val_loss: 2.1139\n",
      "[INFO] Training model: epoch 4 - 14000/20505 samples\n",
      "Train on 2447 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.8558 - val_loss: 2.0986\n",
      "[INFO] Training model: epoch 4 - 14250/20505 samples\n",
      "Train on 2389 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 10ms/step - loss: 1.8420 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 4 - 14500/20505 samples\n",
      "Train on 2447 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.9212 - val_loss: 2.3392\n",
      "[INFO] Training model: epoch 4 - 14750/20505 samples\n",
      "Train on 2448 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 2.0031 - val_loss: 2.2180\n",
      "[INFO] Training model: epoch 4 - 15000/20505 samples\n",
      "Train on 2374 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.8841 - val_loss: 2.4357\n",
      "[INFO] Training model: epoch 4 - 15250/20505 samples\n",
      "Train on 2358 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2358/2358 [==============================] - 22s 9ms/step - loss: 1.8365 - val_loss: 2.1272\n",
      "[INFO] Training model: epoch 4 - 15500/20505 samples\n",
      "Train on 2546 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 23s 9ms/step - loss: 1.8368 - val_loss: 2.4724\n",
      "[INFO] Training model: epoch 4 - 15750/20505 samples\n",
      "Train on 2360 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 20s 9ms/step - loss: 1.9465 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 4 - 16000/20505 samples\n",
      "Train on 2526 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.8555 - val_loss: 2.4807\n",
      "[INFO] Training model: epoch 4 - 16250/20505 samples\n",
      "Train on 2452 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 21s 9ms/step - loss: 1.8927 - val_loss: 2.2656\n",
      "[INFO] Training model: epoch 4 - 16500/20505 samples\n",
      "Train on 2549 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 24s 9ms/step - loss: 1.9135 - val_loss: 2.2410\n",
      "[INFO] Training model: epoch 4 - 16750/20505 samples\n",
      "Train on 2430 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.9829 - val_loss: 2.4204\n",
      "[INFO] Training model: epoch 4 - 17000/20505 samples\n",
      "Train on 2443 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 2.0419 - val_loss: 2.4511\n",
      "[INFO] Training model: epoch 4 - 17250/20505 samples\n",
      "Train on 2577 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2577/2577 [==============================] - 24s 9ms/step - loss: 1.9187 - val_loss: 2.3724\n",
      "[INFO] Training model: epoch 4 - 17500/20505 samples\n",
      "Train on 2380 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.9575 - val_loss: 2.4231\n",
      "[INFO] Training model: epoch 4 - 17750/20505 samples\n",
      "Train on 2398 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.9364 - val_loss: 2.1313\n",
      "[INFO] Training model: epoch 4 - 18000/20505 samples\n",
      "Train on 2418 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 21s 9ms/step - loss: 1.9309 - val_loss: 2.1786\n",
      "[INFO] Training model: epoch 4 - 18250/20505 samples\n",
      "Train on 2332 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2332/2332 [==============================] - 22s 9ms/step - loss: 1.9019 - val_loss: 2.4738\n",
      "[INFO] Training model: epoch 4 - 18500/20505 samples\n",
      "Train on 2443 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.8825 - val_loss: 2.1931\n",
      "[INFO] Training model: epoch 4 - 18750/20505 samples\n",
      "Train on 2513 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 1.9521 - val_loss: 2.2412\n",
      "[INFO] Training model: epoch 4 - 19000/20505 samples\n",
      "Train on 2409 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 21s 9ms/step - loss: 1.8999 - val_loss: 2.2668\n",
      "[INFO] Training model: epoch 4 - 19250/20505 samples\n",
      "Train on 2449 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.9619 - val_loss: 2.0539\n",
      "[INFO] Training model: epoch 4 - 19500/20505 samples\n",
      "Train on 2323 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2323/2323 [==============================] - 20s 9ms/step - loss: 1.9228 - val_loss: 2.3549\n",
      "[INFO] Training model: epoch 4 - 19750/20505 samples\n",
      "Train on 2472 samples, validate on 645 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.9326 - val_loss: 2.2581\n",
      "[INFO] Training model: epoch 4 - 20000/20505 samples\n",
      "Train on 2673 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2673/2673 [==============================] - 25s 9ms/step - loss: 1.8769 - val_loss: 2.1921\n",
      "[INFO] Training model: epoch 4 - 20250/20505 samples\n",
      "Train on 2570 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 24s 9ms/step - loss: 1.9859 - val_loss: 2.5148\n",
      "[INFO] Training model: epoch 4 - 20500/20505 samples\n",
      "Train on 48 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "48/48 [==============================] - 1s 11ms/step - loss: 1.7381 - val_loss: 1.6902\n",
      "[INFO] Training model: epoch 5 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.6588 - val_loss: 2.1795\n",
      "[INFO] Training model: epoch 5 - 250/20505 samples\n",
      "Train on 2528 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.7280 - val_loss: 2.5894\n",
      "[INFO] Training model: epoch 5 - 500/20505 samples\n",
      "Train on 2448 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.6344 - val_loss: 2.3779\n",
      "[INFO] Training model: epoch 5 - 750/20505 samples\n",
      "Train on 2480 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.7078 - val_loss: 2.4007\n",
      "[INFO] Training model: epoch 5 - 1000/20505 samples\n",
      "Train on 2373 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.7302 - val_loss: 2.2991\n",
      "[INFO] Training model: epoch 5 - 1250/20505 samples\n",
      "Train on 2621 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2621/2621 [==============================] - 24s 9ms/step - loss: 1.7348 - val_loss: 2.2687\n",
      "[INFO] Training model: epoch 5 - 1500/20505 samples\n",
      "Train on 2563 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 22s 9ms/step - loss: 1.7571 - val_loss: 2.3786\n",
      "[INFO] Training model: epoch 5 - 1750/20505 samples\n",
      "Train on 2496 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.6953 - val_loss: 2.0289\n",
      "[INFO] Training model: epoch 5 - 2000/20505 samples\n",
      "Train on 2488 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.6804 - val_loss: 2.2218\n",
      "[INFO] Training model: epoch 5 - 2250/20505 samples\n",
      "Train on 2384 samples, validate on 701 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.7762 - val_loss: 2.3217\n",
      "[INFO] Training model: epoch 5 - 2500/20505 samples\n",
      "Train on 2479 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 21s 9ms/step - loss: 1.7130 - val_loss: 2.1191\n",
      "[INFO] Training model: epoch 5 - 2750/20505 samples\n",
      "Train on 2586 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 24s 9ms/step - loss: 1.7713 - val_loss: 2.2365\n",
      "[INFO] Training model: epoch 5 - 3000/20505 samples\n",
      "Train on 2406 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 22s 9ms/step - loss: 1.7563 - val_loss: 2.4710\n",
      "[INFO] Training model: epoch 5 - 3250/20505 samples\n",
      "Train on 2446 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.6794 - val_loss: 2.1599\n",
      "[INFO] Training model: epoch 5 - 3500/20505 samples\n",
      "Train on 2398 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2398/2398 [==============================] - 22s 9ms/step - loss: 1.7460 - val_loss: 2.1127\n",
      "[INFO] Training model: epoch 5 - 3750/20505 samples\n",
      "Train on 2412 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.7539 - val_loss: 2.4862\n",
      "[INFO] Training model: epoch 5 - 4000/20505 samples\n",
      "Train on 2507 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.6685 - val_loss: 2.2009\n",
      "[INFO] Training model: epoch 5 - 4250/20505 samples\n",
      "Train on 2438 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.8401 - val_loss: 2.3447\n",
      "[INFO] Training model: epoch 5 - 4500/20505 samples\n",
      "Train on 2497 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 22s 9ms/step - loss: 1.7904 - val_loss: 2.3172\n",
      "[INFO] Training model: epoch 5 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.7795 - val_loss: 2.4117\n",
      "[INFO] Training model: epoch 5 - 5000/20505 samples\n",
      "Train on 2446 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.7072 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 5 - 5250/20505 samples\n",
      "Train on 2455 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 22s 9ms/step - loss: 1.6254 - val_loss: 2.2444\n",
      "[INFO] Training model: epoch 5 - 5500/20505 samples\n",
      "Train on 2346 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 22s 9ms/step - loss: 1.6726 - val_loss: 2.5422\n",
      "[INFO] Training model: epoch 5 - 5750/20505 samples\n",
      "Train on 2512 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 9ms/step - loss: 1.7776 - val_loss: 2.3551\n",
      "[INFO] Training model: epoch 5 - 6000/20505 samples\n",
      "Train on 2541 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.8737 - val_loss: 2.4247\n",
      "[INFO] Training model: epoch 5 - 6250/20505 samples\n",
      "Train on 2477 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.7692 - val_loss: 2.3936\n",
      "[INFO] Training model: epoch 5 - 6500/20505 samples\n",
      "Train on 2494 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.6913 - val_loss: 2.3650\n",
      "[INFO] Training model: epoch 5 - 6750/20505 samples\n",
      "Train on 2392 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.7650 - val_loss: 2.0583\n",
      "[INFO] Training model: epoch 5 - 7000/20505 samples\n",
      "Train on 2315 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 21s 9ms/step - loss: 1.7746 - val_loss: 2.2880\n",
      "[INFO] Training model: epoch 5 - 7250/20505 samples\n",
      "Train on 2451 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.7709 - val_loss: 2.2970\n",
      "[INFO] Training model: epoch 5 - 7500/20505 samples\n",
      "Train on 2522 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.7517 - val_loss: 2.3807\n",
      "[INFO] Training model: epoch 5 - 7750/20505 samples\n",
      "Train on 2445 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 10ms/step - loss: 1.8237 - val_loss: 2.2784\n",
      "[INFO] Training model: epoch 5 - 8000/20505 samples\n",
      "Train on 2438 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.7687 - val_loss: 2.2626\n",
      "[INFO] Training model: epoch 5 - 8250/20505 samples\n",
      "Train on 2395 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 23s 9ms/step - loss: 1.7875 - val_loss: 2.2748\n",
      "[INFO] Training model: epoch 5 - 8500/20505 samples\n",
      "Train on 2409 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.8377 - val_loss: 2.3619\n",
      "[INFO] Training model: epoch 5 - 8750/20505 samples\n",
      "Train on 2425 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.7089 - val_loss: 2.4154\n",
      "[INFO] Training model: epoch 5 - 9000/20505 samples\n",
      "Train on 2518 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.7544 - val_loss: 2.2951\n",
      "[INFO] Training model: epoch 5 - 9250/20505 samples\n",
      "Train on 2531 samples, validate on 595 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.7499 - val_loss: 2.5523\n",
      "[INFO] Training model: epoch 5 - 9500/20505 samples\n",
      "Train on 2451 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 21s 9ms/step - loss: 1.7993 - val_loss: 2.5333\n",
      "[INFO] Training model: epoch 5 - 9750/20505 samples\n",
      "Train on 2461 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.7712 - val_loss: 2.2353\n",
      "[INFO] Training model: epoch 5 - 10000/20505 samples\n",
      "Train on 2493 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 22s 9ms/step - loss: 1.8271 - val_loss: 2.3032\n",
      "[INFO] Training model: epoch 5 - 10250/20505 samples\n",
      "Train on 2477 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.7321 - val_loss: 2.5237\n",
      "[INFO] Training model: epoch 5 - 10500/20505 samples\n",
      "Train on 2462 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 21s 9ms/step - loss: 1.8266 - val_loss: 2.3225\n",
      "[INFO] Training model: epoch 5 - 10750/20505 samples\n",
      "Train on 2399 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.7260 - val_loss: 2.2284\n",
      "[INFO] Training model: epoch 5 - 11000/20505 samples\n",
      "Train on 2473 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.8306 - val_loss: 2.2246\n",
      "[INFO] Training model: epoch 5 - 11250/20505 samples\n",
      "Train on 2445 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.8767 - val_loss: 2.0386\n",
      "[INFO] Training model: epoch 5 - 11500/20505 samples\n",
      "Train on 2470 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 21s 9ms/step - loss: 1.8679 - val_loss: 2.3615\n",
      "[INFO] Training model: epoch 5 - 11750/20505 samples\n",
      "Train on 2529 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 23s 9ms/step - loss: 1.8508 - val_loss: 2.1514\n",
      "[INFO] Training model: epoch 5 - 12000/20505 samples\n",
      "Train on 2396 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.8328 - val_loss: 2.5286\n",
      "[INFO] Training model: epoch 5 - 12250/20505 samples\n",
      "Train on 2339 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 22s 9ms/step - loss: 1.7740 - val_loss: 2.5101\n",
      "[INFO] Training model: epoch 5 - 12500/20505 samples\n",
      "Train on 2424 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.8361 - val_loss: 2.3302\n",
      "[INFO] Training model: epoch 5 - 12750/20505 samples\n",
      "Train on 2415 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.8605 - val_loss: 2.4586\n",
      "[INFO] Training model: epoch 5 - 13000/20505 samples\n",
      "Train on 2519 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.7856 - val_loss: 2.3343\n",
      "[INFO] Training model: epoch 5 - 13250/20505 samples\n",
      "Train on 2476 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.8638 - val_loss: 2.2934\n",
      "[INFO] Training model: epoch 5 - 13500/20505 samples\n",
      "Train on 2586 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 22s 9ms/step - loss: 1.7022 - val_loss: 2.2078\n",
      "[INFO] Training model: epoch 5 - 13750/20505 samples\n",
      "Train on 2411 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 23s 9ms/step - loss: 1.8114 - val_loss: 2.3719\n",
      "[INFO] Training model: epoch 5 - 14000/20505 samples\n",
      "Train on 2540 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.8806 - val_loss: 2.2540\n",
      "[INFO] Training model: epoch 5 - 14250/20505 samples\n",
      "Train on 2432 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.9148 - val_loss: 2.0796\n",
      "[INFO] Training model: epoch 5 - 14500/20505 samples\n",
      "Train on 2393 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.7767 - val_loss: 2.3064\n",
      "[INFO] Training model: epoch 5 - 14750/20505 samples\n",
      "Train on 2497 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.7721 - val_loss: 2.4710\n",
      "[INFO] Training model: epoch 5 - 15000/20505 samples\n",
      "Train on 2442 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.8235 - val_loss: 2.3506\n",
      "[INFO] Training model: epoch 5 - 15250/20505 samples\n",
      "Train on 2486 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.8534 - val_loss: 2.3857\n",
      "[INFO] Training model: epoch 5 - 15500/20505 samples\n",
      "Train on 2381 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 21s 9ms/step - loss: 1.8651 - val_loss: 2.5534\n",
      "[INFO] Training model: epoch 5 - 15750/20505 samples\n",
      "Train on 2362 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 1.7420 - val_loss: 2.5371\n",
      "[INFO] Training model: epoch 5 - 16000/20505 samples\n",
      "Train on 2430 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.8132 - val_loss: 2.5304\n",
      "[INFO] Training model: epoch 5 - 16250/20505 samples\n",
      "Train on 2425 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.7712 - val_loss: 2.2208\n",
      "[INFO] Training model: epoch 5 - 16500/20505 samples\n",
      "Train on 2371 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.7880 - val_loss: 2.2664\n",
      "[INFO] Training model: epoch 5 - 16750/20505 samples\n",
      "Train on 2435 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.8680 - val_loss: 2.4669\n",
      "[INFO] Training model: epoch 5 - 17000/20505 samples\n",
      "Train on 2440 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.8582 - val_loss: 2.4023\n",
      "[INFO] Training model: epoch 5 - 17250/20505 samples\n",
      "Train on 2473 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.7905 - val_loss: 2.2635\n",
      "[INFO] Training model: epoch 5 - 17500/20505 samples\n",
      "Train on 2396 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.7842 - val_loss: 2.1404\n",
      "[INFO] Training model: epoch 5 - 17750/20505 samples\n",
      "Train on 2482 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.8415 - val_loss: 2.1168\n",
      "[INFO] Training model: epoch 5 - 18000/20505 samples\n",
      "Train on 2350 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 22s 9ms/step - loss: 1.8460 - val_loss: 2.5834\n",
      "[INFO] Training model: epoch 5 - 18250/20505 samples\n",
      "Train on 2489 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 22s 9ms/step - loss: 1.8516 - val_loss: 2.0430\n",
      "[INFO] Training model: epoch 5 - 18500/20505 samples\n",
      "Train on 2575 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 24s 9ms/step - loss: 1.7680 - val_loss: 2.3112\n",
      "[INFO] Training model: epoch 5 - 18750/20505 samples\n",
      "Train on 2357 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 20s 9ms/step - loss: 1.8306 - val_loss: 2.2618\n",
      "[INFO] Training model: epoch 5 - 19000/20505 samples\n",
      "Train on 2486 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.8506 - val_loss: 2.3207\n",
      "[INFO] Training model: epoch 5 - 19250/20505 samples\n",
      "Train on 2561 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 22s 9ms/step - loss: 1.7900 - val_loss: 2.1994\n",
      "[INFO] Training model: epoch 5 - 19500/20505 samples\n",
      "Train on 2447 samples, validate on 633 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.8832 - val_loss: 2.1714\n",
      "[INFO] Training model: epoch 5 - 19750/20505 samples\n",
      "Train on 2476 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.7426 - val_loss: 2.5985\n",
      "[INFO] Training model: epoch 5 - 20000/20505 samples\n",
      "Train on 2446 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.8426 - val_loss: 2.3097\n",
      "[INFO] Training model: epoch 5 - 20250/20505 samples\n",
      "Train on 2414 samples, validate on 673 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.7997 - val_loss: 2.2960\n",
      "[INFO] Training model: epoch 5 - 20500/20505 samples\n",
      "Train on 58 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 1.6416 - val_loss: 3.4273\n",
      "[INFO] Training model: epoch 6 - 0/20505 samples\n",
      "Train on 2421 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.6970 - val_loss: 2.4960\n",
      "[INFO] Training model: epoch 6 - 250/20505 samples\n",
      "Train on 2495 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.6130 - val_loss: 2.2849\n",
      "[INFO] Training model: epoch 6 - 500/20505 samples\n",
      "Train on 2512 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 23s 9ms/step - loss: 1.5883 - val_loss: 2.3773\n",
      "[INFO] Training model: epoch 6 - 750/20505 samples\n",
      "Train on 2433 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 21s 9ms/step - loss: 1.6403 - val_loss: 2.2587\n",
      "[INFO] Training model: epoch 6 - 1000/20505 samples\n",
      "Train on 2507 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.6721 - val_loss: 2.0345\n",
      "[INFO] Training model: epoch 6 - 1250/20505 samples\n",
      "Train on 2429 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.6330 - val_loss: 2.4260\n",
      "[INFO] Training model: epoch 6 - 1500/20505 samples\n",
      "Train on 2474 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.6099 - val_loss: 2.3333\n",
      "[INFO] Training model: epoch 6 - 1750/20505 samples\n",
      "Train on 2524 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.6078 - val_loss: 2.1451\n",
      "[INFO] Training model: epoch 6 - 2000/20505 samples\n",
      "Train on 2427 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.6317 - val_loss: 2.4242\n",
      "[INFO] Training model: epoch 6 - 2250/20505 samples\n",
      "Train on 2426 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.6050 - val_loss: 2.2428\n",
      "[INFO] Training model: epoch 6 - 2500/20505 samples\n",
      "Train on 2335 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 22s 9ms/step - loss: 1.6385 - val_loss: 2.2996\n",
      "[INFO] Training model: epoch 6 - 2750/20505 samples\n",
      "Train on 2536 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 22s 9ms/step - loss: 1.6037 - val_loss: 2.3593\n",
      "[INFO] Training model: epoch 6 - 3000/20505 samples\n",
      "Train on 2480 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.6541 - val_loss: 2.2419\n",
      "[INFO] Training model: epoch 6 - 3250/20505 samples\n",
      "Train on 2513 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 22s 9ms/step - loss: 1.6458 - val_loss: 2.2877\n",
      "[INFO] Training model: epoch 6 - 3500/20505 samples\n",
      "Train on 2426 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.5270 - val_loss: 2.1816\n",
      "[INFO] Training model: epoch 6 - 3750/20505 samples\n",
      "Train on 2467 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.6266 - val_loss: 2.2949\n",
      "[INFO] Training model: epoch 6 - 4000/20505 samples\n",
      "Train on 2384 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.7333 - val_loss: 2.2862\n",
      "[INFO] Training model: epoch 6 - 4250/20505 samples\n",
      "Train on 2461 samples, validate on 672 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.6214 - val_loss: 2.6528\n",
      "[INFO] Training model: epoch 6 - 4500/20505 samples\n",
      "Train on 2435 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.6428 - val_loss: 2.6257\n",
      "[INFO] Training model: epoch 6 - 4750/20505 samples\n",
      "Train on 2580 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 23s 9ms/step - loss: 1.6013 - val_loss: 2.4786\n",
      "[INFO] Training model: epoch 6 - 5000/20505 samples\n",
      "Train on 2373 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.6726 - val_loss: 2.0889\n",
      "[INFO] Training model: epoch 6 - 5250/20505 samples\n",
      "Train on 2420 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 21s 9ms/step - loss: 1.5415 - val_loss: 2.4912\n",
      "[INFO] Training model: epoch 6 - 5500/20505 samples\n",
      "Train on 2460 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.6232 - val_loss: 2.2377\n",
      "[INFO] Training model: epoch 6 - 5750/20505 samples\n",
      "Train on 2436 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 9ms/step - loss: 1.6815 - val_loss: 2.5921\n",
      "[INFO] Training model: epoch 6 - 6000/20505 samples\n",
      "Train on 2461 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.6216 - val_loss: 2.3263\n",
      "[INFO] Training model: epoch 6 - 6250/20505 samples\n",
      "Train on 2424 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.6932 - val_loss: 2.1140\n",
      "[INFO] Training model: epoch 6 - 6500/20505 samples\n",
      "Train on 2421 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.6109 - val_loss: 2.3272\n",
      "[INFO] Training model: epoch 6 - 6750/20505 samples\n",
      "Train on 2408 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.6297 - val_loss: 2.3727\n",
      "[INFO] Training model: epoch 6 - 7000/20505 samples\n",
      "Train on 2421 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.6129 - val_loss: 2.5436\n",
      "[INFO] Training model: epoch 6 - 7250/20505 samples\n",
      "Train on 2473 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.6869 - val_loss: 2.4687\n",
      "[INFO] Training model: epoch 6 - 7500/20505 samples\n",
      "Train on 2464 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.6035 - val_loss: 2.0970\n",
      "[INFO] Training model: epoch 6 - 7750/20505 samples\n",
      "Train on 2477 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.7168 - val_loss: 2.0737\n",
      "[INFO] Training model: epoch 6 - 8000/20505 samples\n",
      "Train on 2444 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.7218 - val_loss: 2.4107\n",
      "[INFO] Training model: epoch 6 - 8250/20505 samples\n",
      "Train on 2465 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.7547 - val_loss: 2.5391\n",
      "[INFO] Training model: epoch 6 - 8500/20505 samples\n",
      "Train on 2529 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.6680 - val_loss: 2.2534\n",
      "[INFO] Training model: epoch 6 - 8750/20505 samples\n",
      "Train on 2465 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.6374 - val_loss: 2.2134\n",
      "[INFO] Training model: epoch 6 - 9000/20505 samples\n",
      "Train on 2425 samples, validate on 566 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.6890 - val_loss: 2.2453\n",
      "[INFO] Training model: epoch 6 - 9250/20505 samples\n",
      "Train on 2443 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.7445 - val_loss: 2.1644\n",
      "[INFO] Training model: epoch 6 - 9500/20505 samples\n",
      "Train on 2543 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 24s 9ms/step - loss: 1.7439 - val_loss: 2.5242\n",
      "[INFO] Training model: epoch 6 - 9750/20505 samples\n",
      "Train on 2472 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.6768 - val_loss: 2.3641\n",
      "[INFO] Training model: epoch 6 - 10000/20505 samples\n",
      "Train on 2438 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.7202 - val_loss: 2.2866\n",
      "[INFO] Training model: epoch 6 - 10250/20505 samples\n",
      "Train on 2510 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 23s 9ms/step - loss: 1.6588 - val_loss: 2.4374\n",
      "[INFO] Training model: epoch 6 - 10500/20505 samples\n",
      "Train on 2416 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.6831 - val_loss: 2.3973\n",
      "[INFO] Training model: epoch 6 - 10750/20505 samples\n",
      "Train on 2518 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.6286 - val_loss: 2.3987\n",
      "[INFO] Training model: epoch 6 - 11000/20505 samples\n",
      "Train on 2462 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.6979 - val_loss: 2.5231\n",
      "[INFO] Training model: epoch 6 - 11250/20505 samples\n",
      "Train on 2452 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.7115 - val_loss: 2.3102\n",
      "[INFO] Training model: epoch 6 - 11500/20505 samples\n",
      "Train on 2476 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.6436 - val_loss: 2.4744\n",
      "[INFO] Training model: epoch 6 - 11750/20505 samples\n",
      "Train on 2431 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.7299 - val_loss: 2.3264\n",
      "[INFO] Training model: epoch 6 - 12000/20505 samples\n",
      "Train on 2475 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.6288 - val_loss: 2.4985\n",
      "[INFO] Training model: epoch 6 - 12250/20505 samples\n",
      "Train on 2558 samples, validate on 686 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.7051 - val_loss: 2.3350\n",
      "[INFO] Training model: epoch 6 - 12500/20505 samples\n",
      "Train on 2429 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.7141 - val_loss: 2.0375\n",
      "[INFO] Training model: epoch 6 - 12750/20505 samples\n",
      "Train on 2440 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.7222 - val_loss: 2.5432\n",
      "[INFO] Training model: epoch 6 - 13000/20505 samples\n",
      "Train on 2413 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.7120 - val_loss: 2.2495\n",
      "[INFO] Training model: epoch 6 - 13250/20505 samples\n",
      "Train on 2609 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 24s 9ms/step - loss: 1.6765 - val_loss: 2.5382\n",
      "[INFO] Training model: epoch 6 - 13500/20505 samples\n",
      "Train on 2483 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.7931 - val_loss: 2.1695\n",
      "[INFO] Training model: epoch 6 - 13750/20505 samples\n",
      "Train on 2518 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.6132 - val_loss: 2.3552\n",
      "[INFO] Training model: epoch 6 - 14000/20505 samples\n",
      "Train on 2485 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.7079 - val_loss: 2.4400\n",
      "[INFO] Training model: epoch 6 - 14250/20505 samples\n",
      "Train on 2338 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2338/2338 [==============================] - 22s 9ms/step - loss: 1.7291 - val_loss: 2.3762\n",
      "[INFO] Training model: epoch 6 - 14500/20505 samples\n",
      "Train on 2376 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 21s 9ms/step - loss: 1.7457 - val_loss: 2.4927\n",
      "[INFO] Training model: epoch 6 - 14750/20505 samples\n",
      "Train on 2474 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.6840 - val_loss: 2.4033\n",
      "[INFO] Training model: epoch 6 - 15000/20505 samples\n",
      "Train on 2540 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.7175 - val_loss: 2.5282\n",
      "[INFO] Training model: epoch 6 - 15250/20505 samples\n",
      "Train on 2365 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.6456 - val_loss: 2.3759\n",
      "[INFO] Training model: epoch 6 - 15500/20505 samples\n",
      "Train on 2454 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.6197 - val_loss: 2.2829\n",
      "[INFO] Training model: epoch 6 - 15750/20505 samples\n",
      "Train on 2514 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 22s 9ms/step - loss: 1.7261 - val_loss: 2.5984\n",
      "[INFO] Training model: epoch 6 - 16000/20505 samples\n",
      "Train on 2359 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 1.6230 - val_loss: 2.3596\n",
      "[INFO] Training model: epoch 6 - 16250/20505 samples\n",
      "Train on 2459 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 21s 9ms/step - loss: 1.7241 - val_loss: 2.3302\n",
      "[INFO] Training model: epoch 6 - 16500/20505 samples\n",
      "Train on 2456 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.7264 - val_loss: 2.6006\n",
      "[INFO] Training model: epoch 6 - 16750/20505 samples\n",
      "Train on 2529 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 23s 9ms/step - loss: 1.7672 - val_loss: 2.2009\n",
      "[INFO] Training model: epoch 6 - 17000/20505 samples\n",
      "Train on 2500 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.7326 - val_loss: 2.2105\n",
      "[INFO] Training model: epoch 6 - 17250/20505 samples\n",
      "Train on 2430 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.7581 - val_loss: 2.2474\n",
      "[INFO] Training model: epoch 6 - 17500/20505 samples\n",
      "Train on 2465 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.7938 - val_loss: 2.3136\n",
      "[INFO] Training model: epoch 6 - 17750/20505 samples\n",
      "Train on 2414 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.7278 - val_loss: 2.1119\n",
      "[INFO] Training model: epoch 6 - 18000/20505 samples\n",
      "Train on 2450 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 22s 9ms/step - loss: 1.7657 - val_loss: 2.2828\n",
      "[INFO] Training model: epoch 6 - 18250/20505 samples\n",
      "Train on 2376 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 21s 9ms/step - loss: 1.7093 - val_loss: 2.3104\n",
      "[INFO] Training model: epoch 6 - 18500/20505 samples\n",
      "Train on 2521 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 22s 9ms/step - loss: 1.7807 - val_loss: 2.3583\n",
      "[INFO] Training model: epoch 6 - 18750/20505 samples\n",
      "Train on 2371 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 21s 9ms/step - loss: 1.7420 - val_loss: 2.1900\n",
      "[INFO] Training model: epoch 6 - 19000/20505 samples\n",
      "Train on 2432 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.7618 - val_loss: 2.2859\n",
      "[INFO] Training model: epoch 6 - 19250/20505 samples\n",
      "Train on 2343 samples, validate on 600 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2343/2343 [==============================] - 21s 9ms/step - loss: 1.6982 - val_loss: 2.4171\n",
      "[INFO] Training model: epoch 6 - 19500/20505 samples\n",
      "Train on 2420 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.7421 - val_loss: 2.5573\n",
      "[INFO] Training model: epoch 6 - 19750/20505 samples\n",
      "Train on 2570 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 23s 9ms/step - loss: 1.7655 - val_loss: 2.4473\n",
      "[INFO] Training model: epoch 6 - 20000/20505 samples\n",
      "Train on 2404 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 22s 9ms/step - loss: 1.7779 - val_loss: 2.5735\n",
      "[INFO] Training model: epoch 6 - 20250/20505 samples\n",
      "Train on 2450 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 21s 9ms/step - loss: 1.6975 - val_loss: 2.5984\n",
      "[INFO] Training model: epoch 6 - 20500/20505 samples\n",
      "Train on 44 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 2.3004 - val_loss: 3.0366\n",
      "[INFO] Training model: epoch 7 - 0/20505 samples\n",
      "Train on 2488 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 23s 9ms/step - loss: 1.4763 - val_loss: 2.2780\n",
      "[INFO] Training model: epoch 7 - 250/20505 samples\n",
      "Train on 2443 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.4953 - val_loss: 2.1234\n",
      "[INFO] Training model: epoch 7 - 500/20505 samples\n",
      "Train on 2385 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.5771 - val_loss: 2.2463\n",
      "[INFO] Training model: epoch 7 - 750/20505 samples\n",
      "Train on 2476 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.5056 - val_loss: 2.1917\n",
      "[INFO] Training model: epoch 7 - 1000/20505 samples\n",
      "Train on 2392 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.4971 - val_loss: 2.4398\n",
      "[INFO] Training model: epoch 7 - 1250/20505 samples\n",
      "Train on 2457 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.5337 - val_loss: 2.2988\n",
      "[INFO] Training model: epoch 7 - 1500/20505 samples\n",
      "Train on 2492 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 22s 9ms/step - loss: 1.5026 - val_loss: 2.3642\n",
      "[INFO] Training model: epoch 7 - 1750/20505 samples\n",
      "Train on 2578 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.5229 - val_loss: 2.6030\n",
      "[INFO] Training model: epoch 7 - 2000/20505 samples\n",
      "Train on 2437 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.5252 - val_loss: 2.0496\n",
      "[INFO] Training model: epoch 7 - 2250/20505 samples\n",
      "Train on 2413 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.5389 - val_loss: 2.3118\n",
      "[INFO] Training model: epoch 7 - 2500/20505 samples\n",
      "Train on 2421 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 21s 9ms/step - loss: 1.4964 - val_loss: 2.0663\n",
      "[INFO] Training model: epoch 7 - 2750/20505 samples\n",
      "Train on 2533 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 23s 9ms/step - loss: 1.5114 - val_loss: 2.2290\n",
      "[INFO] Training model: epoch 7 - 3000/20505 samples\n",
      "Train on 2394 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5039 - val_loss: 2.4504\n",
      "[INFO] Training model: epoch 7 - 3250/20505 samples\n",
      "Train on 2511 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.5438 - val_loss: 2.4028\n",
      "[INFO] Training model: epoch 7 - 3500/20505 samples\n",
      "Train on 2459 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.5891 - val_loss: 2.1991\n",
      "[INFO] Training model: epoch 7 - 3750/20505 samples\n",
      "Train on 2428 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.6195 - val_loss: 2.5187\n",
      "[INFO] Training model: epoch 7 - 4000/20505 samples\n",
      "Train on 2394 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5502 - val_loss: 2.4556\n",
      "[INFO] Training model: epoch 7 - 4250/20505 samples\n",
      "Train on 2430 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.6266 - val_loss: 2.3376\n",
      "[INFO] Training model: epoch 7 - 4500/20505 samples\n",
      "Train on 2454 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 22s 9ms/step - loss: 1.5222 - val_loss: 2.3722\n",
      "[INFO] Training model: epoch 7 - 4750/20505 samples\n",
      "Train on 2412 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.5967 - val_loss: 2.2392\n",
      "[INFO] Training model: epoch 7 - 5000/20505 samples\n",
      "Train on 2414 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 1.5900 - val_loss: 2.4648\n",
      "[INFO] Training model: epoch 7 - 5250/20505 samples\n",
      "Train on 2486 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.5873 - val_loss: 2.4198\n",
      "[INFO] Training model: epoch 7 - 5500/20505 samples\n",
      "Train on 2507 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 24s 9ms/step - loss: 1.5875 - val_loss: 2.1348\n",
      "[INFO] Training model: epoch 7 - 5750/20505 samples\n",
      "Train on 2370 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 21s 9ms/step - loss: 1.6221 - val_loss: 2.2851\n",
      "[INFO] Training model: epoch 7 - 6000/20505 samples\n",
      "Train on 2437 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 1.5326 - val_loss: 2.2213\n",
      "[INFO] Training model: epoch 7 - 6250/20505 samples\n",
      "Train on 2524 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 22s 9ms/step - loss: 1.5721 - val_loss: 2.3666\n",
      "[INFO] Training model: epoch 7 - 6500/20505 samples\n",
      "Train on 2364 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.4773 - val_loss: 2.4268\n",
      "[INFO] Training model: epoch 7 - 6750/20505 samples\n",
      "Train on 2499 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.5269 - val_loss: 2.2204\n",
      "[INFO] Training model: epoch 7 - 7000/20505 samples\n",
      "Train on 2382 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.6021 - val_loss: 2.4607\n",
      "[INFO] Training model: epoch 7 - 7250/20505 samples\n",
      "Train on 2531 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.5950 - val_loss: 2.7721\n",
      "[INFO] Training model: epoch 7 - 7500/20505 samples\n",
      "Train on 2489 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.5564 - val_loss: 2.2557\n",
      "[INFO] Training model: epoch 7 - 7750/20505 samples\n",
      "Train on 2431 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 23s 9ms/step - loss: 1.6196 - val_loss: 2.3948\n",
      "[INFO] Training model: epoch 7 - 8000/20505 samples\n",
      "Train on 2468 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 21s 9ms/step - loss: 1.5953 - val_loss: 2.5672\n",
      "[INFO] Training model: epoch 7 - 8250/20505 samples\n",
      "Train on 2433 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.6247 - val_loss: 2.3639\n",
      "[INFO] Training model: epoch 7 - 8500/20505 samples\n",
      "Train on 2480 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.5937 - val_loss: 2.4006\n",
      "[INFO] Training model: epoch 7 - 8750/20505 samples\n",
      "Train on 2449 samples, validate on 665 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.6109 - val_loss: 2.3355\n",
      "[INFO] Training model: epoch 7 - 9000/20505 samples\n",
      "Train on 2572 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2572/2572 [==============================] - 22s 9ms/step - loss: 1.6855 - val_loss: 2.5221\n",
      "[INFO] Training model: epoch 7 - 9250/20505 samples\n",
      "Train on 2472 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.5566 - val_loss: 2.3681\n",
      "[INFO] Training model: epoch 7 - 9500/20505 samples\n",
      "Train on 2567 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 22s 9ms/step - loss: 1.5753 - val_loss: 2.3222\n",
      "[INFO] Training model: epoch 7 - 9750/20505 samples\n",
      "Train on 2523 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 22s 9ms/step - loss: 1.5586 - val_loss: 2.5310\n",
      "[INFO] Training model: epoch 7 - 10000/20505 samples\n",
      "Train on 2434 samples, validate on 554 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 21s 9ms/step - loss: 1.6161 - val_loss: 2.1261\n",
      "[INFO] Training model: epoch 7 - 10250/20505 samples\n",
      "Train on 2453 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 22s 9ms/step - loss: 1.5927 - val_loss: 2.2858\n",
      "[INFO] Training model: epoch 7 - 10500/20505 samples\n",
      "Train on 2560 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2560/2560 [==============================] - 24s 9ms/step - loss: 1.6111 - val_loss: 2.4876\n",
      "[INFO] Training model: epoch 7 - 10750/20505 samples\n",
      "Train on 2445 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.5732 - val_loss: 2.2471\n",
      "[INFO] Training model: epoch 7 - 11000/20505 samples\n",
      "Train on 2336 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2336/2336 [==============================] - 21s 9ms/step - loss: 1.5799 - val_loss: 2.2332\n",
      "[INFO] Training model: epoch 7 - 11250/20505 samples\n",
      "Train on 2562 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 22s 9ms/step - loss: 1.5524 - val_loss: 2.3192\n",
      "[INFO] Training model: epoch 7 - 11500/20505 samples\n",
      "Train on 2364 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.6110 - val_loss: 2.6067\n",
      "[INFO] Training model: epoch 7 - 11750/20505 samples\n",
      "Train on 2504 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 23s 9ms/step - loss: 1.6525 - val_loss: 2.4365\n",
      "[INFO] Training model: epoch 7 - 12000/20505 samples\n",
      "Train on 2462 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 22s 9ms/step - loss: 1.5801 - val_loss: 2.2681\n",
      "[INFO] Training model: epoch 7 - 12250/20505 samples\n",
      "Train on 2477 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.6111 - val_loss: 2.4492\n",
      "[INFO] Training model: epoch 7 - 12500/20505 samples\n",
      "Train on 2449 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 21s 9ms/step - loss: 1.5695 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 7 - 12750/20505 samples\n",
      "Train on 2586 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2586/2586 [==============================] - 24s 9ms/step - loss: 1.7065 - val_loss: 2.3356\n",
      "[INFO] Training model: epoch 7 - 13000/20505 samples\n",
      "Train on 2406 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 21s 9ms/step - loss: 1.6430 - val_loss: 2.2652\n",
      "[INFO] Training model: epoch 7 - 13250/20505 samples\n",
      "Train on 2443 samples, validate on 684 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.6526 - val_loss: 2.0837\n",
      "[INFO] Training model: epoch 7 - 13500/20505 samples\n",
      "Train on 2506 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 1.6170 - val_loss: 2.2738\n",
      "[INFO] Training model: epoch 7 - 13750/20505 samples\n",
      "Train on 2474 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.5978 - val_loss: 2.3005\n",
      "[INFO] Training model: epoch 7 - 14000/20505 samples\n",
      "Train on 2391 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.5105 - val_loss: 2.4274\n",
      "[INFO] Training model: epoch 7 - 14250/20505 samples\n",
      "Train on 2429 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5688 - val_loss: 2.4713\n",
      "[INFO] Training model: epoch 7 - 14500/20505 samples\n",
      "Train on 2429 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5981 - val_loss: 2.5741\n",
      "[INFO] Training model: epoch 7 - 14750/20505 samples\n",
      "Train on 2422 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 21s 9ms/step - loss: 1.6252 - val_loss: 2.5238\n",
      "[INFO] Training model: epoch 7 - 15000/20505 samples\n",
      "Train on 2446 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.5523 - val_loss: 2.5058\n",
      "[INFO] Training model: epoch 7 - 15250/20505 samples\n",
      "Train on 2418 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.6368 - val_loss: 2.3573\n",
      "[INFO] Training model: epoch 7 - 15500/20505 samples\n",
      "Train on 2431 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.5739 - val_loss: 2.2895\n",
      "[INFO] Training model: epoch 7 - 15750/20505 samples\n",
      "Train on 2458 samples, validate on 666 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.6645 - val_loss: 2.5678\n",
      "[INFO] Training model: epoch 7 - 16000/20505 samples\n",
      "Train on 2425 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.6505 - val_loss: 2.5744\n",
      "[INFO] Training model: epoch 7 - 16250/20505 samples\n",
      "Train on 2518 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.7050 - val_loss: 2.5486\n",
      "[INFO] Training model: epoch 7 - 16500/20505 samples\n",
      "Train on 2455 samples, validate on 555 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 21s 9ms/step - loss: 1.8237 - val_loss: 2.6175\n",
      "[INFO] Training model: epoch 7 - 16750/20505 samples\n",
      "Train on 2493 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.6548 - val_loss: 2.3380\n",
      "[INFO] Training model: epoch 7 - 17000/20505 samples\n",
      "Train on 2262 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2262/2262 [==============================] - 21s 9ms/step - loss: 1.7339 - val_loss: 2.1764\n",
      "[INFO] Training model: epoch 7 - 17250/20505 samples\n",
      "Train on 2570 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 23s 9ms/step - loss: 1.6821 - val_loss: 2.2011\n",
      "[INFO] Training model: epoch 7 - 17500/20505 samples\n",
      "Train on 2498 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 22s 9ms/step - loss: 1.5465 - val_loss: 2.3249\n",
      "[INFO] Training model: epoch 7 - 17750/20505 samples\n",
      "Train on 2409 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.6616 - val_loss: 2.5293\n",
      "[INFO] Training model: epoch 7 - 18000/20505 samples\n",
      "Train on 2377 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.6448 - val_loss: 2.5505\n",
      "[INFO] Training model: epoch 7 - 18250/20505 samples\n",
      "Train on 2443 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.6520 - val_loss: 2.3775\n",
      "[INFO] Training model: epoch 7 - 18500/20505 samples\n",
      "Train on 2499 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 24s 9ms/step - loss: 1.6862 - val_loss: 2.2862\n",
      "[INFO] Training model: epoch 7 - 18750/20505 samples\n",
      "Train on 2343 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 20s 9ms/step - loss: 1.6297 - val_loss: 2.3813\n",
      "[INFO] Training model: epoch 7 - 19000/20505 samples\n",
      "Train on 2364 samples, validate on 652 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.6269 - val_loss: 1.9372\n",
      "[INFO] Training model: epoch 7 - 19250/20505 samples\n",
      "Train on 2603 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 22s 9ms/step - loss: 1.6554 - val_loss: 2.5579\n",
      "[INFO] Training model: epoch 7 - 19500/20505 samples\n",
      "Train on 2489 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.7127 - val_loss: 2.4204\n",
      "[INFO] Training model: epoch 7 - 19750/20505 samples\n",
      "Train on 2465 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 22s 9ms/step - loss: 1.7281 - val_loss: 2.1974\n",
      "[INFO] Training model: epoch 7 - 20000/20505 samples\n",
      "Train on 2533 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 23s 9ms/step - loss: 1.6051 - val_loss: 2.6490\n",
      "[INFO] Training model: epoch 7 - 20250/20505 samples\n",
      "Train on 2380 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 21s 9ms/step - loss: 1.7321 - val_loss: 2.3327\n",
      "[INFO] Training model: epoch 7 - 20500/20505 samples\n",
      "Train on 50 samples, validate on 28 samples\n",
      "Epoch 1/1\n",
      "50/50 [==============================] - 1s 11ms/step - loss: 1.7676 - val_loss: 2.3740\n",
      "[INFO] Training model: epoch 8 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.4254 - val_loss: 2.2604\n",
      "[INFO] Training model: epoch 8 - 250/20505 samples\n",
      "Train on 2357 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.4702 - val_loss: 2.2392\n",
      "[INFO] Training model: epoch 8 - 500/20505 samples\n",
      "Train on 2440 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.4585 - val_loss: 2.5810\n",
      "[INFO] Training model: epoch 8 - 750/20505 samples\n",
      "Train on 2387 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 22s 9ms/step - loss: 1.4499 - val_loss: 2.1828\n",
      "[INFO] Training model: epoch 8 - 1000/20505 samples\n",
      "Train on 2484 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 22s 9ms/step - loss: 1.5182 - val_loss: 2.1674\n",
      "[INFO] Training model: epoch 8 - 1250/20505 samples\n",
      "Train on 2485 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 22s 9ms/step - loss: 1.4507 - val_loss: 2.3934\n",
      "[INFO] Training model: epoch 8 - 1500/20505 samples\n",
      "Train on 2499 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.4543 - val_loss: 2.5001\n",
      "[INFO] Training model: epoch 8 - 1750/20505 samples\n",
      "Train on 2442 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 22s 9ms/step - loss: 1.4923 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 8 - 2000/20505 samples\n",
      "Train on 2531 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 23s 9ms/step - loss: 1.4511 - val_loss: 2.4506\n",
      "[INFO] Training model: epoch 8 - 2250/20505 samples\n",
      "Train on 2399 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.4636 - val_loss: 2.4071\n",
      "[INFO] Training model: epoch 8 - 2500/20505 samples\n",
      "Train on 2478 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 21s 9ms/step - loss: 1.4292 - val_loss: 2.2661\n",
      "[INFO] Training model: epoch 8 - 2750/20505 samples\n",
      "Train on 2516 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 23s 9ms/step - loss: 1.5255 - val_loss: 2.3535\n",
      "[INFO] Training model: epoch 8 - 3000/20505 samples\n",
      "Train on 2429 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.5200 - val_loss: 2.2941\n",
      "[INFO] Training model: epoch 8 - 3250/20505 samples\n",
      "Train on 2471 samples, validate on 555 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.4237 - val_loss: 2.6849\n",
      "[INFO] Training model: epoch 8 - 3500/20505 samples\n",
      "Train on 2439 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4980 - val_loss: 2.3344\n",
      "[INFO] Training model: epoch 8 - 3750/20505 samples\n",
      "Train on 2472 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.4265 - val_loss: 2.3935\n",
      "[INFO] Training model: epoch 8 - 4000/20505 samples\n",
      "Train on 2411 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 21s 9ms/step - loss: 1.4608 - val_loss: 2.4303\n",
      "[INFO] Training model: epoch 8 - 4250/20505 samples\n",
      "Train on 2567 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2567/2567 [==============================] - 24s 9ms/step - loss: 1.4338 - val_loss: 2.5292\n",
      "[INFO] Training model: epoch 8 - 4500/20505 samples\n",
      "Train on 2393 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 21s 9ms/step - loss: 1.4894 - val_loss: 2.5774\n",
      "[INFO] Training model: epoch 8 - 4750/20505 samples\n",
      "Train on 2585 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2585/2585 [==============================] - 24s 9ms/step - loss: 1.5106 - val_loss: 2.4945\n",
      "[INFO] Training model: epoch 8 - 5000/20505 samples\n",
      "Train on 2458 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 21s 9ms/step - loss: 1.4196 - val_loss: 2.4547\n",
      "[INFO] Training model: epoch 8 - 5250/20505 samples\n",
      "Train on 2474 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.4336 - val_loss: 2.3045\n",
      "[INFO] Training model: epoch 8 - 5500/20505 samples\n",
      "Train on 2483 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.4292 - val_loss: 2.3462\n",
      "[INFO] Training model: epoch 8 - 5750/20505 samples\n",
      "Train on 2487 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.5076 - val_loss: 2.2881\n",
      "[INFO] Training model: epoch 8 - 6000/20505 samples\n",
      "Train on 2426 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.5588 - val_loss: 2.3620\n",
      "[INFO] Training model: epoch 8 - 6250/20505 samples\n",
      "Train on 2495 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.4925 - val_loss: 2.2900\n",
      "[INFO] Training model: epoch 8 - 6500/20505 samples\n",
      "Train on 2379 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 21s 9ms/step - loss: 1.4613 - val_loss: 2.4415\n",
      "[INFO] Training model: epoch 8 - 6750/20505 samples\n",
      "Train on 2390 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.4836 - val_loss: 2.3037\n",
      "[INFO] Training model: epoch 8 - 7000/20505 samples\n",
      "Train on 2519 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.4802 - val_loss: 2.2517\n",
      "[INFO] Training model: epoch 8 - 7250/20505 samples\n",
      "Train on 2411 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.5662 - val_loss: 2.4529\n",
      "[INFO] Training model: epoch 8 - 7500/20505 samples\n",
      "Train on 2538 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.4339 - val_loss: 2.2519\n",
      "[INFO] Training model: epoch 8 - 7750/20505 samples\n",
      "Train on 2465 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.5983 - val_loss: 2.5384\n",
      "[INFO] Training model: epoch 8 - 8000/20505 samples\n",
      "Train on 2475 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.5479 - val_loss: 2.2322\n",
      "[INFO] Training model: epoch 8 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.4310 - val_loss: 2.2282\n",
      "[INFO] Training model: epoch 8 - 8500/20505 samples\n",
      "Train on 2368 samples, validate on 587 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368/2368 [==============================] - 22s 9ms/step - loss: 1.5458 - val_loss: 2.3485\n",
      "[INFO] Training model: epoch 8 - 8750/20505 samples\n",
      "Train on 2467 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 21s 9ms/step - loss: 1.4903 - val_loss: 2.4145\n",
      "[INFO] Training model: epoch 8 - 9000/20505 samples\n",
      "Train on 2421 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.4592 - val_loss: 2.2749\n",
      "[INFO] Training model: epoch 8 - 9250/20505 samples\n",
      "Train on 2442 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.5260 - val_loss: 2.3786\n",
      "[INFO] Training model: epoch 8 - 9500/20505 samples\n",
      "Train on 2467 samples, validate on 564 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 21s 9ms/step - loss: 1.5346 - val_loss: 2.4670\n",
      "[INFO] Training model: epoch 8 - 9750/20505 samples\n",
      "Train on 2496 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.5529 - val_loss: 2.5700\n",
      "[INFO] Training model: epoch 8 - 10000/20505 samples\n",
      "Train on 2458 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.5413 - val_loss: 2.4237\n",
      "[INFO] Training model: epoch 8 - 10250/20505 samples\n",
      "Train on 2446 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.5506 - val_loss: 2.5202\n",
      "[INFO] Training model: epoch 8 - 10500/20505 samples\n",
      "Train on 2513 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.5282 - val_loss: 2.4706\n",
      "[INFO] Training model: epoch 8 - 10750/20505 samples\n",
      "Train on 2458 samples, validate on 690 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.5982 - val_loss: 2.4331\n",
      "[INFO] Training model: epoch 8 - 11000/20505 samples\n",
      "Train on 2465 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 21s 9ms/step - loss: 1.4890 - val_loss: 2.5478\n",
      "[INFO] Training model: epoch 8 - 11250/20505 samples\n",
      "Train on 2484 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.5896 - val_loss: 2.2726\n",
      "[INFO] Training model: epoch 8 - 11500/20505 samples\n",
      "Train on 2515 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 22s 9ms/step - loss: 1.4795 - val_loss: 2.6344\n",
      "[INFO] Training model: epoch 8 - 11750/20505 samples\n",
      "Train on 2510 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 22s 9ms/step - loss: 1.5080 - val_loss: 2.4703\n",
      "[INFO] Training model: epoch 8 - 12000/20505 samples\n",
      "Train on 2394 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.5328 - val_loss: 2.1728\n",
      "[INFO] Training model: epoch 8 - 12250/20505 samples\n",
      "Train on 2388 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.5352 - val_loss: 2.4339\n",
      "[INFO] Training model: epoch 8 - 12500/20505 samples\n",
      "Train on 2501 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.5268 - val_loss: 2.5951\n",
      "[INFO] Training model: epoch 8 - 12750/20505 samples\n",
      "Train on 2524 samples, validate on 714 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 1.5869 - val_loss: 2.4815\n",
      "[INFO] Training model: epoch 8 - 13000/20505 samples\n",
      "Train on 2456 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 22s 9ms/step - loss: 1.5443 - val_loss: 2.2870\n",
      "[INFO] Training model: epoch 8 - 13250/20505 samples\n",
      "Train on 2386 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.5590 - val_loss: 2.3811\n",
      "[INFO] Training model: epoch 8 - 13500/20505 samples\n",
      "Train on 2377 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.6301 - val_loss: 2.3500\n",
      "[INFO] Training model: epoch 8 - 13750/20505 samples\n",
      "Train on 2374 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.5277 - val_loss: 2.4277\n",
      "[INFO] Training model: epoch 8 - 14000/20505 samples\n",
      "Train on 2377 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.4668 - val_loss: 2.6192\n",
      "[INFO] Training model: epoch 8 - 14250/20505 samples\n",
      "Train on 2521 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 23s 9ms/step - loss: 1.5401 - val_loss: 2.4191\n",
      "[INFO] Training model: epoch 8 - 14500/20505 samples\n",
      "Train on 2526 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.5665 - val_loss: 2.4617\n",
      "[INFO] Training model: epoch 8 - 14750/20505 samples\n",
      "Train on 2365 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.4607 - val_loss: 2.6013\n",
      "[INFO] Training model: epoch 8 - 15000/20505 samples\n",
      "Train on 2502 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 23s 9ms/step - loss: 1.5806 - val_loss: 2.3278\n",
      "[INFO] Training model: epoch 8 - 15250/20505 samples\n",
      "Train on 2357 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.5798 - val_loss: 2.5623\n",
      "[INFO] Training model: epoch 8 - 15500/20505 samples\n",
      "Train on 2511 samples, validate on 541 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.5130 - val_loss: 2.5665\n",
      "[INFO] Training model: epoch 8 - 15750/20505 samples\n",
      "Train on 2457 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.5821 - val_loss: 2.1772\n",
      "[INFO] Training model: epoch 8 - 16000/20505 samples\n",
      "Train on 2435 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.6315 - val_loss: 2.3547\n",
      "[INFO] Training model: epoch 8 - 16250/20505 samples\n",
      "Train on 2349 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 9ms/step - loss: 1.5623 - val_loss: 2.3017\n",
      "[INFO] Training model: epoch 8 - 16500/20505 samples\n",
      "Train on 2283 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2283/2283 [==============================] - 21s 9ms/step - loss: 1.6112 - val_loss: 2.2483\n",
      "[INFO] Training model: epoch 8 - 16750/20505 samples\n",
      "Train on 2401 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.5802 - val_loss: 2.2122\n",
      "[INFO] Training model: epoch 8 - 17000/20505 samples\n",
      "Train on 2349 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 9ms/step - loss: 1.5594 - val_loss: 2.3625\n",
      "[INFO] Training model: epoch 8 - 17250/20505 samples\n",
      "Train on 2501 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.6021 - val_loss: 2.4631\n",
      "[INFO] Training model: epoch 8 - 17500/20505 samples\n",
      "Train on 2470 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.5539 - val_loss: 2.4974\n",
      "[INFO] Training model: epoch 8 - 17750/20505 samples\n",
      "Train on 2472 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 21s 9ms/step - loss: 1.5754 - val_loss: 2.4237\n",
      "[INFO] Training model: epoch 8 - 18000/20505 samples\n",
      "Train on 2449 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.5953 - val_loss: 2.3047\n",
      "[INFO] Training model: epoch 8 - 18250/20505 samples\n",
      "Train on 2518 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.4867 - val_loss: 2.6699\n",
      "[INFO] Training model: epoch 8 - 18500/20505 samples\n",
      "Train on 2600 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2600/2600 [==============================] - 24s 9ms/step - loss: 1.6077 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 8 - 18750/20505 samples\n",
      "Train on 2429 samples, validate on 655 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2429/2429 [==============================] - 23s 9ms/step - loss: 1.5625 - val_loss: 2.4025\n",
      "[INFO] Training model: epoch 8 - 19000/20505 samples\n",
      "Train on 2542 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 23s 9ms/step - loss: 1.5899 - val_loss: 2.2500\n",
      "[INFO] Training model: epoch 8 - 19250/20505 samples\n",
      "Train on 2461 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 21s 9ms/step - loss: 1.5829 - val_loss: 2.3534\n",
      "[INFO] Training model: epoch 8 - 19500/20505 samples\n",
      "Train on 2433 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.5422 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 8 - 19750/20505 samples\n",
      "Train on 2535 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 23s 9ms/step - loss: 1.5532 - val_loss: 2.3387\n",
      "[INFO] Training model: epoch 8 - 20000/20505 samples\n",
      "Train on 2458 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 22s 9ms/step - loss: 1.6201 - val_loss: 2.4505\n",
      "[INFO] Training model: epoch 8 - 20250/20505 samples\n",
      "Train on 2493 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.4899 - val_loss: 2.3800\n",
      "[INFO] Training model: epoch 8 - 20500/20505 samples\n",
      "Train on 62 samples, validate on 37 samples\n",
      "Epoch 1/1\n",
      "62/62 [==============================] - 1s 10ms/step - loss: 1.3269 - val_loss: 3.3216\n",
      "[INFO] Training model: epoch 9 - 0/20505 samples\n",
      "Train on 2507 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.2494 - val_loss: 2.3022\n",
      "[INFO] Training model: epoch 9 - 250/20505 samples\n",
      "Train on 2478 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 22s 9ms/step - loss: 1.2654 - val_loss: 2.2845\n",
      "[INFO] Training model: epoch 9 - 500/20505 samples\n",
      "Train on 2490 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 22s 9ms/step - loss: 1.3792 - val_loss: 2.5207\n",
      "[INFO] Training model: epoch 9 - 750/20505 samples\n",
      "Train on 2411 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 23s 9ms/step - loss: 1.3050 - val_loss: 2.3013\n",
      "[INFO] Training model: epoch 9 - 1000/20505 samples\n",
      "Train on 2556 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2556/2556 [==============================] - 24s 9ms/step - loss: 1.3251 - val_loss: 2.7311\n",
      "[INFO] Training model: epoch 9 - 1250/20505 samples\n",
      "Train on 2461 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.3897 - val_loss: 2.4335\n",
      "[INFO] Training model: epoch 9 - 1500/20505 samples\n",
      "Train on 2464 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.4240 - val_loss: 2.5491\n",
      "[INFO] Training model: epoch 9 - 1750/20505 samples\n",
      "Train on 2441 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.3969 - val_loss: 2.4459\n",
      "[INFO] Training model: epoch 9 - 2000/20505 samples\n",
      "Train on 2422 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 22s 9ms/step - loss: 1.3862 - val_loss: 2.6346\n",
      "[INFO] Training model: epoch 9 - 2250/20505 samples\n",
      "Train on 2531 samples, validate on 556 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 1.4287 - val_loss: 2.4100\n",
      "[INFO] Training model: epoch 9 - 2500/20505 samples\n",
      "Train on 2479 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 22s 9ms/step - loss: 1.4320 - val_loss: 2.4232\n",
      "[INFO] Training model: epoch 9 - 2750/20505 samples\n",
      "Train on 2489 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.3846 - val_loss: 2.4463\n",
      "[INFO] Training model: epoch 9 - 3000/20505 samples\n",
      "Train on 2348 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 21s 9ms/step - loss: 1.3995 - val_loss: 2.5715\n",
      "[INFO] Training model: epoch 9 - 3250/20505 samples\n",
      "Train on 2473 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.3809 - val_loss: 2.2969\n",
      "[INFO] Training model: epoch 9 - 3500/20505 samples\n",
      "Train on 2485 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.4185 - val_loss: 2.1848\n",
      "[INFO] Training model: epoch 9 - 3750/20505 samples\n",
      "Train on 2528 samples, validate on 651 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.3111 - val_loss: 2.5029\n",
      "[INFO] Training model: epoch 9 - 4000/20505 samples\n",
      "Train on 2420 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.5147 - val_loss: 2.3917\n",
      "[INFO] Training model: epoch 9 - 4250/20505 samples\n",
      "Train on 2451 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.3961 - val_loss: 2.5064\n",
      "[INFO] Training model: epoch 9 - 4500/20505 samples\n",
      "Train on 2489 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.4747 - val_loss: 2.3963\n",
      "[INFO] Training model: epoch 9 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.4757 - val_loss: 2.6546\n",
      "[INFO] Training model: epoch 9 - 5000/20505 samples\n",
      "Train on 2419 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 21s 9ms/step - loss: 1.4721 - val_loss: 2.4276\n",
      "[INFO] Training model: epoch 9 - 5250/20505 samples\n",
      "Train on 2374 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.4015 - val_loss: 2.3351\n",
      "[INFO] Training model: epoch 9 - 5500/20505 samples\n",
      "Train on 2466 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 21s 9ms/step - loss: 1.4323 - val_loss: 2.3597\n",
      "[INFO] Training model: epoch 9 - 5750/20505 samples\n",
      "Train on 2448 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.4114 - val_loss: 2.3271\n",
      "[INFO] Training model: epoch 9 - 6000/20505 samples\n",
      "Train on 2394 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.4814 - val_loss: 2.4957\n",
      "[INFO] Training model: epoch 9 - 6250/20505 samples\n",
      "Train on 2385 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.3888 - val_loss: 2.6494\n",
      "[INFO] Training model: epoch 9 - 6500/20505 samples\n",
      "Train on 2439 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.3862 - val_loss: 2.5470\n",
      "[INFO] Training model: epoch 9 - 6750/20505 samples\n",
      "Train on 2555 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2555/2555 [==============================] - 22s 9ms/step - loss: 1.4329 - val_loss: 2.4876\n",
      "[INFO] Training model: epoch 9 - 7000/20505 samples\n",
      "Train on 2482 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.4097 - val_loss: 2.4222\n",
      "[INFO] Training model: epoch 9 - 7250/20505 samples\n",
      "Train on 2507 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 23s 9ms/step - loss: 1.4090 - val_loss: 2.3161\n",
      "[INFO] Training model: epoch 9 - 7500/20505 samples\n",
      "Train on 2405 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 9ms/step - loss: 1.3927 - val_loss: 2.5329\n",
      "[INFO] Training model: epoch 9 - 7750/20505 samples\n",
      "Train on 2562 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2562/2562 [==============================] - 24s 9ms/step - loss: 1.5146 - val_loss: 2.1525\n",
      "[INFO] Training model: epoch 9 - 8000/20505 samples\n",
      "Train on 2459 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.4617 - val_loss: 2.5031\n",
      "[INFO] Training model: epoch 9 - 8250/20505 samples\n",
      "Train on 2408 samples, validate on 596 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.4500 - val_loss: 2.5077\n",
      "[INFO] Training model: epoch 9 - 8500/20505 samples\n",
      "Train on 2373 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 21s 9ms/step - loss: 1.4290 - val_loss: 2.3043\n",
      "[INFO] Training model: epoch 9 - 8750/20505 samples\n",
      "Train on 2446 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.4198 - val_loss: 2.3607\n",
      "[INFO] Training model: epoch 9 - 9000/20505 samples\n",
      "Train on 2522 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.4920 - val_loss: 2.5335\n",
      "[INFO] Training model: epoch 9 - 9250/20505 samples\n",
      "Train on 2440 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.4412 - val_loss: 2.0988\n",
      "[INFO] Training model: epoch 9 - 9500/20505 samples\n",
      "Train on 2433 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.4807 - val_loss: 2.2379\n",
      "[INFO] Training model: epoch 9 - 9750/20505 samples\n",
      "Train on 2410 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.4218 - val_loss: 2.5125\n",
      "[INFO] Training model: epoch 9 - 10000/20505 samples\n",
      "Train on 2457 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.4569 - val_loss: 2.4772\n",
      "[INFO] Training model: epoch 9 - 10250/20505 samples\n",
      "Train on 2518 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 24s 9ms/step - loss: 1.3941 - val_loss: 2.6484\n",
      "[INFO] Training model: epoch 9 - 10500/20505 samples\n",
      "Train on 2460 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 21s 9ms/step - loss: 1.4324 - val_loss: 2.4306\n",
      "[INFO] Training model: epoch 9 - 10750/20505 samples\n",
      "Train on 2316 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 21s 9ms/step - loss: 1.5087 - val_loss: 2.2779\n",
      "[INFO] Training model: epoch 9 - 11000/20505 samples\n",
      "Train on 2347 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 9ms/step - loss: 1.4858 - val_loss: 2.3544\n",
      "[INFO] Training model: epoch 9 - 11250/20505 samples\n",
      "Train on 2440 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 1.4716 - val_loss: 2.4179\n",
      "[INFO] Training model: epoch 9 - 11500/20505 samples\n",
      "Train on 2405 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.4988 - val_loss: 2.4062\n",
      "[INFO] Training model: epoch 9 - 11750/20505 samples\n",
      "Train on 2423 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.4550 - val_loss: 2.2950\n",
      "[INFO] Training model: epoch 9 - 12000/20505 samples\n",
      "Train on 2536 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 22s 9ms/step - loss: 1.5277 - val_loss: 2.3984\n",
      "[INFO] Training model: epoch 9 - 12250/20505 samples\n",
      "Train on 2495 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.4774 - val_loss: 2.4728\n",
      "[INFO] Training model: epoch 9 - 12500/20505 samples\n",
      "Train on 2446 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.5677 - val_loss: 2.3705\n",
      "[INFO] Training model: epoch 9 - 12750/20505 samples\n",
      "Train on 2377 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 22s 9ms/step - loss: 1.4511 - val_loss: 2.4314\n",
      "[INFO] Training model: epoch 9 - 13000/20505 samples\n",
      "Train on 2460 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.4524 - val_loss: 2.5302\n",
      "[INFO] Training model: epoch 9 - 13250/20505 samples\n",
      "Train on 2473 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 22s 9ms/step - loss: 1.4904 - val_loss: 2.3268\n",
      "[INFO] Training model: epoch 9 - 13500/20505 samples\n",
      "Train on 2403 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 22s 9ms/step - loss: 1.4029 - val_loss: 2.3485\n",
      "[INFO] Training model: epoch 9 - 13750/20505 samples\n",
      "Train on 2399 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.5397 - val_loss: 2.6131\n",
      "[INFO] Training model: epoch 9 - 14000/20505 samples\n",
      "Train on 2321 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2321/2321 [==============================] - 22s 9ms/step - loss: 1.3923 - val_loss: 2.5680\n",
      "[INFO] Training model: epoch 9 - 14250/20505 samples\n",
      "Train on 2371 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.4947 - val_loss: 2.2011\n",
      "[INFO] Training model: epoch 9 - 14500/20505 samples\n",
      "Train on 2511 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.4852 - val_loss: 2.6161\n",
      "[INFO] Training model: epoch 9 - 14750/20505 samples\n",
      "Train on 2603 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 23s 9ms/step - loss: 1.4086 - val_loss: 2.4499\n",
      "[INFO] Training model: epoch 9 - 15000/20505 samples\n",
      "Train on 2578 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.4114 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 9 - 15250/20505 samples\n",
      "Train on 2535 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2535/2535 [==============================] - 23s 9ms/step - loss: 1.4417 - val_loss: 2.3448\n",
      "[INFO] Training model: epoch 9 - 15500/20505 samples\n",
      "Train on 2494 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.4749 - val_loss: 2.4858\n",
      "[INFO] Training model: epoch 9 - 15750/20505 samples\n",
      "Train on 2480 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 24s 9ms/step - loss: 1.5163 - val_loss: 2.5709\n",
      "[INFO] Training model: epoch 9 - 16000/20505 samples\n",
      "Train on 2508 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 22s 9ms/step - loss: 1.4481 - val_loss: 2.5664\n",
      "[INFO] Training model: epoch 9 - 16250/20505 samples\n",
      "Train on 2347 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 9ms/step - loss: 1.4775 - val_loss: 2.6308\n",
      "[INFO] Training model: epoch 9 - 16500/20505 samples\n",
      "Train on 2299 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2299/2299 [==============================] - 21s 9ms/step - loss: 1.5214 - val_loss: 2.5229\n",
      "[INFO] Training model: epoch 9 - 16750/20505 samples\n",
      "Train on 2504 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2504/2504 [==============================] - 22s 9ms/step - loss: 1.4966 - val_loss: 2.3708\n",
      "[INFO] Training model: epoch 9 - 17000/20505 samples\n",
      "Train on 2399 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 23s 9ms/step - loss: 1.5044 - val_loss: 2.3872\n",
      "[INFO] Training model: epoch 9 - 17250/20505 samples\n",
      "Train on 2470 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 21s 9ms/step - loss: 1.5059 - val_loss: 2.5252\n",
      "[INFO] Training model: epoch 9 - 17500/20505 samples\n",
      "Train on 2592 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 22s 9ms/step - loss: 1.5426 - val_loss: 2.4145\n",
      "[INFO] Training model: epoch 9 - 17750/20505 samples\n",
      "Train on 2383 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.4442 - val_loss: 2.3948\n",
      "[INFO] Training model: epoch 9 - 18000/20505 samples\n",
      "Train on 2569 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 22s 9ms/step - loss: 1.4572 - val_loss: 2.4517\n",
      "[INFO] Training model: epoch 9 - 18250/20505 samples\n",
      "Train on 2446 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 21s 9ms/step - loss: 1.4634 - val_loss: 2.1839\n",
      "[INFO] Training model: epoch 9 - 18500/20505 samples\n",
      "Train on 2369 samples, validate on 665 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2369/2369 [==============================] - 22s 9ms/step - loss: 1.4268 - val_loss: 2.4147\n",
      "[INFO] Training model: epoch 9 - 18750/20505 samples\n",
      "Train on 2497 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.5895 - val_loss: 2.5063\n",
      "[INFO] Training model: epoch 9 - 19000/20505 samples\n",
      "Train on 2480 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.5036 - val_loss: 2.5566\n",
      "[INFO] Training model: epoch 9 - 19250/20505 samples\n",
      "Train on 2538 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.5389 - val_loss: 2.6828\n",
      "[INFO] Training model: epoch 9 - 19500/20505 samples\n",
      "Train on 2425 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.5731 - val_loss: 2.3701\n",
      "[INFO] Training model: epoch 9 - 19750/20505 samples\n",
      "Train on 2419 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.5797 - val_loss: 2.4151\n",
      "[INFO] Training model: epoch 9 - 20000/20505 samples\n",
      "Train on 2557 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 24s 9ms/step - loss: 1.5699 - val_loss: 2.4112\n",
      "[INFO] Training model: epoch 9 - 20250/20505 samples\n",
      "Train on 2427 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.5866 - val_loss: 2.3979\n",
      "[INFO] Training model: epoch 9 - 20500/20505 samples\n",
      "Train on 54 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 1s 13ms/step - loss: 1.3256 - val_loss: 3.8678\n",
      "[INFO] Training model: epoch 10 - 0/20505 samples\n",
      "Train on 2477 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.2813 - val_loss: 2.5783\n",
      "[INFO] Training model: epoch 10 - 250/20505 samples\n",
      "Train on 2480 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.2865 - val_loss: 2.4034\n",
      "[INFO] Training model: epoch 10 - 500/20505 samples\n",
      "Train on 2385 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.3301 - val_loss: 2.5189\n",
      "[INFO] Training model: epoch 10 - 750/20505 samples\n",
      "Train on 2480 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.2654 - val_loss: 2.3832\n",
      "[INFO] Training model: epoch 10 - 1000/20505 samples\n",
      "Train on 2421 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.2587 - val_loss: 2.3226\n",
      "[INFO] Training model: epoch 10 - 1250/20505 samples\n",
      "Train on 2525 samples, validate on 684 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.3854 - val_loss: 2.5774\n",
      "[INFO] Training model: epoch 10 - 1500/20505 samples\n",
      "Train on 2450 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.3582 - val_loss: 2.4658\n",
      "[INFO] Training model: epoch 10 - 1750/20505 samples\n",
      "Train on 2563 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 23s 9ms/step - loss: 1.3821 - val_loss: 2.3121\n",
      "[INFO] Training model: epoch 10 - 2000/20505 samples\n",
      "Train on 2462 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 22s 9ms/step - loss: 1.2983 - val_loss: 2.2430\n",
      "[INFO] Training model: epoch 10 - 2250/20505 samples\n",
      "Train on 2362 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2362/2362 [==============================] - 22s 9ms/step - loss: 1.2991 - val_loss: 2.4158\n",
      "[INFO] Training model: epoch 10 - 2500/20505 samples\n",
      "Train on 2488 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 22s 9ms/step - loss: 1.3255 - val_loss: 2.3827\n",
      "[INFO] Training model: epoch 10 - 2750/20505 samples\n",
      "Train on 2427 samples, validate on 720 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 21s 9ms/step - loss: 1.3067 - val_loss: 2.5710\n",
      "[INFO] Training model: epoch 10 - 3000/20505 samples\n",
      "Train on 2528 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 22s 9ms/step - loss: 1.3662 - val_loss: 2.2393\n",
      "[INFO] Training model: epoch 10 - 3250/20505 samples\n",
      "Train on 2495 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 23s 9ms/step - loss: 1.3305 - val_loss: 2.2888\n",
      "[INFO] Training model: epoch 10 - 3500/20505 samples\n",
      "Train on 2456 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.3233 - val_loss: 2.3604\n",
      "[INFO] Training model: epoch 10 - 3750/20505 samples\n",
      "Train on 2392 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.3297 - val_loss: 2.4217\n",
      "[INFO] Training model: epoch 10 - 4000/20505 samples\n",
      "Train on 2527 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 23s 9ms/step - loss: 1.3286 - val_loss: 2.3171\n",
      "[INFO] Training model: epoch 10 - 4250/20505 samples\n",
      "Train on 2452 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.3810 - val_loss: 2.3649\n",
      "[INFO] Training model: epoch 10 - 4500/20505 samples\n",
      "Train on 2375 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 1.3607 - val_loss: 2.4770\n",
      "[INFO] Training model: epoch 10 - 4750/20505 samples\n",
      "Train on 2381 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 21s 9ms/step - loss: 1.3526 - val_loss: 2.2170\n",
      "[INFO] Training model: epoch 10 - 5000/20505 samples\n",
      "Train on 2430 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.3711 - val_loss: 2.5644\n",
      "[INFO] Training model: epoch 10 - 5250/20505 samples\n",
      "Train on 2511 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.2857 - val_loss: 2.3252\n",
      "[INFO] Training model: epoch 10 - 5500/20505 samples\n",
      "Train on 2636 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 25s 9ms/step - loss: 1.4415 - val_loss: 2.4390\n",
      "[INFO] Training model: epoch 10 - 5750/20505 samples\n",
      "Train on 2460 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.3645 - val_loss: 2.8236\n",
      "[INFO] Training model: epoch 10 - 6000/20505 samples\n",
      "Train on 2513 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.3189 - val_loss: 2.5506\n",
      "[INFO] Training model: epoch 10 - 6250/20505 samples\n",
      "Train on 2477 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.3864 - val_loss: 2.5477\n",
      "[INFO] Training model: epoch 10 - 6500/20505 samples\n",
      "Train on 2459 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.3168 - val_loss: 2.6463\n",
      "[INFO] Training model: epoch 10 - 6750/20505 samples\n",
      "Train on 2430 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.3488 - val_loss: 2.7052\n",
      "[INFO] Training model: epoch 10 - 7000/20505 samples\n",
      "Train on 2436 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 22s 9ms/step - loss: 1.3153 - val_loss: 2.6865\n",
      "[INFO] Training model: epoch 10 - 7250/20505 samples\n",
      "Train on 2487 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.4553 - val_loss: 2.3880\n",
      "[INFO] Training model: epoch 10 - 7500/20505 samples\n",
      "Train on 2636 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2636/2636 [==============================] - 24s 9ms/step - loss: 1.4411 - val_loss: 2.6852\n",
      "[INFO] Training model: epoch 10 - 7750/20505 samples\n",
      "Train on 2500 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.4265 - val_loss: 2.5388\n",
      "[INFO] Training model: epoch 10 - 8000/20505 samples\n",
      "Train on 2380 samples, validate on 606 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.3947 - val_loss: 2.6676\n",
      "[INFO] Training model: epoch 10 - 8250/20505 samples\n",
      "Train on 2464 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.4110 - val_loss: 2.7268\n",
      "[INFO] Training model: epoch 10 - 8500/20505 samples\n",
      "Train on 2365 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.3895 - val_loss: 2.3469\n",
      "[INFO] Training model: epoch 10 - 8750/20505 samples\n",
      "Train on 2410 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.4229 - val_loss: 2.4641\n",
      "[INFO] Training model: epoch 10 - 9000/20505 samples\n",
      "Train on 2468 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.4841 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 10 - 9250/20505 samples\n",
      "Train on 2445 samples, validate on 687 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 22s 9ms/step - loss: 1.3823 - val_loss: 2.5592\n",
      "[INFO] Training model: epoch 10 - 9500/20505 samples\n",
      "Train on 2428 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.3235 - val_loss: 2.4626\n",
      "[INFO] Training model: epoch 10 - 9750/20505 samples\n",
      "Train on 2476 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.3637 - val_loss: 2.5549\n",
      "[INFO] Training model: epoch 10 - 10000/20505 samples\n",
      "Train on 2461 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.2935 - val_loss: 2.5553\n",
      "[INFO] Training model: epoch 10 - 10250/20505 samples\n",
      "Train on 2414 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 21s 9ms/step - loss: 1.4189 - val_loss: 2.3249\n",
      "[INFO] Training model: epoch 10 - 10500/20505 samples\n",
      "Train on 2389 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.3648 - val_loss: 2.4715\n",
      "[INFO] Training model: epoch 10 - 10750/20505 samples\n",
      "Train on 2395 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 1.4253 - val_loss: 2.3489\n",
      "[INFO] Training model: epoch 10 - 11000/20505 samples\n",
      "Train on 2473 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.4304 - val_loss: 2.5243\n",
      "[INFO] Training model: epoch 10 - 11250/20505 samples\n",
      "Train on 2348 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 21s 9ms/step - loss: 1.4773 - val_loss: 2.3848\n",
      "[INFO] Training model: epoch 10 - 11500/20505 samples\n",
      "Train on 2405 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.3192 - val_loss: 2.8990\n",
      "[INFO] Training model: epoch 10 - 11750/20505 samples\n",
      "Train on 2394 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.3400 - val_loss: 2.1565\n",
      "[INFO] Training model: epoch 10 - 12000/20505 samples\n",
      "Train on 2367 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 21s 9ms/step - loss: 1.4235 - val_loss: 2.5791\n",
      "[INFO] Training model: epoch 10 - 12250/20505 samples\n",
      "Train on 2399 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 21s 9ms/step - loss: 1.4320 - val_loss: 2.4136\n",
      "[INFO] Training model: epoch 10 - 12500/20505 samples\n",
      "Train on 2565 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2565/2565 [==============================] - 23s 9ms/step - loss: 1.4080 - val_loss: 2.4983\n",
      "[INFO] Training model: epoch 10 - 12750/20505 samples\n",
      "Train on 2537 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 23s 9ms/step - loss: 1.3766 - val_loss: 2.5732\n",
      "[INFO] Training model: epoch 10 - 13000/20505 samples\n",
      "Train on 2515 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 22s 9ms/step - loss: 1.4405 - val_loss: 2.5322\n",
      "[INFO] Training model: epoch 10 - 13250/20505 samples\n",
      "Train on 2391 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2391/2391 [==============================] - 22s 9ms/step - loss: 1.3882 - val_loss: 2.5887\n",
      "[INFO] Training model: epoch 10 - 13500/20505 samples\n",
      "Train on 2517 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 22s 9ms/step - loss: 1.3980 - val_loss: 2.6533\n",
      "[INFO] Training model: epoch 10 - 13750/20505 samples\n",
      "Train on 2445 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.3992 - val_loss: 2.4517\n",
      "[INFO] Training model: epoch 10 - 14000/20505 samples\n",
      "Train on 2448 samples, validate on 551 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 21s 9ms/step - loss: 1.4529 - val_loss: 2.3358\n",
      "[INFO] Training model: epoch 10 - 14250/20505 samples\n",
      "Train on 2536 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 24s 9ms/step - loss: 1.3809 - val_loss: 2.4419\n",
      "[INFO] Training model: epoch 10 - 14500/20505 samples\n",
      "Train on 2456 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.3710 - val_loss: 2.5289\n",
      "[INFO] Training model: epoch 10 - 14750/20505 samples\n",
      "Train on 2420 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 23s 9ms/step - loss: 1.4500 - val_loss: 2.3588\n",
      "[INFO] Training model: epoch 10 - 15000/20505 samples\n",
      "Train on 2373 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.4255 - val_loss: 2.4434\n",
      "[INFO] Training model: epoch 10 - 15250/20505 samples\n",
      "Train on 2411 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.4036 - val_loss: 2.3656\n",
      "[INFO] Training model: epoch 10 - 15500/20505 samples\n",
      "Train on 2440 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.3787 - val_loss: 2.3760\n",
      "[INFO] Training model: epoch 10 - 15750/20505 samples\n",
      "Train on 2522 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 1.4314 - val_loss: 2.1885\n",
      "[INFO] Training model: epoch 10 - 16000/20505 samples\n",
      "Train on 2439 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4104 - val_loss: 2.4741\n",
      "[INFO] Training model: epoch 10 - 16250/20505 samples\n",
      "Train on 2417 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 22s 9ms/step - loss: 1.4709 - val_loss: 2.4638\n",
      "[INFO] Training model: epoch 10 - 16500/20505 samples\n",
      "Train on 2352 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2352/2352 [==============================] - 22s 9ms/step - loss: 1.4960 - val_loss: 2.6431\n",
      "[INFO] Training model: epoch 10 - 16750/20505 samples\n",
      "Train on 2471 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.4400 - val_loss: 2.5334\n",
      "[INFO] Training model: epoch 10 - 17000/20505 samples\n",
      "Train on 2490 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.4389 - val_loss: 2.4421\n",
      "[INFO] Training model: epoch 10 - 17250/20505 samples\n",
      "Train on 2445 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.4755 - val_loss: 2.5807\n",
      "[INFO] Training model: epoch 10 - 17500/20505 samples\n",
      "Train on 2409 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.4552 - val_loss: 2.3073\n",
      "[INFO] Training model: epoch 10 - 17750/20505 samples\n",
      "Train on 2537 samples, validate on 545 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 9ms/step - loss: 1.4278 - val_loss: 2.2083\n",
      "[INFO] Training model: epoch 10 - 18000/20505 samples\n",
      "Train on 2519 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.4099 - val_loss: 2.5587\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 10 - 18250/20505 samples\n",
      "Train on 2419 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.4591 - val_loss: 2.4607\n",
      "[INFO] Training model: epoch 10 - 18500/20505 samples\n",
      "Train on 2459 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 1.4149 - val_loss: 2.2507\n",
      "[INFO] Training model: epoch 10 - 18750/20505 samples\n",
      "Train on 2304 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 20s 9ms/step - loss: 1.4548 - val_loss: 2.1973\n",
      "[INFO] Training model: epoch 10 - 19000/20505 samples\n",
      "Train on 2501 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 23s 9ms/step - loss: 1.5338 - val_loss: 2.5324\n",
      "[INFO] Training model: epoch 10 - 19250/20505 samples\n",
      "Train on 2519 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.3824 - val_loss: 2.7397\n",
      "[INFO] Training model: epoch 10 - 19500/20505 samples\n",
      "Train on 2510 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 23s 9ms/step - loss: 1.5166 - val_loss: 2.2992\n",
      "[INFO] Training model: epoch 10 - 19750/20505 samples\n",
      "Train on 2351 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 1.4894 - val_loss: 2.3523\n",
      "[INFO] Training model: epoch 10 - 20000/20505 samples\n",
      "Train on 2612 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2612/2612 [==============================] - 24s 9ms/step - loss: 1.5049 - val_loss: 2.3938\n",
      "[INFO] Training model: epoch 10 - 20250/20505 samples\n",
      "Train on 2474 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.5264 - val_loss: 2.4127\n",
      "[INFO] Training model: epoch 10 - 20500/20505 samples\n",
      "Train on 70 samples, validate on 21 samples\n",
      "Epoch 1/1\n",
      "70/70 [==============================] - 1s 11ms/step - loss: 1.4037 - val_loss: 2.9908\n",
      "[INFO] Training model: epoch 11 - 0/20505 samples\n",
      "Train on 2370 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 21s 9ms/step - loss: 1.2309 - val_loss: 2.5357\n",
      "[INFO] Training model: epoch 11 - 250/20505 samples\n",
      "Train on 2382 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.1821 - val_loss: 2.5691\n",
      "[INFO] Training model: epoch 11 - 500/20505 samples\n",
      "Train on 2352 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2352/2352 [==============================] - 22s 9ms/step - loss: 1.1994 - val_loss: 2.5280\n",
      "[INFO] Training model: epoch 11 - 750/20505 samples\n",
      "Train on 2494 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.2412 - val_loss: 2.4799\n",
      "[INFO] Training model: epoch 11 - 1000/20505 samples\n",
      "Train on 2416 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 21s 9ms/step - loss: 1.2701 - val_loss: 2.9312\n",
      "[INFO] Training model: epoch 11 - 1250/20505 samples\n",
      "Train on 2401 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2047 - val_loss: 2.4645\n",
      "[INFO] Training model: epoch 11 - 1500/20505 samples\n",
      "Train on 2473 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2480 - val_loss: 2.6627\n",
      "[INFO] Training model: epoch 11 - 1750/20505 samples\n",
      "Train on 2426 samples, validate on 542 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.2830 - val_loss: 2.5884\n",
      "[INFO] Training model: epoch 11 - 2000/20505 samples\n",
      "Train on 2410 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2945 - val_loss: 2.4347\n",
      "[INFO] Training model: epoch 11 - 2250/20505 samples\n",
      "Train on 2541 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.2395 - val_loss: 2.4725\n",
      "[INFO] Training model: epoch 11 - 2500/20505 samples\n",
      "Train on 2473 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2596 - val_loss: 2.7029\n",
      "[INFO] Training model: epoch 11 - 2750/20505 samples\n",
      "Train on 2443 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 1.2199 - val_loss: 2.7177\n",
      "[INFO] Training model: epoch 11 - 3000/20505 samples\n",
      "Train on 2445 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 21s 9ms/step - loss: 1.2165 - val_loss: 2.1850\n",
      "[INFO] Training model: epoch 11 - 3250/20505 samples\n",
      "Train on 2469 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 22s 9ms/step - loss: 1.3073 - val_loss: 2.3856\n",
      "[INFO] Training model: epoch 11 - 3500/20505 samples\n",
      "Train on 2497 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 24s 10ms/step - loss: 1.1882 - val_loss: 2.3857\n",
      "[INFO] Training model: epoch 11 - 3750/20505 samples\n",
      "Train on 2471 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.2442 - val_loss: 2.5019\n",
      "[INFO] Training model: epoch 11 - 4000/20505 samples\n",
      "Train on 2477 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 22s 9ms/step - loss: 1.2202 - val_loss: 2.4028\n",
      "[INFO] Training model: epoch 11 - 4250/20505 samples\n",
      "Train on 2464 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.2981 - val_loss: 2.6262\n",
      "[INFO] Training model: epoch 11 - 4500/20505 samples\n",
      "Train on 2421 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.2153 - val_loss: 2.5997\n",
      "[INFO] Training model: epoch 11 - 4750/20505 samples\n",
      "Train on 2477 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 1.2472 - val_loss: 2.7452\n",
      "[INFO] Training model: epoch 11 - 5000/20505 samples\n",
      "Train on 2454 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 21s 9ms/step - loss: 1.2551 - val_loss: 2.3677\n",
      "[INFO] Training model: epoch 11 - 5250/20505 samples\n",
      "Train on 2536 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2536/2536 [==============================] - 23s 9ms/step - loss: 1.2775 - val_loss: 2.4986\n",
      "[INFO] Training model: epoch 11 - 5500/20505 samples\n",
      "Train on 2485 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.3082 - val_loss: 2.3396\n",
      "[INFO] Training model: epoch 11 - 5750/20505 samples\n",
      "Train on 2440 samples, validate on 561 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 22s 9ms/step - loss: 1.3467 - val_loss: 2.5025\n",
      "[INFO] Training model: epoch 11 - 6000/20505 samples\n",
      "Train on 2347 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 21s 9ms/step - loss: 1.3810 - val_loss: 2.3751\n",
      "[INFO] Training model: epoch 11 - 6250/20505 samples\n",
      "Train on 2464 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 21s 9ms/step - loss: 1.3652 - val_loss: 2.7571\n",
      "[INFO] Training model: epoch 11 - 6500/20505 samples\n",
      "Train on 2495 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 21s 9ms/step - loss: 1.3482 - val_loss: 2.4914\n",
      "[INFO] Training model: epoch 11 - 6750/20505 samples\n",
      "Train on 2494 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 22s 9ms/step - loss: 1.2669 - val_loss: 2.7112\n",
      "[INFO] Training model: epoch 11 - 7000/20505 samples\n",
      "Train on 2593 samples, validate on 686 samples\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 25s 9ms/step - loss: 1.2989 - val_loss: 2.6193\n",
      "[INFO] Training model: epoch 11 - 7250/20505 samples\n",
      "Train on 2449 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 1.2783 - val_loss: 2.5531\n",
      "[INFO] Training model: epoch 11 - 7500/20505 samples\n",
      "Train on 2417 samples, validate on 637 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2417/2417 [==============================] - 22s 9ms/step - loss: 1.2918 - val_loss: 2.8132\n",
      "[INFO] Training model: epoch 11 - 7750/20505 samples\n",
      "Train on 2437 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 21s 9ms/step - loss: 1.3941 - val_loss: 2.4988\n",
      "[INFO] Training model: epoch 11 - 8000/20505 samples\n",
      "Train on 2367 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 20s 9ms/step - loss: 1.3292 - val_loss: 2.3259\n",
      "[INFO] Training model: epoch 11 - 8250/20505 samples\n",
      "Train on 2479 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.2917 - val_loss: 2.6790\n",
      "[INFO] Training model: epoch 11 - 8500/20505 samples\n",
      "Train on 2437 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 22s 9ms/step - loss: 1.3568 - val_loss: 2.6854\n",
      "[INFO] Training model: epoch 11 - 8750/20505 samples\n",
      "Train on 2438 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.3525 - val_loss: 2.4817\n",
      "[INFO] Training model: epoch 11 - 9000/20505 samples\n",
      "Train on 2390 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 21s 9ms/step - loss: 1.2992 - val_loss: 2.7257\n",
      "[INFO] Training model: epoch 11 - 9250/20505 samples\n",
      "Train on 2463 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 22s 9ms/step - loss: 1.3064 - val_loss: 2.8056\n",
      "[INFO] Training model: epoch 11 - 9500/20505 samples\n",
      "Train on 2497 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.3276 - val_loss: 2.8389\n",
      "[INFO] Training model: epoch 11 - 9750/20505 samples\n",
      "Train on 2442 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.3576 - val_loss: 2.1876\n",
      "[INFO] Training model: epoch 11 - 10000/20505 samples\n",
      "Train on 2505 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.3888 - val_loss: 2.5828\n",
      "[INFO] Training model: epoch 11 - 10250/20505 samples\n",
      "Train on 2439 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.3151 - val_loss: 2.6247\n",
      "[INFO] Training model: epoch 11 - 10500/20505 samples\n",
      "Train on 2443 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 21s 9ms/step - loss: 1.2393 - val_loss: 2.7560\n",
      "[INFO] Training model: epoch 11 - 10750/20505 samples\n",
      "Train on 2418 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 9ms/step - loss: 1.3563 - val_loss: 2.6090\n",
      "[INFO] Training model: epoch 11 - 11000/20505 samples\n",
      "Train on 2425 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.4039 - val_loss: 2.6096\n",
      "[INFO] Training model: epoch 11 - 11250/20505 samples\n",
      "Train on 2360 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 20s 9ms/step - loss: 1.4179 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 11 - 11500/20505 samples\n",
      "Train on 2507 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 22s 9ms/step - loss: 1.3092 - val_loss: 2.6899\n",
      "[INFO] Training model: epoch 11 - 11750/20505 samples\n",
      "Train on 2467 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.3841 - val_loss: 2.4422\n",
      "[INFO] Training model: epoch 11 - 12000/20505 samples\n",
      "Train on 2395 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 1.3591 - val_loss: 2.4199\n",
      "[INFO] Training model: epoch 11 - 12250/20505 samples\n",
      "Train on 2491 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 21s 9ms/step - loss: 1.3581 - val_loss: 2.6334\n",
      "[INFO] Training model: epoch 11 - 12500/20505 samples\n",
      "Train on 2483 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.3397 - val_loss: 2.6833\n",
      "[INFO] Training model: epoch 11 - 12750/20505 samples\n",
      "Train on 2387 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 21s 9ms/step - loss: 1.3226 - val_loss: 2.1283\n",
      "[INFO] Training model: epoch 11 - 13000/20505 samples\n",
      "Train on 2482 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 24s 9ms/step - loss: 1.3582 - val_loss: 2.4333\n",
      "[INFO] Training model: epoch 11 - 13250/20505 samples\n",
      "Train on 2419 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 1.3824 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 11 - 13500/20505 samples\n",
      "Train on 2545 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 23s 9ms/step - loss: 1.3950 - val_loss: 2.7967\n",
      "[INFO] Training model: epoch 11 - 13750/20505 samples\n",
      "Train on 2474 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.2810 - val_loss: 2.3460\n",
      "[INFO] Training model: epoch 11 - 14000/20505 samples\n",
      "Train on 2547 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.3375 - val_loss: 2.3385\n",
      "[INFO] Training model: epoch 11 - 14250/20505 samples\n",
      "Train on 2526 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.3521 - val_loss: 2.1959\n",
      "[INFO] Training model: epoch 11 - 14500/20505 samples\n",
      "Train on 2548 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.4120 - val_loss: 2.5015\n",
      "[INFO] Training model: epoch 11 - 14750/20505 samples\n",
      "Train on 2442 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.3917 - val_loss: 2.6781\n",
      "[INFO] Training model: epoch 11 - 15000/20505 samples\n",
      "Train on 2445 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 21s 9ms/step - loss: 1.3617 - val_loss: 2.4649\n",
      "[INFO] Training model: epoch 11 - 15250/20505 samples\n",
      "Train on 2392 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.4431 - val_loss: 2.4181\n",
      "[INFO] Training model: epoch 11 - 15500/20505 samples\n",
      "Train on 2339 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2339/2339 [==============================] - 22s 9ms/step - loss: 1.4015 - val_loss: 2.7118\n",
      "[INFO] Training model: epoch 11 - 15750/20505 samples\n",
      "Train on 2445 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.4225 - val_loss: 2.5225\n",
      "[INFO] Training model: epoch 11 - 16000/20505 samples\n",
      "Train on 2519 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 22s 9ms/step - loss: 1.3761 - val_loss: 2.6158\n",
      "[INFO] Training model: epoch 11 - 16250/20505 samples\n",
      "Train on 2664 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2664/2664 [==============================] - 25s 9ms/step - loss: 1.3578 - val_loss: 2.8205\n",
      "[INFO] Training model: epoch 11 - 16500/20505 samples\n",
      "Train on 2485 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.3746 - val_loss: 2.4532\n",
      "[INFO] Training model: epoch 11 - 16750/20505 samples\n",
      "Train on 2453 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.3805 - val_loss: 2.5250\n",
      "[INFO] Training model: epoch 11 - 17000/20505 samples\n",
      "Train on 2559 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 1.3940 - val_loss: 2.3491\n",
      "[INFO] Training model: epoch 11 - 17250/20505 samples\n",
      "Train on 2456 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 21s 9ms/step - loss: 1.3744 - val_loss: 2.4802\n",
      "[INFO] Training model: epoch 11 - 17500/20505 samples\n",
      "Train on 2393 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.4325 - val_loss: 2.2792\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 11 - 17750/20505 samples\n",
      "Train on 2530 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 22s 9ms/step - loss: 1.3477 - val_loss: 2.2779\n",
      "[INFO] Training model: epoch 11 - 18000/20505 samples\n",
      "Train on 2461 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.4718 - val_loss: 2.1462\n",
      "[INFO] Training model: epoch 11 - 18250/20505 samples\n",
      "Train on 2399 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.3591 - val_loss: 2.6600\n",
      "[INFO] Training model: epoch 11 - 18500/20505 samples\n",
      "Train on 2401 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.3993 - val_loss: 2.2315\n",
      "[INFO] Training model: epoch 11 - 18750/20505 samples\n",
      "Train on 2481 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 21s 9ms/step - loss: 1.3960 - val_loss: 2.4870\n",
      "[INFO] Training model: epoch 11 - 19000/20505 samples\n",
      "Train on 2480 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.3786 - val_loss: 2.4056\n",
      "[INFO] Training model: epoch 11 - 19250/20505 samples\n",
      "Train on 2451 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 22s 9ms/step - loss: 1.4008 - val_loss: 2.3909\n",
      "[INFO] Training model: epoch 11 - 19500/20505 samples\n",
      "Train on 2441 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 21s 9ms/step - loss: 1.4363 - val_loss: 2.4583\n",
      "[INFO] Training model: epoch 11 - 19750/20505 samples\n",
      "Train on 2364 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 22s 9ms/step - loss: 1.3617 - val_loss: 2.4458\n",
      "[INFO] Training model: epoch 11 - 20000/20505 samples\n",
      "Train on 2467 samples, validate on 670 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 22s 9ms/step - loss: 1.4323 - val_loss: 2.5759\n",
      "[INFO] Training model: epoch 11 - 20250/20505 samples\n",
      "Train on 2439 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 21s 9ms/step - loss: 1.4116 - val_loss: 2.2876\n",
      "[INFO] Training model: epoch 11 - 20500/20505 samples\n",
      "Train on 63 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "63/63 [==============================] - 1s 9ms/step - loss: 1.5614 - val_loss: 2.4370\n",
      "[INFO] Training model: epoch 12 - 0/20505 samples\n",
      "Train on 2546 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 24s 9ms/step - loss: 1.1884 - val_loss: 2.4317\n",
      "[INFO] Training model: epoch 12 - 250/20505 samples\n",
      "Train on 2376 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 22s 9ms/step - loss: 1.1951 - val_loss: 2.6852\n",
      "[INFO] Training model: epoch 12 - 500/20505 samples\n",
      "Train on 2474 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 22s 9ms/step - loss: 1.1750 - val_loss: 2.4667\n",
      "[INFO] Training model: epoch 12 - 750/20505 samples\n",
      "Train on 2415 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.2445 - val_loss: 2.3990\n",
      "[INFO] Training model: epoch 12 - 1000/20505 samples\n",
      "Train on 2455 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 1.1705 - val_loss: 2.1942\n",
      "[INFO] Training model: epoch 12 - 1250/20505 samples\n",
      "Train on 2430 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 21s 9ms/step - loss: 1.2072 - val_loss: 2.7040\n",
      "[INFO] Training model: epoch 12 - 1500/20505 samples\n",
      "Train on 2509 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 22s 9ms/step - loss: 1.2525 - val_loss: 2.6146\n",
      "[INFO] Training model: epoch 12 - 1750/20505 samples\n",
      "Train on 2413 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 9ms/step - loss: 1.2572 - val_loss: 2.5434\n",
      "[INFO] Training model: epoch 12 - 2000/20505 samples\n",
      "Train on 2518 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.1916 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 12 - 2250/20505 samples\n",
      "Train on 2388 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.1610 - val_loss: 2.6454\n",
      "[INFO] Training model: epoch 12 - 2500/20505 samples\n",
      "Train on 2457 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 21s 9ms/step - loss: 1.2348 - val_loss: 2.3086\n",
      "[INFO] Training model: epoch 12 - 2750/20505 samples\n",
      "Train on 2378 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 22s 9ms/step - loss: 1.1515 - val_loss: 2.8354\n",
      "[INFO] Training model: epoch 12 - 3000/20505 samples\n",
      "Train on 2485 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 21s 9ms/step - loss: 1.1734 - val_loss: 2.7399\n",
      "[INFO] Training model: epoch 12 - 3250/20505 samples\n",
      "Train on 2381 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 22s 9ms/step - loss: 1.2248 - val_loss: 2.5669\n",
      "[INFO] Training model: epoch 12 - 3500/20505 samples\n",
      "Train on 2511 samples, validate on 699 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 23s 9ms/step - loss: 1.1919 - val_loss: 2.4787\n",
      "[INFO] Training model: epoch 12 - 3750/20505 samples\n",
      "Train on 2438 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 21s 9ms/step - loss: 1.1791 - val_loss: 2.7310\n",
      "[INFO] Training model: epoch 12 - 4000/20505 samples\n",
      "Train on 2456 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.2101 - val_loss: 2.4553\n",
      "[INFO] Training model: epoch 12 - 4250/20505 samples\n",
      "Train on 2472 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.2134 - val_loss: 2.5999\n",
      "[INFO] Training model: epoch 12 - 4500/20505 samples\n",
      "Train on 2433 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.3086 - val_loss: 2.6614\n",
      "[INFO] Training model: epoch 12 - 4750/20505 samples\n",
      "Train on 2444 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.1838 - val_loss: 2.4374\n",
      "[INFO] Training model: epoch 12 - 5000/20505 samples\n",
      "Train on 2505 samples, validate on 532 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 23s 9ms/step - loss: 1.3045 - val_loss: 2.5985\n",
      "[INFO] Training model: epoch 12 - 5250/20505 samples\n",
      "Train on 2409 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.2956 - val_loss: 2.5598\n",
      "[INFO] Training model: epoch 12 - 5500/20505 samples\n",
      "Train on 2447 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 21s 9ms/step - loss: 1.2475 - val_loss: 2.2821\n",
      "[INFO] Training model: epoch 12 - 5750/20505 samples\n",
      "Train on 2472 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 22s 9ms/step - loss: 1.2803 - val_loss: 2.6148\n",
      "[INFO] Training model: epoch 12 - 6000/20505 samples\n",
      "Train on 2575 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 25s 10ms/step - loss: 1.2526 - val_loss: 2.6842\n",
      "[INFO] Training model: epoch 12 - 6250/20505 samples\n",
      "Train on 2399 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.2647 - val_loss: 2.7982\n",
      "[INFO] Training model: epoch 12 - 6500/20505 samples\n",
      "Train on 2547 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 22s 9ms/step - loss: 1.2216 - val_loss: 2.6313\n",
      "[INFO] Training model: epoch 12 - 6750/20505 samples\n",
      "Train on 2464 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.2585 - val_loss: 2.5686\n",
      "[INFO] Training model: epoch 12 - 7000/20505 samples\n",
      "Train on 2489 samples, validate on 578 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.2773 - val_loss: 2.4639\n",
      "[INFO] Training model: epoch 12 - 7250/20505 samples\n",
      "Train on 2472 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 21s 9ms/step - loss: 1.2424 - val_loss: 2.8239\n",
      "[INFO] Training model: epoch 12 - 7500/20505 samples\n",
      "Train on 2386 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.2487 - val_loss: 2.3500\n",
      "[INFO] Training model: epoch 12 - 7750/20505 samples\n",
      "Train on 2459 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.2780 - val_loss: 2.5432\n",
      "[INFO] Training model: epoch 12 - 8000/20505 samples\n",
      "Train on 2350 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2350/2350 [==============================] - 21s 9ms/step - loss: 1.2250 - val_loss: 2.8511\n",
      "[INFO] Training model: epoch 12 - 8250/20505 samples\n",
      "Train on 2375 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 21s 9ms/step - loss: 1.2869 - val_loss: 2.7251\n",
      "[INFO] Training model: epoch 12 - 8500/20505 samples\n",
      "Train on 2387 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2387/2387 [==============================] - 22s 9ms/step - loss: 1.2107 - val_loss: 2.5376\n",
      "[INFO] Training model: epoch 12 - 8750/20505 samples\n",
      "Train on 2401 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 21s 9ms/step - loss: 1.2918 - val_loss: 2.5749\n",
      "[INFO] Training model: epoch 12 - 9000/20505 samples\n",
      "Train on 2399 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 1.2866 - val_loss: 2.4616\n",
      "[INFO] Training model: epoch 12 - 9250/20505 samples\n",
      "Train on 2576 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.2929 - val_loss: 2.5945\n",
      "[INFO] Training model: epoch 12 - 9500/20505 samples\n",
      "Train on 2401 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2458 - val_loss: 2.5714\n",
      "[INFO] Training model: epoch 12 - 9750/20505 samples\n",
      "Train on 2440 samples, validate on 702 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 21s 9ms/step - loss: 1.2527 - val_loss: 2.7648\n",
      "[INFO] Training model: epoch 12 - 10000/20505 samples\n",
      "Train on 2410 samples, validate on 664 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2470 - val_loss: 2.8064\n",
      "[INFO] Training model: epoch 12 - 10250/20505 samples\n",
      "Train on 2487 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 21s 9ms/step - loss: 1.2552 - val_loss: 2.6279\n",
      "[INFO] Training model: epoch 12 - 10500/20505 samples\n",
      "Train on 2530 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 23s 9ms/step - loss: 1.3237 - val_loss: 2.4501\n",
      "[INFO] Training model: epoch 12 - 10750/20505 samples\n",
      "Train on 2435 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 21s 9ms/step - loss: 1.2626 - val_loss: 2.7013\n",
      "[INFO] Training model: epoch 12 - 11000/20505 samples\n",
      "Train on 2409 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 21s 9ms/step - loss: 1.3134 - val_loss: 2.6058\n",
      "[INFO] Training model: epoch 12 - 11250/20505 samples\n",
      "Train on 2372 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2372/2372 [==============================] - 22s 9ms/step - loss: 1.3281 - val_loss: 2.2159\n",
      "[INFO] Training model: epoch 12 - 11500/20505 samples\n",
      "Train on 2540 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 1.3469 - val_loss: 2.4681\n",
      "[INFO] Training model: epoch 12 - 11750/20505 samples\n",
      "Train on 2528 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.2769 - val_loss: 2.3153\n",
      "[INFO] Training model: epoch 12 - 12000/20505 samples\n",
      "Train on 2448 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 22s 9ms/step - loss: 1.3128 - val_loss: 2.4284\n",
      "[INFO] Training model: epoch 12 - 12250/20505 samples\n",
      "Train on 2452 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.2495 - val_loss: 2.6827\n",
      "[INFO] Training model: epoch 12 - 12500/20505 samples\n",
      "Train on 2465 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 21s 9ms/step - loss: 1.3633 - val_loss: 2.4817\n",
      "[INFO] Training model: epoch 12 - 12750/20505 samples\n",
      "Train on 2395 samples, validate on 668 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 21s 9ms/step - loss: 1.3170 - val_loss: 2.6730\n",
      "[INFO] Training model: epoch 12 - 13000/20505 samples\n",
      "Train on 2453 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.3228 - val_loss: 2.3821\n",
      "[INFO] Training model: epoch 12 - 13250/20505 samples\n",
      "Train on 2669 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2669/2669 [==============================] - 25s 9ms/step - loss: 1.3146 - val_loss: 2.9244\n",
      "[INFO] Training model: epoch 12 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 22s 9ms/step - loss: 1.2955 - val_loss: 2.3359\n",
      "[INFO] Training model: epoch 12 - 13750/20505 samples\n",
      "Train on 2589 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2589/2589 [==============================] - 22s 9ms/step - loss: 1.3506 - val_loss: 2.5390\n",
      "[INFO] Training model: epoch 12 - 14000/20505 samples\n",
      "Train on 2606 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2606/2606 [==============================] - 24s 9ms/step - loss: 1.2537 - val_loss: 2.3006\n",
      "[INFO] Training model: epoch 12 - 14250/20505 samples\n",
      "Train on 2435 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 21s 9ms/step - loss: 1.3256 - val_loss: 2.0831\n",
      "[INFO] Training model: epoch 12 - 14500/20505 samples\n",
      "Train on 2563 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 22s 9ms/step - loss: 1.3042 - val_loss: 2.6325\n",
      "[INFO] Training model: epoch 12 - 14750/20505 samples\n",
      "Train on 2383 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.4048 - val_loss: 2.4628\n",
      "[INFO] Training model: epoch 12 - 15000/20505 samples\n",
      "Train on 2528 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.3683 - val_loss: 2.9727\n",
      "[INFO] Training model: epoch 12 - 15250/20505 samples\n",
      "Train on 2500 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 22s 9ms/step - loss: 1.3268 - val_loss: 2.7967\n",
      "[INFO] Training model: epoch 12 - 15500/20505 samples\n",
      "Train on 2433 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 10ms/step - loss: 1.3061 - val_loss: 2.5433\n",
      "[INFO] Training model: epoch 12 - 15750/20505 samples\n",
      "Train on 2477 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 21s 9ms/step - loss: 1.2813 - val_loss: 2.4719\n",
      "[INFO] Training model: epoch 12 - 16000/20505 samples\n",
      "Train on 2400 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 22s 9ms/step - loss: 1.3419 - val_loss: 2.3366\n",
      "[INFO] Training model: epoch 12 - 16250/20505 samples\n",
      "Train on 2277 samples, validate on 703 samples\n",
      "Epoch 1/1\n",
      "2277/2277 [==============================] - 21s 9ms/step - loss: 1.3264 - val_loss: 2.5151\n",
      "[INFO] Training model: epoch 12 - 16500/20505 samples\n",
      "Train on 2523 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 23s 9ms/step - loss: 1.3371 - val_loss: 2.5685\n",
      "[INFO] Training model: epoch 12 - 16750/20505 samples\n",
      "Train on 2392 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 21s 9ms/step - loss: 1.3229 - val_loss: 2.6889\n",
      "[INFO] Training model: epoch 12 - 17000/20505 samples\n",
      "Train on 2502 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 23s 9ms/step - loss: 1.3510 - val_loss: 2.5016\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 12 - 17250/20505 samples\n",
      "Train on 2394 samples, validate on 563 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 21s 9ms/step - loss: 1.3551 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 12 - 17500/20505 samples\n",
      "Train on 2444 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.3190 - val_loss: 2.3521\n",
      "[INFO] Training model: epoch 12 - 17750/20505 samples\n",
      "Train on 2476 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.3401 - val_loss: 2.5740\n",
      "[INFO] Training model: epoch 12 - 18000/20505 samples\n",
      "Train on 2444 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 21s 9ms/step - loss: 1.3549 - val_loss: 2.6335\n",
      "[INFO] Training model: epoch 12 - 18250/20505 samples\n",
      "Train on 2491 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2908 - val_loss: 2.4421\n",
      "[INFO] Training model: epoch 12 - 18500/20505 samples\n",
      "Train on 2326 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2326/2326 [==============================] - 21s 9ms/step - loss: 1.3129 - val_loss: 2.6949\n",
      "[INFO] Training model: epoch 12 - 18750/20505 samples\n",
      "Train on 2497 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 23s 9ms/step - loss: 1.3302 - val_loss: 2.4779\n",
      "[INFO] Training model: epoch 12 - 19000/20505 samples\n",
      "Train on 2566 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2566/2566 [==============================] - 22s 9ms/step - loss: 1.3780 - val_loss: 2.5958\n",
      "[INFO] Training model: epoch 12 - 19250/20505 samples\n",
      "Train on 2425 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 22s 9ms/step - loss: 1.2921 - val_loss: 2.5769\n",
      "[INFO] Training model: epoch 12 - 19500/20505 samples\n",
      "Train on 2415 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 23s 9ms/step - loss: 1.3342 - val_loss: 2.5212\n",
      "[INFO] Training model: epoch 12 - 19750/20505 samples\n",
      "Train on 2508 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2508/2508 [==============================] - 23s 9ms/step - loss: 1.3358 - val_loss: 2.5891\n",
      "[INFO] Training model: epoch 12 - 20000/20505 samples\n",
      "Train on 2380 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.2774 - val_loss: 2.5000\n",
      "[INFO] Training model: epoch 12 - 20250/20505 samples\n",
      "Train on 2450 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 21s 9ms/step - loss: 1.4014 - val_loss: 2.5701\n",
      "[INFO] Training model: epoch 12 - 20500/20505 samples\n",
      "Train on 52 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "52/52 [==============================] - 1s 10ms/step - loss: 2.1503 - val_loss: 1.2227\n",
      "[INFO] Training model: epoch 13 - 0/20505 samples\n",
      "Train on 2394 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1681 - val_loss: 2.2861\n",
      "[INFO] Training model: epoch 13 - 250/20505 samples\n",
      "Train on 2433 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.1308 - val_loss: 2.3463\n",
      "[INFO] Training model: epoch 13 - 500/20505 samples\n",
      "Train on 2389 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.1554 - val_loss: 2.1439\n",
      "[INFO] Training model: epoch 13 - 750/20505 samples\n",
      "Train on 2405 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.1226 - val_loss: 2.4390\n",
      "[INFO] Training model: epoch 13 - 1000/20505 samples\n",
      "Train on 2385 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1484 - val_loss: 2.1855\n",
      "[INFO] Training model: epoch 13 - 1250/20505 samples\n",
      "Train on 2451 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 21s 9ms/step - loss: 1.2039 - val_loss: 2.8291\n",
      "[INFO] Training model: epoch 13 - 1500/20505 samples\n",
      "Train on 2374 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 23s 10ms/step - loss: 1.1345 - val_loss: 2.7188\n",
      "[INFO] Training model: epoch 13 - 1750/20505 samples\n",
      "Train on 2375 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2375/2375 [==============================] - 22s 9ms/step - loss: 1.1465 - val_loss: 2.4266\n",
      "[INFO] Training model: epoch 13 - 2000/20505 samples\n",
      "Train on 2487 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 22s 9ms/step - loss: 1.1350 - val_loss: 2.5639\n",
      "[INFO] Training model: epoch 13 - 2250/20505 samples\n",
      "Train on 2389 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.1659 - val_loss: 2.7454\n",
      "[INFO] Training model: epoch 13 - 2500/20505 samples\n",
      "Train on 2569 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2569/2569 [==============================] - 24s 9ms/step - loss: 1.1579 - val_loss: 2.6287\n",
      "[INFO] Training model: epoch 13 - 2750/20505 samples\n",
      "Train on 2416 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.1136 - val_loss: 2.7806\n",
      "[INFO] Training model: epoch 13 - 3000/20505 samples\n",
      "Train on 2476 samples, validate on 525 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 22s 9ms/step - loss: 1.1667 - val_loss: 2.7894\n",
      "[INFO] Training model: epoch 13 - 3250/20505 samples\n",
      "Train on 2495 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 1.1847 - val_loss: 2.3461\n",
      "[INFO] Training model: epoch 13 - 3500/20505 samples\n",
      "Train on 2532 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.1381 - val_loss: 2.6230\n",
      "[INFO] Training model: epoch 13 - 3750/20505 samples\n",
      "Train on 2486 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 22s 9ms/step - loss: 1.1969 - val_loss: 2.5509\n",
      "[INFO] Training model: epoch 13 - 4000/20505 samples\n",
      "Train on 2547 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.1586 - val_loss: 2.5952\n",
      "[INFO] Training model: epoch 13 - 4250/20505 samples\n",
      "Train on 2482 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.2058 - val_loss: 2.6656\n",
      "[INFO] Training model: epoch 13 - 4500/20505 samples\n",
      "Train on 2503 samples, validate on 673 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 22s 9ms/step - loss: 1.1188 - val_loss: 2.7083\n",
      "[INFO] Training model: epoch 13 - 4750/20505 samples\n",
      "Train on 2374 samples, validate on 725 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.2142 - val_loss: 2.7237\n",
      "[INFO] Training model: epoch 13 - 5000/20505 samples\n",
      "Train on 2348 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2348/2348 [==============================] - 20s 9ms/step - loss: 1.2338 - val_loss: 2.6558\n",
      "[INFO] Training model: epoch 13 - 5250/20505 samples\n",
      "Train on 2360 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 22s 9ms/step - loss: 1.2276 - val_loss: 2.2035\n",
      "[INFO] Training model: epoch 13 - 5500/20505 samples\n",
      "Train on 2382 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2382/2382 [==============================] - 22s 9ms/step - loss: 1.1619 - val_loss: 2.6144\n",
      "[INFO] Training model: epoch 13 - 5750/20505 samples\n",
      "Train on 2463 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.1542 - val_loss: 2.4655\n",
      "[INFO] Training model: epoch 13 - 6000/20505 samples\n",
      "Train on 2456 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 22s 9ms/step - loss: 1.2435 - val_loss: 2.7665\n",
      "[INFO] Training model: epoch 13 - 6250/20505 samples\n",
      "Train on 2516 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.2016 - val_loss: 2.5575\n",
      "[INFO] Training model: epoch 13 - 6500/20505 samples\n",
      "Train on 2481 samples, validate on 604 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.2674 - val_loss: 2.6208\n",
      "[INFO] Training model: epoch 13 - 6750/20505 samples\n",
      "Train on 2575 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2575/2575 [==============================] - 23s 9ms/step - loss: 1.1781 - val_loss: 2.4991\n",
      "[INFO] Training model: epoch 13 - 7000/20505 samples\n",
      "Train on 2571 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2571/2571 [==============================] - 24s 9ms/step - loss: 1.2175 - val_loss: 2.7427\n",
      "[INFO] Training model: epoch 13 - 7250/20505 samples\n",
      "Train on 2423 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.0938 - val_loss: 2.4453\n",
      "[INFO] Training model: epoch 13 - 7500/20505 samples\n",
      "Train on 2475 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.1944 - val_loss: 2.4015\n",
      "[INFO] Training model: epoch 13 - 7750/20505 samples\n",
      "Train on 2513 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 22s 9ms/step - loss: 1.2082 - val_loss: 2.6704\n",
      "[INFO] Training model: epoch 13 - 8000/20505 samples\n",
      "Train on 2383 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.1868 - val_loss: 2.8137\n",
      "[INFO] Training model: epoch 13 - 8250/20505 samples\n",
      "Train on 2357 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 21s 9ms/step - loss: 1.2685 - val_loss: 2.6211\n",
      "[INFO] Training model: epoch 13 - 8500/20505 samples\n",
      "Train on 2406 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 10ms/step - loss: 1.2111 - val_loss: 2.5712\n",
      "[INFO] Training model: epoch 13 - 8750/20505 samples\n",
      "Train on 2345 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2345/2345 [==============================] - 22s 9ms/step - loss: 1.1781 - val_loss: 2.6281\n",
      "[INFO] Training model: epoch 13 - 9000/20505 samples\n",
      "Train on 2438 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 23s 9ms/step - loss: 1.2099 - val_loss: 2.3352\n",
      "[INFO] Training model: epoch 13 - 9250/20505 samples\n",
      "Train on 2479 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 23s 9ms/step - loss: 1.1469 - val_loss: 2.7611\n",
      "[INFO] Training model: epoch 13 - 9500/20505 samples\n",
      "Train on 2433 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 9ms/step - loss: 1.2217 - val_loss: 2.6948\n",
      "[INFO] Training model: epoch 13 - 9750/20505 samples\n",
      "Train on 2419 samples, validate on 664 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 21s 9ms/step - loss: 1.1979 - val_loss: 2.7193\n",
      "[INFO] Training model: epoch 13 - 10000/20505 samples\n",
      "Train on 2492 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 1.2902 - val_loss: 2.4032\n",
      "[INFO] Training model: epoch 13 - 10250/20505 samples\n",
      "Train on 2475 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 22s 9ms/step - loss: 1.2068 - val_loss: 2.7705\n",
      "[INFO] Training model: epoch 13 - 10500/20505 samples\n",
      "Train on 2494 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.2008 - val_loss: 2.6127\n",
      "[INFO] Training model: epoch 13 - 10750/20505 samples\n",
      "Train on 2482 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 21s 9ms/step - loss: 1.2692 - val_loss: 2.2856\n",
      "[INFO] Training model: epoch 13 - 11000/20505 samples\n",
      "Train on 2416 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.2081 - val_loss: 2.4837\n",
      "[INFO] Training model: epoch 13 - 11250/20505 samples\n",
      "Train on 2445 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.2761 - val_loss: 2.3846\n",
      "[INFO] Training model: epoch 13 - 11500/20505 samples\n",
      "Train on 2525 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.2181 - val_loss: 2.5468\n",
      "[INFO] Training model: epoch 13 - 11750/20505 samples\n",
      "Train on 2463 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.2889 - val_loss: 2.5805\n",
      "[INFO] Training model: epoch 13 - 12000/20505 samples\n",
      "Train on 2452 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.3121 - val_loss: 2.8777\n",
      "[INFO] Training model: epoch 13 - 12250/20505 samples\n",
      "Train on 2570 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2570/2570 [==============================] - 24s 9ms/step - loss: 1.2860 - val_loss: 2.4413\n",
      "[INFO] Training model: epoch 13 - 12500/20505 samples\n",
      "Train on 2378 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 25s 10ms/step - loss: 1.2392 - val_loss: 2.4371\n",
      "[INFO] Training model: epoch 13 - 12750/20505 samples\n",
      "Train on 2428 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 24s 10ms/step - loss: 1.2632 - val_loss: 2.3211\n",
      "[INFO] Training model: epoch 13 - 13000/20505 samples\n",
      "Train on 2482 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 30s 12ms/step - loss: 1.2634 - val_loss: 2.6472\n",
      "[INFO] Training model: epoch 13 - 13250/20505 samples\n",
      "Train on 2474 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 28s 11ms/step - loss: 1.2644 - val_loss: 2.6802\n",
      "[INFO] Training model: epoch 13 - 13500/20505 samples\n",
      "Train on 2481 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.2862 - val_loss: 2.4489\n",
      "[INFO] Training model: epoch 13 - 13750/20505 samples\n",
      "Train on 2457 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 10ms/step - loss: 1.2377 - val_loss: 2.5902\n",
      "[INFO] Training model: epoch 13 - 14000/20505 samples\n",
      "Train on 2431 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 1.2907 - val_loss: 2.6848\n",
      "[INFO] Training model: epoch 13 - 14250/20505 samples\n",
      "Train on 2607 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2607/2607 [==============================] - 24s 9ms/step - loss: 1.2425 - val_loss: 2.7250\n",
      "[INFO] Training model: epoch 13 - 14500/20505 samples\n",
      "Train on 2463 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 1.2485 - val_loss: 2.3472\n",
      "[INFO] Training model: epoch 13 - 14750/20505 samples\n",
      "Train on 2541 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 1.2776 - val_loss: 2.5587\n",
      "[INFO] Training model: epoch 13 - 15000/20505 samples\n",
      "Train on 2537 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 9ms/step - loss: 1.2785 - val_loss: 2.6488\n",
      "[INFO] Training model: epoch 13 - 15250/20505 samples\n",
      "Train on 2404 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 23s 9ms/step - loss: 1.3118 - val_loss: 2.6508\n",
      "[INFO] Training model: epoch 13 - 15500/20505 samples\n",
      "Train on 2460 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.2495 - val_loss: 2.4094\n",
      "[INFO] Training model: epoch 13 - 15750/20505 samples\n",
      "Train on 2476 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.2591 - val_loss: 2.5843\n",
      "[INFO] Training model: epoch 13 - 16000/20505 samples\n",
      "Train on 2388 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 10ms/step - loss: 1.2660 - val_loss: 2.8181\n",
      "[INFO] Training model: epoch 13 - 16250/20505 samples\n",
      "Train on 2373 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2373/2373 [==============================] - 22s 9ms/step - loss: 1.2892 - val_loss: 2.8678\n",
      "[INFO] Training model: epoch 13 - 16500/20505 samples\n",
      "Train on 2410 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 22s 9ms/step - loss: 1.2527 - val_loss: 2.5705\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 13 - 16750/20505 samples\n",
      "Train on 2462 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.3198 - val_loss: 2.3820\n",
      "[INFO] Training model: epoch 13 - 17000/20505 samples\n",
      "Train on 2414 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 23s 9ms/step - loss: 1.2549 - val_loss: 2.6669\n",
      "[INFO] Training model: epoch 13 - 17250/20505 samples\n",
      "Train on 2402 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 24s 10ms/step - loss: 1.2253 - val_loss: 2.6443\n",
      "[INFO] Training model: epoch 13 - 17500/20505 samples\n",
      "Train on 2445 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.3274 - val_loss: 2.5191\n",
      "[INFO] Training model: epoch 13 - 17750/20505 samples\n",
      "Train on 2432 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.2943 - val_loss: 2.5945\n",
      "[INFO] Training model: epoch 13 - 18000/20505 samples\n",
      "Train on 2462 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 21s 9ms/step - loss: 1.3899 - val_loss: 2.3965\n",
      "[INFO] Training model: epoch 13 - 18250/20505 samples\n",
      "Train on 2474 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.3381 - val_loss: 2.5519\n",
      "[INFO] Training model: epoch 13 - 18500/20505 samples\n",
      "Train on 2551 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 23s 9ms/step - loss: 1.2981 - val_loss: 2.7234\n",
      "[INFO] Training model: epoch 13 - 18750/20505 samples\n",
      "Train on 2498 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.2994 - val_loss: 2.4684\n",
      "[INFO] Training model: epoch 13 - 19000/20505 samples\n",
      "Train on 2519 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 23s 9ms/step - loss: 1.3448 - val_loss: 2.5957\n",
      "[INFO] Training model: epoch 13 - 19250/20505 samples\n",
      "Train on 2480 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 24s 9ms/step - loss: 1.2890 - val_loss: 2.5116\n",
      "[INFO] Training model: epoch 13 - 19500/20505 samples\n",
      "Train on 2548 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 23s 9ms/step - loss: 1.2763 - val_loss: 2.5991\n",
      "[INFO] Training model: epoch 13 - 19750/20505 samples\n",
      "Train on 2468 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 24s 10ms/step - loss: 1.2964 - val_loss: 2.5093\n",
      "[INFO] Training model: epoch 13 - 20000/20505 samples\n",
      "Train on 2380 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 21s 9ms/step - loss: 1.3566 - val_loss: 2.2832\n",
      "[INFO] Training model: epoch 13 - 20250/20505 samples\n",
      "Train on 2491 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2711 - val_loss: 2.5337\n",
      "[INFO] Training model: epoch 13 - 20500/20505 samples\n",
      "Train on 41 samples, validate on 20 samples\n",
      "Epoch 1/1\n",
      "41/41 [==============================] - 1s 13ms/step - loss: 1.4036 - val_loss: 2.7953\n",
      "[INFO] Training model: epoch 14 - 0/20505 samples\n",
      "Train on 2443 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.0526 - val_loss: 2.9585\n",
      "[INFO] Training model: epoch 14 - 250/20505 samples\n",
      "Train on 2439 samples, validate on 682 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 1.0797 - val_loss: 2.9356\n",
      "[INFO] Training model: epoch 14 - 500/20505 samples\n",
      "Train on 2487 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 23s 9ms/step - loss: 1.1280 - val_loss: 2.9764\n",
      "[INFO] Training model: epoch 14 - 750/20505 samples\n",
      "Train on 2464 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.1282 - val_loss: 2.5604\n",
      "[INFO] Training model: epoch 14 - 1000/20505 samples\n",
      "Train on 2524 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0790 - val_loss: 2.3977\n",
      "[INFO] Training model: epoch 14 - 1250/20505 samples\n",
      "Train on 2354 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 22s 9ms/step - loss: 1.0573 - val_loss: 2.9022\n",
      "[INFO] Training model: epoch 14 - 1500/20505 samples\n",
      "Train on 2432 samples, validate on 579 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.0340 - val_loss: 2.6100\n",
      "[INFO] Training model: epoch 14 - 1750/20505 samples\n",
      "Train on 2458 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.0817 - val_loss: 2.7535\n",
      "[INFO] Training model: epoch 14 - 2000/20505 samples\n",
      "Train on 2447 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.1494 - val_loss: 2.8183\n",
      "[INFO] Training model: epoch 14 - 2250/20505 samples\n",
      "Train on 2446 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 1.1104 - val_loss: 2.2876\n",
      "[INFO] Training model: epoch 14 - 2500/20505 samples\n",
      "Train on 2467 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.1198 - val_loss: 2.5077\n",
      "[INFO] Training model: epoch 14 - 2750/20505 samples\n",
      "Train on 2475 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 23s 9ms/step - loss: 1.1595 - val_loss: 2.2208\n",
      "[INFO] Training model: epoch 14 - 3000/20505 samples\n",
      "Train on 2364 samples, validate on 568 samples\n",
      "Epoch 1/1\n",
      "2364/2364 [==============================] - 20s 9ms/step - loss: 1.1147 - val_loss: 2.5708\n",
      "[INFO] Training model: epoch 14 - 3250/20505 samples\n",
      "Train on 2526 samples, validate on 680 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 1.1760 - val_loss: 2.7828\n",
      "[INFO] Training model: epoch 14 - 3500/20505 samples\n",
      "Train on 2371 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2371/2371 [==============================] - 22s 9ms/step - loss: 1.1518 - val_loss: 2.5813\n",
      "[INFO] Training model: epoch 14 - 3750/20505 samples\n",
      "Train on 2500 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.0834 - val_loss: 2.7539\n",
      "[INFO] Training model: epoch 14 - 4000/20505 samples\n",
      "Train on 2515 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 24s 9ms/step - loss: 1.1497 - val_loss: 2.8131\n",
      "[INFO] Training model: epoch 14 - 4250/20505 samples\n",
      "Train on 2435 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.1599 - val_loss: 2.7319\n",
      "[INFO] Training model: epoch 14 - 4500/20505 samples\n",
      "Train on 2432 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.1219 - val_loss: 2.3819\n",
      "[INFO] Training model: epoch 14 - 4750/20505 samples\n",
      "Train on 2403 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 21s 9ms/step - loss: 1.1484 - val_loss: 2.8080\n",
      "[INFO] Training model: epoch 14 - 5000/20505 samples\n",
      "Train on 2420 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 23s 9ms/step - loss: 1.1608 - val_loss: 2.6976\n",
      "[INFO] Training model: epoch 14 - 5250/20505 samples\n",
      "Train on 2435 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 23s 9ms/step - loss: 1.1181 - val_loss: 2.5411\n",
      "[INFO] Training model: epoch 14 - 5500/20505 samples\n",
      "Train on 2435 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 22s 9ms/step - loss: 1.2306 - val_loss: 2.9144\n",
      "[INFO] Training model: epoch 14 - 5750/20505 samples\n",
      "Train on 2462 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 9ms/step - loss: 1.1817 - val_loss: 2.4831\n",
      "[INFO] Training model: epoch 14 - 6000/20505 samples\n",
      "Train on 2541 samples, validate on 611 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2541/2541 [==============================] - 23s 9ms/step - loss: 1.0866 - val_loss: 2.6962\n",
      "[INFO] Training model: epoch 14 - 6250/20505 samples\n",
      "Train on 2369 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2369/2369 [==============================] - 22s 9ms/step - loss: 1.1899 - val_loss: 2.6757\n",
      "[INFO] Training model: epoch 14 - 6500/20505 samples\n",
      "Train on 2423 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 1.1987 - val_loss: 2.8957\n",
      "[INFO] Training model: epoch 14 - 6750/20505 samples\n",
      "Train on 2459 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.1641 - val_loss: 2.5555\n",
      "[INFO] Training model: epoch 14 - 7000/20505 samples\n",
      "Train on 2442 samples, validate on 507 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 22s 9ms/step - loss: 1.1629 - val_loss: 2.6858\n",
      "[INFO] Training model: epoch 14 - 7250/20505 samples\n",
      "Train on 2361 samples, validate on 540 samples\n",
      "Epoch 1/1\n",
      "2361/2361 [==============================] - 23s 10ms/step - loss: 1.1715 - val_loss: 2.7752\n",
      "[INFO] Training model: epoch 14 - 7500/20505 samples\n",
      "Train on 2357 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 22s 9ms/step - loss: 1.1519 - val_loss: 2.6262\n",
      "[INFO] Training model: epoch 14 - 7750/20505 samples\n",
      "Train on 2402 samples, validate on 727 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1504 - val_loss: 2.7175\n",
      "[INFO] Training model: epoch 14 - 8000/20505 samples\n",
      "Train on 2466 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 21s 9ms/step - loss: 1.1636 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 14 - 8250/20505 samples\n",
      "Train on 2430 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.1933 - val_loss: 2.4823\n",
      "[INFO] Training model: epoch 14 - 8500/20505 samples\n",
      "Train on 2452 samples, validate on 692 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1515 - val_loss: 2.3191\n",
      "[INFO] Training model: epoch 14 - 8750/20505 samples\n",
      "Train on 2615 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2615/2615 [==============================] - 24s 9ms/step - loss: 1.2396 - val_loss: 2.5740\n",
      "[INFO] Training model: epoch 14 - 9000/20505 samples\n",
      "Train on 2465 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 23s 9ms/step - loss: 1.1939 - val_loss: 2.4041\n",
      "[INFO] Training model: epoch 14 - 9250/20505 samples\n",
      "Train on 2438 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2438/2438 [==============================] - 22s 9ms/step - loss: 1.1828 - val_loss: 2.9110\n",
      "[INFO] Training model: epoch 14 - 9500/20505 samples\n",
      "Train on 2466 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.1729 - val_loss: 2.5145\n",
      "[INFO] Training model: epoch 14 - 9750/20505 samples\n",
      "Train on 2446 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.1608 - val_loss: 2.2801\n",
      "[INFO] Training model: epoch 14 - 10000/20505 samples\n",
      "Train on 2428 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 1.1831 - val_loss: 2.5697\n",
      "[INFO] Training model: epoch 14 - 10250/20505 samples\n",
      "Train on 2513 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 24s 9ms/step - loss: 1.2424 - val_loss: 2.6369\n",
      "[INFO] Training model: epoch 14 - 10500/20505 samples\n",
      "Train on 2469 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.1988 - val_loss: 2.6358\n",
      "[INFO] Training model: epoch 14 - 10750/20505 samples\n",
      "Train on 2441 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.2172 - val_loss: 3.0045\n",
      "[INFO] Training model: epoch 14 - 11000/20505 samples\n",
      "Train on 2503 samples, validate on 559 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 1.1385 - val_loss: 2.5518\n",
      "[INFO] Training model: epoch 14 - 11250/20505 samples\n",
      "Train on 2521 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2521/2521 [==============================] - 24s 9ms/step - loss: 1.2008 - val_loss: 2.4104\n",
      "[INFO] Training model: epoch 14 - 11500/20505 samples\n",
      "Train on 2558 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 23s 9ms/step - loss: 1.1940 - val_loss: 2.9328\n",
      "[INFO] Training model: epoch 14 - 11750/20505 samples\n",
      "Train on 2514 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2514/2514 [==============================] - 22s 9ms/step - loss: 1.2445 - val_loss: 2.5280\n",
      "[INFO] Training model: epoch 14 - 12000/20505 samples\n",
      "Train on 2418 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.1794 - val_loss: 2.3512\n",
      "[INFO] Training model: epoch 14 - 12250/20505 samples\n",
      "Train on 2547 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 1.1824 - val_loss: 2.5754\n",
      "[INFO] Training model: epoch 14 - 12500/20505 samples\n",
      "Train on 2444 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 22s 9ms/step - loss: 1.1919 - val_loss: 2.6997\n",
      "[INFO] Training model: epoch 14 - 12750/20505 samples\n",
      "Train on 2495 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2495/2495 [==============================] - 22s 9ms/step - loss: 1.2771 - val_loss: 2.4880\n",
      "[INFO] Training model: epoch 14 - 13000/20505 samples\n",
      "Train on 2416 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 23s 9ms/step - loss: 1.2313 - val_loss: 2.4450\n",
      "[INFO] Training model: epoch 14 - 13250/20505 samples\n",
      "Train on 2518 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.2359 - val_loss: 2.3428\n",
      "[INFO] Training model: epoch 14 - 13500/20505 samples\n",
      "Train on 2459 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.2364 - val_loss: 2.5417\n",
      "[INFO] Training model: epoch 14 - 13750/20505 samples\n",
      "Train on 2413 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 1.3127 - val_loss: 2.6574\n",
      "[INFO] Training model: epoch 14 - 14000/20505 samples\n",
      "Train on 2481 samples, validate on 710 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 22s 9ms/step - loss: 1.1633 - val_loss: 2.6111\n",
      "[INFO] Training model: epoch 14 - 14250/20505 samples\n",
      "Train on 2467 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 1.2198 - val_loss: 2.3812\n",
      "[INFO] Training model: epoch 14 - 14500/20505 samples\n",
      "Train on 2405 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.2593 - val_loss: 2.5718\n",
      "[INFO] Training model: epoch 14 - 14750/20505 samples\n",
      "Train on 2411 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.2435 - val_loss: 2.4176\n",
      "[INFO] Training model: epoch 14 - 15000/20505 samples\n",
      "Train on 2432 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 22s 9ms/step - loss: 1.2552 - val_loss: 2.5886\n",
      "[INFO] Training model: epoch 14 - 15250/20505 samples\n",
      "Train on 2459 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 1.2295 - val_loss: 2.4746\n",
      "[INFO] Training model: epoch 14 - 15500/20505 samples\n",
      "Train on 2424 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2424/2424 [==============================] - 22s 9ms/step - loss: 1.1866 - val_loss: 2.8634\n",
      "[INFO] Training model: epoch 14 - 15750/20505 samples\n",
      "Train on 2493 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2493/2493 [==============================] - 23s 9ms/step - loss: 1.2274 - val_loss: 2.9647\n",
      "[INFO] Training model: epoch 14 - 16000/20505 samples\n",
      "Train on 2401 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2048 - val_loss: 2.6362\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 14 - 16250/20505 samples\n",
      "Train on 2473 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2532 - val_loss: 2.3116\n",
      "[INFO] Training model: epoch 14 - 16500/20505 samples\n",
      "Train on 2499 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1839 - val_loss: 2.7059\n",
      "[INFO] Training model: epoch 14 - 16750/20505 samples\n",
      "Train on 2484 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.2256 - val_loss: 2.5901\n",
      "[INFO] Training model: epoch 14 - 17000/20505 samples\n",
      "Train on 2441 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.2346 - val_loss: 2.6685\n",
      "[INFO] Training model: epoch 14 - 17250/20505 samples\n",
      "Train on 2401 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 22s 9ms/step - loss: 1.2021 - val_loss: 2.7811\n",
      "[INFO] Training model: epoch 14 - 17500/20505 samples\n",
      "Train on 2547 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 23s 9ms/step - loss: 1.2543 - val_loss: 2.5712\n",
      "[INFO] Training model: epoch 14 - 17750/20505 samples\n",
      "Train on 2557 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 23s 9ms/step - loss: 1.2095 - val_loss: 2.7230\n",
      "[INFO] Training model: epoch 14 - 18000/20505 samples\n",
      "Train on 2507 samples, validate on 676 samples\n",
      "Epoch 1/1\n",
      "2507/2507 [==============================] - 24s 9ms/step - loss: 1.1946 - val_loss: 2.4608\n",
      "[INFO] Training model: epoch 14 - 18250/20505 samples\n",
      "Train on 2468 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.2261 - val_loss: 2.4564\n",
      "[INFO] Training model: epoch 14 - 18500/20505 samples\n",
      "Train on 2405 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 22s 9ms/step - loss: 1.2453 - val_loss: 2.6626\n",
      "[INFO] Training model: epoch 14 - 18750/20505 samples\n",
      "Train on 2539 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 9ms/step - loss: 1.2307 - val_loss: 2.6883\n",
      "[INFO] Training model: epoch 14 - 19000/20505 samples\n",
      "Train on 2473 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.2462 - val_loss: 2.6410\n",
      "[INFO] Training model: epoch 14 - 19250/20505 samples\n",
      "Train on 2309 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2309/2309 [==============================] - 21s 9ms/step - loss: 1.2278 - val_loss: 2.6431\n",
      "[INFO] Training model: epoch 14 - 19500/20505 samples\n",
      "Train on 2489 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 21s 9ms/step - loss: 1.2471 - val_loss: 2.4865\n",
      "[INFO] Training model: epoch 14 - 19750/20505 samples\n",
      "Train on 2491 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 23s 9ms/step - loss: 1.2789 - val_loss: 2.6601\n",
      "[INFO] Training model: epoch 14 - 20000/20505 samples\n",
      "Train on 2392 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 23s 9ms/step - loss: 1.2030 - val_loss: 2.5679\n",
      "[INFO] Training model: epoch 14 - 20250/20505 samples\n",
      "Train on 2407 samples, validate on 656 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 10ms/step - loss: 1.3407 - val_loss: 2.8099\n",
      "[INFO] Training model: epoch 14 - 20500/20505 samples\n",
      "Train on 78 samples, validate on 7 samples\n",
      "Epoch 1/1\n",
      "78/78 [==============================] - 1s 10ms/step - loss: 1.2407 - val_loss: 3.1446\n",
      "[INFO] Training model: epoch 15 - 0/20505 samples\n",
      "Train on 2331 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2331/2331 [==============================] - 22s 9ms/step - loss: 1.1331 - val_loss: 2.9295\n",
      "[INFO] Training model: epoch 15 - 250/20505 samples\n",
      "Train on 2518 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 24s 9ms/step - loss: 1.0381 - val_loss: 2.6519\n",
      "[INFO] Training model: epoch 15 - 500/20505 samples\n",
      "Train on 2354 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 22s 9ms/step - loss: 1.0688 - val_loss: 3.0876\n",
      "[INFO] Training model: epoch 15 - 750/20505 samples\n",
      "Train on 2499 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1073 - val_loss: 2.5800\n",
      "[INFO] Training model: epoch 15 - 1000/20505 samples\n",
      "Train on 2429 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.0695 - val_loss: 2.8064\n",
      "[INFO] Training model: epoch 15 - 1250/20505 samples\n",
      "Train on 2470 samples, validate on 681 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 24s 10ms/step - loss: 1.0238 - val_loss: 2.6690\n",
      "[INFO] Training model: epoch 15 - 1500/20505 samples\n",
      "Train on 2441 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.0588 - val_loss: 2.7763\n",
      "[INFO] Training model: epoch 15 - 1750/20505 samples\n",
      "Train on 2399 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 23s 10ms/step - loss: 1.0339 - val_loss: 2.5999\n",
      "[INFO] Training model: epoch 15 - 2000/20505 samples\n",
      "Train on 2315 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2315/2315 [==============================] - 22s 9ms/step - loss: 1.0842 - val_loss: 2.6414\n",
      "[INFO] Training model: epoch 15 - 2250/20505 samples\n",
      "Train on 2450 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 23s 9ms/step - loss: 1.1063 - val_loss: 2.8094\n",
      "[INFO] Training model: epoch 15 - 2500/20505 samples\n",
      "Train on 2453 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 1.0391 - val_loss: 2.5060\n",
      "[INFO] Training model: epoch 15 - 2750/20505 samples\n",
      "Train on 2520 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 23s 9ms/step - loss: 1.0579 - val_loss: 2.4260\n",
      "[INFO] Training model: epoch 15 - 3000/20505 samples\n",
      "Train on 2529 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.1151 - val_loss: 2.5902\n",
      "[INFO] Training model: epoch 15 - 3250/20505 samples\n",
      "Train on 2458 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.0946 - val_loss: 2.9541\n",
      "[INFO] Training model: epoch 15 - 3500/20505 samples\n",
      "Train on 2388 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 9ms/step - loss: 1.0853 - val_loss: 2.8799\n",
      "[INFO] Training model: epoch 15 - 3750/20505 samples\n",
      "Train on 2412 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 22s 9ms/step - loss: 1.0967 - val_loss: 2.3592\n",
      "[INFO] Training model: epoch 15 - 4000/20505 samples\n",
      "Train on 2415 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2415/2415 [==============================] - 22s 9ms/step - loss: 1.1337 - val_loss: 2.5667\n",
      "[INFO] Training model: epoch 15 - 4250/20505 samples\n",
      "Train on 2379 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2379/2379 [==============================] - 22s 9ms/step - loss: 1.0970 - val_loss: 2.4808\n",
      "[INFO] Training model: epoch 15 - 4500/20505 samples\n",
      "Train on 2457 samples, validate on 561 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 22s 9ms/step - loss: 1.0490 - val_loss: 2.7659\n",
      "[INFO] Training model: epoch 15 - 4750/20505 samples\n",
      "Train on 2408 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.0856 - val_loss: 2.5832\n",
      "[INFO] Training model: epoch 15 - 5000/20505 samples\n",
      "Train on 2470 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.0941 - val_loss: 2.7505\n",
      "[INFO] Training model: epoch 15 - 5250/20505 samples\n",
      "Train on 2534 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2534/2534 [==============================] - 23s 9ms/step - loss: 1.1479 - val_loss: 2.7339\n",
      "[INFO] Training model: epoch 15 - 5500/20505 samples\n",
      "Train on 2392 samples, validate on 639 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2392/2392 [==============================] - 21s 9ms/step - loss: 1.1235 - val_loss: 2.4902\n",
      "[INFO] Training model: epoch 15 - 5750/20505 samples\n",
      "Train on 2576 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 1.0981 - val_loss: 2.7348\n",
      "[INFO] Training model: epoch 15 - 6000/20505 samples\n",
      "Train on 2441 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 9ms/step - loss: 1.1493 - val_loss: 2.9630\n",
      "[INFO] Training model: epoch 15 - 6250/20505 samples\n",
      "Train on 2442 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 21s 9ms/step - loss: 1.0885 - val_loss: 3.0562\n",
      "[INFO] Training model: epoch 15 - 6500/20505 samples\n",
      "Train on 2340 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 22s 10ms/step - loss: 1.1056 - val_loss: 2.3974\n",
      "[INFO] Training model: epoch 15 - 6750/20505 samples\n",
      "Train on 2449 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 22s 9ms/step - loss: 1.0739 - val_loss: 2.5867\n",
      "[INFO] Training model: epoch 15 - 7000/20505 samples\n",
      "Train on 2472 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.1090 - val_loss: 2.5161\n",
      "[INFO] Training model: epoch 15 - 7250/20505 samples\n",
      "Train on 2402 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1223 - val_loss: 2.4847\n",
      "[INFO] Training model: epoch 15 - 7500/20505 samples\n",
      "Train on 2451 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 24s 10ms/step - loss: 1.1270 - val_loss: 2.4395\n",
      "[INFO] Training model: epoch 15 - 7750/20505 samples\n",
      "Train on 2434 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 25s 10ms/step - loss: 1.0877 - val_loss: 2.8560\n",
      "[INFO] Training model: epoch 15 - 8000/20505 samples\n",
      "Train on 2471 samples, validate on 676 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.0647 - val_loss: 2.5131\n",
      "[INFO] Training model: epoch 15 - 8250/20505 samples\n",
      "Train on 2541 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 10ms/step - loss: 1.1874 - val_loss: 2.7540\n",
      "[INFO] Training model: epoch 15 - 8500/20505 samples\n",
      "Train on 2381 samples, validate on 551 samples\n",
      "Epoch 1/1\n",
      "2381/2381 [==============================] - 23s 10ms/step - loss: 1.1156 - val_loss: 2.6978\n",
      "[INFO] Training model: epoch 15 - 8750/20505 samples\n",
      "Train on 2475 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.1583 - val_loss: 2.6210\n",
      "[INFO] Training model: epoch 15 - 9000/20505 samples\n",
      "Train on 2347 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2347/2347 [==============================] - 22s 10ms/step - loss: 1.1305 - val_loss: 2.4200\n",
      "[INFO] Training model: epoch 15 - 9250/20505 samples\n",
      "Train on 2501 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 24s 10ms/step - loss: 1.1533 - val_loss: 2.7463\n",
      "[INFO] Training model: epoch 15 - 9500/20505 samples\n",
      "Train on 2485 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 24s 10ms/step - loss: 1.1980 - val_loss: 2.6791\n",
      "[INFO] Training model: epoch 15 - 9750/20505 samples\n",
      "Train on 2389 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 23s 9ms/step - loss: 1.1991 - val_loss: 2.7248\n",
      "[INFO] Training model: epoch 15 - 10000/20505 samples\n",
      "Train on 2374 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 1.1210 - val_loss: 2.6510\n",
      "[INFO] Training model: epoch 15 - 10250/20505 samples\n",
      "Train on 2558 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.2004 - val_loss: 2.6337\n",
      "[INFO] Training model: epoch 15 - 10500/20505 samples\n",
      "Train on 2413 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 1.0770 - val_loss: 2.6536\n",
      "[INFO] Training model: epoch 15 - 10750/20505 samples\n",
      "Train on 2475 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.1151 - val_loss: 2.7780\n",
      "[INFO] Training model: epoch 15 - 11000/20505 samples\n",
      "Train on 2509 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2509/2509 [==============================] - 24s 9ms/step - loss: 1.1291 - val_loss: 2.7472\n",
      "[INFO] Training model: epoch 15 - 11250/20505 samples\n",
      "Train on 2432 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 9ms/step - loss: 1.1479 - val_loss: 2.5829\n",
      "[INFO] Training model: epoch 15 - 11500/20505 samples\n",
      "Train on 2397 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 10ms/step - loss: 1.1320 - val_loss: 2.9159\n",
      "[INFO] Training model: epoch 15 - 11750/20505 samples\n",
      "Train on 2360 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2360/2360 [==============================] - 23s 10ms/step - loss: 1.1171 - val_loss: 2.5413\n",
      "[INFO] Training model: epoch 15 - 12000/20505 samples\n",
      "Train on 2526 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 23s 9ms/step - loss: 1.1114 - val_loss: 2.4176\n",
      "[INFO] Training model: epoch 15 - 12250/20505 samples\n",
      "Train on 2404 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2404/2404 [==============================] - 24s 10ms/step - loss: 1.1859 - val_loss: 2.7987\n",
      "[INFO] Training model: epoch 15 - 12500/20505 samples\n",
      "Train on 2406 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 9ms/step - loss: 1.2046 - val_loss: 2.5153\n",
      "[INFO] Training model: epoch 15 - 12750/20505 samples\n",
      "Train on 2506 samples, validate on 552 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1929 - val_loss: 2.6046\n",
      "[INFO] Training model: epoch 15 - 13000/20505 samples\n",
      "Train on 2498 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 9ms/step - loss: 1.1683 - val_loss: 2.6654\n",
      "[INFO] Training model: epoch 15 - 13250/20505 samples\n",
      "Train on 2511 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 22s 9ms/step - loss: 1.2345 - val_loss: 2.9101\n",
      "[INFO] Training model: epoch 15 - 13500/20505 samples\n",
      "Train on 2437 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.1747 - val_loss: 2.5648\n",
      "[INFO] Training model: epoch 15 - 13750/20505 samples\n",
      "Train on 2418 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 24s 10ms/step - loss: 1.1908 - val_loss: 2.8365\n",
      "[INFO] Training model: epoch 15 - 14000/20505 samples\n",
      "Train on 2450 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2450/2450 [==============================] - 24s 10ms/step - loss: 1.1300 - val_loss: 2.5605\n",
      "[INFO] Training model: epoch 15 - 14250/20505 samples\n",
      "Train on 2506 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 9ms/step - loss: 1.1920 - val_loss: 2.5458\n",
      "[INFO] Training model: epoch 15 - 14500/20505 samples\n",
      "Train on 2517 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 24s 9ms/step - loss: 1.1624 - val_loss: 2.8510\n",
      "[INFO] Training model: epoch 15 - 14750/20505 samples\n",
      "Train on 2524 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 1.2065 - val_loss: 2.7859\n",
      "[INFO] Training model: epoch 15 - 15000/20505 samples\n",
      "Train on 2455 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 10ms/step - loss: 1.2362 - val_loss: 2.4933\n",
      "[INFO] Training model: epoch 15 - 15250/20505 samples\n",
      "Train on 2547 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 25s 10ms/step - loss: 1.2009 - val_loss: 2.8018\n",
      "[INFO] Training model: epoch 15 - 15500/20505 samples\n",
      "Train on 2492 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.2984 - val_loss: 2.5872\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 15 - 15750/20505 samples\n",
      "Train on 2458 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.2579 - val_loss: 2.7299\n",
      "[INFO] Training model: epoch 15 - 16000/20505 samples\n",
      "Train on 2423 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.1368 - val_loss: 2.4889\n",
      "[INFO] Training model: epoch 15 - 16250/20505 samples\n",
      "Train on 2481 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 24s 10ms/step - loss: 1.2146 - val_loss: 2.9762\n",
      "[INFO] Training model: epoch 15 - 16500/20505 samples\n",
      "Train on 2448 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 23s 9ms/step - loss: 1.2419 - val_loss: 2.7460\n",
      "[INFO] Training model: epoch 15 - 16750/20505 samples\n",
      "Train on 2537 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2537/2537 [==============================] - 24s 10ms/step - loss: 1.2492 - val_loss: 2.7059\n",
      "[INFO] Training model: epoch 15 - 17000/20505 samples\n",
      "Train on 2488 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2488/2488 [==============================] - 24s 10ms/step - loss: 1.2518 - val_loss: 2.5754\n",
      "[INFO] Training model: epoch 15 - 17250/20505 samples\n",
      "Train on 2478 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 24s 10ms/step - loss: 1.2247 - val_loss: 2.6553\n",
      "[INFO] Training model: epoch 15 - 17500/20505 samples\n",
      "Train on 2498 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.1885 - val_loss: 2.7258\n",
      "[INFO] Training model: epoch 15 - 17750/20505 samples\n",
      "Train on 2374 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 23s 10ms/step - loss: 1.1766 - val_loss: 2.5925\n",
      "[INFO] Training model: epoch 15 - 18000/20505 samples\n",
      "Train on 2559 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2559/2559 [==============================] - 24s 9ms/step - loss: 1.2059 - val_loss: 2.7214\n",
      "[INFO] Training model: epoch 15 - 18250/20505 samples\n",
      "Train on 2558 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2558/2558 [==============================] - 24s 9ms/step - loss: 1.3310 - val_loss: 2.3532\n",
      "[INFO] Training model: epoch 15 - 18500/20505 samples\n",
      "Train on 2463 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 24s 10ms/step - loss: 1.1660 - val_loss: 2.5401\n",
      "[INFO] Training model: epoch 15 - 18750/20505 samples\n",
      "Train on 2410 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 10ms/step - loss: 1.2774 - val_loss: 2.6960\n",
      "[INFO] Training model: epoch 15 - 19000/20505 samples\n",
      "Train on 2550 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 24s 9ms/step - loss: 1.2430 - val_loss: 2.8580\n",
      "[INFO] Training model: epoch 15 - 19250/20505 samples\n",
      "Train on 2496 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.2518 - val_loss: 2.7315\n",
      "[INFO] Training model: epoch 15 - 19500/20505 samples\n",
      "Train on 2498 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 10ms/step - loss: 1.1718 - val_loss: 2.6074\n",
      "[INFO] Training model: epoch 15 - 19750/20505 samples\n",
      "Train on 2378 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 23s 10ms/step - loss: 1.2462 - val_loss: 2.4960\n",
      "[INFO] Training model: epoch 15 - 20000/20505 samples\n",
      "Train on 2510 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 24s 9ms/step - loss: 1.3002 - val_loss: 2.9654\n",
      "[INFO] Training model: epoch 15 - 20250/20505 samples\n",
      "Train on 2469 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.2027 - val_loss: 2.4907\n",
      "[INFO] Training model: epoch 15 - 20500/20505 samples\n",
      "Train on 47 samples, validate on 14 samples\n",
      "Epoch 1/1\n",
      "47/47 [==============================] - 1s 11ms/step - loss: 1.5079 - val_loss: 1.6176\n",
      "[INFO] Training model: epoch 16 - 0/20505 samples\n",
      "Train on 2449 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 23s 9ms/step - loss: 0.9983 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 16 - 250/20505 samples\n",
      "Train on 2407 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 9ms/step - loss: 0.9501 - val_loss: 2.9764\n",
      "[INFO] Training model: epoch 16 - 500/20505 samples\n",
      "Train on 2491 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 24s 10ms/step - loss: 1.0341 - val_loss: 2.7407\n",
      "[INFO] Training model: epoch 16 - 750/20505 samples\n",
      "Train on 2516 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 24s 9ms/step - loss: 1.0242 - val_loss: 2.4131\n",
      "[INFO] Training model: epoch 16 - 1000/20505 samples\n",
      "Train on 2453 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 24s 10ms/step - loss: 1.0159 - val_loss: 2.6177\n",
      "[INFO] Training model: epoch 16 - 1250/20505 samples\n",
      "Train on 2465 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2465/2465 [==============================] - 24s 10ms/step - loss: 1.0454 - val_loss: 2.5644\n",
      "[INFO] Training model: epoch 16 - 1500/20505 samples\n",
      "Train on 2469 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 1.0215 - val_loss: 2.7709\n",
      "[INFO] Training model: epoch 16 - 1750/20505 samples\n",
      "Train on 2444 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 10ms/step - loss: 1.0894 - val_loss: 2.7102\n",
      "[INFO] Training model: epoch 16 - 2000/20505 samples\n",
      "Train on 2484 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 1.0157 - val_loss: 2.8553\n",
      "[INFO] Training model: epoch 16 - 2250/20505 samples\n",
      "Train on 2378 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2378/2378 [==============================] - 22s 9ms/step - loss: 0.9970 - val_loss: 2.8719\n",
      "[INFO] Training model: epoch 16 - 2500/20505 samples\n",
      "Train on 2390 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 23s 10ms/step - loss: 1.0443 - val_loss: 2.9657\n",
      "[INFO] Training model: epoch 16 - 2750/20505 samples\n",
      "Train on 2489 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 24s 10ms/step - loss: 1.0189 - val_loss: 2.6347\n",
      "[INFO] Training model: epoch 16 - 3000/20505 samples\n",
      "Train on 2477 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 24s 10ms/step - loss: 1.0143 - val_loss: 2.8704\n",
      "[INFO] Training model: epoch 16 - 3250/20505 samples\n",
      "Train on 2469 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.0132 - val_loss: 2.8750\n",
      "[INFO] Training model: epoch 16 - 3500/20505 samples\n",
      "Train on 2492 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.0481 - val_loss: 2.6044\n",
      "[INFO] Training model: epoch 16 - 3750/20505 samples\n",
      "Train on 2395 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 23s 10ms/step - loss: 1.1016 - val_loss: 2.9041\n",
      "[INFO] Training model: epoch 16 - 4000/20505 samples\n",
      "Train on 2500 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 9ms/step - loss: 1.0904 - val_loss: 2.6777\n",
      "[INFO] Training model: epoch 16 - 4250/20505 samples\n",
      "Train on 2440 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 24s 10ms/step - loss: 1.0469 - val_loss: 2.9893\n",
      "[INFO] Training model: epoch 16 - 4500/20505 samples\n",
      "Train on 2531 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 10ms/step - loss: 1.1035 - val_loss: 2.8099\n",
      "[INFO] Training model: epoch 16 - 4750/20505 samples\n",
      "Train on 2461 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 1.0165 - val_loss: 2.7785\n",
      "[INFO] Training model: epoch 16 - 5000/20505 samples\n",
      "Train on 2500 samples, validate on 560 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2500/2500 [==============================] - 23s 9ms/step - loss: 1.0688 - val_loss: 2.6050\n",
      "[INFO] Training model: epoch 16 - 5250/20505 samples\n",
      "Train on 2428 samples, validate on 696 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 24s 10ms/step - loss: 1.0508 - val_loss: 2.8019\n",
      "[INFO] Training model: epoch 16 - 5500/20505 samples\n",
      "Train on 2388 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 22s 9ms/step - loss: 1.0622 - val_loss: 2.8949\n",
      "[INFO] Training model: epoch 16 - 5750/20505 samples\n",
      "Train on 2484 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 24s 10ms/step - loss: 1.1655 - val_loss: 2.7134\n",
      "[INFO] Training model: epoch 16 - 6000/20505 samples\n",
      "Train on 2473 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.1333 - val_loss: 2.8752\n",
      "[INFO] Training model: epoch 16 - 6250/20505 samples\n",
      "Train on 2354 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2354/2354 [==============================] - 23s 10ms/step - loss: 1.0938 - val_loss: 2.5080\n",
      "[INFO] Training model: epoch 16 - 6500/20505 samples\n",
      "Train on 2485 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 24s 10ms/step - loss: 1.0767 - val_loss: 2.4303\n",
      "[INFO] Training model: epoch 16 - 6750/20505 samples\n",
      "Train on 2485 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.1094 - val_loss: 2.6812\n",
      "[INFO] Training model: epoch 16 - 7000/20505 samples\n",
      "Train on 2436 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 10ms/step - loss: 1.0820 - val_loss: 2.6339\n",
      "[INFO] Training model: epoch 16 - 7250/20505 samples\n",
      "Train on 2337 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2337/2337 [==============================] - 22s 9ms/step - loss: 1.0910 - val_loss: 2.4352\n",
      "[INFO] Training model: epoch 16 - 7500/20505 samples\n",
      "Train on 2474 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.1137 - val_loss: 2.7438\n",
      "[INFO] Training model: epoch 16 - 7750/20505 samples\n",
      "Train on 2478 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 1.1322 - val_loss: 2.4278\n",
      "[INFO] Training model: epoch 16 - 8000/20505 samples\n",
      "Train on 2502 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.0313 - val_loss: 2.5378\n",
      "[INFO] Training model: epoch 16 - 8250/20505 samples\n",
      "Train on 2386 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.1094 - val_loss: 2.4691\n",
      "[INFO] Training model: epoch 16 - 8500/20505 samples\n",
      "Train on 2422 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 1.1337 - val_loss: 2.7323\n",
      "[INFO] Training model: epoch 16 - 8750/20505 samples\n",
      "Train on 2406 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 22s 9ms/step - loss: 1.1031 - val_loss: 2.5611\n",
      "[INFO] Training model: epoch 16 - 9000/20505 samples\n",
      "Train on 2482 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.0771 - val_loss: 2.7091\n",
      "[INFO] Training model: epoch 16 - 9250/20505 samples\n",
      "Train on 2451 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 24s 10ms/step - loss: 1.0644 - val_loss: 2.7200\n",
      "[INFO] Training model: epoch 16 - 9500/20505 samples\n",
      "Train on 2513 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.0869 - val_loss: 2.7013\n",
      "[INFO] Training model: epoch 16 - 9750/20505 samples\n",
      "Train on 2472 samples, validate on 591 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 23s 9ms/step - loss: 1.0944 - val_loss: 2.6165\n",
      "[INFO] Training model: epoch 16 - 10000/20505 samples\n",
      "Train on 2452 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.1097 - val_loss: 2.7837\n",
      "[INFO] Training model: epoch 16 - 10250/20505 samples\n",
      "Train on 2480 samples, validate on 584 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.0722 - val_loss: 2.9084\n",
      "[INFO] Training model: epoch 16 - 10500/20505 samples\n",
      "Train on 2503 samples, validate on 613 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 23s 9ms/step - loss: 1.1793 - val_loss: 2.6631\n",
      "[INFO] Training model: epoch 16 - 10750/20505 samples\n",
      "Train on 2394 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1578 - val_loss: 2.6566\n",
      "[INFO] Training model: epoch 16 - 11000/20505 samples\n",
      "Train on 2426 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 1.1017 - val_loss: 2.7182\n",
      "[INFO] Training model: epoch 16 - 11250/20505 samples\n",
      "Train on 2446 samples, validate on 543 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 22s 9ms/step - loss: 1.1649 - val_loss: 2.4252\n",
      "[INFO] Training model: epoch 16 - 11500/20505 samples\n",
      "Train on 2590 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2590/2590 [==============================] - 22s 9ms/step - loss: 1.0900 - val_loss: 2.6227\n",
      "[INFO] Training model: epoch 16 - 11750/20505 samples\n",
      "Train on 2489 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.1183 - val_loss: 2.6726\n",
      "[INFO] Training model: epoch 16 - 12000/20505 samples\n",
      "Train on 2411 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 1.1546 - val_loss: 2.8114\n",
      "[INFO] Training model: epoch 16 - 12250/20505 samples\n",
      "Train on 2481 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2481/2481 [==============================] - 23s 9ms/step - loss: 1.1160 - val_loss: 2.8245\n",
      "[INFO] Training model: epoch 16 - 12500/20505 samples\n",
      "Train on 2421 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 1.1357 - val_loss: 2.8259\n",
      "[INFO] Training model: epoch 16 - 12750/20505 samples\n",
      "Train on 2533 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 1.1177 - val_loss: 2.6389\n",
      "[INFO] Training model: epoch 16 - 13000/20505 samples\n",
      "Train on 2411 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 21s 9ms/step - loss: 1.1377 - val_loss: 2.8588\n",
      "[INFO] Training model: epoch 16 - 13250/20505 samples\n",
      "Train on 2409 samples, validate on 658 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 1.2043 - val_loss: 2.5796\n",
      "[INFO] Training model: epoch 16 - 13500/20505 samples\n",
      "Train on 2455 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2455/2455 [==============================] - 23s 9ms/step - loss: 1.1689 - val_loss: 2.6230\n",
      "[INFO] Training model: epoch 16 - 13750/20505 samples\n",
      "Train on 2419 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 22s 9ms/step - loss: 1.1453 - val_loss: 2.9169\n",
      "[INFO] Training model: epoch 16 - 14000/20505 samples\n",
      "Train on 2396 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 22s 9ms/step - loss: 1.1187 - val_loss: 2.7596\n",
      "[INFO] Training model: epoch 16 - 14250/20505 samples\n",
      "Train on 2516 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2516/2516 [==============================] - 23s 9ms/step - loss: 1.1450 - val_loss: 2.8539\n",
      "[INFO] Training model: epoch 16 - 14500/20505 samples\n",
      "Train on 2349 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2349/2349 [==============================] - 22s 10ms/step - loss: 1.1809 - val_loss: 2.9646\n",
      "[INFO] Training model: epoch 16 - 14750/20505 samples\n",
      "Train on 2505 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 22s 9ms/step - loss: 1.0939 - val_loss: 2.5317\n",
      "[INFO] Training model: epoch 16 - 15000/20505 samples\n",
      "Train on 2480 samples, validate on 688 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 1.1239 - val_loss: 2.7220\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 16 - 15250/20505 samples\n",
      "Train on 2376 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 22s 9ms/step - loss: 1.1672 - val_loss: 2.8551\n",
      "[INFO] Training model: epoch 16 - 15500/20505 samples\n",
      "Train on 2557 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2557/2557 [==============================] - 23s 9ms/step - loss: 1.1876 - val_loss: 2.6456\n",
      "[INFO] Training model: epoch 16 - 15750/20505 samples\n",
      "Train on 2380 samples, validate on 581 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.1035 - val_loss: 2.5155\n",
      "[INFO] Training model: epoch 16 - 16000/20505 samples\n",
      "Train on 2477 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 22s 9ms/step - loss: 1.0815 - val_loss: 2.6339\n",
      "[INFO] Training model: epoch 16 - 16250/20505 samples\n",
      "Train on 2518 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 22s 9ms/step - loss: 1.1643 - val_loss: 2.6151\n",
      "[INFO] Training model: epoch 16 - 16500/20505 samples\n",
      "Train on 2445 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 1.1738 - val_loss: 2.9454\n",
      "[INFO] Training model: epoch 16 - 16750/20505 samples\n",
      "Train on 2543 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2543/2543 [==============================] - 23s 9ms/step - loss: 1.2228 - val_loss: 2.6314\n",
      "[INFO] Training model: epoch 16 - 17000/20505 samples\n",
      "Train on 2429 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 23s 10ms/step - loss: 1.1839 - val_loss: 2.7489\n",
      "[INFO] Training model: epoch 16 - 17250/20505 samples\n",
      "Train on 2430 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.2367 - val_loss: 2.3456\n",
      "[INFO] Training model: epoch 16 - 17500/20505 samples\n",
      "Train on 2471 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 23s 9ms/step - loss: 1.1852 - val_loss: 2.7800\n",
      "[INFO] Training model: epoch 16 - 17750/20505 samples\n",
      "Train on 2414 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.1961 - val_loss: 2.4988\n",
      "[INFO] Training model: epoch 16 - 18000/20505 samples\n",
      "Train on 2416 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.1739 - val_loss: 2.8059\n",
      "[INFO] Training model: epoch 16 - 18250/20505 samples\n",
      "Train on 2524 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 22s 9ms/step - loss: 1.2073 - val_loss: 2.5295\n",
      "[INFO] Training model: epoch 16 - 18500/20505 samples\n",
      "Train on 2444 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2444/2444 [==============================] - 23s 9ms/step - loss: 1.2064 - val_loss: 2.5997\n",
      "[INFO] Training model: epoch 16 - 18750/20505 samples\n",
      "Train on 2388 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2388/2388 [==============================] - 23s 10ms/step - loss: 1.1778 - val_loss: 2.6540\n",
      "[INFO] Training model: epoch 16 - 19000/20505 samples\n",
      "Train on 2469 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.2310 - val_loss: 2.8563\n",
      "[INFO] Training model: epoch 16 - 19250/20505 samples\n",
      "Train on 2512 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 10ms/step - loss: 1.1143 - val_loss: 2.6969\n",
      "[INFO] Training model: epoch 16 - 19500/20505 samples\n",
      "Train on 2539 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 9ms/step - loss: 1.2172 - val_loss: 2.8458\n",
      "[INFO] Training model: epoch 16 - 19750/20505 samples\n",
      "Train on 2451 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.1893 - val_loss: 2.3518\n",
      "[INFO] Training model: epoch 16 - 20000/20505 samples\n",
      "Train on 2497 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2497/2497 [==============================] - 24s 9ms/step - loss: 1.2013 - val_loss: 2.6247\n",
      "[INFO] Training model: epoch 16 - 20250/20505 samples\n",
      "Train on 2408 samples, validate on 595 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 22s 9ms/step - loss: 1.1041 - val_loss: 2.7736\n",
      "[INFO] Training model: epoch 16 - 20500/20505 samples\n",
      "Train on 46 samples, validate on 17 samples\n",
      "Epoch 1/1\n",
      "46/46 [==============================] - 1s 11ms/step - loss: 1.8807 - val_loss: 2.5004\n",
      "[INFO] Training model: epoch 17 - 0/20505 samples\n",
      "Train on 2419 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 24s 10ms/step - loss: 1.0017 - val_loss: 2.7597\n",
      "[INFO] Training model: epoch 17 - 250/20505 samples\n",
      "Train on 2397 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 23s 9ms/step - loss: 1.0012 - val_loss: 2.9054\n",
      "[INFO] Training model: epoch 17 - 500/20505 samples\n",
      "Train on 2394 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 23s 10ms/step - loss: 0.9167 - val_loss: 2.8373\n",
      "[INFO] Training model: epoch 17 - 750/20505 samples\n",
      "Train on 2377 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2377/2377 [==============================] - 21s 9ms/step - loss: 0.9693 - val_loss: 2.6920\n",
      "[INFO] Training model: epoch 17 - 1000/20505 samples\n",
      "Train on 2487 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 0.9938 - val_loss: 2.6396\n",
      "[INFO] Training model: epoch 17 - 1250/20505 samples\n",
      "Train on 2448 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 22s 9ms/step - loss: 0.9835 - val_loss: 2.8758\n",
      "[INFO] Training model: epoch 17 - 1500/20505 samples\n",
      "Train on 2329 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2329/2329 [==============================] - 22s 9ms/step - loss: 1.0472 - val_loss: 2.8908\n",
      "[INFO] Training model: epoch 17 - 1750/20505 samples\n",
      "Train on 2592 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 24s 9ms/step - loss: 0.9826 - val_loss: 2.8343\n",
      "[INFO] Training model: epoch 17 - 2000/20505 samples\n",
      "Train on 2515 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 24s 10ms/step - loss: 1.0178 - val_loss: 2.7633\n",
      "[INFO] Training model: epoch 17 - 2250/20505 samples\n",
      "Train on 2473 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 0.9895 - val_loss: 2.7203\n",
      "[INFO] Training model: epoch 17 - 2500/20505 samples\n",
      "Train on 2551 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2551/2551 [==============================] - 23s 9ms/step - loss: 0.9872 - val_loss: 2.8223\n",
      "[INFO] Training model: epoch 17 - 2750/20505 samples\n",
      "Train on 2418 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 10ms/step - loss: 1.0305 - val_loss: 2.7459\n",
      "[INFO] Training model: epoch 17 - 3000/20505 samples\n",
      "Train on 2486 samples, validate on 674 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 0.9566 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 3250/20505 samples\n",
      "Train on 2511 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 0.9859 - val_loss: 2.5696\n",
      "[INFO] Training model: epoch 17 - 3500/20505 samples\n",
      "Train on 2524 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 9ms/step - loss: 0.9989 - val_loss: 2.8635\n",
      "[INFO] Training model: epoch 17 - 3750/20505 samples\n",
      "Train on 2432 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 23s 10ms/step - loss: 1.0931 - val_loss: 2.8016\n",
      "[INFO] Training model: epoch 17 - 4000/20505 samples\n",
      "Train on 2496 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 24s 10ms/step - loss: 1.0310 - val_loss: 2.5127\n",
      "[INFO] Training model: epoch 17 - 4250/20505 samples\n",
      "Train on 2460 samples, validate on 689 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 24s 10ms/step - loss: 1.0273 - val_loss: 2.7648\n",
      "[INFO] Training model: epoch 17 - 4500/20505 samples\n",
      "Train on 2473 samples, validate on 570 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.0124 - val_loss: 2.8310\n",
      "[INFO] Training model: epoch 17 - 4750/20505 samples\n",
      "Train on 2492 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 23s 9ms/step - loss: 1.0560 - val_loss: 2.5926\n",
      "[INFO] Training model: epoch 17 - 5000/20505 samples\n",
      "Train on 2431 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 23s 10ms/step - loss: 1.0501 - val_loss: 2.8781\n",
      "[INFO] Training model: epoch 17 - 5250/20505 samples\n",
      "Train on 2541 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2541/2541 [==============================] - 24s 9ms/step - loss: 1.0259 - val_loss: 3.0532\n",
      "[INFO] Training model: epoch 17 - 5500/20505 samples\n",
      "Train on 2506 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.0523 - val_loss: 2.5453\n",
      "[INFO] Training model: epoch 17 - 5750/20505 samples\n",
      "Train on 2468 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 24s 10ms/step - loss: 1.0446 - val_loss: 2.9264\n",
      "[INFO] Training model: epoch 17 - 6000/20505 samples\n",
      "Train on 2462 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2462/2462 [==============================] - 23s 10ms/step - loss: 1.0265 - val_loss: 2.6951\n",
      "[INFO] Training model: epoch 17 - 6250/20505 samples\n",
      "Train on 2447 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2447/2447 [==============================] - 23s 9ms/step - loss: 1.0243 - val_loss: 2.6062\n",
      "[INFO] Training model: epoch 17 - 6500/20505 samples\n",
      "Train on 2442 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2442/2442 [==============================] - 23s 9ms/step - loss: 1.0276 - val_loss: 2.4541\n",
      "[INFO] Training model: epoch 17 - 6750/20505 samples\n",
      "Train on 2480 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 22s 9ms/step - loss: 1.0952 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 7000/20505 samples\n",
      "Train on 2474 samples, validate on 594 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 23s 9ms/step - loss: 1.0354 - val_loss: 2.8625\n",
      "[INFO] Training model: epoch 17 - 7250/20505 samples\n",
      "Train on 2487 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 1.0581 - val_loss: 2.5959\n",
      "[INFO] Training model: epoch 17 - 7500/20505 samples\n",
      "Train on 2448 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2448/2448 [==============================] - 23s 10ms/step - loss: 1.0141 - val_loss: 2.9285\n",
      "[INFO] Training model: epoch 17 - 7750/20505 samples\n",
      "Train on 2396 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 23s 9ms/step - loss: 1.1087 - val_loss: 2.1447\n",
      "[INFO] Training model: epoch 17 - 8000/20505 samples\n",
      "Train on 2436 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2436/2436 [==============================] - 23s 10ms/step - loss: 1.0189 - val_loss: 2.7016\n",
      "[INFO] Training model: epoch 17 - 8250/20505 samples\n",
      "Train on 2511 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 1.0544 - val_loss: 2.7902\n",
      "[INFO] Training model: epoch 17 - 8500/20505 samples\n",
      "Train on 2432 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2432/2432 [==============================] - 24s 10ms/step - loss: 1.0913 - val_loss: 3.0249\n",
      "[INFO] Training model: epoch 17 - 8750/20505 samples\n",
      "Train on 2563 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2563/2563 [==============================] - 25s 10ms/step - loss: 1.1346 - val_loss: 2.7360\n",
      "[INFO] Training model: epoch 17 - 9000/20505 samples\n",
      "Train on 2310 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2310/2310 [==============================] - 23s 10ms/step - loss: 1.0845 - val_loss: 2.4522\n",
      "[INFO] Training model: epoch 17 - 9250/20505 samples\n",
      "Train on 2426 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 10ms/step - loss: 1.0874 - val_loss: 2.4807\n",
      "[INFO] Training model: epoch 17 - 9500/20505 samples\n",
      "Train on 2439 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.1209 - val_loss: 2.7332\n",
      "[INFO] Training model: epoch 17 - 9750/20505 samples\n",
      "Train on 2410 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2410/2410 [==============================] - 23s 9ms/step - loss: 1.1525 - val_loss: 2.3952\n",
      "[INFO] Training model: epoch 17 - 10000/20505 samples\n",
      "Train on 2542 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 24s 9ms/step - loss: 1.0238 - val_loss: 2.8738\n",
      "[INFO] Training model: epoch 17 - 10250/20505 samples\n",
      "Train on 2413 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 1.0568 - val_loss: 2.7993\n",
      "[INFO] Training model: epoch 17 - 10500/20505 samples\n",
      "Train on 2511 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2511/2511 [==============================] - 24s 9ms/step - loss: 1.0314 - val_loss: 2.7383\n",
      "[INFO] Training model: epoch 17 - 10750/20505 samples\n",
      "Train on 2385 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1645 - val_loss: 2.9513\n",
      "[INFO] Training model: epoch 17 - 11000/20505 samples\n",
      "Train on 2439 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 10ms/step - loss: 1.0990 - val_loss: 2.7914\n",
      "[INFO] Training model: epoch 17 - 11250/20505 samples\n",
      "Train on 2458 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 23s 9ms/step - loss: 1.1120 - val_loss: 2.7903\n",
      "[INFO] Training model: epoch 17 - 11500/20505 samples\n",
      "Train on 2517 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 23s 9ms/step - loss: 1.0835 - val_loss: 2.6622\n",
      "[INFO] Training model: epoch 17 - 11750/20505 samples\n",
      "Train on 2666 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2666/2666 [==============================] - 25s 9ms/step - loss: 1.0112 - val_loss: 2.7902\n",
      "[INFO] Training model: epoch 17 - 12000/20505 samples\n",
      "Train on 2474 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2474/2474 [==============================] - 24s 10ms/step - loss: 1.1217 - val_loss: 2.7922\n",
      "[INFO] Training model: epoch 17 - 12250/20505 samples\n",
      "Train on 2460 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.0967 - val_loss: 2.6633\n",
      "[INFO] Training model: epoch 17 - 12500/20505 samples\n",
      "Train on 2441 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 10ms/step - loss: 1.0969 - val_loss: 2.5391\n",
      "[INFO] Training model: epoch 17 - 12750/20505 samples\n",
      "Train on 2384 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2384/2384 [==============================] - 22s 9ms/step - loss: 1.1017 - val_loss: 2.6273\n",
      "[INFO] Training model: epoch 17 - 13000/20505 samples\n",
      "Train on 2454 samples, validate on 572 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 22s 9ms/step - loss: 1.0918 - val_loss: 2.8309\n",
      "[INFO] Training model: epoch 17 - 13250/20505 samples\n",
      "Train on 2489 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2489/2489 [==============================] - 23s 9ms/step - loss: 1.1318 - val_loss: 2.4994\n",
      "[INFO] Training model: epoch 17 - 13500/20505 samples\n",
      "Train on 2538 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2538/2538 [==============================] - 23s 9ms/step - loss: 1.0943 - val_loss: 2.7106\n",
      "[INFO] Training model: epoch 17 - 13750/20505 samples\n",
      "Train on 2483 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.1202 - val_loss: 2.8043\n",
      "[INFO] Training model: epoch 17 - 14000/20505 samples\n",
      "Train on 2325 samples, validate on 687 samples\n",
      "Epoch 1/1\n",
      "2325/2325 [==============================] - 22s 10ms/step - loss: 1.1483 - val_loss: 2.7629\n",
      "[INFO] Training model: epoch 17 - 14250/20505 samples\n",
      "Train on 2416 samples, validate on 546 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 1.0924 - val_loss: 2.5856\n",
      "[INFO] Training model: epoch 17 - 14500/20505 samples\n",
      "Train on 2433 samples, validate on 669 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 22s 9ms/step - loss: 1.1171 - val_loss: 2.9418\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 17 - 14750/20505 samples\n",
      "Train on 2418 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 22s 9ms/step - loss: 1.1694 - val_loss: 2.5151\n",
      "[INFO] Training model: epoch 17 - 15000/20505 samples\n",
      "Train on 2328 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2328/2328 [==============================] - 20s 9ms/step - loss: 1.0865 - val_loss: 2.4355\n",
      "[INFO] Training model: epoch 17 - 15250/20505 samples\n",
      "Train on 2545 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2545/2545 [==============================] - 24s 9ms/step - loss: 1.0970 - val_loss: 2.3715\n",
      "[INFO] Training model: epoch 17 - 15500/20505 samples\n",
      "Train on 2344 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 22s 9ms/step - loss: 1.0990 - val_loss: 2.6788\n",
      "[INFO] Training model: epoch 17 - 15750/20505 samples\n",
      "Train on 2390 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 23s 9ms/step - loss: 1.1033 - val_loss: 2.7593\n",
      "[INFO] Training model: epoch 17 - 16000/20505 samples\n",
      "Train on 2425 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2425/2425 [==============================] - 23s 9ms/step - loss: 1.1782 - val_loss: 2.9337\n",
      "[INFO] Training model: epoch 17 - 16250/20505 samples\n",
      "Train on 2498 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 23s 9ms/step - loss: 1.1287 - val_loss: 2.4064\n",
      "[INFO] Training model: epoch 17 - 16500/20505 samples\n",
      "Train on 2365 samples, validate on 571 samples\n",
      "Epoch 1/1\n",
      "2365/2365 [==============================] - 22s 9ms/step - loss: 1.1559 - val_loss: 2.4488\n",
      "[INFO] Training model: epoch 17 - 16750/20505 samples\n",
      "Train on 2491 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2491/2491 [==============================] - 22s 9ms/step - loss: 1.1277 - val_loss: 2.6632\n",
      "[INFO] Training model: epoch 17 - 17000/20505 samples\n",
      "Train on 2428 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 1.1324 - val_loss: 2.7551\n",
      "[INFO] Training model: epoch 17 - 17250/20505 samples\n",
      "Train on 2524 samples, validate on 661 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.1615 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 17 - 17500/20505 samples\n",
      "Train on 2574 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2574/2574 [==============================] - 24s 9ms/step - loss: 1.1741 - val_loss: 3.2363\n",
      "[INFO] Training model: epoch 17 - 17750/20505 samples\n",
      "Train on 2515 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.1676 - val_loss: 3.0051\n",
      "[INFO] Training model: epoch 17 - 18000/20505 samples\n",
      "Train on 2430 samples, validate on 667 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 22s 9ms/step - loss: 1.1260 - val_loss: 2.7207\n",
      "[INFO] Training model: epoch 17 - 18250/20505 samples\n",
      "Train on 2476 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.1031 - val_loss: 2.7186\n",
      "[INFO] Training model: epoch 17 - 18500/20505 samples\n",
      "Train on 2394 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2394/2394 [==============================] - 22s 9ms/step - loss: 1.1297 - val_loss: 2.8500\n",
      "[INFO] Training model: epoch 17 - 18750/20505 samples\n",
      "Train on 2304 samples, validate on 665 samples\n",
      "Epoch 1/1\n",
      "2304/2304 [==============================] - 22s 10ms/step - loss: 1.1580 - val_loss: 2.4239\n",
      "[INFO] Training model: epoch 17 - 19000/20505 samples\n",
      "Train on 2428 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 22s 9ms/step - loss: 1.1718 - val_loss: 2.5803\n",
      "[INFO] Training model: epoch 17 - 19250/20505 samples\n",
      "Train on 2499 samples, validate on 629 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 23s 9ms/step - loss: 1.1715 - val_loss: 2.7985\n",
      "[INFO] Training model: epoch 17 - 19500/20505 samples\n",
      "Train on 2513 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2513/2513 [==============================] - 23s 9ms/step - loss: 1.1181 - val_loss: 2.8429\n",
      "[INFO] Training model: epoch 17 - 19750/20505 samples\n",
      "Train on 2402 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 23s 9ms/step - loss: 1.1569 - val_loss: 2.8702\n",
      "[INFO] Training model: epoch 17 - 20000/20505 samples\n",
      "Train on 2420 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.1346 - val_loss: 2.8192\n",
      "[INFO] Training model: epoch 17 - 20250/20505 samples\n",
      "Train on 2463 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2463/2463 [==============================] - 23s 9ms/step - loss: 1.0940 - val_loss: 2.6720\n",
      "[INFO] Training model: epoch 17 - 20500/20505 samples\n",
      "Train on 71 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "71/71 [==============================] - 1s 12ms/step - loss: 1.0095 - val_loss: 4.2551\n",
      "[INFO] Training model: epoch 18 - 0/20505 samples\n",
      "Train on 2468 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 0.9432 - val_loss: 2.7818\n",
      "[INFO] Training model: epoch 18 - 250/20505 samples\n",
      "Train on 2486 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 0.9197 - val_loss: 2.7538\n",
      "[INFO] Training model: epoch 18 - 500/20505 samples\n",
      "Train on 2431 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2431/2431 [==============================] - 22s 9ms/step - loss: 0.9541 - val_loss: 2.8043\n",
      "[INFO] Training model: epoch 18 - 750/20505 samples\n",
      "Train on 2540 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 22s 9ms/step - loss: 0.9200 - val_loss: 2.8726\n",
      "[INFO] Training model: epoch 18 - 1000/20505 samples\n",
      "Train on 2443 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 23s 9ms/step - loss: 0.9293 - val_loss: 2.7009\n",
      "[INFO] Training model: epoch 18 - 1250/20505 samples\n",
      "Train on 2526 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 0.9791 - val_loss: 2.8556\n",
      "[INFO] Training model: epoch 18 - 1500/20505 samples\n",
      "Train on 2399 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2399/2399 [==============================] - 22s 9ms/step - loss: 0.9893 - val_loss: 2.7956\n",
      "[INFO] Training model: epoch 18 - 1750/20505 samples\n",
      "Train on 2419 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2419/2419 [==============================] - 23s 9ms/step - loss: 0.9367 - val_loss: 3.0318\n",
      "[INFO] Training model: epoch 18 - 2000/20505 samples\n",
      "Train on 2342 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2342/2342 [==============================] - 22s 10ms/step - loss: 0.9534 - val_loss: 2.7286\n",
      "[INFO] Training model: epoch 18 - 2250/20505 samples\n",
      "Train on 2445 samples, validate on 573 samples\n",
      "Epoch 1/1\n",
      "2445/2445 [==============================] - 23s 9ms/step - loss: 0.9583 - val_loss: 2.4451\n",
      "[INFO] Training model: epoch 18 - 2500/20505 samples\n",
      "Train on 2499 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 22s 9ms/step - loss: 0.9184 - val_loss: 2.7506\n",
      "[INFO] Training model: epoch 18 - 2750/20505 samples\n",
      "Train on 2421 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 22s 9ms/step - loss: 0.9276 - val_loss: 2.7725\n",
      "[INFO] Training model: epoch 18 - 3000/20505 samples\n",
      "Train on 2469 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 23s 9ms/step - loss: 0.9909 - val_loss: 2.5665\n",
      "[INFO] Training model: epoch 18 - 3250/20505 samples\n",
      "Train on 2434 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 23s 9ms/step - loss: 1.0166 - val_loss: 2.8835\n",
      "[INFO] Training model: epoch 18 - 3500/20505 samples\n",
      "Train on 2413 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 0.9707 - val_loss: 2.6490\n",
      "[INFO] Training model: epoch 18 - 3750/20505 samples\n",
      "Train on 2430 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 10ms/step - loss: 1.0240 - val_loss: 2.7994\n",
      "[INFO] Training model: epoch 18 - 4000/20505 samples\n",
      "Train on 2397 samples, validate on 670 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2397/2397 [==============================] - 22s 9ms/step - loss: 0.9866 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 18 - 4250/20505 samples\n",
      "Train on 2486 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 23s 9ms/step - loss: 1.0078 - val_loss: 2.6311\n",
      "[INFO] Training model: epoch 18 - 4500/20505 samples\n",
      "Train on 2548 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2548/2548 [==============================] - 24s 9ms/step - loss: 0.9312 - val_loss: 2.8432\n",
      "[INFO] Training model: epoch 18 - 4750/20505 samples\n",
      "Train on 2411 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2411/2411 [==============================] - 22s 9ms/step - loss: 0.9752 - val_loss: 2.6434\n",
      "[INFO] Training model: epoch 18 - 5000/20505 samples\n",
      "Train on 2531 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2531/2531 [==============================] - 24s 9ms/step - loss: 0.9718 - val_loss: 3.0324\n",
      "[INFO] Training model: epoch 18 - 5250/20505 samples\n",
      "Train on 2414 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2414/2414 [==============================] - 22s 9ms/step - loss: 1.0249 - val_loss: 2.7234\n",
      "[INFO] Training model: epoch 18 - 5500/20505 samples\n",
      "Train on 2525 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2525/2525 [==============================] - 23s 9ms/step - loss: 1.0700 - val_loss: 2.5666\n",
      "[INFO] Training model: epoch 18 - 5750/20505 samples\n",
      "Train on 2383 samples, validate on 626 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 22s 9ms/step - loss: 1.0236 - val_loss: 2.7478\n",
      "[INFO] Training model: epoch 18 - 6000/20505 samples\n",
      "Train on 2423 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 22s 9ms/step - loss: 0.9926 - val_loss: 2.7383\n",
      "[INFO] Training model: epoch 18 - 6250/20505 samples\n",
      "Train on 2443 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2443/2443 [==============================] - 22s 9ms/step - loss: 1.0206 - val_loss: 2.8369\n",
      "[INFO] Training model: epoch 18 - 6500/20505 samples\n",
      "Train on 2528 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 23s 9ms/step - loss: 1.0120 - val_loss: 2.6608\n",
      "[INFO] Training model: epoch 18 - 6750/20505 samples\n",
      "Train on 2374 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2374/2374 [==============================] - 22s 9ms/step - loss: 0.9914 - val_loss: 2.7737\n",
      "[INFO] Training model: epoch 18 - 7000/20505 samples\n",
      "Train on 2530 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2530/2530 [==============================] - 23s 9ms/step - loss: 0.9630 - val_loss: 2.8892\n",
      "[INFO] Training model: epoch 18 - 7250/20505 samples\n",
      "Train on 2466 samples, validate on 570 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.0281 - val_loss: 2.7736\n",
      "[INFO] Training model: epoch 18 - 7500/20505 samples\n",
      "Train on 2390 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.0465 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 18 - 7750/20505 samples\n",
      "Train on 2468 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.0300 - val_loss: 2.6032\n",
      "[INFO] Training model: epoch 18 - 8000/20505 samples\n",
      "Train on 2401 samples, validate on 558 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 9ms/step - loss: 1.0728 - val_loss: 2.8673\n",
      "[INFO] Training model: epoch 18 - 8250/20505 samples\n",
      "Train on 2473 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 21s 9ms/step - loss: 1.0917 - val_loss: 2.5969\n",
      "[INFO] Training model: epoch 18 - 8500/20505 samples\n",
      "Train on 2476 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 1.0823 - val_loss: 2.4519\n",
      "[INFO] Training model: epoch 18 - 8750/20505 samples\n",
      "Train on 2423 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 21s 9ms/step - loss: 1.0260 - val_loss: 2.5291\n",
      "[INFO] Training model: epoch 18 - 9000/20505 samples\n",
      "Train on 2346 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2346/2346 [==============================] - 22s 10ms/step - loss: 1.0396 - val_loss: 3.0978\n",
      "[INFO] Training model: epoch 18 - 9250/20505 samples\n",
      "Train on 2524 samples, validate on 575 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0258 - val_loss: 2.7623\n",
      "[INFO] Training model: epoch 18 - 9500/20505 samples\n",
      "Train on 2416 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2416/2416 [==============================] - 22s 9ms/step - loss: 0.9630 - val_loss: 2.3985\n",
      "[INFO] Training model: epoch 18 - 9750/20505 samples\n",
      "Train on 2437 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2437/2437 [==============================] - 23s 9ms/step - loss: 1.0564 - val_loss: 2.7762\n",
      "[INFO] Training model: epoch 18 - 10000/20505 samples\n",
      "Train on 2518 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2518/2518 [==============================] - 23s 9ms/step - loss: 1.0274 - val_loss: 2.6226\n",
      "[INFO] Training model: epoch 18 - 10250/20505 samples\n",
      "Train on 2452 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.0672 - val_loss: 2.8824\n",
      "[INFO] Training model: epoch 18 - 10500/20505 samples\n",
      "Train on 2457 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.0273 - val_loss: 3.0981\n",
      "[INFO] Training model: epoch 18 - 10750/20505 samples\n",
      "Train on 2434 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 22s 9ms/step - loss: 1.0691 - val_loss: 2.8633\n",
      "[INFO] Training model: epoch 18 - 11000/20505 samples\n",
      "Train on 2494 samples, validate on 590 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 1.1319 - val_loss: 2.7680\n",
      "[INFO] Training model: epoch 18 - 11250/20505 samples\n",
      "Train on 2502 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 9ms/step - loss: 1.0556 - val_loss: 2.9950\n",
      "[INFO] Training model: epoch 18 - 11500/20505 samples\n",
      "Train on 2393 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.0817 - val_loss: 2.6052\n",
      "[INFO] Training model: epoch 18 - 11750/20505 samples\n",
      "Train on 2602 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2602/2602 [==============================] - 24s 9ms/step - loss: 1.0657 - val_loss: 3.0729\n",
      "[INFO] Training model: epoch 18 - 12000/20505 samples\n",
      "Train on 2390 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2390/2390 [==============================] - 22s 9ms/step - loss: 1.0750 - val_loss: 2.6785\n",
      "[INFO] Training model: epoch 18 - 12250/20505 samples\n",
      "Train on 2359 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2359/2359 [==============================] - 22s 9ms/step - loss: 1.0819 - val_loss: 3.3371\n",
      "[INFO] Training model: epoch 18 - 12500/20505 samples\n",
      "Train on 2423 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.0705 - val_loss: 2.9523\n",
      "[INFO] Training model: epoch 18 - 12750/20505 samples\n",
      "Train on 2496 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2496/2496 [==============================] - 23s 9ms/step - loss: 1.1152 - val_loss: 2.9089\n",
      "[INFO] Training model: epoch 18 - 13000/20505 samples\n",
      "Train on 2549 samples, validate on 553 samples\n",
      "Epoch 1/1\n",
      "2549/2549 [==============================] - 23s 9ms/step - loss: 1.0360 - val_loss: 2.9781\n",
      "[INFO] Training model: epoch 18 - 13250/20505 samples\n",
      "Train on 2468 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2468/2468 [==============================] - 23s 9ms/step - loss: 1.0542 - val_loss: 2.5845\n",
      "[INFO] Training model: epoch 18 - 13500/20505 samples\n",
      "Train on 2420 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2420/2420 [==============================] - 22s 9ms/step - loss: 1.1649 - val_loss: 2.7396\n",
      "[INFO] Training model: epoch 18 - 13750/20505 samples\n",
      "Train on 2454 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 23s 9ms/step - loss: 1.1051 - val_loss: 2.8910\n",
      "[INFO] Training model: epoch 18 - 14000/20505 samples\n",
      "Train on 2392 samples, validate on 655 samples\n",
      "Epoch 1/1\n",
      "2392/2392 [==============================] - 22s 9ms/step - loss: 1.0719 - val_loss: 2.6278\n",
      "[INFO] Training model: epoch 18 - 14250/20505 samples\n",
      "Train on 2601 samples, validate on 625 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2601/2601 [==============================] - 24s 9ms/step - loss: 1.0618 - val_loss: 2.9545\n",
      "[INFO] Training model: epoch 18 - 14500/20505 samples\n",
      "Train on 2515 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2515/2515 [==============================] - 23s 9ms/step - loss: 1.1398 - val_loss: 2.5537\n",
      "[INFO] Training model: epoch 18 - 14750/20505 samples\n",
      "Train on 2429 samples, validate on 638 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 22s 9ms/step - loss: 1.1956 - val_loss: 3.0650\n",
      "[INFO] Training model: epoch 18 - 15000/20505 samples\n",
      "Train on 2423 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 9ms/step - loss: 1.1139 - val_loss: 3.2373\n",
      "[INFO] Training model: epoch 18 - 15250/20505 samples\n",
      "Train on 2470 samples, validate on 620 samples\n",
      "Epoch 1/1\n",
      "2470/2470 [==============================] - 23s 9ms/step - loss: 1.1225 - val_loss: 2.7245\n",
      "[INFO] Training model: epoch 18 - 15500/20505 samples\n",
      "Train on 2505 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2505/2505 [==============================] - 24s 9ms/step - loss: 1.0658 - val_loss: 2.7332\n",
      "[INFO] Training model: epoch 18 - 15750/20505 samples\n",
      "Train on 2396 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2396/2396 [==============================] - 21s 9ms/step - loss: 1.1214 - val_loss: 2.8891\n",
      "[INFO] Training model: epoch 18 - 16000/20505 samples\n",
      "Train on 2466 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 1.0915 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 18 - 16250/20505 samples\n",
      "Train on 2461 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 22s 9ms/step - loss: 1.0768 - val_loss: 2.6934\n",
      "[INFO] Training model: epoch 18 - 16500/20505 samples\n",
      "Train on 2451 samples, validate on 654 samples\n",
      "Epoch 1/1\n",
      "2451/2451 [==============================] - 23s 9ms/step - loss: 1.1657 - val_loss: 3.1628\n",
      "[INFO] Training model: epoch 18 - 16750/20505 samples\n",
      "Train on 2385 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2385/2385 [==============================] - 22s 9ms/step - loss: 1.1427 - val_loss: 2.6621\n",
      "[INFO] Training model: epoch 18 - 17000/20505 samples\n",
      "Train on 2452 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 22s 9ms/step - loss: 1.0555 - val_loss: 2.7870\n",
      "[INFO] Training model: epoch 18 - 17250/20505 samples\n",
      "Train on 2459 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 23s 9ms/step - loss: 1.1140 - val_loss: 2.8887\n",
      "[INFO] Training model: epoch 18 - 17500/20505 samples\n",
      "Train on 2485 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2485/2485 [==============================] - 23s 9ms/step - loss: 1.0537 - val_loss: 2.9955\n",
      "[INFO] Training model: epoch 18 - 17750/20505 samples\n",
      "Train on 2483 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 23s 9ms/step - loss: 1.0585 - val_loss: 2.7522\n",
      "[INFO] Training model: epoch 18 - 18000/20505 samples\n",
      "Train on 2386 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2386/2386 [==============================] - 22s 9ms/step - loss: 1.0394 - val_loss: 2.4840\n",
      "[INFO] Training model: epoch 18 - 18250/20505 samples\n",
      "Train on 2460 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2460/2460 [==============================] - 23s 9ms/step - loss: 1.0950 - val_loss: 2.5444\n",
      "[INFO] Training model: epoch 18 - 18500/20505 samples\n",
      "Train on 2542 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2542/2542 [==============================] - 23s 9ms/step - loss: 1.1051 - val_loss: 2.7910\n",
      "[INFO] Training model: epoch 18 - 18750/20505 samples\n",
      "Train on 2482 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 22s 9ms/step - loss: 1.1232 - val_loss: 2.6184\n",
      "[INFO] Training model: epoch 18 - 19000/20505 samples\n",
      "Train on 2370 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 22s 9ms/step - loss: 1.1474 - val_loss: 2.9380\n",
      "[INFO] Training model: epoch 18 - 19250/20505 samples\n",
      "Train on 2457 samples, validate on 601 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 1.1237 - val_loss: 3.0535\n",
      "[INFO] Training model: epoch 18 - 19500/20505 samples\n",
      "Train on 2523 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2523/2523 [==============================] - 22s 9ms/step - loss: 1.1631 - val_loss: 2.6603\n",
      "[INFO] Training model: epoch 18 - 19750/20505 samples\n",
      "Train on 2540 samples, validate on 583 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 23s 9ms/step - loss: 1.0741 - val_loss: 2.7600\n",
      "[INFO] Training model: epoch 18 - 20000/20505 samples\n",
      "Train on 2464 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.1240 - val_loss: 2.5807\n",
      "[INFO] Training model: epoch 18 - 20250/20505 samples\n",
      "Train on 2426 samples, validate on 647 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 21s 9ms/step - loss: 1.1292 - val_loss: 2.8161\n",
      "[INFO] Training model: epoch 18 - 20500/20505 samples\n",
      "Train on 44 samples, validate on 28 samples\n",
      "Epoch 1/1\n",
      "44/44 [==============================] - 1s 12ms/step - loss: 1.3792 - val_loss: 4.8115\n",
      "[INFO] Training model: epoch 19 - 0/20505 samples\n",
      "Train on 2427 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2427/2427 [==============================] - 22s 9ms/step - loss: 0.9222 - val_loss: 2.7577\n",
      "[INFO] Training model: epoch 19 - 250/20505 samples\n",
      "Train on 2413 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 22s 9ms/step - loss: 0.9591 - val_loss: 2.9073\n",
      "[INFO] Training model: epoch 19 - 500/20505 samples\n",
      "Train on 2520 samples, validate on 548 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 22s 9ms/step - loss: 0.9091 - val_loss: 3.0033\n",
      "[INFO] Training model: epoch 19 - 750/20505 samples\n",
      "Train on 2459 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 22s 9ms/step - loss: 0.9315 - val_loss: 2.8249\n",
      "[INFO] Training model: epoch 19 - 1000/20505 samples\n",
      "Train on 2395 samples, validate on 663 samples\n",
      "Epoch 1/1\n",
      "2395/2395 [==============================] - 22s 9ms/step - loss: 0.9188 - val_loss: 2.6159\n",
      "[INFO] Training model: epoch 19 - 1250/20505 samples\n",
      "Train on 2316 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 22s 10ms/step - loss: 0.9730 - val_loss: 2.5742\n",
      "[INFO] Training model: epoch 19 - 1500/20505 samples\n",
      "Train on 2467 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2467/2467 [==============================] - 23s 9ms/step - loss: 0.8922 - val_loss: 2.7719\n",
      "[INFO] Training model: epoch 19 - 1750/20505 samples\n",
      "Train on 2330 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2330/2330 [==============================] - 21s 9ms/step - loss: 0.9017 - val_loss: 2.6170\n",
      "[INFO] Training model: epoch 19 - 2000/20505 samples\n",
      "Train on 2322 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2322/2322 [==============================] - 22s 9ms/step - loss: 0.9265 - val_loss: 2.7872\n",
      "[INFO] Training model: epoch 19 - 2250/20505 samples\n",
      "Train on 2422 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2422/2422 [==============================] - 23s 9ms/step - loss: 0.9825 - val_loss: 2.7195\n",
      "[INFO] Training model: epoch 19 - 2500/20505 samples\n",
      "Train on 2428 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 9ms/step - loss: 0.9926 - val_loss: 2.6763\n",
      "[INFO] Training model: epoch 19 - 2750/20505 samples\n",
      "Train on 2476 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 23s 9ms/step - loss: 0.9291 - val_loss: 2.7136\n",
      "[INFO] Training model: epoch 19 - 3000/20505 samples\n",
      "Train on 2502 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2502/2502 [==============================] - 24s 10ms/step - loss: 0.8985 - val_loss: 2.5489\n",
      "[INFO] Training model: epoch 19 - 3250/20505 samples\n",
      "Train on 2397 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2397/2397 [==============================] - 22s 9ms/step - loss: 0.9399 - val_loss: 2.9378\n",
      "[INFO] Training model: epoch 19 - 3500/20505 samples\n",
      "Train on 2591 samples, validate on 544 samples\n",
      "Epoch 1/1\n",
      "2591/2591 [==============================] - 25s 9ms/step - loss: 0.9191 - val_loss: 2.4402\n",
      "[INFO] Training model: epoch 19 - 3750/20505 samples\n",
      "Train on 2521 samples, validate on 614 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2521/2521 [==============================] - 24s 9ms/step - loss: 0.9959 - val_loss: 2.9614\n",
      "[INFO] Training model: epoch 19 - 4000/20505 samples\n",
      "Train on 2321 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2321/2321 [==============================] - 22s 10ms/step - loss: 1.0236 - val_loss: 3.1506\n",
      "[INFO] Training model: epoch 19 - 4250/20505 samples\n",
      "Train on 2426 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 22s 9ms/step - loss: 0.9928 - val_loss: 2.8356\n",
      "[INFO] Training model: epoch 19 - 4500/20505 samples\n",
      "Train on 2430 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9653 - val_loss: 3.2060\n",
      "[INFO] Training model: epoch 19 - 4750/20505 samples\n",
      "Train on 2475 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.0055 - val_loss: 2.6078\n",
      "[INFO] Training model: epoch 19 - 5000/20505 samples\n",
      "Train on 2490 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2490/2490 [==============================] - 23s 9ms/step - loss: 1.0002 - val_loss: 2.6924\n",
      "[INFO] Training model: epoch 19 - 5250/20505 samples\n",
      "Train on 2494 samples, validate on 587 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 23s 9ms/step - loss: 0.9418 - val_loss: 2.9382\n",
      "[INFO] Training model: epoch 19 - 5500/20505 samples\n",
      "Train on 2539 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2539/2539 [==============================] - 24s 10ms/step - loss: 0.9957 - val_loss: 2.8705\n",
      "[INFO] Training model: epoch 19 - 5750/20505 samples\n",
      "Train on 2576 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2576/2576 [==============================] - 24s 9ms/step - loss: 0.9907 - val_loss: 3.0956\n",
      "[INFO] Training model: epoch 19 - 6000/20505 samples\n",
      "Train on 2486 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2486/2486 [==============================] - 24s 10ms/step - loss: 0.9790 - val_loss: 2.8852\n",
      "[INFO] Training model: epoch 19 - 6250/20505 samples\n",
      "Train on 2482 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 0.9659 - val_loss: 2.8126\n",
      "[INFO] Training model: epoch 19 - 6500/20505 samples\n",
      "Train on 2393 samples, validate on 565 samples\n",
      "Epoch 1/1\n",
      "2393/2393 [==============================] - 22s 9ms/step - loss: 1.0122 - val_loss: 2.7792\n",
      "[INFO] Training model: epoch 19 - 6750/20505 samples\n",
      "Train on 2409 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2409/2409 [==============================] - 22s 9ms/step - loss: 0.9541 - val_loss: 3.0745\n",
      "[INFO] Training model: epoch 19 - 7000/20505 samples\n",
      "Train on 2506 samples, validate on 628 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 23s 9ms/step - loss: 0.9594 - val_loss: 2.8316\n",
      "[INFO] Training model: epoch 19 - 7250/20505 samples\n",
      "Train on 2426 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 10ms/step - loss: 0.9579 - val_loss: 3.0970\n",
      "[INFO] Training model: epoch 19 - 7500/20505 samples\n",
      "Train on 2439 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 23s 9ms/step - loss: 0.9676 - val_loss: 3.1359\n",
      "[INFO] Training model: epoch 19 - 7750/20505 samples\n",
      "Train on 2503 samples, validate on 678 samples\n",
      "Epoch 1/1\n",
      "2503/2503 [==============================] - 24s 9ms/step - loss: 0.9924 - val_loss: 3.0336\n",
      "[INFO] Training model: epoch 19 - 8000/20505 samples\n",
      "Train on 2453 samples, validate on 643 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 10ms/step - loss: 1.0063 - val_loss: 2.7270\n",
      "[INFO] Training model: epoch 19 - 8250/20505 samples\n",
      "Train on 2532 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2532/2532 [==============================] - 24s 9ms/step - loss: 1.0022 - val_loss: 2.8855\n",
      "[INFO] Training model: epoch 19 - 8500/20505 samples\n",
      "Train on 2526 samples, validate on 611 samples\n",
      "Epoch 1/1\n",
      "2526/2526 [==============================] - 24s 9ms/step - loss: 1.0056 - val_loss: 2.6776\n",
      "[INFO] Training model: epoch 19 - 8750/20505 samples\n",
      "Train on 2592 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2592/2592 [==============================] - 25s 10ms/step - loss: 0.9807 - val_loss: 2.3118\n",
      "[INFO] Training model: epoch 19 - 9000/20505 samples\n",
      "Train on 2439 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.0218 - val_loss: 3.0609\n",
      "[INFO] Training model: epoch 19 - 9250/20505 samples\n",
      "Train on 2498 samples, validate on 574 samples\n",
      "Epoch 1/1\n",
      "2498/2498 [==============================] - 24s 9ms/step - loss: 1.0473 - val_loss: 2.8939\n",
      "[INFO] Training model: epoch 19 - 9500/20505 samples\n",
      "Train on 2268 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2268/2268 [==============================] - 22s 10ms/step - loss: 1.0087 - val_loss: 2.7694\n",
      "[INFO] Training model: epoch 19 - 9750/20505 samples\n",
      "Train on 2501 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2501/2501 [==============================] - 24s 9ms/step - loss: 1.0118 - val_loss: 2.7092\n",
      "[INFO] Training model: epoch 19 - 10000/20505 samples\n",
      "Train on 2363 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2363/2363 [==============================] - 22s 9ms/step - loss: 1.0402 - val_loss: 2.7114\n",
      "[INFO] Training model: epoch 19 - 10250/20505 samples\n",
      "Train on 2344 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2344/2344 [==============================] - 23s 10ms/step - loss: 1.0391 - val_loss: 2.6761\n",
      "[INFO] Training model: epoch 19 - 10500/20505 samples\n",
      "Train on 2603 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2603/2603 [==============================] - 25s 10ms/step - loss: 1.0738 - val_loss: 2.8809\n",
      "[INFO] Training model: epoch 19 - 10750/20505 samples\n",
      "Train on 2426 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2426/2426 [==============================] - 23s 9ms/step - loss: 1.0309 - val_loss: 2.9924\n",
      "[INFO] Training model: epoch 19 - 11000/20505 samples\n",
      "Train on 2482 samples, validate on 610 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 0.9618 - val_loss: 2.9536\n",
      "[INFO] Training model: epoch 19 - 11250/20505 samples\n",
      "Train on 2408 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 9ms/step - loss: 1.0816 - val_loss: 2.7447\n",
      "[INFO] Training model: epoch 19 - 11500/20505 samples\n",
      "Train on 2357 samples, validate on 592 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 23s 10ms/step - loss: 1.0541 - val_loss: 2.8024\n",
      "[INFO] Training model: epoch 19 - 11750/20505 samples\n",
      "Train on 2453 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2453/2453 [==============================] - 23s 9ms/step - loss: 1.0147 - val_loss: 2.8662\n",
      "[INFO] Training model: epoch 19 - 12000/20505 samples\n",
      "Train on 2367 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2367/2367 [==============================] - 23s 10ms/step - loss: 1.0537 - val_loss: 2.6470\n",
      "[INFO] Training model: epoch 19 - 12250/20505 samples\n",
      "Train on 2449 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 24s 10ms/step - loss: 1.0041 - val_loss: 2.2383\n",
      "[INFO] Training model: epoch 19 - 12500/20505 samples\n",
      "Train on 2499 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 26s 10ms/step - loss: 1.0798 - val_loss: 2.5349\n",
      "[INFO] Training model: epoch 19 - 12750/20505 samples\n",
      "Train on 2383 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2383/2383 [==============================] - 25s 10ms/step - loss: 1.0249 - val_loss: 3.0277\n",
      "[INFO] Training model: epoch 19 - 13000/20505 samples\n",
      "Train on 2343 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2343/2343 [==============================] - 23s 10ms/step - loss: 1.1097 - val_loss: 2.5419\n",
      "[INFO] Training model: epoch 19 - 13250/20505 samples\n",
      "Train on 2407 samples, validate on 671 samples\n",
      "Epoch 1/1\n",
      "2407/2407 [==============================] - 23s 10ms/step - loss: 1.0463 - val_loss: 2.4872\n",
      "[INFO] Training model: epoch 19 - 13500/20505 samples\n",
      "Train on 2417 samples, validate on 657 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 24s 10ms/step - loss: 1.0459 - val_loss: 3.1451\n",
      "[INFO] Training model: epoch 19 - 13750/20505 samples\n",
      "Train on 2480 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2480/2480 [==============================] - 23s 9ms/step - loss: 0.9855 - val_loss: 2.6958\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 19 - 14000/20505 samples\n",
      "Train on 2524 samples, validate on 622 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 24s 10ms/step - loss: 1.0499 - val_loss: 2.5189\n",
      "[INFO] Training model: epoch 19 - 14250/20505 samples\n",
      "Train on 2376 samples, validate on 564 samples\n",
      "Epoch 1/1\n",
      "2376/2376 [==============================] - 23s 10ms/step - loss: 1.0014 - val_loss: 2.5998\n",
      "[INFO] Training model: epoch 19 - 14500/20505 samples\n",
      "Train on 2335 samples, validate on 578 samples\n",
      "Epoch 1/1\n",
      "2335/2335 [==============================] - 22s 9ms/step - loss: 1.0450 - val_loss: 3.0092\n",
      "[INFO] Training model: epoch 19 - 14750/20505 samples\n",
      "Train on 2593 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2593/2593 [==============================] - 24s 9ms/step - loss: 1.0362 - val_loss: 2.6478\n",
      "[INFO] Training model: epoch 19 - 15000/20505 samples\n",
      "Train on 2421 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2421/2421 [==============================] - 23s 9ms/step - loss: 1.0505 - val_loss: 2.8659\n",
      "[INFO] Training model: epoch 19 - 15250/20505 samples\n",
      "Train on 2522 samples, validate on 597 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 24s 9ms/step - loss: 1.0652 - val_loss: 2.6258\n",
      "[INFO] Training model: epoch 19 - 15500/20505 samples\n",
      "Train on 2449 samples, validate on 717 samples\n",
      "Epoch 1/1\n",
      "2449/2449 [==============================] - 24s 10ms/step - loss: 1.0636 - val_loss: 2.9232\n",
      "[INFO] Training model: epoch 19 - 15750/20505 samples\n",
      "Train on 2403 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2403/2403 [==============================] - 23s 10ms/step - loss: 1.0571 - val_loss: 3.0399\n",
      "[INFO] Training model: epoch 19 - 16000/20505 samples\n",
      "Train on 2524 samples, validate on 675 samples\n",
      "Epoch 1/1\n",
      "2524/2524 [==============================] - 23s 9ms/step - loss: 1.0083 - val_loss: 2.8676\n",
      "[INFO] Training model: epoch 19 - 16250/20505 samples\n",
      "Train on 2461 samples, validate on 625 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 24s 10ms/step - loss: 0.9984 - val_loss: 2.5887\n",
      "[INFO] Training model: epoch 19 - 16500/20505 samples\n",
      "Train on 2434 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2434/2434 [==============================] - 23s 9ms/step - loss: 1.0308 - val_loss: 2.7769\n",
      "[INFO] Training model: epoch 19 - 16750/20505 samples\n",
      "Train on 2553 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2553/2553 [==============================] - 24s 9ms/step - loss: 1.0659 - val_loss: 2.7299\n",
      "[INFO] Training model: epoch 19 - 17000/20505 samples\n",
      "Train on 2473 samples, validate on 566 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 24s 10ms/step - loss: 1.0745 - val_loss: 3.0547\n",
      "[INFO] Training model: epoch 19 - 17250/20505 samples\n",
      "Train on 2510 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2510/2510 [==============================] - 24s 9ms/step - loss: 1.0764 - val_loss: 2.9385\n",
      "[INFO] Training model: epoch 19 - 17500/20505 samples\n",
      "Train on 2435 samples, validate on 606 samples\n",
      "Epoch 1/1\n",
      "2435/2435 [==============================] - 24s 10ms/step - loss: 1.1201 - val_loss: 2.9584\n",
      "[INFO] Training model: epoch 19 - 17750/20505 samples\n",
      "Train on 2464 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 23s 9ms/step - loss: 1.0935 - val_loss: 3.0776\n",
      "[INFO] Training model: epoch 19 - 18000/20505 samples\n",
      "Train on 2401 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2401/2401 [==============================] - 23s 10ms/step - loss: 1.1295 - val_loss: 2.8364\n",
      "[INFO] Training model: epoch 19 - 18250/20505 samples\n",
      "Train on 2578 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2578/2578 [==============================] - 24s 9ms/step - loss: 1.0703 - val_loss: 2.7388\n",
      "[INFO] Training model: epoch 19 - 18500/20505 samples\n",
      "Train on 2528 samples, validate on 623 samples\n",
      "Epoch 1/1\n",
      "2528/2528 [==============================] - 24s 10ms/step - loss: 1.0585 - val_loss: 2.7927\n",
      "[INFO] Training model: epoch 19 - 18750/20505 samples\n",
      "Train on 2482 samples, validate on 560 samples\n",
      "Epoch 1/1\n",
      "2482/2482 [==============================] - 23s 9ms/step - loss: 1.0888 - val_loss: 2.7047\n",
      "[INFO] Training model: epoch 19 - 19000/20505 samples\n",
      "Train on 2529 samples, validate on 642 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 9ms/step - loss: 1.0695 - val_loss: 2.4776\n",
      "[INFO] Training model: epoch 19 - 19250/20505 samples\n",
      "Train on 2456 samples, validate on 646 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.0996 - val_loss: 2.7192\n",
      "[INFO] Training model: epoch 19 - 19500/20505 samples\n",
      "Train on 2517 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2517/2517 [==============================] - 24s 10ms/step - loss: 1.1036 - val_loss: 2.8878\n",
      "[INFO] Training model: epoch 19 - 19750/20505 samples\n",
      "Train on 2550 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2550/2550 [==============================] - 25s 10ms/step - loss: 1.0740 - val_loss: 3.0209\n",
      "[INFO] Training model: epoch 19 - 20000/20505 samples\n",
      "Train on 2456 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.1257 - val_loss: 2.7437\n",
      "[INFO] Training model: epoch 19 - 20250/20505 samples\n",
      "Train on 2457 samples, validate on 648 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 24s 10ms/step - loss: 1.1427 - val_loss: 3.0866\n",
      "[INFO] Training model: epoch 19 - 20500/20505 samples\n",
      "Train on 54 samples, validate on 16 samples\n",
      "Epoch 1/1\n",
      "54/54 [==============================] - 1s 10ms/step - loss: 0.7647 - val_loss: 3.9848\n",
      "[INFO] Training model: epoch 20 - 0/20505 samples\n",
      "Train on 2466 samples, validate on 650 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 9ms/step - loss: 0.8772 - val_loss: 2.8746\n",
      "[INFO] Training model: epoch 20 - 250/20505 samples\n",
      "Train on 2477 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 24s 10ms/step - loss: 0.8611 - val_loss: 2.7570\n",
      "[INFO] Training model: epoch 20 - 500/20505 samples\n",
      "Train on 2527 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 24s 10ms/step - loss: 0.8867 - val_loss: 3.0272\n",
      "[INFO] Training model: epoch 20 - 750/20505 samples\n",
      "Train on 2540 samples, validate on 569 samples\n",
      "Epoch 1/1\n",
      "2540/2540 [==============================] - 24s 10ms/step - loss: 0.8715 - val_loss: 2.4588\n",
      "[INFO] Training model: epoch 20 - 1000/20505 samples\n",
      "Train on 2527 samples, validate on 627 samples\n",
      "Epoch 1/1\n",
      "2527/2527 [==============================] - 24s 10ms/step - loss: 0.9176 - val_loss: 2.9459\n",
      "[INFO] Training model: epoch 20 - 1250/20505 samples\n",
      "Train on 2461 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 24s 10ms/step - loss: 0.9293 - val_loss: 2.6768\n",
      "[INFO] Training model: epoch 20 - 1500/20505 samples\n",
      "Train on 2429 samples, validate on 596 samples\n",
      "Epoch 1/1\n",
      "2429/2429 [==============================] - 23s 9ms/step - loss: 0.8735 - val_loss: 2.8972\n",
      "[INFO] Training model: epoch 20 - 1750/20505 samples\n",
      "Train on 2484 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2484/2484 [==============================] - 23s 9ms/step - loss: 0.9053 - val_loss: 2.7521\n",
      "[INFO] Training model: epoch 20 - 2000/20505 samples\n",
      "Train on 2408 samples, validate on 621 samples\n",
      "Epoch 1/1\n",
      "2408/2408 [==============================] - 23s 10ms/step - loss: 0.8652 - val_loss: 2.9732\n",
      "[INFO] Training model: epoch 20 - 2250/20505 samples\n",
      "Train on 2370 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2370/2370 [==============================] - 23s 10ms/step - loss: 0.9307 - val_loss: 2.8537\n",
      "[INFO] Training model: epoch 20 - 2500/20505 samples\n",
      "Train on 2472 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2472/2472 [==============================] - 24s 10ms/step - loss: 0.9756 - val_loss: 2.8670\n",
      "[INFO] Training model: epoch 20 - 2750/20505 samples\n",
      "Train on 2423 samples, validate on 614 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 10ms/step - loss: 0.9644 - val_loss: 2.6924\n",
      "[INFO] Training model: epoch 20 - 3000/20505 samples\n",
      "Train on 2454 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 24s 10ms/step - loss: 0.9538 - val_loss: 2.9333\n",
      "[INFO] Training model: epoch 20 - 3250/20505 samples\n",
      "Train on 2446 samples, validate on 669 samples\n",
      "Epoch 1/1\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2446/2446 [==============================] - 24s 10ms/step - loss: 0.9323 - val_loss: 2.7179\n",
      "[INFO] Training model: epoch 20 - 3500/20505 samples\n",
      "Train on 2406 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2406/2406 [==============================] - 23s 10ms/step - loss: 0.9968 - val_loss: 2.7366\n",
      "[INFO] Training model: epoch 20 - 3750/20505 samples\n",
      "Train on 2356 samples, validate on 639 samples\n",
      "Epoch 1/1\n",
      "2356/2356 [==============================] - 23s 10ms/step - loss: 0.9795 - val_loss: 2.9514\n",
      "[INFO] Training model: epoch 20 - 4000/20505 samples\n",
      "Train on 2561 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2561/2561 [==============================] - 25s 10ms/step - loss: 0.9739 - val_loss: 2.7247\n",
      "[INFO] Training model: epoch 20 - 4250/20505 samples\n",
      "Train on 2412 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2412/2412 [==============================] - 23s 10ms/step - loss: 0.9360 - val_loss: 2.9094\n",
      "[INFO] Training model: epoch 20 - 4500/20505 samples\n",
      "Train on 2430 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9404 - val_loss: 3.0012\n",
      "[INFO] Training model: epoch 20 - 4750/20505 samples\n",
      "Train on 2456 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 0.9547 - val_loss: 3.2422\n",
      "[INFO] Training model: epoch 20 - 5000/20505 samples\n",
      "Train on 2458 samples, validate on 618 samples\n",
      "Epoch 1/1\n",
      "2458/2458 [==============================] - 24s 10ms/step - loss: 0.9714 - val_loss: 2.8212\n",
      "[INFO] Training model: epoch 20 - 5250/20505 samples\n",
      "Train on 2479 samples, validate on 652 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 24s 10ms/step - loss: 0.9516 - val_loss: 2.5386\n",
      "[INFO] Training model: epoch 20 - 5500/20505 samples\n",
      "Train on 2413 samples, validate on 547 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 9ms/step - loss: 0.8988 - val_loss: 3.0341\n",
      "[INFO] Training model: epoch 20 - 5750/20505 samples\n",
      "Train on 2461 samples, validate on 562 samples\n",
      "Epoch 1/1\n",
      "2461/2461 [==============================] - 23s 9ms/step - loss: 0.8881 - val_loss: 2.9847\n",
      "[INFO] Training model: epoch 20 - 6000/20505 samples\n",
      "Train on 2446 samples, validate on 631 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 23s 9ms/step - loss: 0.9611 - val_loss: 2.5921\n",
      "[INFO] Training model: epoch 20 - 6250/20505 samples\n",
      "Train on 2430 samples, validate on 630 samples\n",
      "Epoch 1/1\n",
      "2430/2430 [==============================] - 23s 9ms/step - loss: 0.9322 - val_loss: 2.7023\n",
      "[INFO] Training model: epoch 20 - 6500/20505 samples\n",
      "Train on 2413 samples, validate on 598 samples\n",
      "Epoch 1/1\n",
      "2413/2413 [==============================] - 23s 10ms/step - loss: 0.9243 - val_loss: 2.8292\n",
      "[INFO] Training model: epoch 20 - 6750/20505 samples\n",
      "Train on 2547 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2547/2547 [==============================] - 24s 9ms/step - loss: 0.9554 - val_loss: 2.8236\n",
      "[INFO] Training model: epoch 20 - 7000/20505 samples\n",
      "Train on 2522 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2522/2522 [==============================] - 23s 9ms/step - loss: 0.9682 - val_loss: 3.2812\n",
      "[INFO] Training model: epoch 20 - 7250/20505 samples\n",
      "Train on 2483 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2483/2483 [==============================] - 24s 10ms/step - loss: 0.9026 - val_loss: 2.8475\n",
      "[INFO] Training model: epoch 20 - 7500/20505 samples\n",
      "Train on 2418 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2418/2418 [==============================] - 23s 9ms/step - loss: 0.9574 - val_loss: 2.8752\n",
      "[INFO] Training model: epoch 20 - 7750/20505 samples\n",
      "Train on 2487 samples, validate on 644 samples\n",
      "Epoch 1/1\n",
      "2487/2487 [==============================] - 24s 10ms/step - loss: 1.0249 - val_loss: 2.6443\n",
      "[INFO] Training model: epoch 20 - 8000/20505 samples\n",
      "Train on 2428 samples, validate on 580 samples\n",
      "Epoch 1/1\n",
      "2428/2428 [==============================] - 23s 10ms/step - loss: 1.0199 - val_loss: 2.9591\n",
      "[INFO] Training model: epoch 20 - 8250/20505 samples\n",
      "Train on 2456 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 23s 9ms/step - loss: 1.0000 - val_loss: 2.7896\n",
      "[INFO] Training model: epoch 20 - 8500/20505 samples\n",
      "Train on 2417 samples, validate on 640 samples\n",
      "Epoch 1/1\n",
      "2417/2417 [==============================] - 23s 10ms/step - loss: 0.9377 - val_loss: 2.9389\n",
      "[INFO] Training model: epoch 20 - 8750/20505 samples\n",
      "Train on 2433 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2433/2433 [==============================] - 23s 10ms/step - loss: 0.9886 - val_loss: 2.9208\n",
      "[INFO] Training model: epoch 20 - 9000/20505 samples\n",
      "Train on 2340 samples, validate on 604 samples\n",
      "Epoch 1/1\n",
      "2340/2340 [==============================] - 23s 10ms/step - loss: 0.9615 - val_loss: 2.9226\n",
      "[INFO] Training model: epoch 20 - 9250/20505 samples\n",
      "Train on 2580 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2580/2580 [==============================] - 24s 9ms/step - loss: 0.9418 - val_loss: 2.7592\n",
      "[INFO] Training model: epoch 20 - 9500/20505 samples\n",
      "Train on 2380 samples, validate on 585 samples\n",
      "Epoch 1/1\n",
      "2380/2380 [==============================] - 22s 9ms/step - loss: 1.0275 - val_loss: 2.7439\n",
      "[INFO] Training model: epoch 20 - 9750/20505 samples\n",
      "Train on 2457 samples, validate on 635 samples\n",
      "Epoch 1/1\n",
      "2457/2457 [==============================] - 23s 9ms/step - loss: 0.9699 - val_loss: 2.8970\n",
      "[INFO] Training model: epoch 20 - 10000/20505 samples\n",
      "Train on 2494 samples, validate on 645 samples\n",
      "Epoch 1/1\n",
      "2494/2494 [==============================] - 24s 10ms/step - loss: 1.0251 - val_loss: 3.3458\n",
      "[INFO] Training model: epoch 20 - 10250/20505 samples\n",
      "Train on 2471 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2471/2471 [==============================] - 24s 10ms/step - loss: 1.0047 - val_loss: 2.8272\n",
      "[INFO] Training model: epoch 20 - 10500/20505 samples\n",
      "Train on 2389 samples, validate on 577 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.0217 - val_loss: 3.0992\n",
      "[INFO] Training model: epoch 20 - 10750/20505 samples\n",
      "Train on 2405 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2405/2405 [==============================] - 23s 10ms/step - loss: 1.0618 - val_loss: 3.2234\n",
      "[INFO] Training model: epoch 20 - 11000/20505 samples\n",
      "Train on 2533 samples, validate on 589 samples\n",
      "Epoch 1/1\n",
      "2533/2533 [==============================] - 24s 9ms/step - loss: 0.9685 - val_loss: 2.9900\n",
      "[INFO] Training model: epoch 20 - 11250/20505 samples\n",
      "Train on 2476 samples, validate on 634 samples\n",
      "Epoch 1/1\n",
      "2476/2476 [==============================] - 24s 10ms/step - loss: 1.0137 - val_loss: 2.9637\n",
      "[INFO] Training model: epoch 20 - 11500/20505 samples\n",
      "Train on 2389 samples, validate on 636 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 0.9836 - val_loss: 2.8098\n",
      "[INFO] Training model: epoch 20 - 11750/20505 samples\n",
      "Train on 2477 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2477/2477 [==============================] - 23s 9ms/step - loss: 0.9760 - val_loss: 3.0091\n",
      "[INFO] Training model: epoch 20 - 12000/20505 samples\n",
      "Train on 2456 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2456/2456 [==============================] - 24s 10ms/step - loss: 1.0020 - val_loss: 3.0511\n",
      "[INFO] Training model: epoch 20 - 12250/20505 samples\n",
      "Train on 2473 samples, validate on 582 samples\n",
      "Epoch 1/1\n",
      "2473/2473 [==============================] - 23s 9ms/step - loss: 1.0514 - val_loss: 2.9545\n",
      "[INFO] Training model: epoch 20 - 12500/20505 samples\n",
      "Train on 2389 samples, validate on 588 samples\n",
      "Epoch 1/1\n",
      "2389/2389 [==============================] - 22s 9ms/step - loss: 1.0055 - val_loss: 2.9810\n",
      "[INFO] Training model: epoch 20 - 12750/20505 samples\n",
      "Train on 2500 samples, validate on 615 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 10ms/step - loss: 0.9591 - val_loss: 2.8290\n",
      "[INFO] Training model: epoch 20 - 13000/20505 samples\n",
      "Train on 2439 samples, validate on 624 samples\n",
      "Epoch 1/1\n",
      "2439/2439 [==============================] - 24s 10ms/step - loss: 1.0339 - val_loss: 2.6524\n",
      "[INFO] Training model: epoch 20 - 13250/20505 samples\n",
      "Train on 2446 samples, validate on 649 samples\n",
      "Epoch 1/1\n",
      "2446/2446 [==============================] - 24s 10ms/step - loss: 1.0551 - val_loss: 2.5736\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[INFO] Training model: epoch 20 - 13500/20505 samples\n",
      "Train on 2423 samples, validate on 603 samples\n",
      "Epoch 1/1\n",
      "2423/2423 [==============================] - 23s 10ms/step - loss: 1.0256 - val_loss: 2.7173\n",
      "[INFO] Training model: epoch 20 - 13750/20505 samples\n",
      "Train on 2512 samples, validate on 616 samples\n",
      "Epoch 1/1\n",
      "2512/2512 [==============================] - 24s 10ms/step - loss: 1.0480 - val_loss: 3.1636\n",
      "[INFO] Training model: epoch 20 - 14000/20505 samples\n",
      "Train on 2441 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2441/2441 [==============================] - 23s 10ms/step - loss: 1.0378 - val_loss: 2.8572\n",
      "[INFO] Training model: epoch 20 - 14250/20505 samples\n",
      "Train on 2316 samples, validate on 605 samples\n",
      "Epoch 1/1\n",
      "2316/2316 [==============================] - 22s 10ms/step - loss: 1.0007 - val_loss: 2.7598\n",
      "[INFO] Training model: epoch 20 - 14500/20505 samples\n",
      "Train on 2519 samples, validate on 612 samples\n",
      "Epoch 1/1\n",
      "2519/2519 [==============================] - 24s 9ms/step - loss: 1.0588 - val_loss: 2.6922\n",
      "[INFO] Training model: epoch 20 - 14750/20505 samples\n",
      "Train on 2357 samples, validate on 586 samples\n",
      "Epoch 1/1\n",
      "2357/2357 [==============================] - 22s 9ms/step - loss: 1.0280 - val_loss: 2.8910\n",
      "[INFO] Training model: epoch 20 - 15000/20505 samples\n",
      "Train on 2475 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2475/2475 [==============================] - 24s 10ms/step - loss: 1.0677 - val_loss: 3.1557\n",
      "[INFO] Training model: epoch 20 - 15250/20505 samples\n",
      "Train on 2609 samples, validate on 660 samples\n",
      "Epoch 1/1\n",
      "2609/2609 [==============================] - 25s 10ms/step - loss: 1.0872 - val_loss: 2.7097\n",
      "[INFO] Training model: epoch 20 - 15500/20505 samples\n",
      "Train on 2500 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2500/2500 [==============================] - 24s 10ms/step - loss: 0.9392 - val_loss: 2.8872\n",
      "[INFO] Training model: epoch 20 - 15750/20505 samples\n",
      "Train on 2351 samples, validate on 608 samples\n",
      "Epoch 1/1\n",
      "2351/2351 [==============================] - 22s 9ms/step - loss: 1.0663 - val_loss: 2.4584\n",
      "[INFO] Training model: epoch 20 - 16000/20505 samples\n",
      "Train on 2499 samples, validate on 637 samples\n",
      "Epoch 1/1\n",
      "2499/2499 [==============================] - 24s 10ms/step - loss: 1.0225 - val_loss: 2.6461\n",
      "[INFO] Training model: epoch 20 - 16250/20505 samples\n",
      "Train on 2469 samples, validate on 576 samples\n",
      "Epoch 1/1\n",
      "2469/2469 [==============================] - 24s 10ms/step - loss: 1.0650 - val_loss: 3.0242\n",
      "[INFO] Training model: epoch 20 - 16500/20505 samples\n",
      "Train on 2454 samples, validate on 632 samples\n",
      "Epoch 1/1\n",
      "2454/2454 [==============================] - 24s 10ms/step - loss: 1.0914 - val_loss: 2.9343\n",
      "[INFO] Training model: epoch 20 - 16750/20505 samples\n",
      "Train on 2459 samples, validate on 617 samples\n",
      "Epoch 1/1\n",
      "2459/2459 [==============================] - 24s 10ms/step - loss: 1.1257 - val_loss: 2.6547\n",
      "[INFO] Training model: epoch 20 - 17000/20505 samples\n",
      "Train on 2529 samples, validate on 641 samples\n",
      "Epoch 1/1\n",
      "2529/2529 [==============================] - 24s 10ms/step - loss: 1.0780 - val_loss: 2.7337\n",
      "[INFO] Training model: epoch 20 - 17250/20505 samples\n",
      "Train on 2400 samples, validate on 633 samples\n",
      "Epoch 1/1\n",
      "2400/2400 [==============================] - 23s 10ms/step - loss: 1.0419 - val_loss: 2.9985\n",
      "[INFO] Training model: epoch 20 - 17500/20505 samples\n",
      "Train on 2546 samples, validate on 602 samples\n",
      "Epoch 1/1\n",
      "2546/2546 [==============================] - 24s 9ms/step - loss: 1.0504 - val_loss: 2.9189\n",
      "[INFO] Training model: epoch 20 - 17750/20505 samples\n",
      "Train on 2478 samples, validate on 549 samples\n",
      "Epoch 1/1\n",
      "2478/2478 [==============================] - 23s 9ms/step - loss: 1.0307 - val_loss: 2.5250\n",
      "[INFO] Training model: epoch 20 - 18000/20505 samples\n",
      "Train on 2369 samples, validate on 567 samples\n",
      "Epoch 1/1\n",
      "2369/2369 [==============================] - 23s 10ms/step - loss: 1.0685 - val_loss: 2.6356\n",
      "[INFO] Training model: epoch 20 - 18250/20505 samples\n",
      "Train on 2464 samples, validate on 600 samples\n",
      "Epoch 1/1\n",
      "2464/2464 [==============================] - 24s 10ms/step - loss: 1.0587 - val_loss: 2.7259\n",
      "[INFO] Training model: epoch 20 - 18500/20505 samples\n",
      "Train on 2440 samples, validate on 619 samples\n",
      "Epoch 1/1\n",
      "2440/2440 [==============================] - 23s 9ms/step - loss: 1.0634 - val_loss: 3.1154\n",
      "[INFO] Training model: epoch 20 - 18750/20505 samples\n",
      "Train on 2492 samples, validate on 659 samples\n",
      "Epoch 1/1\n",
      "2492/2492 [==============================] - 24s 10ms/step - loss: 1.0790 - val_loss: 2.7095\n",
      "[INFO] Training model: epoch 20 - 19000/20505 samples\n",
      "Train on 2520 samples, validate on 593 samples\n",
      "Epoch 1/1\n",
      "2520/2520 [==============================] - 24s 9ms/step - loss: 1.0600 - val_loss: 2.6155\n",
      "[INFO] Training model: epoch 20 - 19250/20505 samples\n",
      "Train on 2466 samples, validate on 599 samples\n",
      "Epoch 1/1\n",
      "2466/2466 [==============================] - 23s 10ms/step - loss: 1.0733 - val_loss: 2.6178\n",
      "[INFO] Training model: epoch 20 - 19500/20505 samples\n",
      "Train on 2479 samples, validate on 609 samples\n",
      "Epoch 1/1\n",
      "2479/2479 [==============================] - 24s 10ms/step - loss: 1.0512 - val_loss: 2.6358\n",
      "[INFO] Training model: epoch 20 - 19750/20505 samples\n",
      "Train on 2402 samples, validate on 653 samples\n",
      "Epoch 1/1\n",
      "2402/2402 [==============================] - 24s 10ms/step - loss: 1.0468 - val_loss: 2.4997\n",
      "[INFO] Training model: epoch 20 - 20000/20505 samples\n",
      "Train on 2452 samples, validate on 662 samples\n",
      "Epoch 1/1\n",
      "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1216 - val_loss: 2.6810\n",
      "[INFO] Training model: epoch 20 - 20250/20505 samples\n",
      "Train on 2506 samples, validate on 607 samples\n",
      "Epoch 1/1\n",
      "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1131 - val_loss: 2.7156\n",
      "[INFO] Training model: epoch 20 - 20500/20505 samples\n",
      "Train on 39 samples, validate on 22 samples\n",
      "Epoch 1/1\n",
      "39/39 [==============================] - 1s 13ms/step - loss: 0.8315 - val_loss: 3.1535\n"
     ]
    }
   ],
   "source": [
    "# Continue from loaded epoch number or new epoch if not loaded\n",
    "for k in range(k_start, NB_EPOCH+1):\n",
    "    # Shuffling the training data every epoch to avoid local minima\n",
    "    indices = np.arange(num_examples)\n",
    "    np.random.shuffle(indices)\n",
    "    X_train = X_train[indices]\n",
    "    Y_train = Y_train[indices]\n",
    "    indices = np.arange(num_test)\n",
    "    np.random.shuffle(indices)\n",
    "    X_test = X_test[indices]\n",
    "    Y_test = Y_test[indices]\n",
    "\n",
    "    # This for loop rotates through NB_SET samples at a time to avoid memory issues\n",
    "    # E.g. Training 100 sequences at a time\n",
    "    for i in range(0, num_examples, NB_SET):\n",
    "        if i + NB_SET >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + NB_SET\n",
    "        \n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "            \n",
    "        I_1_train, I_2_train, Y_set_train = generate_set(X_train, Y_train, i_end, i)\n",
    "        I_1_test, I_2_test, Y_set_test = generate_set(X_test, Y_test, i_test_end, i_test)\n",
    "              \n",
    "        print('[INFO] Training model: epoch {} - {}/{} samples'.format(k, i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size=BATCH_SIZE, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "        # Get history and apppend new data to running set here\n",
    "    model.save_weights('v2_kerascheckpoint_epoch_{}.hdf5'.format(k))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "[INFO] Training model: epoch 20 - 20000/20505 samples\n",
    "Train on 2452 samples, validate on 662 samples\n",
    "Epoch 1/1\n",
    "2452/2452 [==============================] - 23s 9ms/step - loss: 1.1216 - val_loss: 2.6810\n",
    "[INFO] Training model: epoch 20 - 20250/20505 samples\n",
    "Train on 2506 samples, validate on 607 samples\n",
    "Epoch 1/1\n",
    "2506/2506 [==============================] - 24s 10ms/step - loss: 1.1131 - val_loss: 2.7156\n",
    "[INFO] Training model: epoch 20 - 20500/20505 samples\n",
    "Train on 39 samples, validate on 22 samples\n",
    "Epoch 1/1\n",
    "39/39 [==============================] - 1s 13ms/step - loss: 0.8315 - val_loss: 3.1535\n",
    "```\n",
    "\n",
    "So using the shared embedding appears to provide a small advantage in reducing our loss function. It also lowers the number of parameters for our model, which is a good thing as it reduces over-fitting and training time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f9416ff6d30>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've trained our model we need some code to test it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: 1 a method comprising determining by a media device that a smart card has been communicatively coupled to the media device communicating by the media device with the smart card through a smart card in\n",
      "\n",
      "Predicted title is: method and apparatus for providing a mobile device mobile terminal  (with prob 4.6621154170702336e-06). \n",
      " Test title is: module id based encryption for financial transactions  \n",
      "---\n",
      "Sample of claim text: 1 a processing device comprising a cpu a first interface for performing data transfer with an external terminal device in synchronization with an external clock supplied from the external terminal dev\n",
      "\n",
      "Predicted title is: method and apparatus for power management power management power management  (with prob 0.00015047525079029634). \n",
      " Test title is: processing device and clock control method  \n",
      "---\n",
      "Sample of claim text: 1 a touch controlled electronic apparatus comprising a loading plate having a display touch area a wire area and a first hot area a touch panel disposed on the display touch area of the loading plate \n",
      "\n",
      "Predicted title is: touch panel and display device touch panel touch panel and display panel display  (with prob 0.0013282932321973912). \n",
      " Test title is: touch controlled electronic apparatus and related assembly method  \n",
      "---\n",
      "Sample of claim text: 1 a method of allocating memory the method comprising receiving a first memory allocation request specifying a first amount of memory receiving a second memory allocation request simultaneously with t\n",
      "\n",
      "Predicted title is: method and apparatus for performing a memory memory memory memory  (with prob 5.709919106958785e-06). \n",
      " Test title is: parallel dynamic memory allocation using a lock free only  \n",
      "---\n",
      "Sample of claim text: 1 a method for delivering ordered data updates from a plurality of data sources the method comprising receiving at a computer system data updates from a plurality of data sources assigning by the comp\n",
      "\n",
      "Predicted title is: method and system for generating a data data data data  (with prob 3.501261300041264e-05). \n",
      " Test title is: systems and methods for providing ordered update delivery  \n",
      "---\n"
     ]
    }
   ],
   "source": [
    "# Set up dictionary to translate indices to words\n",
    "y_dictionary = dict(\n",
    "            (i, char) for char, i in t_joint.word_index.items()\n",
    "        )\n",
    "\n",
    "x_dictionary = dict(\n",
    "            (i, char) for char, i in t_joint.word_index.items()\n",
    "        )\n",
    "\n",
    "def seq2text(seq, dictionary):\n",
    "    text = ''\n",
    "    for k in seq:\n",
    "        k = k.astype(int)\n",
    "        # Adapted to take account of different control integers\n",
    "        if k not in [t_joint.word_index[\"stopseq\"], t_joint.word_index[\"startseq\"], 0] and k < (len(dictionary)-1):\n",
    "            w = dictionary[k]\n",
    "            text = text + w + ' '\n",
    "    return text\n",
    "\n",
    "def greedy_decoder(X_seq):\n",
    "    # reformat input seq\n",
    "    input_seq = np.zeros((1, X_max_len))\n",
    "    input_seq[0, :] = X_seq\n",
    "    flag = 0\n",
    "    prob = 1\n",
    "    ans_partial = np.zeros((1, y_max_len))\n",
    "    # Add start token integer to end of ans_partial input - initially [0,0,...BOS]\n",
    "    ans_partial[0, -1] = t_joint.word_index[\"startseq\"]  #  the index of the symbol BOS (begin of sentence)\n",
    "    for k in range(y_max_len - 1):\n",
    "        ye = model.predict([input_seq, ans_partial])\n",
    "        yel = ye[0,:]\n",
    "        p = np.max(yel)\n",
    "        mp = np.argmax(ye)\n",
    "        # It is this line that sets how our training data should be arranged - need to change both\n",
    "        # the line below shifts the existing ans_partial by 1 to the left - [0, 0, ..., BOS, 0]\n",
    "        ans_partial[0, 0:-1] = ans_partial[0, 1:]\n",
    "        # This then adds the newly decoded word onto the end of ans_partial\n",
    "        ans_partial[0, -1] = mp\n",
    "        if mp == t_joint.word_index[\"stopseq\"]:  #  the index of the symbol EOS (end of sentence)\n",
    "            flag = 1\n",
    "        if flag == 0:    \n",
    "            prob = prob * p\n",
    "    text = seq2text(ans_partial[0], y_dictionary)\n",
    "    return(text, prob)\n",
    "\n",
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    text, prob = greedy_decoder(X_test[i])\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {} (with prob {}). \\n Test title is: {} \\n---\".format(text, prob, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Results\n",
    "\n",
    "*** Possibly scrap this - there was an error in the get dataset code! ***\n",
    "\n",
    "From this training there now appears more of a link between the claim text and the predicted title. The model seems to be learning a few patterns such as - \"method and system for creating a [] method and system method\". \n",
    "\n",
    "This result seems close:\n",
    "```\n",
    "Sample of claim text: 1 an apparatus comprising a capacitive sense array and a processing device wherein the capacitive sense array is configured to detect a presence of a touch object or a stylus wherein the capacitive se\n",
    "\n",
    "Predicted title is: method and apparatus for displaying a touch screen method and apparatus for the same  (with prob 1.9565373226245597e-05). \n",
    " Test title is: capacitive sense array for detecting touch objects and an active stylus  \n",
    " ```\n",
    " \n",
    " Training still appears unstable. Some of this may be due to the shuffling for regularisation.\n",
    " \n",
    " The results appear an improvement though on the previous model. It is worth keeping this feature."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options for Further Investigation\n",
    "\n",
    "It may be worth experimenting with different training parameters and not shuffling the data. Lowering the batch size might reduce some of the loss variance.\n",
    "\n",
    "\n",
    "Also adding some regularisation may help prevent overfitting. Maybe by adding some dropout (0.2?) to the LSTMs and by adding an L2 regulariser to the dense layer."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Chollet/Brownlee Model\n",
    "\n",
    "This is more of a true sequence-to-sequence model, and is thus slightly more involved.\n",
    "\n",
    "Our model consists of two portions - a portion for training and a portion for inference (i.e. for actually predicting new titles)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "from random import randint\n",
    "from numpy import array\n",
    "from numpy import argmax\n",
    "from numpy import array_equal\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Model\n",
    "from keras.layers import Input\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense\n",
    "\n",
    "def target_one_hot(input_seqs, seq_max_len, vocab_len):\n",
    "    \"\"\" Convert a sequence of integers to a one element shifted sequence of one-hot vectors.\"\"\"\n",
    "    one_hot_out = np.zeros((len(input_seqs), seq_max_len, vocab_len))\n",
    "    for i, sequence in enumerate(input_seqs):\n",
    "        for t, word_int in enumerate(sequence):\n",
    "            if t > 0:\n",
    "                # Shift decoder target get so it is one ahead\n",
    "                one_hot_out[i, t-1, word_int] = 1\n",
    "    return one_hot_out\n",
    "\n",
    "# We need to convert this for our present problem - this is similar to our generate dataset above\n",
    "# prepare data for the LSTM\n",
    "def get_dataset(X, Y, i, i_end, num_decoder_tokens):\n",
    "    \"\"\"Return encoder_input_data, decoder_input_data, and decoder_target_data, latter as one-hot\"\"\"\n",
    "    encoder_input_data = X[i:i_end]\n",
    "    decoder_input_data = Y[i:i_end]\n",
    "    decoder_target_data = target_one_hot(decoder_input_data, Y.shape[1], num_decoder_tokens)\n",
    "    return encoder_input_data, decoder_input_data, decoder_target_data\n",
    "\n",
    "# returns train, inference_encoder and inference_decoder models\n",
    "def define_models(vocab_size, latent_dim, embedding_matrix):\n",
    "    # define training encoder\n",
    "    # Define an input sequence and process it.\n",
    "    encoder_inputs = Input(shape=(None,))\n",
    "    Shared_Embedding = Embedding(\n",
    "        output_dim=latent_dim, \n",
    "        input_dim=vocab_size, \n",
    "        weights=[embedding_matrix]\n",
    "    )\n",
    "    encoder_embedding = Shared_Embedding(encoder_inputs)\n",
    "    encoder_outputs, state_h, state_c = LSTM(latent_dim, return_state=True)(encoder_embedding)\n",
    "    encoder_states = [state_h, state_c]\n",
    "\n",
    "    # Set up the decoder, using `encoder_states` as initial state.\n",
    "    decoder_inputs = Input(shape=(None,))\n",
    "    # Possibly share the embedding below\n",
    "    decoder_embedding = Shared_Embedding(decoder_inputs)\n",
    "    decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "    decoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n",
    "    decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "\n",
    "    # Define the model that will turn\n",
    "    # `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "    model = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "    # define inference encoder\n",
    "    encoder_model = Model(encoder_inputs, encoder_states)\n",
    "    # define inference decoder\n",
    "    decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "    decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "    decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "    # Need to adjust this line for the embedding\n",
    "    decoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\n",
    "    decoder_states = [state_h, state_c]\n",
    "    decoder_outputs = decoder_dense(decoder_outputs)\n",
    "    decoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)\n",
    "    # return all models\n",
    "    return model, encoder_model, decoder_model\n",
    "\n",
    "def train_model(X_train, Y_train, X_test, Y_test, model, set_size, batch_size, num_decoder_tokens):\n",
    "    \"\"\" Code to train model in sets of set_size.\"\"\"\n",
    "    num_examples = len(X_train)\n",
    "    num_test = len(X_test)\n",
    "    train_loss = []\n",
    "    val_loss = []\n",
    "    # Loop here to avoid memory issues with the target one hot vector\n",
    "    for i in range(0, num_examples, set_size):\n",
    "        if i + set_size >= num_examples:\n",
    "            i_end = num_examples\n",
    "        else:\n",
    "            i_end = i + set_size\n",
    "        # Generate a range for the test data\n",
    "        i_test = math.floor(i * (num_test/num_examples))\n",
    "        i_test_end = math.floor(i_end * (num_test/num_examples))\n",
    "        # Generate small sets of train and test data\n",
    "        I_1_train, I_2_train, Y_set_train = get_dataset(X_train, Y_train, i, i_end, num_decoder_tokens)\n",
    "        I_1_test, I_2_test, Y_set_test = get_dataset(X_test, Y_test, i_test, i_test_end, num_decoder_tokens)\n",
    "        print('[INFO] Training model: {}/{} samples'.format(i, num_examples))\n",
    "        callback = model.fit(\n",
    "            [I_1_train, I_2_train], \n",
    "            Y_set_train, \n",
    "            validation_data=([I_1_test, I_2_test], Y_set_test),\n",
    "            batch_size= batch_size, \n",
    "            epochs=1\n",
    "        )\n",
    "        train_loss += callback.history['loss']\n",
    "        val_loss += callback.history['val_loss']\n",
    "    return model, train_loss, val_loss\n",
    "\n",
    "# define model\n",
    "train, infenc, infdec = define_models(vocab_size, word_embedding_size, embedding_matrix)\n",
    "train.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['acc'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_4 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "input_3 (InputLayer)            (None, None)         0                                            \n",
      "__________________________________________________________________________________________________\n",
      "embedding_2 (Embedding)         (None, None, 100)    250000      input_3[0][0]                    \n",
      "                                                                 input_4[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lstm_3 (LSTM)                   [(None, 100), (None, 80400       embedding_2[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "lstm_4 (LSTM)                   [(None, None, 100),  80400       embedding_2[1][0]                \n",
      "                                                                 lstm_3[0][1]                     \n",
      "                                                                 lstm_3[0][2]                     \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, None, 2500)   252500      lstm_4[0][0]                     \n",
      "==================================================================================================\n",
      "Total params: 663,300\n",
      "Trainable params: 663,300\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "train.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--------\n",
      " Epoch -  0\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 82s 16ms/step - loss: 1.3725 - acc: 0.7448 - val_loss: 1.7861 - val_acc: 0.7027\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 84s 17ms/step - loss: 1.3737 - acc: 0.7435 - val_loss: 1.7589 - val_acc: 0.7081\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3650 - acc: 0.7461 - val_loss: 1.7568 - val_acc: 0.7059\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3451 - acc: 0.7480 - val_loss: 1.7507 - val_acc: 0.7123\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 7s 16ms/step - loss: 1.3241 - acc: 0.7517 - val_loss: 1.8438 - val_acc: 0.7028\n",
      "\n",
      "--------\n",
      " Epoch -  1\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3540 - acc: 0.7466 - val_loss: 1.7954 - val_acc: 0.7037\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 1.3543 - acc: 0.7455 - val_loss: 1.7682 - val_acc: 0.7069\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3461 - acc: 0.7478 - val_loss: 1.7668 - val_acc: 0.7059\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3257 - acc: 0.7500 - val_loss: 1.7582 - val_acc: 0.7105\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 7s 16ms/step - loss: 1.3035 - acc: 0.7544 - val_loss: 1.8474 - val_acc: 0.6994\n",
      "\n",
      "--------\n",
      " Epoch -  2\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.3346 - acc: 0.7485 - val_loss: 1.8030 - val_acc: 0.7032\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3357 - acc: 0.7480 - val_loss: 1.7726 - val_acc: 0.7069\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3261 - acc: 0.7496 - val_loss: 1.7745 - val_acc: 0.7055\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3060 - acc: 0.7528 - val_loss: 1.7639 - val_acc: 0.7117\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 7s 16ms/step - loss: 1.2814 - acc: 0.7556 - val_loss: 1.8607 - val_acc: 0.6977\n",
      "\n",
      "--------\n",
      " Epoch -  3\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.3154 - acc: 0.7506 - val_loss: 1.8116 - val_acc: 0.7018\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 90s 18ms/step - loss: 1.3182 - acc: 0.7493 - val_loss: 1.7804 - val_acc: 0.7065\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.3084 - acc: 0.7511 - val_loss: 1.7823 - val_acc: 0.7052\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2864 - acc: 0.7547 - val_loss: 1.7725 - val_acc: 0.7109\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 7s 17ms/step - loss: 1.2620 - acc: 0.7606 - val_loss: 1.8603 - val_acc: 0.7024\n",
      "\n",
      "--------\n",
      " Epoch -  4\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2959 - acc: 0.7525 - val_loss: 1.8224 - val_acc: 0.7015\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2991 - acc: 0.7515 - val_loss: 1.7889 - val_acc: 0.7056\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 85s 17ms/step - loss: 1.2897 - acc: 0.7536 - val_loss: 1.7939 - val_acc: 0.7050\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2691 - acc: 0.7564 - val_loss: 1.7883 - val_acc: 0.7107\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 1.2425 - acc: 0.7617 - val_loss: 1.8748 - val_acc: 0.6994\n",
      "\n",
      "--------\n",
      " Epoch -  5\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2791 - acc: 0.7549 - val_loss: 1.8285 - val_acc: 0.7009\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 90s 18ms/step - loss: 1.2804 - acc: 0.7540 - val_loss: 1.7985 - val_acc: 0.7069\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 89s 18ms/step - loss: 1.2710 - acc: 0.7560 - val_loss: 1.8045 - val_acc: 0.7037\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 90s 18ms/step - loss: 1.2514 - acc: 0.7579 - val_loss: 1.7953 - val_acc: 0.7101\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 1.2280 - acc: 0.7637 - val_loss: 1.8877 - val_acc: 0.6973\n",
      "\n",
      "--------\n",
      " Epoch -  6\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 89s 18ms/step - loss: 1.2617 - acc: 0.7572 - val_loss: 1.8394 - val_acc: 0.7012\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2635 - acc: 0.7557 - val_loss: 1.8104 - val_acc: 0.7043\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.2535 - acc: 0.7577 - val_loss: 1.8103 - val_acc: 0.7036\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 86s 17ms/step - loss: 1.2328 - acc: 0.7603 - val_loss: 1.8069 - val_acc: 0.7084\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 7s 17ms/step - loss: 1.2100 - acc: 0.7662 - val_loss: 1.9022 - val_acc: 0.6973\n",
      "\n",
      "--------\n",
      " Epoch -  7\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2437 - acc: 0.7587 - val_loss: 1.8531 - val_acc: 0.7008\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.2468 - acc: 0.7578 - val_loss: 1.8198 - val_acc: 0.7050\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 93s 19ms/step - loss: 1.2379 - acc: 0.7594 - val_loss: 1.8221 - val_acc: 0.7036\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2153 - acc: 0.7628 - val_loss: 1.8194 - val_acc: 0.7079\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 8s 20ms/step - loss: 1.1902 - acc: 0.7663 - val_loss: 1.9142 - val_acc: 0.6985\n",
      "\n",
      "--------\n",
      " Epoch -  8\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 87s 17ms/step - loss: 1.2260 - acc: 0.7611 - val_loss: 1.8655 - val_acc: 0.6996\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.2317 - acc: 0.7594 - val_loss: 1.8317 - val_acc: 0.7036\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.2206 - acc: 0.7613 - val_loss: 1.8321 - val_acc: 0.7031\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 89s 18ms/step - loss: 1.1990 - acc: 0.7646 - val_loss: 1.8356 - val_acc: 0.7081\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 8s 18ms/step - loss: 1.1742 - acc: 0.7680 - val_loss: 1.9237 - val_acc: 0.6981\n",
      "\n",
      "--------\n",
      " Epoch -  9\n",
      "[INFO] Training model: 0/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 90s 18ms/step - loss: 1.2092 - acc: 0.7635 - val_loss: 1.8768 - val_acc: 0.6985\n",
      "[INFO] Training model: 5000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 88s 18ms/step - loss: 1.2145 - acc: 0.7622 - val_loss: 1.8442 - val_acc: 0.7035\n",
      "[INFO] Training model: 10000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 89s 18ms/step - loss: 1.2038 - acc: 0.7641 - val_loss: 1.8421 - val_acc: 0.7036\n",
      "[INFO] Training model: 15000/20423 samples\n",
      "Train on 5000 samples, validate on 1250 samples\n",
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 89s 18ms/step - loss: 1.1822 - acc: 0.7671 - val_loss: 1.8415 - val_acc: 0.7073\n",
      "[INFO] Training model: 20000/20423 samples\n",
      "Train on 423 samples, validate on 106 samples\n",
      "Epoch 1/1\n",
      "423/423 [==============================] - 8s 19ms/step - loss: 1.1642 - acc: 0.7720 - val_loss: 1.9424 - val_acc: 0.6990\n"
     ]
    }
   ],
   "source": [
    "# setup variables\n",
    "epochs = 10\n",
    "batch_size = 64\n",
    "set_size = 5000\n",
    "\n",
    "for e in range(0, epochs):\n",
    "    print(\"\\n--------\\n Epoch - \", e)\n",
    "    train, tl, vl = train_model(X_train, Y_train, X_test, Y_test, train, set_size, batch_size, num_decoder_tokens)\n",
    "    train_loss += tl\n",
    "    val_loss += vl\n",
    "    model.save_weights(\"chollet_weights_v2.hdf5\", overwrite=True)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have some data from a previous model iteration to remove\n",
    "train_loss = train_loss[82:]\n",
    "val_loss = val_loss[82:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7fbe3112f6d8>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# summarize history for accuracy\n",
    "plt.plot(train_loss)\n",
    "plt.plot(val_loss)\n",
    "plt.title('Model Loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Iteration')\n",
    "plt.legend(['train', 'test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So here we want to stop after around 50 iterations - this is where our training and test loss diverge and marks where over-fitting begins."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We then need the inference code to allow prediction and decoding.\n",
    "\n",
    "The general pattern is as follows:\n",
    "* Predict the state with infenc using an input X vector.\n",
    "* Create an initial target vector - is this 0s with first entry the startseq token 1? In the one-hot case, it's a one-hot encoding of one character - would our equivalent just be `array([1])`\n",
    "* while stop condition is false, where stop condition = len=max_y_len or token=2=stopseq\n",
    "    * use infdec to predict yhat and return the state of the decoder h and c \n",
    "    * remember the yhat \n",
    "    * set yhat as the next target sequence and pass generated state\n",
    "    \n",
    "I.e. I think we can similar code to Brownlee's or Chollet's model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "I_1_train, I_2_train, Y_set_train = get_dataset(X_train, Y_train, 100, 0, num_decoder_tokens)\n",
    "I_1_test, I_2_test, Y_set_test = get_dataset(X_test, Y_test, 10, 0, num_decoder_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 300) (0, 22) (0, 22, 2500)\n",
      "(0, 300) (0, 22) (0, 22, 2500)\n"
     ]
    }
   ],
   "source": [
    "print(I_1_train.shape, I_2_train.shape, Y_set_train.shape)\n",
    "print(I_1_test.shape, I_2_test.shape, Y_set_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, decoder_seq_length):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([1])\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(decoder_seq_length):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence - this needs to be the argmax\n",
    "        next_int = argmax(yhat[0, 0, :])\n",
    "        output.append(next_int)\n",
    "        # It seems like we throw a lot of information away here - can we build in the probabilities?\n",
    "        target_seq = array([next_int])\n",
    "        # Check for stopping character\n",
    "        if next_int == 2:\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: method for authenticating an identity of cardholder in financial transaction initiated by cardholder with merchant via first communication medium, said method comprising receiving purchase authenticat\n",
      "\n",
      "Predicted title is: a more more dimensional more more more more more more more dimensional dimensional more more more more more dimensional dimensional more more . \n",
      " Test title is: methods and systems for authenticating an identity of a in a financial transaction  \n",
      "---\n",
      "\n",
      "Sample of claim text: an array substrate including display area and peripheral area, wherein display area includes plurality of thin film transistors provided on base substrate, first transparent electrodes electrically co\n",
      "\n",
      "Predicted title is: a more more dimensional more more more more more more more dimensional dimensional more more more more more dimensional dimensional more more . \n",
      " Test title is: array substrate and manufacturing method thereof touch display device  \n",
      "---\n",
      "\n",
      "Sample of claim text: method for identifying conditional actions in business process comprising determining plurality of pairs of text fragments that respectively include text fragments that are similar according to pre-de\n",
      "\n",
      "Predicted title is: a more more dimensional more more more more more more more dimensional dimensional more more more more more dimensional dimensional more more . \n",
      " Test title is: identifying and conditional actions in business processes  \n",
      "---\n",
      "\n",
      "Sample of claim text: method of processing merchandise return comprising receiving request to merchandise return made by consumer at point of return determining with one or more computer processors whether to return made b\n",
      "\n",
      "Predicted title is: a more more dimensional more more more more more more more dimensional dimensional more more more more more dimensional dimensional more more . \n",
      " Test title is: systems and methods for data collection at a point of return  \n",
      "---\n",
      "\n",
      "Sample of claim text: method, comprising detecting, on touch screen of an information device, user input determining, using processor, that user input occurs within predetermined edge region of touch screen adjusting, usin\n",
      "\n",
      "Predicted title is: a more more dimensional more more more more more more more dimensional dimensional more more more more more dimensional dimensional more more . \n",
      " Test title is: detecting and filtering edge touch inputs  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "attachments": {
    "temperature.png": {
     "image/png": "iVBORw0KGgoAAAANSUhEUgAAAusAAAOBCAIAAADHg3niAAAAA3NCSVQICAjb4U/gAAAAGXRFWHRTb2Z0d2FyZQBnbm9tZS1zY3JlZW5zaG907wO/PgAAIABJREFUeJzsvX1cE1e++P+BpJlt6/BrN7m7EtoK3S3R1YAQiBDCszyKgAg+LCIr4i5FL4p7qfQrhSvFXiy9Wtxqda1Yq2gLYhVpsbgF3AXpFnCXh64EaxOsBEoTZJlgnDCB3x95IAkJD4oVvOf9yh8w+cw5Zz5P58w5JzNW1LASxkFRajqdNv64WZAwEkbCSBgJI2EkjIR/YmHrKZ6GQCAQCAQCMXtAIxgEAoFAIBBzDzSCQSAQCAQCMfdAIxgEAoFAIBBzDzSCQSAQCAQCMfdAIxgEAoFAIBBzDzSCQSAQCAQCMfdAIxgEAoFAIBBzDzSCQSAQCAQCMfdAIxgEAoFAIBBzD6v7SsXjbgMCgUAgEAjE9KCbfR/B7HwDAhJGwkgYCSNhJIyEkbAGtIqEQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7oFGMAgEAoFAIOYeaASDQCAQCARi7mF1X6l43G1AIBAIBAKBmB50s2+1np3v0UbCSBgJI2EkjISRMBLWgFaREAgEAoFAzD3QCAaBQCAQiJmFaCk9WS2dRIhsLTteM5kQwjJoBINAIBAIxIMhrytI25SckvzHj1oI/UGyo3j32xJXL/YkJ2NOnszy3H1NxCRyCAugEQwCgUAgEA+CrHzPazXMAI68+eonF0Xag2TroaxyxzfSuNjkBbCjd8d05+VWyh5pM59Y0AhmpmjI8hamXCYfdzNmF+I/reOtPSk2PTy3dCWvzosX8PmCXbUz22JxUbw55UzUkgvJQr+8ZjPfNO/z46eUyACgNoMvTKsBAHmJWeGm/OWC1JJHni4tmdhCq8YgLqQKBdkNj7Bp/1fQe8IEGPh2U74fP6X0p+tHH1VY6ahNm/zypw7ZUhjvl1w2Llrl1eXXSQ7P3c03NvG1zW6ag9KSgipW/PqFUxi/AACwfDd7SQ6faHtAPYj2h/CTTv2kK1GzKEifvBGMvCSBz+XHHxAZ+UN1+hQ0Lm0oudw5HTciOy6X1T14zJOiLz59iNMfkMHWigut0520lFQX13ZPvy726tyi3CD2g9c780y7GdKq4+Vyt9zKmn1+U8xIjwHHjYUf7AxgGR5iBmS8X5jkCABGjsrZuP/oDmPJnxLDVs1upp0NAABkTSfTwoXc6Pc6JpMk6/cIlsYdEBkcat0fslS4qVRuIFSb4c2PL35kvZOhb3M2Fn6w0/8nc4xHElaGCZmX/sH76W4zU+5gff5r55g78lc7mFbYVteqcuAuWei/bfd/+tppDoo+LpHy1oQwp1w85hwbgZUfq3782XEiiLbPZkMCN+HJG8EAAAPHek5nH+uYZvrprj+2r3xaOav9dMFH9Q+eXtqL9z/M6Q8GUX9i/+km+eSChogqDhy5Mp3ZAi0Y29GZw8YeuN6ZZ/rNIOSDwHTmMGfv8AUAcFtnJ0eT3ofF4TqzcQAwclSc7cQ1lfwpMWjVrGb62YBoLEyKzW62sZ9S14W5+XrhXfVNY/HfUdMgY0BrTfOg7gjZdLWReCVAMNlmigfG0Ldx9ngXeoQ8krAyTMi4gxPXYWYcrfN4wRV8087o8dqRtItV8xwcbA2PdZRflXJ83aZ1YQ6u7nh7Zf2sGx8YQNR/+O4sSOCmPJEjGHCI3RpGfJxV3Gn228HWs5m/WyXgC3n80JXJ+RfEJAB0FMVH7m1XXcv358cfFwOAvK4oIz48VMAXeq9MzihuGzQphazN8H71orzndLJQPxHKIK4X/3GjH5/P847aVNigvRkg2kqyk0K8hdylQkF4UlZpJ6k7/ZK81/B0AABo2xc+dh8mK03hLg3NbdJ+11IQxUuukAGQoorc1PgQbyGPH7oydX+11FymlTUcSI/342vqTckq7yRBXpIc9lqNQnRwAy88vxGAFFfkJsctF3hylwr91mac0g2xxUXxvISTlYVJfvyo3E/yQxI+khBXtvMDUsoNPFh6Nl6rKwAgq9MDuPyMam1DpMfXCmOLJLpVJNN6Nbo6lR5vqisj5I1FGbHhAbylfJ533Ka8KrGZqyQ7yvdsitbIhMamv6e7AyO7a/anrI0S8IU877jktz7rIAHMNcOgJGl1QdrKQOEyga8gPD6tqFkGAE35fgkfSVQ3310rFKRXGdVPVqXxAzLLPstNjo+NjvILjEsr0jiJvCRZuLKg4lRqFI+/u9pSybpr7CjdHRso5PIDQpLzK3XdGSmu2PuHdX58voldAABUPRfykkK8hVx+aOyuCu0wfWwVaaxk7XqNiaMarSKNObkgPGnMyQ08x3tlapZpR07W7QoYc1rxydil/JWFEu139bsF3rs1bmDOxEarSIOisqzkKAGfz/OOSykYm+RjgLy6MG2lt5DLD1iZfrbFTGLXqpS7lM8L1J8rPZUgDCloG9OA7l9xUTwv4b3K4t3xa+P8vENX7qroENfuS02KjQ71Xpm6r940L5tmg4ksqIcg2DFHPj242W0ew8y348B4AW4McY3e83sar/W4Rwax26426dTdUXNdbu/p5QAW/NkUUlSWsTaUxxcKolP21cgNRMwZ2sS3x1aRajP4oVnltQfSkzSOnVKoH1RNrRniitzkOPPeq8Gk6vo9An7aBb1U057lgh0XiIlbIq0rzIgNFPKWBoT/7o2SVmJcQjZYRdKZj8cXeq/cOGa+1nw/flpJ/cm0hPjY8FC/8JTcGjM9NNl09qJ0yZpIe6OjorNpCXErUz+WgKI+b0Ns8u5yiVbVrSI5m2NvYyArq9+fkpwUm5xfLe68kJeRkpqy8Xe7jhvt3nV04qham8Z3WG37woXJZZN0BwCgEpdlJYTy+PxlIcm5Yz9uMh/g+vS+XLAqtxVMzLopr2KcWeUlyWGvXzVO4OaDVFuUt8DXQlEzDTWsHP+5r1SYPT4XhO+cWceL/vBGf22m0GX90U7tt1XbePzXq6lhJdVTmuzBW5P3l16FklLcuvR6sHNQToNCSQ0ra1/3dN5S2j+spIaV7e/EOK/Yea69jxpW/vj1B8k+nsllt0wr7Spa6xK8t1nzb3WmB5e/Ytvhupv9ir6bZduEi4P3tiup4YGGHN9FQZlVXX3U8EDXpczAxbpTuorWuATpTtd/Bhpe9+XvrBwaVlLDfZe2eYatCI5+p4UaVt5Xth+N4a398BbVczHVxzPhnbouhZJS3KrKiXAOymlWmGhDXrXTk59Y1N6vpIb7uqpyoj1ijnYqqeGWghW86KM3qGHt38JtpTf6FJTiTu1bMc4+mbUKJTWs7PpwvbNHcPJb1V39fUPDyqFLW5xddtaaGqWlYAUvoewONaykhuuyfSLCVgRnNyi1SnaJ2NuuvPF2hHPMkZvDJvVqdXW04ZahrkzM3X9pG98lZm/DnaFhZX/n6VQf3toPb1Em5u48Eu0SkV17a2hYOdTz9YktvsKdlUPDyqGGnECPmOyqG/3DyqGeurfXegp3VvabNsNI7c1vBTv7bDvX3ndfqehtPpLgwUs4c4saVlLtBWEuMXpHMvhUprpwncN3VfUoqWHlUPPeaBffzNoBarjv3BYe32d99qUb/f0DE5R882jMIhfPta9fvNk/MNRTV7CO55x4uktvl9RPbvYrje1y51wiz9kjIv1MS69ioLe9KNmDG6bxjbo3hC6JZ3qU1HBlugsvtUpJDd85k8gT5tSZOmpDjtBl45keUyfvby7SOfmAoed8V/mGznOMTROU0zyspIaVvWcShSsihImne4eV95WK5reCnbdc7LdgYsNW3f/+01Qfz4SjdV39fb3tp1N9eNHvtGi05+wTk37m617FQH97UYIHb+2Ht0x8o7dsi7PPtnOdA9Swsr+zND3IM7nsDjV868Q6XuBbXxumgsC3vtb48yKX4HRNCHcVrXXh8WNyanuU1PBAS16E84qC9nH5xCAbWPYNc5+bR2M0BU6avvrLtji7bDnXr6SGlfe/P5Xgsv5EZ3Wmj8aLNG7A1bTfsj8bfBRfZwdxA3de7FIoqf6WMzsjnBfzUquU95UKC4Y29u2GHKFL4qnvFdRwdboH1zkmR+/YYYsjCtqVU22GLquYeK+pNgyrrs3k6/RADSuphkyhS/K5fuUELWl/J8I5aOel9jtD/be+zItx9thW1W+SkCtTtYEwZj5qWHnn68Nj5mveG7iYF7iztEuhMdx6fQI0TDLNbwU7ryvqMmfB5reCF3lkGifGukwfXnJZn4Fd6vZuO9KuqM704C7y2XKifYAaVv54Yauzx7ZL/QZF5QQ7J5b2jstLDa/7uqd/Nr47oIZvaLuD9r2Biz0Dt+yt6uwbUtyq3BWxyEN7FZbsrk/v3/X1jM+WBevMm/XtcH3mNB+khh7yo1JhuSjTz8OMCp7MORggwcZrZ7a/9HD2WZO1j+4vztczgv6wzYOFAWDssLSNTtKqkiaTgWLz6fIu96TMaA4OADh33auheGPp1Uk3grAjtybxbG0w3CFkhRNDLhaTAJh7RmnNJ5kBbBwAswuNcGfKO0QTzMVhTv48aPuqAwDI9vpW++h4V1lbmwwAZN/UiRcECNiymvP1WMSO7Tw7DABjB2xPdJfVljaZlKMaJFTAwHEcAHA7/8xzfyvebLqK65h66mJ5foQDDoAxhZGebKJTpBu+q0jHqBRPOxy3PBvqKHRjiurbSAAQNTTinglejNb6TgAg2xpacV4AZxJdbXZjG+vKCJvQ7PLPj+xwY2IANg4RYU7QMf4ehZATABiOYwAYi5tw+HLtPj8MiOriCkKwbZe/vQ0AxuL94fc+qprPJpqjJa+XlvcsTErXWJzllJgaMq/p3CQWxwDsVyZo9pRgTuuiOP11Ne3adrFXbA61t8GxyUpesiEj2AHHMBYvNckTWq/Uy0Bjl0/fWmHOLiqVfcyOOEcWhrE46zeH/FxyreEBVvcAwMTJbZzW65zcyHPYfrvGe46NmwdH1tYkBgCi8Vrnwvh1C8VfNRIAIGlqkjv58zQ3oBObWHr1k3oITk3i2eE4i7M6e1/2Zq95GgmVQ8yuOC4Lw2w4wWEcEIu6TJpOEgrA5tngGADYOEQUfF59JHKytRvcNSqSDQDAXsLBVUxBjJAFAJg9bwFIeyZay30g35gKNoJgJ7heXU8AANFwtZXt6u7gGuCmaqzpBAAQN9RLbb1CuDBFfxZdqZcuWJMSbIcB4I5rUiJ0RrtuwdAWwQAcIjfqHNt1IaNHJCan2owJs8p0sdCS5tPlPU6bdoZxmBjO9tqWW5Cxgm3pXt/EfNyNY+bDAIAZEB9hhwEAOLgtYRFdYtPcTIjFcszB3s5M0XKxqAfslxgFB0kMEsDADZavRO2EwHehtLODYLhtz0ngYACA4/Mworm+dUzKhs3QZDMTBVjuDto13QEAADC8knYGOOAYxvZf6cIkNVdhKcABdOmdjePjs2Vqiu8k2VJTgpkgHSsKn05RDwP9EZb9mMEDMjID1ubmFnueiLfXH5WKpMAOctB3yyy2Ha4QS+Rg+Mt9maRbrmrKDuRmG5TH7JIBmPNjPQwWW7cgimE2GMhUKgAM5M2nCj6qbpXKVSoAIAmV04Ttxtw8nWRnm8TgrGpowZfE+Ts2HrzaSKz2af9KxOLtcABxsUQlvb5h6ceGZ7nJ5QCGSRwP2771cmp+qPdJNzee0D8oNIRnN24wQogq9h2paBHLFSoAUBEq20GV/mJsJ92u4OS/BPZ+1QF+rKbrhNOWUIH88Ik2GTh217cz3DKdAG5PT1fG3kjKG0/sP17TKSVUAACkCrxUpCbtjLVg3a7Q5qyNYZUcV6Gbb0CkXwCHCSCXSlWEaLvbF4air0hlAJauiJCKiXls+zEfYDuw4YtO8WQWZ9vql8CZLBaDkGqn7nE2224KJTPYjvqleoy9gK262i0HYAEhqsh/v6JNIidM7cLADZIp24ENX0i6AV6cqJEWsOjkRp7j6RO4Itzd1HNYngGcA9Vt8s3szvpWe68MHpQfqxdB0Avf1IkdA7w0fmjWxGNIRT3ADtbrheUWHAYAQGi0p9tywGAwAMZ1TnaRWzdcztgeHmrvxBP6+4aG+DqzJtl3wMCZ+m0MGMZgsbXBgjEYGKgsnQXwwL4xBViuYRx4t6adDHVtqv2G5fX7hYCxvZbIiq52AJfVdFWMu+7iwBT9mZT2yBi2esUB25atWc2SdU0/mzFYTH0ywTAMCJVq6mGlySqt4vHe+wCYa4lM0k0w7HQWBMw+IPJXAABmx0kTm4/BHNOYeQ8iCAKYHLPjY0mrGJj+xoMblUplog+nxDwnkJXmi8DxNTdtOeLOmwQwGEY1MoAkxg/DMDdPJ7mZ7iCgrUHTHYAIgMF20F/fPExbquVejKVP7xQ8SLYEAPNB+oBFPQyPcARDkiSGPdbtjyy/XRmfxe7NL/EvnP4OtXmhh6oLvACm+daGcXQeSM26yN5a+Ml6ZxYANOcGbp/kphl39eLkV7fJQ4l2wmnLQtYCL/v36kXk89faGYIcZ4BGAOCkX/5k/cQJFOOsP/JlhLipoa6mofrI9sNHfPM+2htmqAhpWUbqSVV8wUeFS+c/SwPxydi1FWPfmsSX2SqcfN2Ik01iObNesjByiY2TfKHoaiPBk7YRTpuWPJztycaClNeu8d48VBrtgAOQ1emBGWbE2AG5xTVpnY3XGqprzucmHDqeUliUhAMAO/74FxlcjdBULDilvQuTNNngb4OLn3bJ0rKM1JPk+n3Fh91ZGJjYhTETLdUx5uRGGHjOl39OP3psnOcA293N9v36tkH76y34kg1se9IJK6nvJBb/VcR23TXljacP3q/hvPRTlQmi63VNDfWXDyUVHos6UJRteiHkTC3Bz6DGjWF7hTruK7raSkBNO8N9jSMA2Ah8nfLO14vXM2s6MbctTjpHmq4/G2PB0A/Q4kmbocsqxYd44713SpDjh6zjUE1BRsejMp+0UyRnLHQy/mEdAxjaKzDMf0TjtXZgx7hrQ0Pe1tAFuKe74Sw1oQKMaaajx10Fjvm147oDVn07Q5DtPEkTzdu9G0zTu6FZHxJNUQ/XaU6DR7WKdOs7ydeN/2hq/qdarX5EVUwFVmjmDm7nu9kVMobWjdkcNkPSPjafLZWIiXkOJj8fYNk7MBVikUR/gJRJBx8sHcraWqUMYbxm+KJx+knzNlvov0BU31BfL3ESLMGA7eSEtdRcudaucPdaAgAOHHuG9LpobGqOkEnNzNORBDEIuINbcEJGzolPC8LIqyXG+9RI0VetsGRDCk9z+zooahZPt0vBeUJOT+O1hnqRvZcTDvgSd/u2+pqGOumSALeHHHX31DUp7P0To7VzFF2N5htHDhIkxnIURiZmHyg+l2HfUfxZK9iy2QyZqHNsuyUh7554JpPFtsMVUon+Jo4Ui6Rg72i67GaKStKpX+DokcpVONvWdNw2YckqeZd+EzYp7ZIymA5MrV1++3tXc3ZRyaUS/XVJxVJgm53fngKWndzQcz44t2+85wDAQi8e3vZVdVMz4eTpALBQsIRoaq6pbce9fBdOrX42x9YwEmVNZcfLx+2XtwRJDJIYi+MZHb+z4NTpPC/5xXPNJGAYAEnqlSWXTh5rU+ABfWNK2Al8HYjm6ssNbaRrgObnKyye0KGrsamhvo3hFuqKAcDU/BljMXGVXKoXknRq3Ya1YIay2ZSa8SBZBQMGqFS6Jg3KJzMby96OaWARUlJZdNbi8/sf1nw4joNcbm6Hr7hdDLYcjnGiw5gsHAhCYSzaXt+kwt08tZXKasvbVPaRGwMMTpURBJhfsmcL/Mx0B3VthKY7sMhUe7HpZ0uLzGBRU8WaotTjPwBg9vgUhWXyfqm0FwCUyvtdXXdmsOSpCKtHYXREf/y5iMwd3I5Dh5tUoyMjFKX+ZWC02+jVo3++3jukpoZuVbx7tmPBipildIpS0+kMVbf427sDQ0NLV0csEBf9z8l/9FGUmpB8tjthzaZTN0wrtX7qKSDu3Oq7O3SPokZGRmFUrW+G9l/q6eeZDNWNr1vuUuqh29X799XeZ4Lsuz7N6QxQ6E43KvlFF9d5rSdPtS7g/eYZilL/2mWxrO5kjdTVdymdotTPeUcLRhsO7Lt8e0hNDfV9dSBtZcL/XLlroo32/DVhm/bV376rpqh7vf/q+I6cZ/vLpymKNjqqkn3X3Xv3HvXcfKZK8re/9wGQvX8/sfuinAnEjz/coyi1Wj0Ko6NqfYF0Bqikt74duDtkYpTnPHwWtJScbJzn4voLNUW96LKE8fXx8x0Llrk+pzUKjI5QlNqw3iG9crSFmKhO83lmgS1IOxpvDqmpu7cqcv/cMjpP9eOPPxibu/fT/wqJ3n32m74hSk3dvfVVowxsX/wlRfdYtZzZdGzPpzfuUmrqbkvx/9sYu+PcbdNmGGrMOSZiQUfR/vPfDgBA79//fLhaJYgJ/CWlpqhRAFCr1SY2oqiRUQBp7anz3w5Q1L3bn/35E9F8/6BfUZR6ZBQ0zjZJySMAZNtH7zb2Umrq7o2TxxuAu9z1OTXtuflMleRas5yi7pnYRTkKjI7zh/5yZ4hSD3177oMahaMH/0WNnkFjr5FR0OpWPQqgaYaho6pHAEBNqSnKyMnvfluuc/IWQ8+RdXbqPMf48hd5c8lrxy/2cJctolFq2m+WccTnTzQDb9mvjPzf2MSGrWL7rnIbvXrg3frbdwd6vynPf+PAhVv0Z0y1px4ZhdHREWPfGLjyRlxI6omvbt+jKPXQ7davu1XM+c/TqKd/uWAe0doqJoGi7t389OyXMm1Rxv48MmKQIgBgFAxcXfcxyAYT+Ibh597d3r7e3js//KgCcvCH230ymfzukJqi1EP/OLcn99z1IXOJ60W+wLbny6JaKdfDhaY5+KKHq21L0cnGUdfgpXSKUlMT+bOhRQIFzJufvH/55l31UG/LycNVMtCElasFQxv7tnoEYBQALNtuSs2g6bKKifeOS+YGVf/i12yQfP3PAYpSU3cbD5W0A8DIRF60KCZ4QUfR/rPf9N29e6f+z3m5Rc33rE0Tsi4QxsxHUWpZ83HD0B6F0RGDJhn/q0kyz7y04Ofkd9+ZaptS374hIRgLlrxglJEo6sVX7EF2o89I+F/XviaA/PHHu5Saou6cf+OYhLt9f+pvaAYu/X23gvnKi8+N9xBK7cAz0x1Ud2u7A5Nma/x5ZKIAHwsHABhv1pOvxZvxLooGMJY5zQapYVEEgOWiTD8PMyqwptNp4z8AYPb4VIStra1ufTu2TiLt6R0ZHZmRkqcoTLMCK2uDr16KzN7uqJKrrKyt6XQafX5kweGt7OY3Y/x9l4Vu/VDhV/D+H12fpdHpNJfoCKf+U4kh6/73Bm1xemFhnM2l/1q3zM13+R8+UYUWHExeZFrpfEG0F35tT8SK7ZU/0K2trcCKpm+G9l/6swHpWUE/q9i6XBC0IuPLF1Lf2hu/RF62ZdWhf9HnCyI95+lONy75NwK+qkvC4i17iUan055dKnDu6ZJyfDye19Qbuvd4pnPv8XX+vsv81+V8Y59++PWg5020sSTz3cxFN99eF+Lp4hYcs/tvL79akOnzDJ3+q1VrXKEqPSgy56+//l12PLv5vyKWCWK2fGy98c29qQL44r9i/vvvFI1mBVZWNF1pzy5bHWXf9U5sxJYPbpkY5aVlPFZXFzgLFtNpdDptMZ+r6OqyC/B6SWcUsNL4mEG9Sp1ytIWYqE7z+cWKHekBiuPr/H194vd+tXTbwTciOF3vr0sp+d7A3PNX/XdBpFVZWoyPm+eykK0fKvwK3o59iU573uf1o/nBwyfTlws8l0Vmf4EnHNwX+5JpMww19ozrjsKCUNWJP0QsE/jG7PnHy9sLC1b9gk6n0elWAECjGRuITqPTra2AIVjtczN/y3JB8Kr9XQsz9qYve4ZOp1lbgdbZJixZPaRicCLWvnBhW0jQspCtZT+LKHgz9iU6je7yu+x4dpNZu6gY7KhE579mx/j7+vz2A4VX5jupi3SztRp7WVuBVrc0KwCtzxs4Ks0aADSWteDkzoaes+r//VXnOcaX/6xToFO/pMvee9lzdDqN/rwT365LQrguX/aMkf8bm9iwVcBaUXB468vtb6/zD16RckoekHckfdE47dGsrcDKytrYN54LeqMglfW3nPhgFzdPn03vSpwyD+5wptOf8U3dGYV9sjFy1ar4bX+6uzLZi6Eapuh0mrE/W1sbpAgAsIIxV9d/DLLBBL5h8Om7uC00Iig0ZsvZLlXPhW2REUGhMa//jaLTaerv/3ru/F9vj5hNXIsChcyenl6un8fzuoOLA3lYTxfh5OejC2rL/mxoEffMA1sXdr69zt83KOn93ujfBzLBiqIAwHI2M/BtmjWAFQBMYLspNcPFfFbJvkYaX7hB1S9F7truKPqfmOWR69ZlfLloQwQbVJR6Ai96xnVXYUGo6kxKjI//upwG29TDORHzTROyLhCMzLfqv68bhrYVWFkbNMn4X22SWRzIwzv/9tWAieGob7/pAg7vN88aCdPpv3BxspV23bpnIPz9P673wCthC//+ekr6lk3Zte45Hx1d98qzhqV9397FWMhfaM5DaODoYaY7WOin7Q6Mm63xZ+uJAnwsHDRtNjFrlU2iGbPSf7VytYs+c5oN0ikXNe4CH2JUYEUNK8fPzFDTWcQyEe7q+v7290b73Of/8hevvPLyw5eMhJHwbBKuzeBn3X/r6p+Wz6E2I2EkjISnK9x5IDqpPvL0uSR7gy/b9oVvrvY3tytI/F7sxq7NnxeEaReJ5CXJYW8SW8s/SXQwLVmH6L2VqT3pn+8NMLeMNMu0MbuEZ3gfDKlS3enuMTnY+0Pf/RnbVIdAIBAIxE+G4+aMIKJ4/wUZAMCgqOJAQVmLqL1VpvnOixgsAAAgAElEQVSt+zgcEje7tZ0u1+28IZqrW4Ht5mp55w1ZV3wFIhPNDl8QEzPDI5jvbklGRkbGH7/ddWdmK0IgEAgE4ifAxmvn26HydzPLxEDUF+YXlV5pqm/o5qxLMP9gDDwsLRHKP2okYLBmz8rw3HoVyC5nxebVmt+oLq043uq6a068LGz2MZO/pu7vH5DJ+81+9UPfj2z2/Hnznp3B6hCIx4pfwdd1FPU4f2qHQCB+EnDnjOJaAABgRAY5ET11Texd+9ZbnFZxWF+YsiejoLYgN+fS33ImKpjsPJ59xSm3UDgH3hU2G5mxEQxFqTtvfjuBQIfoJs91sp+vIxAIBAIxW7ELzSkOnVyM5Z+TBxUdMhBO+CwyUtTJTCvY7IQWkB6QGRvBdIg6h4epCQSUyvtdXd+/8MLDPscSgUAgEIhZjp1/xKS9HeYUEf1TtOWJZWb2wXR399y9++9Jxb6/I/33v6f6zCoEAoFAIBAIS8zACKb/7sB3YtNXr1lC1Hnz3j0zv99GIBCPhcGmho7H3QYEAoF4AB52BNPb2ycS3Zy6vFo98s+WdjQTg0D85JDimrP70tMONhselDfJGDPygHwEAoH4iXnwEYxarb757Xc3v/3uAU5sbfvX9993m/3dNQKBeDRgDv7rQ9kKoxeVSNtI9kO+gxOBQCAeD9PeyatWq+/dUw4N3bt7d0A1PGxjg4+OjlpZWU3xdL1w/92BoaF7zz//3NNP/+xnP/sZg/HUdFuCQCAeku5WFTsUA5BUFhyrFEmkwGYzlyRkJbqj33YiEIhZz7RHMDQaDcfn4fi8+fN/oTny6J4fjEAgHiWSVrAPAwCC4ZSy1+nyycbQxGg0dkEgEHOEGX4mLwKBmDOIOoHjCACAs+1weX0bsRANXxAIxNyBbumhotN62CgSRsJIePYLS699eqFDJvr3p1eZ4V72mOjbkcUhakrzFCei8Z8jv1lBqcc/02kOXSASRsJI+P+U8My/mxoJI2EkPAeEybbKa8wwf/ZjbgYSRsJIGAk/qPBMvhcJgUDMDsiW8kOlNRJcEMwmJOK2Liw2c5cX00iirQfjmnuzLgKBQMwR0D4YBOKJg7jaRMZEMbuq25hRSduyNzGrD1aITWQ4nl4TvrEFgUAgZjloBINAPHEwPOMiobWNdI/0tAEgpXIZITd5iCSG4+gxMAgEYk6DRjAIhFmIltKT1dLH3YoHA8NtVO2NUq4XBwDI1mttGNd14eNuFAKBQMwsaASDQIyH7Cje/bbE1WuSfa5Atn16vGY2DnPI1uYOpq0DDkA0lLSyX03xwwAAiOq8/TXEZCcjEAjEXOCJHcHILu9ZGZh0XPS424GYRcjrCtI2JadsSj/ZMmEvTrYeyip3fCONO+k6C8b1YJbn7muadYMCcVM7YD2nC97bV3jda19hgvbVR3hA1k5/9NAXBALxRPDEjmAIuRzjuDqNv4cW7Q/hJxU/8tvm2gy+MK1mOme05vvxU0pkZopK0xYlv5As9MtrBgBosiSMsIisfM9rNcwAjryp5uzFiYa2PSUFVaz49QuntE/ENnp3THdebuXssoW8tU3ulJKXl7FtV9bOaA4OAEB2Vhbvz8hrmOnRlqQkOTS2sI00/63eex8p0w+32YS4KH7Zbz8Sg1Fck6KzKeFCLj9++rdhDVnewpTLFgwy+xAXxfPWnjTdaT4RBpnQpKjCOG1RY+lUXmJWeM6kUHnNWxsFfL5gV+2jsehPEKHy6rz4R3QJT+wIxiH+4LnD23Svd5FUF9d2P94GPTi89A/eT3czPsbZWPjBzgAWAMBga8WF1lk3B/ATQnZcLqubPBPJq8uvkxyeu5tv3KbMzW6WBUWflEh5a0KYliWMYflu9pIcPmGpC38cEA3VInt3jvEQjGAstAcCmzfTUzD2a/K3sc5lWZiIMue9s4/ZEkQGcd1YfKweX1f6ZdFmzpROnS2X8Fhhx+0tyg0yvm9lBmS8X5jkCAAAkpozV7UdgYGqZzXSqhMVcrfcypp9fjO49d7AWx59hEqrjpfP/CVoeGJHMEaIKg4cuTKdMf6sAndw4jqYdDs429nJkQUAQNSf2H+6Sf44GjZLaD9d8FH9pJNqZFtdq8qBu2Sh/7bs7X52lgVFFVelHF+3aYQa5hwbgZUfq54t3YfkwpF2doijuLjKyOdZtrIaiXsIUzrj7WRF7No072LBeXOTBea8d9Yxa4JoLK5JFaFi2C9ZONVfjM2aS3isYGxHZw7bRGUsDteZjQMAiCoO/vkv2qAYU/XshpATwHTmMGe07zf0lkcfoYR8cOYvQcsTOIKR1b+XlpoSn7zngsZVm/JDEj6SEFe28wNSyrURTko+zUoI5fH5vMCkXDM7MeUlCcKQvIqSXSmxa+PCQ1bE7irrIAE0E54JJysLk/z4UbmtAEB2lOdvig7l8YU876j47DKjuyBZ7YHUOAGfzwuMSytu0/6clWgryU4K8RZylwq9VyZnlXYa3rsTTSfTokN5S4WC6LQD9ZrWmpvl006BykuSw16rUYgObuCF55cVxnHD97eMCXUeiBauLOw0ubZBUVlWcpSAz+d5x6UU6KamSGl1QdrKQCGPLxSEx6cVNWsnNVrz/fhpp2reS0uIXxkY4Ld2z2VJ54XslNjoKL/AqJQizUUZqSskMFSvrvH60W5Aac3346eV1J9MS4iPDQ/1C0/JrdEnX3ldUUZ8eKiALxSEJ2Xo9KbRfHXpnk1r41cGhi7/7ZsXxABkbYb3qxflPaeThZNMUUraxap5Dg62E4hoam/t7Gdz7G0MDsnq96ckJ8Um51eLOy/kZaSkpsQnZBw3nHJwcHXH2yvrZ8kQxj46IzM7KzM7I9jB6LhCpmIypD3wCLKVQ2SMk/jsOTPz+kZroCsLqi7kpcWvjQsJDF31x487zBlssPVsRkKUgC/k8UNXJudfEGuErqbxQ7NKKzKihbzkChkAKSrLWBvK4wsF0Sn7auQGJZHS2ndT1kYJ+EKed9ymvAptLU35fvyMU5fzY72FsUUSgwqNgqgRAGQNx9PjQ7yFPH6A39q0feZ2aouL4nkJ71UW745fG+fnHbpyV0WHuHZfalJsdKggPGVfvc6ZLRYlrS5ICfEW8rxDY3eVteh9XxvX0pLksIwaleqLLB4/PivHNK4PrvY1jutxlwDAIK6fSo/34/OX+a3aVNigm6O0EI+gDX8XN09eoEFasBCMRjTt8eOnHb+8PyUhfmV4qN9Y4pKXJAtXFlScSo3i8XfXgOUkAwAg7yjdHRso5PIDQpLzL+v01F3zXsraUN5SPpcfujL1PaOpVlXPhbykEG+hi2BF7C6tlcdWkYyUI/TLa9Z2BIq/aDsCw1Ukou1UdsrKwAAeP8BvbcZxnfmIto8zEqIEfD6XHxCSsPuUuSkuUlyRmxznx+e7uPn6rc3Qy+jceErncpcKDc810G2+X8JHEtXNd9cKBelVZP0eAT/tgl6qaY+f9t/aDH5oVnntgfSktatX+QXGpRQ2D+orubw/RdOnhKfklktIA29ZtnJfo1H/MlG6Lr32kbl0bXg9Y/b1XrlRa1+TSzBz2sNBDSvHf+4rFWaPzwHhrtPpO0u7FHXZPtywd1o0Xw1d2uLssrNWI9m+N3CxZ0ByXlVn35DiVtXrEYs8MmsVJqXdOZfIXeQSs7ehjxpW3u/7S2aQtrSuD9c7ewQnv1Xd1d83NKzsr9opdInIrLo1NKwc6qneG8NzT/20d1hJDVemu3D5QduONtzqV/TdLNsZuNg3u2GAGh5oyPFdFJRZ1dVHDQ98d2FX4OLgvc1KalhJNecIF3sKE/fWdvUN9d+qyolw9th2qV9JDVemuvBSq5T3lV3nEnnCnDpqWEk15AhdEs/0KKnhloIVvOijN6hhJdVVtNbFN7NhQKuN9oIwl5ijncaX1nMx1ccz4WhdV39fb/vpVB9e9Dst95Xy5reCnX22nWvvo4aVvc1HEjx4CWduUcNKqnlv4GJeWE5l77CSUrQUrOA6+2wsaO6jhpX9tZlCl/VnekzVRfVX69X1Y2W6iX742y726ooN3FnapVBSw8qbR9c7+2R+OaCghpXt78Q4r9ipaUl/c1Gyj2dy2S2N5he5+CZ/2DI0rKSG75Qk85y3XezXXrVOh2Y/7UWvro0I8+EtWszl+0REJ+4812lZeLjuNR9eclnf2BFF3d5tR9oV1Zke3EU+W060D1DDyv5L2zTW0bnowKVtOtNMwZ/7awuSt2yZ+LPj9PVZFFaTf26dWMcLyBvfZq33UsN957bwnD3W65ykcocPb+2Ht0zle0qTPXhr36ruVSgpxa1Lrwc7B+U0KJT3lX9J9+AJYzLPtN/pVwxQiq+zg7iBOy92KZRUf8uZnRHOizW1KIcacgKWxWRX3egfVg711BWs8xTurOzXupxv2LYjDT19QwqTCzQIouEbR2N4/MSi5h4lNdzXfmab0CWioN1UG10frl/kEpxedksXdzx+TE5tj5IaHmh/K8J5RUH7sPK+st1SUb1lic4u648291HDA721e9d68BatOnzTKK4HLm3jOe+sNIlralhpPq6NLqE604PLX6FNPjdKtgoXB+9tV1Lm8pUmHnvLtjj7bDvXOXBfqejvLE0P8kwuuzNBMBppozlHuJgn3FbaNaykhgdufrje2WPbpR6txfk+67Mv3ejvH5ggydw8GrPIxXPt6xdv9g8M9dQVrOM5bzzVNaykuk4nuHgmHP26V6Ec6vn6aKInf0tprzY/85w9ItLPtPQqBu7884NkD23CuflOhHPMkZuaVmk1eeeMLm0OXdri7JKu7QjGVH3rTKKncNtpjZlulu0M1Kr36zeX86Lf+bpXoaQUdxreWc8P2tts6t4tBSt4wm2lN/uV9we6at+KcfbR9CZf7w2a6Fy912nOpRR3DM41/hiauzaT77LlXL/uq4ZMofbf6nQPrnNMTlWP8r5SMdS8N2yx1tP6azMDXWKyq270K/puXsoMdAnObhjQe8t9pcIgQi26hyZdB6R/YpiuxzV1wNC+d74+PNaJmPfYmclIT9ocjLi+3Skpwk50tV7+84VuCyxIMbx+tyPAAccwdkAkj0l2ic1OvjrFbHbDAQBwjzh/W0mNdk5eRTpGpXja4TgGRH3pVcJty2v+bAwAY3m+uslT1fBZnW6MzPTfstmNbYPhDpFb1nD6qy+3A2DuGaU1n2QGsHEAjB2ywp0p7xDpq2cIN20VsnEMZwekrHMiGiqbpjNmZQfHuSmqSxs0o++O8qtSp5hQ49vw7pqP6yE4NYlnh+MszursfdmbveaR5D9Ky3sWJqVrtnyynBJTQ+Y1nbvaDQAYANgGxPmxAABb4OzAUNkGJTjhAGDDWeIA0g79XeWYujx16iLqy/5qoh+yvqKO0BTLDIiPsMMAABzclrCILokcAJpPl3e5J2VqWmLjtP7VULyxVLd0jfE2xDpiAABMLm8BiDuntCGbs/7Ahx/nhTIBX/H2l6XnPtgb7WBZmCQIAhi4wTSFqJ0Q+C6UdnYQDLftOQkcDABs8HkY0VzfqhfC2EwmIemZ4r5AG69tRw4fnPiTv9pxaoXNEtgODgy55KaZe3RDuDGvap2EJ3AEsajL5PvuL87XM4JeTfNkYQAYOyxto5O0qqSJBAAMVLhg/RoO0wbDQHSlXrpgTUqwHQaAO65JidCZlKguriAEqbv87W0AMBYvNcVXVfNZvdblwDl2nTsLxyaYzhadLxHZRmWsd2YBAL4wbksUu+tyeZsZSdw1KpINAMBewsFVTEGMkAUAmIObPUh7pAAgumChKKLucjt4bdzghANgLK+tmwWMCVU7Lq65q0In8GHNSZFbtcknONyJIReLSTCXrzTxSBIKwObZ4BgA2DhEFHxefSSSOUkwGjEvID7CDgAAc4iMcScbKnW7wgj2is2h9jY4BhMkGQCAJRsygh1wDGPxUpM8oe1KvQyAHVH4eWlhEpeFAcbiRoU4kqJ23fyKSmUfsyPOkYVhLM66zSE/l1xreMB9AqLzp1rtN2es1pjJIXLrBk7XhfJOAAVBAIbjOAaAMd23F137fKez6cmOqaculudHOOAAGFMY6ckmOkVSeLhzHwQMwCFyo2ZbD+bkupDRI9JY/NwVmVfiLn97Gwx3CN1ZuG9LAFNloQyL7qFJ1/7rVxima9NOk7xuZF/uRmP7PiqetPciOcTlOABZl10lZfvlWdrLwGDb6xcTcIYlIZzN1q+SsthMkMu7ARwAGCxbtraD6+mQqlhetvoVBxsHW7aqQSwF4AAAw46rH0LZspkMQionATB586mCj6pbpXKVanQUVAqVk0HDOA6Yvko7XCWWTmthmxkQ5/n2rvPVMr+I59ov1sjdU4JNNnxIRVJgj+10Y7kFhwFQvdfExDy2/dgGOLYDG77oFAPYAQADt9PuasUYDAaDqdsKimEYAKgmUFdPp1TFEprTDwAwmGMn6G0gk3TLVU3Zgdxsw8vqkgGwABhMJksniTEYoFJNeXwnF4t6wH7JZGkfQKVSARguIYFTYp4TyErzReD4mptWEWJRJwEMQ9exYTOgTU4AaK+JbMhde3Lh4SNrJnuizAPAXcqf+UKnT9s/vzb8l4Xj8B1BmGjPGIzFNPp2nP00/qkPAmCx7XCFWCKHZQDAsNMtApLSHhnDdsx/2LZs7RhALpWqFKJ0tyrDUl+RaoaWhvFlAVLcI2PYcsastmAhm3Fa2kOC6U/rGThzzH8xBos9FiQYqACAlFgqChNLVSwv/XYNjM1mMibqfsfiOprVdrFG7rZl+QQbuTStY7F1OQ7DbDCQqVQT5KvoyK0bLmdsDw+157oKA/xCQ3ydWdgEwWhaO4PtoL9MnMnCNIkLBwCczdYKEz0TJBkG21G/FQNjL2CrrnbLAVgqcc177567LpYSKgAgFSrcXl8l7mBvZ1SUpHt8w6YAKe2SqtrfDue/bXRBUgC/TX/02PY/a/zPLXFzcxWGRIR62Y/3bUJUse9IRatYPkiClZWKUNkOqgDAc3OGZ0reVM8lVACgP/fBYLCY+h8fYBgGhEoFIO8QA8vLXudp+EL/CAAA6DFXguXuDAAYTPZY8ebOJqQTdSKPDLqlt1rPwvdoT1WYqPmkut9+dZQLTU1RAACUehRgVE2pKQCgRkdhdEyYGh2F0RFKK6lDPTIKoyMj+trV6lEYHVVTarV6FJ56iq4pCtSjxmJAjZIAo5SaokZGAZ5Sq3VfqdWjADBCUTcOvZpVzn51f/E6JxYAXN8bki4eUVOUGtQjAKN0a31LRkZGYVQ9oikK1GoAGBkF0FSnHtFeEaVpg7aiZ/hr/PD0C1/2BTn+5ctBjwzvZ0wUqB4B1eiIVhUGPAUwqh5Tgv56KWp0FJ5S6/SjHtXqmQYA1Mio9iyL6gKwoB8wVvuYUUZHYV7IwSv5AhPTqqXqURh9yqjl2haOjMLoiNrEgiZ0tYiB6fvSL8dduCnWIwyA++p7FGUYpsRXde1gu8r1F5pa5P+o74J5Hq6/UoPOkagRBtwfvKcvn7ZodU6G/S9MWzUjzv+PpoapF/LoGOdaowAwzrW03jvOSdQAMDo6Mt4/wcg/tVGgKWiURtNqWx/RWv8Zq0U9Crbrj33+xyXGjVVTIrORrr0QfRBpSjYQU6p1QUczuOqxANE3UheDmqyg1l6X+aIMY1Z71QAUpaYM4lqjinFxXfXloEeGHz7ONwzL1ChtrHz9vxbz1dNL//NExXrRP641f3Wt8r2kwmOR7xzb7WgxGPUq1Ocig8vUJy71yCiMPjVWncUkMwIGygSgRgFglFLf/WxPSkFP6FuH3vOzxQBkZakr/qzxDfXIKDBG6OMTDqVTmpEmdWqn1AYuqhdQjwJj2Z4v3o003h9GUWqHlfs+8+tpbf6qtvbqqV0fHea+duxPq4zugqSf/lfqSdX6fScLXVkYgOSjtb/9fJRSUxS8GJ7/mfdE51K3z1k617gdGtdWU5TOyHqZe6Ok9l8jixv+++yoanREaclbNML62LHoHjCFTpManaATGbsECzxwYqSbfav17HyP9hSFZX/7/JrildToRff+vv991ZZd/riaZgVgRaPT6ABAt7ICKwDQlky3sgIrazqNbjQbRbO2Uil6ewfoNBYARal/uN0Ddn4v0Wk0mhVY6YqCFxa9zCju+v4e3Vkzbh38vlfOmP/ySzQ63doKVD0/9NHp9gAA0PdDvwrn2j078K+2HobwtXjX+QAA1O3OTrmKYU2j02lAswZVz807NPp8AACQ9fYoGHYv/ged/q0VANBoAGBtBWBtrRXWXBGdZmUFVpoSAIDuvjHSNr6i8osFV1QBe32ep5lMsr24iM248q/batpLGACArKnsotQxJtz2BVwh/v4HOl0zgiZvf9sDDsG/ptPodCsrbUUAADQr0KiODgB0aysAKxqNTjdSFwDo1PUCYT9eP7Yvv0SjS43VrjfKfIeXmYrWb7+n+2j0BqRMSuJsGwyMNQ8AoP2Xbm0FVtY0Ewsa+8btzk45Y+HShZO7E/0/WDhI7inp9GfGDpI3vrquwv0Fv9bULvvbpTaVfVxi0PM00HkdfUgFP2M9N9a85xa7PGfaDJ3wYP3+1050TjyBNM9n+582LpqkteNKfozCd4cUgOPP0U1czlrjvXQ6zdoKrDTeCwBAAwArK2uTwl9cxGZcHfNPkN7uUsx7+Vf/AdBlbaV1NgCg/5KFq9p+GKDRnwcAgFvfSlTgQKPR6S+8aMeQd94coDtrJ0gIeTcw7XBLka69QH0Q0X9tz1Zdufk9ja6dGu272aNieb38LJ1mqA1jb7S2NoxBmjZkMPsFbNVfzBXFfOE/GPLeH9T0RZoHJd++3aPShJVBXNOsAfT60cX1FYcrqoC9AhzGGcUwD1gb6oqiQPev2Xxl+/JLNLqaGAR8/mKvSI5HzMbfV6ZHZX36z8wDFoPRyDdo1qDq6eqj0V8CAMPEpTK0OMWymGRU1qDqv/2DmrYYAwAg+25LGT9/+Ze0bz9tV3ESk5e/8CwAAPntN10qcKDRaXSgWVup5L23B+juJvkZdEoz0qQubappVgCgtZpO4NkX7dmqK+23qBjdnP2gVI6xmRjA3d6BZ+a/4Lo81nV57E7ReysTPqn4PjbdYBhC3vp7GyzJS3WfjwFFqe99+w+JCoR0Gp0OgzICY1k8l6LUaoNzAWDQ4Fwj6JoAotHpAM9YYTBMqbUygwP9Kq1Lj1mcotQG//7ixZcZ8jGLEy3l50XsiDVuWm8BADpdH6GW3UM6hU5zvp2hfSnqnmEnMnYJ5niYjPSk7YMBgI6mdhUnIpTdWXqOcNcsumMYqHrEYmJwGrtKGAzR+XdrpCQAKfn0+BcKe4HnuDUI3Cs2CG86+bZGTNrw7pEG3G9VgOb5YQDi8mMXxAQA2V1zrERkGxDqqJli7WhqGwQgpbUH//evJBNkEjmAZjlGUV98toUAAHnjifOtuGfY5D/qZQCoZJIeGUFqLm5hZIyD6NjeWkZYLG/8yXb+Me5w9d2DDd0EIRNV7Ms+cEGM4eASF7mgo+jABTEBALKmY+/XqLziTFegpqoucZlOXbjX6uWm+vGPCZjotzC8NZELxCfyT7XKAWBQXJG1cU1SsenPqUxqZgDRLZEPkhatS0q+EYMth6OvmOwo3R0bHiDw1n5CUst067X2jvYgExkv3okaGgkgZXICAEB6IfuY2Cn9oPETe2UEAbp3JYovv7cvOy2tVGKpPTZeO498cOTEhJ8Dv51b+2CkYrGKab9ggiWkqWAXEuMOV98/0iwjAUhJZeHHHfYRceOjgBskZN4sOVIlJoCUtZ06ckVnMMwrNojZ/EFueecgABBtp3bFx6WXTbYYbxBEnIg1XPnFg2c7CAAgOkrfuyh9ZU3sA9mCE26hKKZXyBKo/+hwk5wEsrvm0OnWScvSxvWbNZjZuB6fB8xhLl/5xwTgRHV2XOjWk41SEgBIaXujVMViM7FpBKOivuikLnF93Ip7BphJXBMmGbLt1MFmGQAQnaeLGoAb5M4CFpupkl5vlAIA0VKae1qMMwipjAAAUAEwROcP6/NzjYJjJj+Pw2xHwIlJcJNfLDhUJyMByO6a/KTopH1NJIhPJkduefOyZBAAgOho7SQwW5NfHWNMW5aqq75JDkDKmj/KKpezgJDLSBCfTApPmsa5TSfHzp0AtqMdSBrbCAAAovn90vbJLhj3ivXFm06+fVkySBDimkNZeec7YJ4Fb7HkHpNVosXVyL7Nx6ffiTwIT+AIxiky0Ytx5c3Ms4xNOzXax9xiouwlb68KSzoyYV9oDO4f41aTFekt9PntB4R/5sEUM1nMxivzSBavu3CDgC8UJOwXu2Uey/G1AQBSBTAvIMlXtHeDHz8wMk/Cycjb4YYB5rdjdxBW/qo/PyAk/Yrt79/Mi18iL01aWdgGQALDdUOk6v2EUAE/ans9c8OBzCl4j310nCtc3u4fnqV9HolD8BonULFXrXEyJ86KePvQVofW/DjvwJDkkzL/vCPbHQEw57TCglDyeHIYjy+MzL7ukFb4duSUH+lmrC7B2mN6deGC10z0cyLXb+JObuH2wsJY/GJ6HG+p0D/5LBlSoHsalQVYnlFeeH12WOjWCksdlbSzi2DYO9tr/yVbz1diiUWfV74d4vvG59XX/lb9xeHVukhjOi2xlYo7DXekipuapfBKGKchIzltU0JWtVtO8QfrjTdUEN1SBYuzgAUAsqoL8uANXFVrU88sesbdQzDY1NAxqZCsoVo0z8vvlYetjBXx9qGt7KbcSG8hb3nKccK34PBO5/G9IcZ77cBWjig/1lvov/GQNHJLABOAJAHAxivz0N4gVVGaP5/PC8+6jCcW5q+eLI0aBpF9woGCzXhFSriQx49KOYclHD64efK+0Xyxloqyi8vOi4TL6WFu/Kjtl1/ZHO/IIBWTeIs2rmPMx/X4PGCO8fnqRK6fDdbOTmIAACAASURBVOABWQWvMq9mrQ10cfMUJOwXczML07gw9WBkLFkTCce1ict2w4HMMDOJy2KSIQkVgxOxhn0+JTCAF5hSgkXk56yyA3CIy9zBkbwdLeR5J70rCXrjwNYw1vWs6IxKGQDJYEcmOunzs1dmgbn8bNoCt5jIBV3jOgL2mgPv77Bvf3NVII8fGF8odc8t3OWGgcO6AzkesiMp/kv5XH7U9nNYQn5OtMkDZJwS34i3bUwP4/GjtpyBhNy9rwqgMj0qS7qqMNdz6uduKjY4t96yI7AjXtvu2JEX5RceF5t+hRMfwZ5sM6CNV/aRrCXdB5P8vQPjCzqdswp2uWF6bwlamW3oLRbcY4oY2XfVfz9IJ/IAWFHDyvFHZ8Ok9GMVll9IjnrXvrA2i/dYm/Fgwp0HolNa1n/84dpf/FTNMFLXjJY8I8JkxfbA1/u3Xj613qgnI5tz09sTDieadE/Ut39at+n25s8LdFlYXpIc9iaxtfwTU0mDZrTlhm+XZVQe9MeAJAaBuJic1Jp0scAfMyc84xc4U8KkuOZ8SXkDI/6g/hmdFNX317987xVq9r5/DHFRfOwXnh8Vv7p4Vl/gnBbuPBCd0hpfeiKOObva3JrvlyxJ/fzImgkfDze72oyEnxThJ3AO5v80pLSuYE8pRKRFPPLB79yhs61TxXZaYnoj3nalleVo5qdC9gmb3dpOl+t+10g0V7cC2811ovtw0dVG0jNagAEAYLiN9MpFqWeUACaY0J+VYA7+60PZCqN7eGk7yV4yyVqmrGJfsSIsLXFqj79HTB9dXO949De1CMQc4lH8mpr64Zu/ltd8823Pv5UUDX9+/ivOgpXLOcynHkFVCEOa8v2Sz6s4Qa8d2Or0KB7gPNcYFFUcLycDIlVt8vleIVyTb1tqmnHuFnN6wsPSEk9nftQYmclp2hOffUWiAsblrFgyvSjL7JwqWVd8BSILAnRliWuqCP+dC68dK2FvS5jjvbq0TcVegQFIKguOVYokUmCzmUsSshLdx5YJJCWZ78kiCwq9cJjODwoQU8Ugrs0sqCEQ/4eZ8VUkSlJ54mDtDzDPzmmx3c/pVHfnNzd+JJ92XPnaZmfmbJ2JQsJPojBRmRr2WtOSHSmMU9XLTpyON55EIeoK9stic8Y/3U5TsqxmT0aNb0Gu38RvTqEoNb3vwqbU9s2ncoS6Tn2wJv+1y8BxCtocz7MxEZ6xCyQ7Ln+sfRsUQfx7ZNTK2spEwiF0SzTHTI83ccktBUkX/YuytatIkorPlBErFgEh7QY2XD7ZGJoYbXlv1tzxDSSMhJHwkyA803Mw/c1ldT9Qz7v+5/bwV54GAIBh/pWjxy51/rX2tvPql2a4NgTCMrhTZJAT0VPXxP6vt9aN/x2ZMCNngpNZ/jl5UNEhA+HEQxiy83j2FafcQqFBv27jn3nE/0FbPVUwFrSfOiIJOFyU7YaPRTVJdEs6RaKrJUfOl0ocAw4EP9SPg0SdwAkEAMDZdiAvaSOc4mai7QgEAjETzPA+mGEFZfPSAv5ygXb4AgBPsVyXzgf4d3ff/ZmtC4GYGLvQnOJTR04czgx9oAfj2vlHTDJ8ASA7bzLTCtIfx6IdKzS7IBIuZudXG77LAMPtOLyAyJ1HPj39GjRUT/E1Bzq668suiuSi8rI6MQkAHWJwstd9RzS3whQeaoxAIBA/FTM8B/PUS15b/uBlcpAi7gNgNk8/aW8wQCAw7oroKc9/zjS4e8beDRuTsrIrPj4YZjq/idlH745pmeZDyu28Vmd7rdb+Q7aJsSVBY7UF5+U+VHMRCARiZnn0o4rhrtoWOcz7Df9lNIJBIGYUzDH9QHrr2vzMD391InmR6UQQizvuZXJ6yJbyQ6U1ElwQzCYk4rYuLDZzl5fR71zIth6My9U8/h+BQCBmIY/419TDA38/c77+7rOuMcG/eXpycQQCMT3YqwtyfaV/zt7XZPlBZuMhrjaRMVHMruo2ZlTStuxNzOqDFabvFuR4ek22iIZAIBCPkUc5glHeuVJ0rPhfsGhVQvzieY+wIgTi/zAs/8z8CLi4a3/d1B8/w/CMi4TWNtI90tMGgJTKZYR80FgE070kAYFAIGYnj2plZ7ivpbjo8+vEc/yN6zcsNn3FHQKBmDlw7kqfgP/Pbxr7iTHchrjaKOVGcQCAbL3WhnFXLHx0DUQgEIhHwNgLyk144LddA8BwT8OfP6i9RX85KmW1r61pFQ9TMhJGwkjYFOmVg1WL//jH3zxDqS2/vp6s/993Vb/f5Y9rSyb/0dTx8/n/+bSaulv/SYvtH/7Xm6Y93UjyUbUZCSNhJIyEH1r4EbwXqa/5/UOVN5/+ze9+H+P08xktGQkjYSRsAtF8vFDikx79yrPjhEm5TMVkjXsAnabkjsK4lGv2QrcFOKnixG2J5ph/UN3jv0AkjISRMBK2IDzjq0i95WeqbsDL8eaGLwgEYiYhJSWF7U7bEx2w8XcwRMuR91ojcxJwAKKtsuZqdZPjrtxg3d5ceWub3CnldJ7xuyfNSSIQCMQsZYZHMINN1fU9arot/U5d1R3jr556yTVyKcqKCMRMIa8+ch5P2umOA2W8ejQobbh85L13RcHF2wEABmW4u8D+4mWDh8MQDdUie69x7xwwI4lAIBCzlZkewfz4byUA9HRe7TH96mnFr8KWskzf3YJAIB4EsqMoI7ecYF2LPw4wOgpWVgAAJCGXy/oJFQAAJ22v5hG6Ng72ZP1J0i1RdwMhuXCknR3iKC6uEmcEGz5md5wkAoFAzF5meATzQtirB8MmErC80xCBQEwdbGFSUW2S9p9JF5LFTT0L/e11/9lHZ2RGT0kSgUAgZi+P+Il2CATi8ULKZaS0UWTrzpk5SQQCgZgFoCf9IxBPMh3Fu/eJ7J0ityRM9rSYqUsiEAjEbACNYBCIJ5mFSUdOzLQkAoFAzAbQKhICgUAgEIi5BxrBIBAIBOIRQQ5O/XVdiCcDkpjOa2YfCjSCQSAQCMQMQxLSjvqzuQlRSUc6H3dbED8N5KBMUle+P2XVhoLmn6hKNIJ5EiElxX9YEVvYSQKQorMp4UIuP/646JFU1V2cxIt+r8PMN7VpfGF6reUzRftD+EmnpDNS10wi/tM63tqT4olE5CXJQr+8B4tR+YUHP3cixEXxkzV7qi0RF8Zpi2rNXy5ILZGBxUtuyvfjp5TIHrjVGhqyvIUpl9Gt+pNDd2lGUvqB019crW7rN7KrrCotPC6rftq36OLy3Su9+dzA/P+fvXePa+O684Z/3e47s8+W4d1dabdleHctdTeIPEbIeGBigTAgBRA2t2AudjGm5vIGYwKGhpgkBDfUuHZwTcjFwY2N4/iWgHHNJYHgFnAfZFIDbrn0Y4TrldSakV9WIpQRK89ITt4/dEGAxC12Ll59P/MHGn5zzu9+zpxz5pz+h8fkXOF2h388oe86mB5MksH7ex5ljNFdFXuKqs50dfQpqK8ulh/DHszMcNuV4a9sEGuNeJRMMmN1L9cxGdVFPihA//l3Fdj2xt/UZ3/Vn8gSxSffKSS+dDFUX0PH+FfZuOHbKusrI/GlSDjS0ndqs3y+Ko6+auApVYs04Ciyuut8z4TltmBX7ckS6bds/ztmrKOp98v2uh41vhVMuoR3SvX5k9UH88K8F/yDG3XwZb/+isr25UUbr0kko6st4zfjV+qvstG1io/Lgh4Bt84c/jEC1XmqRR9Y2d59JPxRfmWISSvrT9cc2B/vhTzCWhbi8evB0IrTx84N6L9uNpbGo2SSajty3iD/yTN8AACGpVmE5+eLffUfyGJ8fyHf+XGBq8CE4t0jLV9pDwbFfUQCfGl9cQVCEf6lZfumwqkG5kRWttXUXbW+sGK4yN/nW9aBgdFz1e8rVjP493XgW8HkWuAZUpDN73u9bnA1QU3TNML39/N8NGlsJSH/LQatnwGOSMB5LAX8G7P5weILAJze/8YTT17Mjnmh26B8YycRc+hT8wOzefLayed/FCMXkxJxzO7n3x/6zPzAbH6gem8XsfPNtvdf+lFqSrhEHvdCyx//1PXzPbu3JcjFMc/+/LeTZvMD82zHc6T0+Q9bqp7dtS0hPlyW8txJ6+OuijX/7tDTwfvPfHRom0Sy7eQds/nBn3/95rOpcmIDKSTlcXvevHbvgSOTT8Ud+dR898xOSdSRIZsgkxdtP2+fTCd2nm6r2R1Oxr/6+wcAzJ9//YtnU+PFpISQpPy4suWPs0708McPPxjmJf5IiJrNdy9mx5R2s+wn5QSZfuyPD8yzd68eeS5OJiFIiTgm/bmT/ffmtDFX0Vxpfz7/IzL9l3+y/Pzvq0VSIfl8N2Mxyt1fpkq2nbzz4MEX8AXzl48O/ThGSmyQhKe+dPlP/202PzCbu54jJcU9VuJrNc9vk0mIDdKonS9d/P202fzAbP7iC/jC+KdLL+2UEyRJyHZX9WgXynIyPb5qlL1+OIJM/+WfHjjW9VRgmENdD2b/2PLqnvQoiYQg5XF7fnH1z//txJFciL9Az6o3txOpp29bi730fKqcICXihOeO/bbjJZnkuY/+22yevJgtCa/st6vu6oc//XFqepxMHp7608tWdT2Y/VPLq9kp4SQp3CAJT33+zO+nLWx8/gXA558vNNzvfhpOPvfLj37x7M70uBh5eMJzb1zX29Qof+nDlucTJER2yz3zA/M9xS+LLJJKw1Of+/mv71oF/BzgC90fP3xpm0wiJKVR2Yfa/mwtfIETKnTWsPr8C4D7E5crd0dJJEJSvu0Fq0fdrkmxauDB5wDwwOKWFpF/dygq4301fbWIlD77q0nz7w6Fk89evPfAbH5g/mzo/E/z42RSgpSGpz7/S0sQmR989vvzz++MF5OkkJRG7XzpjNX6jtH9+edfwP/114EzRenhJElI4n9co7CYxvzZ0MXy3VESSUBgmDhm90sf3po1PzB/1vGcRPLsr6bt2vvsV88RkufbPrMG5q64rQsD037Ndj0v2dOs157LkYhf6Jo1P2CUHznznMnL2ZK4Iy0Xy5/dlhAvlsQ/+/7Qn397uvjHuyxWtup2kdWO2aR2oY3Ji9mSuCMtZ/bEE+RLV10JuIDJzzqeJaXP/9YuQkdxcOTzv3VWmrO8tDiL/vm3bz6XICVIiXADabskhOS5i/ceen7+/AsA+HwB8T9Ebt8003Hxt58tU/IXX8AXnz8wz3Y8Jylq1LOKihhbVrdmpGsvSMUvdDGWkv90etsGMq7mjjX6fvuSWPLS1dkH5s+GzpQ/azdEvTWs5l1zDm/uep6Uv/SrrmNFu7clxD8dvf3Zmn6bCzlLYr87FE4+b0n4ae+pl0hEC7LB+RHaWvs9xbGi9HBSItwgEcc8+9Kvbs3a/MfO9tM/2m+PpvnX9Kfvv7RNJiFIux3JgOAwe/qycpjxvpq9/XqaRFzUMevA8LaTdwDAFp4SgpTHZR+yZVQn/k9df/+5nenz/N/p9eALS9/ioTqSS2Iwm4yLr/tGg9P73wbioeqtROKJW5abo0eTRFtLLo1Omk3GqcH6nM3inKY7ZpPxP09tfzIgqrjpjtlkNGvq0wIIMulAj9ZoNk2PHooVba0eNRnNpvb8AKFoa1n7Xwxmk3F2sCoxIKysZ3qJYs2DVdL1YTEFdX3ayVmD0aw5lxEgzjhx457BOKu9cSJTTOY23nNg8r7RYDbdOb2dkB26YRPk7gXbT817O0SbonIOdWmmJmdNxr/2viLblFTReWvKZJzV9lZvF0tK2qcW6uHO6SRCdmjIpo3p1gJCVNJu+XvwUJRoc4GF7XuDdRmbiIwLVm04VuRQ2lD1ViKj6a7ZZDSbeis2x8ZsjXql12A2Gc3axpyA2KpRo+a9HU9uCks70Hx7anpW21udRIhyG6es2iP2tBvMJuPo0VhRZEnr6N3ZqTs9h5JEmwo6p4zm0SrZerEst6pzfHLWcKfzxdgnn9rfY1ho1p4XxbYC59X117/8dq4ubXP+ZnHG0V6NwWg23Ok8ECuKPDBoWOAbLsVfoOdbr8WKkupum4xmQ29FpFBW0qwxGGc1XdWZUeR6Ir/TaDbdvZBJSA702hwpLOe9oVmT0Wy6eymXEBU0T9lUJylovD1lNBvu9hxKEm0u+820wWy6e8n27Lxr8IBkPSEpaNSYjGbT9O33doie2tuqNZpNXcWbCElS2YXRu1OGabPp1okkgsysH9QazabJ0QsFkoDY6lHjfaPh9omkJwPEaS/aDLGdEGWe05icOGFQzof3LNxmEqJNscUXhu4Zpu+N1udsEsYcHTKbjLeP2jQweEASsOuCdp7Is625ooCSHgvbfQckAZkXtEaz6c6FTLEk/6yFsdtNJbKApBPjRrPpRlUkkXj0xj2D0Wy423d0BxlZNbgwurvKNgnJrQUn+u5MGSZvNxVI1kdVjRrNpum+A2FPRpZ1aibvG/Wa1jLZ+qiqQaPZNNlZMOcVFrWTJe1TtsBs+IN2YWA6Xpr6tABLOUaztnmPc8+ZvJRLiDbnnh6dNpuM91oLyPXimJLG/7QFrOTFXudW21TQupQ2Ji/lEuTmHRWtt6ampl0LOJ/JqeacAHFxj41/Q/Me688FpTnPSwuy6FTfgcSkgqoLja2tjWVJUfknGltbm1s72zv77swuSLna5orc3BzXV3ZOTs6BZs0SaVlTn7be6lTzSp5qzAkQW3Kp62Q+VL1VKDs0ZEs+RE7T5AKyqdYCMvLADaPBbDLeu5Ap2RoryTx3z2Q0m4yDh6JEuc1TFkMUnLMbQmo1xLxrzuFNXcWbhKKkA51ao9lk/OuNgzHrY6tHjS6T2GCVzJbw/zptcJ2IFmcDS66b7iwRk5n1o1NGs2lS03kgcZOFvXls32ooljlhe3r0RGZM5oHTTc2tTVVpkbnVTc2trc3t7R/1jM9X1Gh1jP1xB4ZnDcb7f/kwZxORdqjrnsFoNtxpfTFKFHmgz5X/F3+osTQxdv93ds225orWh73Q+xX1Ch6/WSRHDJ5r0QRllSUKMADw9N+xR471N16zTuFjGxPicQAA3E+AsZzgJAkXAFB+IA8orWX4FgXgx2dGcAEAUP/tCYKp3u7RpYpFAQBEyduDuBiKAuCxtR831mYJuSigXGFCtA+jHF3VejGW8UnIE3tjGAp094WP6eCC/RE8TwCUS+TnhbHdHy1aEqcZpkAgXOekLOZmY4vWN6vYwjbXPzM/2mPgklUbDhU5wkcSyFEqRhgAUPb1Y+KMEGT4+jgAMCN9wxghta6tEWYXRfExFOUSidHrgFLPH/wePNei9d9dEiPgoBguKayqLt2KW0eQkZCsEikfQ1FcGk9wWI1q+Yk1e10b7XXpui8r0Nh9RYQ3CoDi0qLMIF1P48CXFl95VUE9kZoX5Y0CiouLC8XO541QYmeyDwoAwBEFrgPVOAUA4JN/trnlcCwfA0A5kngxTo8rFx13Oh8e0vRYbwAAlB+fFMh+2j7CAAAKLBa8I1XA8URRUF5uUHollO4QcQEA803JTcA1HS0jthL8dpZaDZGfJYbhqwqdEydkx+1OyLK8pH0pPlwU5Qp2ZEf/k/p63xrXMyovnx3m7f7JMxbG+PF7dwo0V1rGAQw0DSiGYSgAygkqqr/+cYnIWQF4/N7sQNwTxfjRW/0RvUrFAKBBpY3dH5ZJcQwA9ZbHBnH0Y0o9ABaSLEYHOrsszq/rax7wkMaLPW2BGe803p1B1335OrLVpef4xyYIUADgCvxwQEQpsZZ84SvwoCmtbSHHPKsFMX3tI4xrbQAA0PjWbDnPE0NdC7gKOJTmPC/ND0Z6WPnEKyer96fExkRwGNovMT02Rh4VExEuDVw0jcKNqjj+Rp3r6+03X68rj1q40mUlwHz4XHZM/WWn0T0DNwl0IwNqAKD7r4/7pm/3VX3aTwOAemBA7x9BeCovnx3mZZdusxsi3WfOEE6BAvDjd1mWdqHCAF9Eq1QxLpPY/ITvOhEtzga3lRQAsDM0CwiGYQCAeUeUXfo/57P51miaYzsu39F/rGDGh9HM0yfLMuKjYngww4vKiI+KkUdFhIdJlpi8n88w1fkrBRK5p1DMRQFQPKZwlz/V2TBgm9+b7//CbVu9ARb5/9eMx3pPXp16Qs8OVMiEFQ43ORodwD8CIBjHPn+PoggX51j/RhAUWNt/EBz3sj/J5SI0pWd0tKtivQEA8RLw7amAVXW/9fqlmyqKZgGAMbAYb1USIFwv23ILPaVl6fGiwE8c//8EpQNwdFdaTzMIF0MBHiwsi6ZUtAfOm1uvhvNx+GRcBfBv8yqaB/8IP6j6dAzCuQM3af9cebD+eP0fdfDkhGIUCSzzB9ABIJy5ZxEUBZad//WBeoJGvG3qBZQnjecBAOgBEJxvZwdDVrL+y2ldKqWapW7u3PCBI2WgXg/AmfvtWny+C/EZSq9DcNz+hGCjAGlzxhKHazO4o/i0su1IXduwSk+zAMDSrJdh6Zn/edrgcBBWQ1lSPOLNtzoho9LqEC/BnBDrfHHkHKVl4H8DAIL72HMXiq/D2WsTegDuYif8N3uVGJ9nb4FwPg6fqCcsbrxKMJSGYkePxouPzhOIAgjPLhXnHUyNuOQXGLhREh0rD+F5OhOeaw80FPVEQceyACjoB89Wv981TOkY9jvfAYZm/S0kgbFSrLSjW58Yz9F1tw1zw/eFoPZ4D3AamM6gUqpZ7c2dGz50vBmo1wMgAIBhHCurKIIiGMfR8cBmy/lW46KsitIz4EobXgCA4fgcPy4EXDnmSnOd7v7NgVySvs3yFzPQ2c/x2/f1LI7wwDlAU3qAL7d8liuWCmp+M6L/f//1jmKYF1JKQMu7CiXE8EZ7VT7SEA6j1FDs6GtbyNccHkK8KYAlluEjXI49b6AoCjTLLp3E7Al/iUS0OBvMsACAxRTt7cg/LA89ExhISCIi5dGEN2qNpoVs4/PZRoWp6dY/x7r7gB+70uVoDgxT41rAo+baKy7ujRlUaj2EYLDI/7ketgIc/d852GX+//DwWPdgAAA85G93VYcsvPvntRU2ZxXnxS7ATEflnmpKfuSduggcBdA15kXXLV/HPNMjiGOGwdNPfVIqXA3H87BUF2F+RXag/mGB9JkBlZ6jUPvG+3n66wXKnn46kBqh/Xf72RvuZSp+mP7soi5BcceHO5Zuetcg/tpZoppK88+w6dXn3ya4KIDqTHKak97PimtwxTvr4v4clnZCZFnbrRzIplc/qUn6x4VHZPPjqz+JoIYG+rq6r50tSz0u3H/6+Db+ikocr8kvb8b31n64Y/0/PPjbv/1DpazIOkSEbkyI4OR19OnixV2fjOIR9nEdD/nbXT9/apmTuufBp6ijIX2R53zp7wSda4MGsL4HA8BSAq4c8xzXSV6yLB1YjOHuPhDErmUE5RsEPCjQ63jf6My//2EI89uJ8xh/tEExPkNfU+Ib9+MASgBk089+80airfdpXu4Ud5dYYRJzmogWZYNttmyACnbU/SZWNdDX293XVVd0vC7s4PtVUpjH9nI8j7d36/l5zsbd/wfgsZ5F4vL4HINKqbbfYHTUKjeIZFVKje1vLaVnMdwLXXGxyoERRhCbHWEZnmXGRtTOGhwUBWAY+3/0lN5ps+SFeyE65fjc2B2tn1icZjEOhrIztDNuuLg3ZnCY4WFUSgp4Psu0JRghEWj7r/cplLwQfwwwP4I3quju66X8pIEr+xiHy/PmONTLqNvrL3Y91I8s+AIeQt1UzmmD1lGLVLN68VEuB2Mpyv6EclS5fIfBVrry02Hw25lHWIZnZpSDqmWfZSmVvS4dRRkQHOcsIEH563BWo5xr5bRjFMvFeZZWjNVr7BsxMJSGQjh8ztJOyOoptd2jKBUFOG9tTRqKr8NZzYjDR2MzlN7yY0ZHMxguithWXPlG68ld2MAHV1bYSutGhilEkm6ZMgOgxpVzoYEGxYdxBzp7lZ3Nw+sSk30A1hLvfAEPoX6/jOcsjflWm6ARHOcsoY0VC+gABBBgGfvIpl7vPEOsTvyR9usGvv+SOwJQnZX5ebtzXF45z+bvrmhbYpLONQyUHrBF7r0G+IYQ2MinXQODtL+YD+Ab7EcPDHZ1j2AhYb42txxWzmmBdmqIZbGyJOYqES3OBvYgZGh6BjB+YFRG6YHTv6qOYa41dOsXs+3cfyxQ9SkoL5FgLa9guI8Xoh5V2Yum1Crag897CHb5yvD49WAQAFan1upohgEiNX6d6vThs8N6AJhRtZXvSs06v7oNIqnuMy1qGoCZ6Hi3QekllfvAiovl4hyWutlPAQA91Fh5ToUhNKWjFzDpgfM96BGLGzGqlg+6nE8woiHbnuYOvFvZMj4DAPTI2f3pKcVNi9LHOl8clCMaJwXAxpT4dWP1NVdUNADoBt59p5sNSVl2GpsTEsEbbjzTj20MwgGAFyhE+usvK3nioJWOWvqlyNeN1dc0KPUzNNVbV/mz0zeZFb/5owjCUmoVTTOuEw83IikE+mqqOycYAEbfX1sUn3G4a2FLtHrxhWFBnNsNp3smGGCoviN111beuKEcLy6rUQzoARjdwJnyFj0XaN0yydOgqD8zRAOAvv/0ByMem6SBi7KSIDZVqG9+4+IYDQD0WONbzdQTqcm2dogZOfvGoA4A6PFz9X3gHxnEdeqEWh0NAMACIMrLx7spBoBRNZ3qNgiCxcuPjqAosFqVip7XOgqSMgL1Lb94p1fHADAT3YezErOODDCgOpO1JetnHeoZAAB6bHicRr1W+o09xuGi7NjAyAwAQ12rqb7GcEBnXzzhHyvHRxur28YEsXIr09bAPD+yZGAiCAL0hFo/wzDciKRg+HQ5z1ka86w2jImlgahLbaxcQAcmAeXxcVapGGUAAPRd9W0ueoCrSXfDVxUUx1ewpCXwqIrjdadPurxOnjh+unL5UZwFs8oAAPS4Sof48jgAwAw3VR5sGlrzIK0wzJ/99FSL1j/YDwVAFRx8TwAAIABJREFU/cW+6sunBiAo2AfA6pbN1W/bDZGTnOPEEMtjRUnMVSJanA04QOt1DMDIkbSYrOq+CRoAGJ1yXMV6eOMeC9imeo449x8AAJi4fk2J+ghWNqq5AHjUM0Fw7Z26QR0DwKjbaz8Y48WmLE47q4HlZXz+iJW+q/ZwTfcj2Rvg8evB8BJTNkJHUcSW8i4afItqa5Ox5uIUYoMkIuciE129yo3IkJCUMOXPc8NJWXy1WlB6cF8gCrDSYvkpZfsE6tcSJURo1uvqyFdq9sZwb5YnlrbrrExGxlV00agkryQBuZi+JSEubU+NLjY7BHEYkpkDFvxC3eEotr4wgiSJLeUdWGbt4W2L0gceEuylG3C6HhMVFdZWy5lTOTEEKYmvuMkvrH0tfvnutnfgRo5aA/5iXwAAEBB+tFqDR4hX/LKOikprq+XM2ZyEkNDU8utee96uiFnxFiL+8bH++vd3ylKOjLgm4kYdPFkmot5NCZUQoSnlI+v2HS+TLkzOqxcfFe8/sos/XBn/lCS6+DKelRu48ikX/8xX0r36i2MIMmH3eciorNoTDJ88n1SucJ09Eb/UeDiVIQ8mE4oUXum/eCHGSfvCy6ipzsba8rZICDIh7xKacfyNbMvOPzSLCGJT8ct5Mikhy2tAY6srt3k7c8Jozu/LE0vbdQAMgsdn+neXx4dKgtPepUPKqvOWjw40MCmBp37tmZj5u8XjqTXvFPJGf/aMjCBl6bVUUGXt/kAU+NtrK8W6uryIDaSQTCi6hGYcPpC4Quuj4ftejkRb9kSQ0q3P/9o7r+pgup++MSuu1uIKPonxXsMDGv/4uW6oJTBbnt++VGByxQkhmKIiRr63bYIbVXniheU8Z0nMt9rOmrIYzLU2Vi6gI5Pgk1G6C79eGrElJTnj1f6QHREc1lmGWEW60ynHdZyNIbzVSLoazHS/mpyYEp3x9hiC6BqLohNT0l76yP66NTPQN4wSUn8UABj1tcZL15YfoXQF1C/cb0qt5kksQ8KYXxCuUdOErfePp9a8s8/BEIEHapwYYgXVrCiJuUpEi7JBnhjaixPKFT77a8p8lYdTZKRwgyy+7Bo/r/qFEHQB27ve1Dr3HwAARjkwjgVak/Oqwd362tt78YHK+FAJ8XTeKTqs+niJaK0dmP7q9LjEhPjqm4Cw3S9tj0tMz7N2oPVD3Zc7Hs3+Z98xm4yL765qsvDxJe4pJcuZI73HQr9FPANQTbsT3/c5cfHFgL//Otl4TIgZBlBrROuadm95l3+8oyLwEbAxfDg8R53/cV0qdwXEqyrZTfzoiBdZ7ethYy3EDMOg6KK26ithQ38lJ+EdXm1LOeGqrfxmq+4bRjzfkt9MnhnFq3nKzNNZvIde8uM3BvM/HnjsvnSk5Re/enyP+fjKMF6TGBpd3KaiARiqq+6DYUwsXftCajfc+ObASfflq8GM4q13VOJ9eS67L26sDl+bJVcOWtGi8Q30Wp5w9XD3YB4/oKK86jz0bHntV7oZ/+MIn/wjFRLdu+kyUhi684jSb//xEsk3Plu44cY3F7rOn1WNBlWWrXwe2Y1vPzDpkfr9/o8kdbpnkdzEbmI3sZvYTewmdhN/+4jdYzBuuOGGG2644ca3D+4ejBtuuOGGG2648e3Dqvfk/fzzz//7v43G+/dnZuh79yY///zzNdeNIgiO/8DD43v/6+//F7qiPeXdcMMNN9xwww03AAC+c99oWPPDLMuO375D02spwesH3+fx/m15OjfccMMNN9xww41FeAgreceUt//rv1a3Wc0T//HDH/zgX5Yl+9Krgegr+TGvcauvV4ofdskPj9j4h5r8l8+NGPxfbj6dstQGa4+KjeHD4Tmq/I9PON3T4kuU3FNKlt8/dO3Np1fK8+2T6duvRl36MHPR9pI9hWQ5HOl9I0J/JSfhdV5tTzlxuyZl+6exi4jtlGvj+dERu9LGnETzbj8qo7iJlyP+xm3xYt2VytGlH0bJzh3P/LtDTz/3Z4v4jPJiUfHbCt26fWfPZwtWxfPqieer/RvqG99OYlV9evInTvPqlyhZeSw6Y3TnlfoMF0dzfptW8v7Hv//w+99fvjtih0DwHyvpvqwZM8NtV4a/9MFsD7sol1UozpxT8vZ//Juluy//s0EUn3ynOHDeLXxbZX1lpCV8HMzkhNINN9xYKXx21Z4skXIBAPrPv6vAtjf+pt5p98WN1YAZ62jqdX5czNcHerzxpznRoRIhKY3OeLVBuWxL902U4uGs5PV54oceHt9bCaXXD77/L//8SLcCoBWnj517OBsYP8SiXIKlWeD6CHD3NiNLAOP7CxccpoPiPiKr1hzN5ITSDTfcWCkwL5G/DxcAgGFpFuH5+WLu1PTlMXqu+n3FIzkXaM2guyoKj44/se9kc/fH9fv9x4/kV7Yv0zv54zdPiof3LdL/ftLnb/5mmdI8PL73iNe+6BtyYl7oNijf2ElsOdwPAAAI6LtqC+NCJUJSGld8ccja0WQmuo/lpSUEkxIiNGX3wbaxhbu/zRX1VNyRftA35EjiqtvO5icQ5MtdAECPNFRkRYdKhBskwVuyyhut28ep3ttFZJzpanx1d1p6nEwenvaq7SReqqu6ME4mEW4gCVlKXnXPBIDyzV3RVTdZ6oMsUrq7UQ/AjLUc3p0oJ0gJEZqQXtFk47ankJRXNH1Umighctp0w4fDycKz3W8VZqTHyaThaa+2q8avVOQlJyaEyxLy6kdmbCL01pemb5EHk5LgLVml5+33GVXLq+lbJAQpjc44fEXtdN87fUOGJPpgW8P+vOS0lGiZPHl/k0VFFgHba7PCyYTKYXDNs6WYazX5KcEkSchSCu0MuFCd5YGxxpeTZRIhKY3OOdxO2cWXFHbP40/15nYi7YxqocUdKedM/FT4dgcTOzGEI+jWfYTs8JD112CljBTmNFlDm27Ls0jNWAt5KjgseEt6Yf2ghWCsOoFIu2gvcKw2xfGnrYLBU/kpwaSEkKUU1g8u0UGmB84UJsqJDZLgxMIahZ3QtVk7juVZ6LfkVbbY7KrrO1WcHh0qIUhpeFrhEev5avorOZK46raGirzkxITg0IS88yMTijOFGVanbbefwqv8qDLf8rg8Lv9YF7XYW+aKStv2zBJFzQxfLM1ICCYlBCmPyzlsY3BRZLkU0AHDh8PJwgbFmcKM9OQt8vAteZXdNv3QI+d/mh8nkxKkNDyt9JRi7r5zrxs8Ek6Wnu04nBwqSa5X2yqgzmZIwvf3zUlLNaWT8orrC8VnlG1O9cMom8p+tJUgJcFb8o50t5WHSvI6GEux0dX2I770DQ4/J7rfykuTExtIISmPy39ruZddfX99afIWKbGBJEJTdh/stJ0w3FNKystbemqKs5ITE8JlKXvfvGmLuxU43uCRcDKvQUc15MSUdrPsJ+UEmV6jnPv/TEuhQ3TcdB4dK7HgElnIlQWde3hPcfDW8sY2a24EAHrkbEWeKwfYEh62KO24Sgh6xXv7l5MCJhRvFSZKCVISECgWbiCFG0jhBgkRWthgNx/TUxq6p1mvPZcjCd7fwwCArq/+J7vmhyTTu19q/S8AqM4kbyDjatXWAq6/Ehz6chfjutGpT7fn5KoRi0R50aESIlSevL9pyKmldZ1nFRD/k30xAg6Xy5MWliSgfeeWOHyR6SkL3ztPCgBW1VSeISdIkpBlVc49q++tL90Vt3VpvT00mE3Gxdd9o8Hp/aWJ//xnVbdrXLt2zUB/traSV0M8VL2VSDxxy2wymk2Tl3IJ0eak4gs37hmmp0brMzYRae/dMZuMf+19RbYpqaLz1pTJOKvtrd4ulpS0Ty0s01rUfaPBUhS5eUdF662pqWmzabrvQNiTkWWdmkmzaVrTWiZbH1U1aDSbjP95avuTAWE57w3Nmoxm091LuYSooHnKZLzXlCvaXHBpfNpsMk6NNxZHinOa7t43Gu5dyBRFVg2ajGaTcaqzRBIQW9Z5Z9ZknNV2VSURZEHzPZPRbOoq3kRIntl/YfTulGHaPFglW0/EHGi/ZzKaDUPVW4WizZnVg5Nmk3Gqp0wSsOOC1njfaBg9miTaWnJpdNJsMk4N1udsFuc03TGbjObxusQAcc6FoSmTcXa8uSxJLFq/64J2gex3L2UKnwxIquqbNJuM5qmuskhhzNEhi4CiTVE5h7o0U5OzS/HcXhwgDHp674m+O1OGydtNJbL1YRV9S6nu1jtJTwaI015svj01Pavtrd5OiDLPaUxGs6k9P4DI77RwRUgO9JpNxluvxYqS6m4vtLid0jjbd8Bu4r/+5bd2Ezs1xDxHunM2LSDpxLjRbDKaR6sTI2NjNhe0ThnNJuNsZwm5uazHMD14KEq0ueDS6OR9o+HeYF3GJiLjwh2zyTh6KEqUVK+xFTV6NNb2s704gNjTbjCbJjtLxKKtB3q0RrPp7uCJXEmA0CLRvGvwgGS9WJJZ1aOZnJ2603kgVrTJyoNTs943GqZ6ymQBSRWdt6YMk7dby2QBURV902bTrRNJBJlZP6g1mk2ToxcKJAGxr/3BYAuN3NOj02aT8V5rAbleHFPSqDEZzaY7p7cTkhd7zSajWdu8Z7M442ivxmA0G+50HogVRR4YNCxwlbmi7hsNrotqzNlEpB3qumcwmg13Wl+MEj39Sp/BuCiyXAo4Xz9VsvWErKRRYzCaTcbbJ3aINpf1GIxm050LmWJJ/lmLvLebSmRWU7r0uvs3DsrWh8UU1PVpJ2cNRvPgAUlA5gWt8V5Trl3nZpNR894OUWTVjQVsaJvznerHcKMiUigt/pXGYDRPDV0oiRWtt7jlndPbCdmhG/You2D7ef/O2YwAccaJG/cMxlntjROZYjK30RZHVpd2zHVTrQVkQFJV391Zk3Fq/Fz+ZmtmM5u6ijcJRUkHOrVGs8k4O1gVsz62etS4Qse73/uKRXyzabq1gBCVtC/0TM05e3Tc/8NrzqJjZRZ0koUs9bqyoNGFh3fte4qQJJVZc6Pl8YJzrhyg/Y52gQO4SgijR5NEW4qd5E+Ha6rvQGJSQdWFxtbWxheeicw/0dja2tza2d7Zd2d2ntLq0wKs1VlCMmjXSceQrB41TrUWkJEHLA3BvQuZkq2xksxz90xGs8l442CkKLd5yrUPa97bYc/JfzUa7jVligJ2nBicNJum7/VUpW0inrSmSoerp4QMKLgybTfKdGsBQZa0zy4gm5cYT85JMVolWy+W5VZ1jk/OGu50vhj75CZLAFqt3/AH7RJ6W1jyl+gVPMz9YHCvH3zvey5PE+Tx/vXv/u7vHmJ1KwTLT9qfIuSiqKcgKkYAKqUGgO6+8DEdXLA/gucJgHKJ/LwwtvsjxXLzgDS+NVvO88RQADSotLH7wzIpjgGg3vLYII5+TGnr66LEzmQfFACAIwpcB6pxCoChDYB6eGIoAHjyY6s/7qpbeDAyrWi8RgfmvhCBowAoV7xnt5hRtPXSAAAosJg4LVXA8URRQAHAS5oSzgUAdJ2Ij7B4ZIY/BgCeAj8+UGMUANw816IJyipLFGAA4Om/Y48c62+8NgGg6u5UYlHZKT6eACg/al+y6+OI/ZOyrSe+ilMivNTdnZbhJJbxScgTe2MYuiTPAMANz84OxD1RjB+fmyqY6uoYXUZ14LezNIqPoSiXyM8Sw/BVxRqnXemu820OJt5oN/HyhsADpHxN74geACYGbuoCtyfi4wolAMCYYhT8w4LgZmOL1jer2KJbrn9mfrTHwKVrC8danIIZbL9u8E/PlXABgCPKynV9EjIi2b1XgmMohkvztvvTfe0DDMCgU7NSQCsuXdWFZO6P4HmiGF9eUnskV8phQXm5QemVULpDxAUAzDclNwHXdLSNWmvwj00QoADAFfjhgIhSYr0BAHBfgQdNaXUAuu7L15Gt+4oIbxQAxaVFmUG6nsYBZ8wuV9TEJ5cVSOSeQjEXBUDxmMJdQu2vGwas75wOkeVKwPlAAYAjTY/1RgEA+IF+XFqj0gMoL58d5u3+yTMWefnxe3cKNFdaxpfyOgQAQJS8PYiLOR4ww41IkkJfQ4fFM6mujnE8OtZ/Phe67ssKNNaJfpRXFdQ6eWakNwqA+aTmxS5eRLkQ+Jbajxtrs4RcFFCuMCHah1GOLnG0mae8ouXjun2BHBTAkx8b4w9jA+N23fDjd1nWsqD+GwWIVqliVuN4S/NJ2KODGnQWHeiKLOgyC7m0oAsPB0CAxYJ3WHOj8vLZYV526TZXDhCxyAFcJITBcy2awB+/sDh/OoAeVj7xysnq/SmxMREclvZLTI+NkUfFRIRLA10vC1BeblB6xZdsnxeSLSOegZsEupEBFQDQ/dfHfdO3+6o+7acBQD0wOOUfQXgumTkdc3JvxyiE7NrpjwGg3JC92cFOdiqZ0dMM6uEwQ4hyMQ+GNqzmIBokJKtEysdQFJfGExxGo9KDPX7jl9Lbw8Sq94NZGk/8xw//MDS6+P73vvf33vgjOdhpWWA4blt3gyAIAAMAekrL0uNFgZ84Ej5B6QCWjGoMx73tP/SDZ6vf7xqm9CwLAAzN2rMbwuFwbZ6BoCiwLAPgG793Z0dp0RY5z5+QRITJo8NE3AVOrh2jWG6Il6fttyffC2f7VBSAAAAQnOegQATztja7KIIgCBezMm455YsF0Gkm9OxAhUxY4VADR6MDYNV6wNfZl5Bz+TwMcZoqEQfVARfngF4/AfBvAAjXC8dWxrPfOtt/vHAOQlN6BgBdQnW4j30VC4qvw9lrE3qAtayb0lMUSyudmDhmeUPwAgM5pxQjTDwxrFD7ysMDsQ+uKMYhEBkY0funEyjdqaI9cN7cKnycj8Mn46qVcErrKdqDj9v7TLgvH+lySol4Cfg2xri4N8aqKD3o1C7Mqh9TATeEZ3sA842IBQCmQ6tDvARznK7zxZFzlJaBHwIAhnGshkMRFME4Ns0jKGqJE5VSzWpv7tzwoSNfgXo9wMJV55aizK6LopQU4JF2gYCL4x4GjVoPIRg4RpZLAWHh9DPCmfNOW7EMpaHY0aPx4qOOhDgF4LNEwAKCz6l6TiRxajQnr6VzImWHN3WtQ+mTesQH4IEjiUqpZqmbOzd8sEA/DK3VIV5zDoJ74ctvd8Wqut96/dJNFUWzAMAYWIy3FDmj7z997FT3uIUcGBZCWMaqCYTLsRsIRRAAll2F4y0Dh+jo0/jGLIoOXedKLKhzkoXUsJQFEacebvm/N9+aGy2Pv7aFfG3h4y4dwNtpQrD44atRwlcXSjHXBAAmSd9mrXegc4CzvngFS4YYlYuQ5IqlgpquEX02Pq4Y5oWUEtDyrkIJMbzR6+onZCEcgCUbHYecrKJYboi9C4XiOAdRL8/YqoHgfLsUGGKtzha/AYus7w2PBA+5B4NhHv/4j//3Z5/9dcH9J/7jhw+3oi8PPP3UJ6WrPGh4zkHHa/LLm/G9tR9a3m4HK2VFDr0AZ+kKI4rPtmcob/YO9Ck63s6qfTehpv6lp1wOWVnAOv6Yt+nfSjYA9JC/3VUdsvBu//xSLQ3M6oAgS4SqY+nOuFxadQ8TdhPP/wDPiSEqQuZ1XX0jNiIVn47RaJeSF1LO8eX40KdHJnTQq/KLCcZcyLUysIvuuFY/6rwaJ2Y1m+/8HtgVmHJx9cvBp6ijIf0RZZ85zPMnpwLO6zosBWTTq5/UJP3jgo8z1+B1aFBKJJ5xuUG1I7G7TeW/Iwa39NHmQ1Dc8eGOBfphOgBW5CSM3WD0Jwf3VGvlR96pi8BRAF1jXnTdUg/2V+e9cJ342duNiXwMgOkqlpUuXdVqHG9p2KOjZ3xdyCtOomNlFnSdhZxbUO25hIc75kZk089+80biwndRqwMcO5+68QffnecAzjJzhQAAPKLfuHp084q+8h3u7gOfLWsKE7se8KBAr3cUIzO8m0OY306cx/ijDYrxGfqa0mtjGQ7L+PCSOXkxPDkYyhhoxt4FoHW0AcU4D2PZtof87a6fP7WKD6S/DB7+qQK8dQtflricf8Iwj4de0ZeAF+6F6JTjcxMUtH5iVR9N60aGKUSSbvEkAGpcqV+ubWDoGQblCsSJ6SXVZ88dDNE3XxqcH45evnxEp9LY1z3NqLQ6xGuun7sqcNfxOQaVUj1Xv46aYQAAuDwvoDT2QV2dSuOCd5amKLuKKBUFOG9RiC7NM0tptbb/aCk9i+Fe6JKqY/Ua+1JRhtJQCIe/xm/MvXDchYmXNwSgwjB/emSg+9owtjEIB9Rf7Kv8VHH9UyVfHMS1jIgYKLVdhYxKSQHPhw8ACAIMa5OH0VGLVMvhcBDDBGWbNWPUw5QLz2G1Y2rb3zpqgkZwnANcnguzcvB5hqCHWs40DOhR/jqc1Sjn8px2jGI5+LoV5im+gIdQv3f4ypLWUWvcXAAX4Ih6VGVXNKVWGzz4vEXWdSngioDi63BWM+KwNHyG0jOwpoAFAEFSqkDbdantSos2MDls8QAbX8BDqJuL9YNyORirtRsZ1OMqa20oCsAw9qr1dgdRDo4ygtjsCMurMzM2ol6SP23vgIEXkZloHbHU9KuWE2fljrcc5qLDw2l0rMiCrrKQSwu68PCFvOHrcFYzrHTpAP6LHcBpQrBIMb6MFDaMtF838IRPLKG0OQ4tITlXsHaMYrk4DwXwDSGwkU+7BgZpfzEfwDfYjx4Y7OoewYI3+8LKfZjjzUV0lD2P0iq11gmdYKMARgZH7dl2VDEMgkCfL9uD+XLxuwY8/B6Mh8f3uJx/sv/87ne/+8N/5z30WlwDAWB1aq2OZpZ4uQ3Z9jR34N3KlvEZAKBHzu5PTyluWjRX57oojMNF2bGBkRkAhuqpqb7GcECnXuqzkq6KFPneM/0UAwAMNdpPsVx8QYcXC0mOxAbOvNZNMQAM1fd6XR8WkbTG6WrYmBq/TnX68NlhPQDMqNrKd6VmnR8HAH6ImKfvPHV+fAZgRtV25JLaxYkOCKK8/LqFGVXTqU8MvGDxoun8pXhmANStp66oaABmovvdBqWXVO6zjOqYkbNvDOoAgB4/V98H/pFBy0/MODUTGpIc6WDiUZuJV2IIAJSQCrVX6vsYf4IPAJhfED5ytn6EY9XAxpT4dWP1NVdUNADoBt59p5sNSYnyBsAFPKD6+ikAAEb5wbmBRakDJWJCPIbPv9tLMcBQ/XVnep1mIRYADIrzlk/n9P2nLw9j4phAFIBwYVYsJDkMGzjzWod6hqZV3W+XH7w8Bh4giE0V6pvfuDhGAwA91vhWM/VE8jbXK5/mgxuRFAyf1lR3TjAAjL6/tig+43DXmvow3tFJQXDtnbpBHQPAqNtrP1Cu25oSuDhhuhJwZRAkZQTqW37xTq+OAWAmug9nJWYdGWBWH7AW4DEpG6nGY420ODXCSRxyI5JCoM+JfoSREo7m0i+vqmhgdCNn667aavLA+R70iKUnx6haPuiydbE5OIelbvZTAEAPNVaeU2EITelcqhrj40ApB1UMAK1uP/juMHiwOv1Sa8ZW6HgrgS06WOFGZ9GxIgu6zEKuLOjKwxdAkJQRqG+uftuVA9ALHcBVQiBS49ep33ttRX44fFVBcQQ+rjM1giBAT6j1MwxjCcmWtz5wDMlUyzIgYZg/03eqResf7IcCoP5iX/XlUwMQKH4CYOWNDick2g8U7x8f0DPATHS/fW7YGUvcqIwIaPnF6+1K/YxuvL36WDuEZcs5AMAomyoPNg0tbj4RdE4Kl7Ba//zImuJ39XgkJzvy+XPDMLx1//rVnnnES0zZCB1FEVvKl0i1WPALdYej2PrCCJIktpR3YJm1h7ctGmCwFhUZV7GwKDR838uRaMueCFIaXXzVO6/qYLqfvjErrnZkYRm2CqXl1Xs418rTZMINZHDGMZWwrLZw4RyWZ0hZXTkxUbszmJQEZxxTBZadrgz3dFreCuBbVFubjDUXpxAbJBE5F5no6tosHwAAQW71y2JdfVbIBkl8xWDI7lgcWKfTC1hEUmB3eXyoJDjtXTqi7I08Jy2fS54ZFsAj4seblVU7w0lZ/EG1oPTgvkB0CdWxNIsIYlPxy3kyKSHLa0BjqysXG2UxnFvcM6TMbuKn4l6xmXhFhgDAgkJ4arXekkoAeIGBqFqNBkVYNICKCmur5cypnJingsPiK27yC2tfi+cAgGfE3lci6ONp8ujE9Lx6j9R0HwTY+arFYl6u2on3vZAYSjxddArbkR+IsE6UzwASsDOefSdDHkwmFCk4O2vKLP1CV2b1DKmoK/ebeCMrIlSWXj0uKq/eH4gC8DJqqrOxtrwtEoJMyLuEZhx/I4u3vE6t4EZVnnhBRL2bEiohQlPKR9btO162xi41N/a1t/fiA5XxoRLi6bxTdNjhN/eJnL3xufTbFQFPrXmnkDf6s2dkBClLr6WCKmv3L+l1y3AdkSRFDVhEUpDTl1Nu1MGTZU70gxIv1OwVKF9LDiWDd71NRe8KtKZAVJJXkoBcTN+SEJe2p0YXmx2CWIZk+Nte2CdQv5YoIUKzXldHvlKzN4Z7szyx1MUWHZyYomIp/W5yqCQ4rVLhv7e2PFagfjsl56LrqbEVOt5KYI0OoXi9s+hYmQVdZiEXFnTp4QuAp9a8s8+1AzwdHDnfAdSuEoJvUe2xbSvyQ51yXMfZGMxzrTCuOCEEU1TEyPe2TQAvo6Z6t8fHjiGZbXk1RP2k/nq1miexfj/hF4Rr1DQRQaAAq2h0vFMqDsZDR3FMIJlQ1PFEdroPwtCLOh2YtPKNl300r+ckhGzJe11NvHKyQmIJbdW15kvXnAzqcTc5SOESFuu3PL99TfG7ajyEUwWcEv9/k/+lVv2Z+8+cf/8h7+GW7Cb+Sohd7Hb/jebZTewmftjEVFN64mXph+ctbcxaS3ZyMsAj5NlN/FUTMwyDfve7XzsbD4uYOpvztvfbVVJ0JcSPjo0VET/klbx2fP9f/vn7//LPj6hwN9xww41HDUY3cq7i7Ym4E5teAAAgAElEQVSIipTlP4Z2438yUBQF8+JV3t9SqK52IeLqb8lWzI+qB+OGG2648e3FWG1Kymk9LyK3tnztM7luuPHtAz/z9PGvm4cV4zv3jYavmwc33HDDDTfccMON1eFvnc4/fTNnvNzEbmI3sZvYTewmdhO7iS14JN8iueGGG2644YYbbjxSuHswbrjhhhtuuOHGtw/uHowbbrjhhhtuuPHtg7sHsybQgzUZcmKDZHfjstt6PhoMHw4n8xrWeG7zEugpJSWF3at4QFWfTqSdcbaPVk8hKSnuAQD9lRxJ+MFBAFDVpjgj7ilcZaWr5ORbC+WxaDLr7MJzmWG+xvRdB9NDg8XB+3vWtHn3qi3+NWD48NPB+Ut6O30lXxJc0bfWCuZc1I2vBqqWl+NCSaHscP9XVGFfeagkr+NR7m+/ajgkxscvd31VeAx7MDPDbVeG13h6y0qrUJw5p+Tt//g3p1PWeGzP/wAQxSffKZy/Hx6eUlVfGWk5NMnBTETxyXeKA79yBr8+MN2lROjLvQC9+6VE8Rp6Hg4aozpPtegDD7R1HwlHQd11vmetB9mP1yRK0s9ToDqTTKafWpRNv4KwWjWovoaO8W9Uo+TGyjB+pf4qG12r+Lgs6FFW8010WjceKh6/HgytOH3s3KITvx4uWJoFro8A/5Zs+vP1AOP7C/nzd6BHcR+RVWuOZnJC+XgDRTxQBEMBUBRBMXT1buSgMVo/AxyhgIMCgLKtpu7qWt/kPLgYIAgKmAcG6KKDbr+KsFotJhTvHmlx92C+jaBpGuH7+3k+2gz6TXRaNx4uHrMejL4hJ+aFboPyjZ3ElsP9oG/IkcRVt53NTyDIl7sAgB5pqMiKDpUEBIYFb8kqb7SmP1V9OpFxpqvx1d1p6XEyeXjaq1es7QDVVV34THSYcANJyFLyqnsmAMZq06OrbrLUB1mkdHejHoAZazm8O1FOkBIiNGHXT381ZOn0DxwOJ0vPdhxODpUk16th+HA4WXi2+63CjPQ4mTQ87dV21XjLT/OTExPCZQl59SO2M1f1vfWl6VvkwaQkeEtW6Xn7fUbV+rP0LRKClEZnHL6idpq39Q0ZkuiDbQ3789J+tD1aJk/e3zTGzAnYXpsVTiZUDoNLni3Q9dTkpwSTJCFLKbQz4EJ1lnrHGl9OlkmEpDQ653C7ddbDPos0B9ss0gIzOc6JMBPdx/LSEoJJCRGasvtg2xgzZ4g4mcRuCCdTKy45AUb5UWV+enSohCDlcfnHuuzntuoGz+7Pig6VCEl5cvGZfus8xTzlpFc02ZTTU0rKyxs7K/PT47bIg7fkHVGohy+8kp6WEi2TxxU32Q5ediWCA1AUwxAMAMFQDPEAgJnhi6UZCcEkKSSl0Rkvn3V4cWRVTeUZcoIkCVlWZTdl121hN8DA4fCM99Xs7Td/FBb8471RGe+r6atFpDSvRQ8AjLLNqdSM8lelaXKClAQn5h3p1jN2nlBAMQ9AURQQbN5RZgvsBaDrO1VsKVkanlZ4pJsCgJmWwqeijwxZHxmslJHCnCarRum2PIvj2bxIuEESGpcz50ULggUYVcurS3v7WH16fNUoe/1whG3ECAF9V21hXKgkIDgyrvii3aVd6cEF9P31pclbpMQGkghN2X2w02rWgcPhZOn5T47McdjxavoWKUFKo3OOtXcfi5ub77OGcGhwmGMIL4rBeaBHPijNSAgmJQQpj8s5fMVaa08pKS9v6akpzkpOTAiXpeTVDi6XKFYYKc7lzTl0VcUAwMiRLXNT5LrGPOEGeeWA9YGh6gQip00HQPUcz0uTExtIISmPy3+rVwcA1NkMSfj+vjkVU03ppLxc4aBzprMwtKhRzyoqYmzhLy9vbCtNlFiKBV1f/U92LfAuy5xLXHVbQ0VecmJCcGhC3vmRCcWZwoz0Z6K3hqe92r5QzkVOC4DQN8//ZFc4SRKhCbtr+2zTkisIWGDGWl7dnWjRkjy52CKsxaZvtZ9/OT0t5enwrXH728ZUPUfys5ITLfnBqkBG1VaZkxJOksINkvC00rNLDwvRI2cr8uJkUoKUhqeVnrIWsqgtW8ieNWU9Ff7MXMoaPhxOFjYozhRmpCdvkYdvyavs1jvW8kx05PxaAHR9NcXp4aREuEESvCWv/Jv/hmA2GRdf940Gp/e/DcRD1VuJxBO3zCaj2TR5KZcgN++oaL01NTVtNk33HQh7MrKsUzN536jXtJbJ1kdVDRrNJqPmvR1PBoTlvDc0azKaTXcv5RKiguYpk/FeU65oc0HDLb3ZZJwabyyOFOc03TWbjPcuZIoiqwZNRrPJONVZIgmILeu8M2syzmq7fvYMQRY03zMZzYNVsvVhMQV1fdrJWYPlJxFzoP2eyWg2DFVvFYo2Z752Q2s2Gad6yiQBOy5ojWaTcfRokmhryaXRSbPJODVYn7NZnNN0x2wymsfrEgLEOReGpkzG2fHmsiSxaH2m5RGH6+6lTOGTAUlVfZP3jQbzVFdZpDDm6JBFQNGmqJxDXZqpydkleDa1FwcIyciCE313pgyTt5tKZOvDKvqWUt3tE0lPBojTXmy+PTU9q+2t3k6IMs9pTEazqT0/gNjTbjCb7l7KJCQHes0m4+2jsaKkutsLzdSeH0DkdxrvGw2zfQdkm5IqOm9NmYyz2t7q7WJJSbvdEJfGp+2GyG7QLHAAl5xom/dsFmcc7dUYjGbDnc4DsaLIA4MGo9l063SmWFJwblA7OaW9cSJTbKH/r/ZiR+VUJdmV01W8SUhurx6cMppN0z0vhj25KSz71OisyWjWNudsIvJbJ80moysR5vmz4e7o+N1Zk3FWe+u2dtpsulEVSSQevXHPYDQb7vYd3UFGVt0wGsyjVbL1YlluVef45KzhTueLsU9uKusxzGnMbDKaR6tjApKO3zKYTcbZ1lxRQEmPpQptc75TqQ03XnlaKCtp1hiM5qmhCyWxovXWoqbGhzRTRrNpUjN6a2qpsLp1IokgM+sHtUazaXL0QoEkILZ61GjWnEsNSDoxbuUqMTI2ZnNB65TRbDLOdpaQm8t6DHNeZDZN/+eV/XYvWhgs43WJC7191yJvN/a8KBblNk7ZIl20Oan4wo17hun/+sPJjE1E2nt3ltLDPAHnXHSqtYAMSKrquztrMk6Nn8vfbCvHwmH+8Xkcvjc0ZZq+N1ifs1UsCshcEML3jQbHEF4Qg/Nk0TZmP0WkHeq6ZzCaDXdaX4wSRR7oM1hdTpR0oFNrNJuMs4NVMetjq0eN940GV4liJZHieC2Qd49V3um+F8PIkvZZk9FsmmwtEMdsjUo8OmS3ftp7d8yaczsDxBknbtwzGGe1N05kisncxnsWBjZZ7W6VOrJqcGEy763YTOQ0TZqtYUVIksoujN6dMkxbyg/adXKhd1lNnHt6dNpsMt5rLSDXi2NKGjUm433j7dPbCcmLvYukc3TarrJNQnJrwfHe21OGydtNBZL1UVWjxpUG7HhdYkBsRY8lJ9w4nRsmKWmftTYcUcVNd8wm4/07J9MCCDLpQI/WaDZNjx6KFW2tHrWxISlovD1lNBvu9hxKEm0u+830/MR4IsmWGO9csCYlo9k0ebupRGaN7gVt2XwjOuTzv/7l13Mpa7BKtp6QlTRqDJYMuUO02ZJArLXc+IvBXsuJcaPZNN1ZIiYz60cteaDzQOImW0R/4xp66/WYjcE4AY1vzZbzPDEUAA0qbez+sEyKYwCotzw2iKMfU9r6niixM9kHBQDgiALXgWqcAmBoA6AemAcKAJ782OqPu+riFyx8oRWN1+jA3BcicBQA5YrzMjcxirZeGgAFABAlbw/iYihq+eklTQnnAgC6TsRHWDzyR0IMADwFfnygxigAGDzXognKKksUYADg6b9jjxzrb7w2AaDq7hzHns5O8fEEQPlR+5Jdn/bpn5RtPdpUnBLhpe7utAwnsYxPQp7YG8PQJXgGAABORG52IO6JYvz43FTBVFfH6DKqA7+dpVF8DEW5RH6WGIavKta4xJjuOt9GBxfsj+B5AqBcIj8vjO3+SEFbDeGJzRni7TinK5CccKLrvnwd2bqviPBGAVBcWpQZpOtpHABQtjUMcxLytom4mCdXmF1Z9UqyDwq0oum3jsrZs1tsVw4KwJcniTAAQH0DecAI47bxUADg+gThQFH6JUSYB5Tjy+egACiXx+eiAAaaBhTDMBQA5QQV1V//uMTfSoqEZJVI+RiK4tJ4gsNoVCsbFNd1X1agsc6kvqrQrkvNi/JGATCf1LxY+5k/nnwfbwwAMG8Bb6l99JWXG5ReCaU7RFwAwHxTchNwTUfLCOBEOE/TO6IHgImBm7rA7Yn4uEIJADCmGAX/sCB0nhfh0VvnvGh+sKi6O5VY1Iq83QEsP2l/ipCLopggMkYAKqVmKT24gKe8ouXjun2BHBTAkx8b4w9jA+N2DoXb0uZxmO7jCSjXf8f+eC/bOc8uQxjmxeA8THxy+Tr69J5CMRcFQPGYwl3+VGfDAGOplh+/S8oFAED9N/oiWqWKAbjpqpYVR4pzeaP9LPKi/hEEjHw6BgDMqGKYl5i+UTcyogMA3Wivap00GAc8tqblg9osIRcFlCtMiPZhlKMqy2ne0NfQYXFTqqtjHI+OFS1pOBRYLHhHqoDjiaIW74ov2b7Quyzwj00QoADAFfjhgIhSYr0BALx8BR40pV026+Dxe7MIL08U40dv9Uf0KhWz0oCl9TQAaglQrjDjeEfPkXCrEbGNCfE4AADuJ8BYTnCShAsAKD+QB5SWAgDwyT/b3HI4lo8BoBxJvBinx5VaFywqL58d5mWXbrOIz4/fu1OgaW0dt3Ix15bNY25+Pt80l7JQAOBI02O9UQAAfqAfl9ao9HO1+DvUcqVlHICdoVlAMMySByLKLv0f65mm31g8/uciYTjubf+hHzxb/X7XMKVj2O98BxiatbUTgHA4XJtjICgKLMsA+Mbv3dlRWhLfx/MnJBFh8ugwEXeB92jHKJYb4mXP+BjPC2c/VVmGNBFcwHegRzBvazJBEQRBuJh17QeKogDAAujUE3p2oEImrHCogaPRAbBqPXitw233uHwehqidiYtgOM4FsJwyxsU5oNdPAPABEK4Xji3HswAAEG/hOtt/vHAOQlN6BgBdQnW4j30VC4qvw9lrE3oArjPuloGeolhaWRT4iePNJygdxMTv3dlRWrRFbjfE+n9w4rpOOVEp1az25s4NHzpSBur1DKuhwMvXrlNcnIgDwPg4xXIlc8rx5HvhbJ9dORyO1YQIIAjmYXMHBAFg6KVEgKUW+oizS8V5B1MjLvkFBm6URMfKQ3h/bxOJb+cQW7Q6xTVUSjVL3dy54YOFUtNaPfID3G4d3AtHFj+9FBiVVod4CexcwTpfHDlHaRkQBhL/9J5ihIknhhVqX3l4IPbBFcU4BCIDI3r/dAKFuQDUs+wXXwBrmPMix2DRqfWAL/D25Zf3WDzfUhaCADBL6QHARbvO6PtPHzvVPU7RLAAAw0IIy1jaAgQX8JxzyBf4YIjW8g9XIcydF4PzQCkp8JLNpQou7o0ZVGo9hAAAwuXYWUVRFGiWBZ3GVS2ilUWKK3m/sMsbKPbXXRxQgYjtG8L8UiJ8+t+41k9vk470KbnEPj4AsKprx9+8/HuV5UnGwGI8AABMnBrNyWvpnEjZ4U1d61D6pB5ZtgOKePO9rOy49C4eAGAYxxqYKIIiGMemTARFrfZeshYu7mVXpCcKOpZdacD6b98vHyzfFdMu2CgJDJPGh0sFtjyAcezBhKIIF59L8ShYe7W0su1IXduwSk+zAMDSrJfBBbMMpaHY0de2kK858u2lBfh/YEFbNoeF+XwuZQEAwpkLdpuDOa8FpwB8Yor2duQfloeeCQwkJBGR8mjC+5u92vPx78HAnAH+f/bOP66p+1z8D8JybluOa5u82nK8LcldJdwVoiUBhYRCQkVQhBQB6yL1inobdQWxjbCJdEbcwGwiTpFeBS9Fri2oFUonYgXpCLgS3EzYRtKtCXfjsO2b7G4c1+1kQb5/hB9JSEJQVNTP+8Ufmjznc57n+Xw+z3nO51cM5duLmogdFR+uf+nJ0YCAXygT8hziortAjvPz6y6u/6Xm2i9+pm49llNxIq28plg4w6JTq8dvfHlWBCYda1cJXT/tdS119rOTDG/PP8fS3Wnp3XVzCSGrvqQIn/YxP7/uYrb+epemx14RqT888e4rT/paaEhea4PMpfPTHQC++dFzhbr3qAcTvMFJVV0Skzc0Pe0dnXWFWZXhBSeOSBfPqojpcPNbP1zvanXrHRY6nSn3cOMjGPuuDVBYu54tLGKGMkOoU7ohM3QZw5JjcMdWtIQFNlvv91fme2hFd9zaHXHnBw/QvSr57m7+/mONUg4OQLfnJyjcyoHVqaNgjv8Z78Iux58PwQx9cJa4DxT2kOVzT3G193JeQuF4ORFCbmm7zpJE9VO8raGsYCH7qFpPs9T9jJjiJQAjrcodPyKTy45XiQkMwNwoX1llvxKLzFxBZJ9vMK6XdrQYeeuTCQ83d4ThKTZ67nxzhw8dlpAo6ztyDb3dPe0d55XZx6rlFTU5vvVx8pxie61Vpqo/xmdhAMbajHUt3uQZy/dfOSJ1eMjYbKMAXwF4ijdumNlrjOX7rxxJecz1OH+Mu77qSopR09PV0dNelVdZFVfy/oHk23kdvUc8/LNIU5h1WpIhktlHvwFIg94yU0XT1AiNsbjLpbJdqrrTJUJL09k+52gaFMphmI2DE8vogDINmxlBHF867XRYbA7zplFvmrq/mRyh7d8EwfDg5GI1s3HQg+5WiiQnR1NJIwkEe1rs9q6zlSQnhziHSYsVJ4Iwr66zWgYnF0fS5CDJYHJuc495EEEwzHrD1GgwZRmyD+eOV0T0ZEU0n7s+/bHmVhMOl80gf66fGhamzCQF44M0g/rJRyjZU1fTNkAHhbCdnDNinFWFejbBKyNmisaJJeK1+cojH598A9d88LHJxzu6h8NlM8jrbqxmMXHrn6eaiMlgnOUzAuM4+83+CkiwMQAs7BUepdN0dGrxiEgCMF50qP6auvuanhMdyZpFB2Sxg4D0pbXPjCc/eGC4S3OTLd4oHR/KG+z14B0WkwmWwUkvGrWGcQ09d2EvEFyCYfqlcVKMNBmpQA7bcy9iBXu8i289ZQJXezWmSXsJkThYr+5Rq028mDAMCB4Pu9FxuUtHRQrDAECv0VlDVm0W27cW0gM6k0Mmm57FHW4/23KheViQETerx99465qybKp13R187LD0CEVjrBBR6sbi8vqzCvZA/SfTVmO7h9Zf00LYBjnfPl47ou/z0uPsQUmrn6qxEdIyU/Nxjeczhiwvd6EpagRwjiAxW/HuqY9UyXRnw+Ti33nJw5fBMACsZtOwmaJdKx5nsjDrgEY3AkCTneWqTpoJZpOX6qHaizOTdtRqSBoAaLK/l7SyCKZzX8KFGStwTe3BDpIGoMmeI/91DRenS25zbzA/KzXYeKq0TmsBgBFjS9EbWTn1BgDgCKPZlk+r6w0jACPGlrKzJg8vLQyG/vxhuzLGc9WXbrJjoqfNY3rTmQYwNp+4YKQA6KGOEw36IElSyAyuo3V1R/rMAEAZTtf0AG9F5MxBy201YcKMFSzNCWWzYQQAKF1dgSwz/9zQREX0OlQE07UiPGrCEqfHwLVyVdsQDUBbeivyUrNL2ykAbkpWuKXpSO0NMzVC6upK9h3upnAMF6591dE5h6t6ZlOhnkzwirE2Z1XO/lbTCAAANaA1UFgQO9DHOzreHAPrsNFIjdDAEqcLoceN1eErYphfNFS1GSmgzbq6qsu+xSeH+hr325kBCgCogcajTeTiLPtSFSxCEj58oaaH5vE5AICHRRK6uhod094InVrR1SM/+sxTB+QIo9mWthlbO8ZgWEmTkZre1afw6Af34BwCSH2fkQagTBdLTmgh0Gq2TF9gESqOJsi26mYTDWDW1pY3WyY09NiFvbBoZboAPjte1WemAWjTxYoPBtgpmQIvT+0ID3fx2FNo/Tllybkb02Kii706B3s5Aj6uq63TsSN5OACECsIs6tp2ki8RYADAIpjW4Z/3kgBA3WhUnjbiDIo0jzuWSM6MIBsPNVLRWeJZhkJuSla4pfnoB25a16zx/CyYwqcOa25WJEmLGvQWGgAoU6/GaQ7ROxgziGUdVGssALRZU1vUbGEBZfaUlnDTswWWJtWxLjMNQA91lOZIc37Y5z2HcYnn12YOWRN3UTvcpUxDA+jK1iXnqHqGKACgzXqD0Rq4iAgEAGPzoQP/fW3Ec5H3iwU22+j0PwBw+/mDIPx8SvrL0JonTt5z+f9Gb43B2K1b4zL+sW8Vvspo3iaOkqx+59Pntij3rX/J3JizpvzG6OgYjI2NThQ18d/HXykse/Ppq8XfSgxfGhWTfejLl3Yf2v5Nm23UdmtK/vFlimPfefn3hzfERIlisg8Z+btPFMc+bhu12cbGYOzWlIZjY+BwizGAW7cmdL41BjA2Omqzjb64o/xQeuCF/Ez+UpF4y5l/rCg79MY3bLZR2zdySr+z/P/V5AiXilL3aqLfWE0APfqVqxNujQEe91rElT2vxcfFrDsxErf70JZvOFg0LuZR57/9YwwCxRtjf10ii49KSC0xhexSvrU0wIvrvvqrlRGyeu2z595MkPAT5B8yVpUWS5+dMMpu4K0xAHst3AIYuzWtmsbNB4DHlymOHlhBV+eKo6L4yXsuBmYfKpE+O1ERe7ISJiui/NthLrZ71OTJBOV7u8OHTmTEivixmXu0L7x1RPHKY6M22/PrVWX/8URb3qoEoVTR8LXVh0qkz9pG8Zjdjs75MmKyQm/dGhuvpnGXwlQN3hoDuDXuW3cmeG3Pz2ceenf5/zsuFy+NCo9Ky21kfOtAUSoL3DahW84NxmazuxlstlH/pdLUYNPB15I3Vf7a9mTCvip3VvsvVfxwW8hAaUasKD776O9Xb45nwthXX82mW9n91iJPFvGj0uSNjG/9uHzj83ZhPGJ5sMlkCV/27/62UZvt+ZcjGCYTQ/DKN1w64MqdbUH/uX+yFbla6qa1W6e39m+uXh1ufn9DQmbpL5x6OgDcGoMxe0vz5AdnAyea6JMrduwUj5zIiBVFZ+376UvyH31ndYjxWMbm+i9sY2MwNlWD38z5wa6woYoNgijJpuMja7a+gk/07skuvEwQ59iFXfqg09+TyaU/3hbUu29NrIifID858krpkbyX/F2b3OR/AcBDoPDcU35ztens1d+6+tDV3kPfnbR31PaNZXx60PT0yxHPjNpso/7/viycHCRDYl9+bNRmG33+td1vhQyWSUV8UU75lwnfVW1bybxeJH2n5Q+jNtvok7FSMeNmYJz0ZX+3wdyxAbvY+Px6VdmmwJ9Mb11TYWSyhImSR2+NwdjYNMc6BZlJ17nc1JcO++Sqoh+kjH24PS1madR4BR1Ie9a5Tsdb3a2Ju49OBPxvbvju+uc+z0/mR6Vtqrv1rWLlm9Fw6Z307372d3eB8dl01bHcYJ1SmsCPSpAdHuK/e+gdPmY3f+pZ5vznGM9f2XTYIWR5CiDjdzmQkTh5l7eXBths33xbtTtk4AcZCVHhSxPWFFwN3lr29rIAm230f7tazraZ/uL5+eshbtx1YT/bP/8+Pa+xzcvf0UbCMwlbLmxJO8yuuFrEf3B0RsJI+MEUpmmYOIyQ7lCIC6DkpyoJ5kH4/utM1m05tujYAYnX+Zg5U4M8J5Oel3w4tZNlnnkDCT8kwg/fLBICgUDcZcgzsthkeb1hBIA291XW9IFwBW8+79owXm5nRN8bDWmzrrr42JB4a+b83oiLeAh4BPYiIRAIxNxCrD9YNlxUIRerbgL+NEewsWJP4jzesQHA2Xiq8l7cZ6AiM/OUhS3eWlEU7+1UIQRiLkCzSEgYCSNhJIyEkTASfvCE0SwSAoFAIBCIBw+UwSAQCAQCgXjwuP8ZzA9/Me2HNhEIBAKBQCC8cp8zmB/+ov3y72Y47gmBQCAQCATChfu2F+nmP+l9vZe0FnJmUQQCgUAgEAhn7k8Gc/Of9O6ej3/71xl/Dh2BQCAQCATCDfchg/nDV5RScwmlLwgEAoFAIG6be53B/HbE8p3PP/nbP2f6uU0EAoFAIBAIz9zTlby/+asZpS8IBAKBQCDunHs3BtP2v/of3ei4Z7dDIBAIBALxEOP3j7/fvL0rv60+VxqVEvg1n34r7NPfG8p1nW6/enXR4nxe/O3pgEAgEAgE4tHk9n8XaeXHVc8+jhcLVrKfeMq78PF+9QWjzu1XK54PeWepxNOF8/OHGJAwEkbCSBgJI2EkfN+F72gdzB+/onb3fNzzR5MXmR/+ot1T+vL2ErGX9AWBQCAQCATCE3e6kvdv/6RLrl/+yKid/pX9zDpPR+6+vUSc+AL3Du+OQCAQCATi0WRuVvJW9Xf/9q+Wd5aKJz/xcmbdEwGMgzGpL36dNSe3RiAQCAQC8QgyZ7upL/9Or+huvvlPGlD6gkAgEAgE4i4zl7uptRZyd8/HUnZ41a+63R768m9fZxa9vGIR/uQc3vTRhWxTqi6TtPvDdcbGxvz8/Bw/wcW7VJnse6EYAnFfIK9Wq5kbMsN9XROIQCAecG4/g/m3rzO//KvF5cPf/tXs6dCXf/s6UxWd+i9+9+23JB8Q6BEaW+jLFnUihGNWNuqApzhdI2M7XUHTf7ONjv79T0a9wWjqV7e2ter+DKbzGzJ3LblLWt8BNEVjuE978hFuoSna/7FHqFvR+nNFqstmgEUZxSVJxPin5qtFBZ8IylQYgM3r5QPNRwfCt0o5qMkhEA88tz+LpIpO5TGDfBSOfo6tik718fCYRxOaIgfUZ5TZaTlV7tc+T4OdXZYvxK3aCuVpo/M3GIZh2EIWe4kwUSrbpapralauYJvbmjTz6TRk2jKkvVpdIFuZ34J+ImsHdLYAACAASURBVOt2eEQdqDtcUG6OicP115vO9kwYbrlw4NiIrFBKeL0UAABCY8LUxcr2R8llCMTDyu1nMIFfw1QxaSueD5lRcsXzId+LTELpixeGGhU5+eWnL3W26/48iyyDWFuiiMOt/ZWFRwe8XYZxUg9UFYVrW/vnSwqjr5Vv2Xf47OX27i8s90sn/aGVUTl15H26+x1yPx1IXdguiinuucd3HUfzyUVTEI8XJlqZvjc30b6ejlYfPW6M3pzE9KkEVvxeOaO88MzQ3VTz3jBUn8OXHh2Y/oWmND5K3uA5S/N4oRNXc6NEub6eoz4rYQAA0M6g5NwWZTdZf5s3sDRsEcWX9N3erX1ipipDuOVOB5/fWSp5zP9rzaZfehLYECLI5gru8C6zwdKQnbx/2gE0REb1paLwe6jG7FiUqarPBCDPyJqvj8zmQlZqYYlal3fpfcWRuLOKcC9J4qLU/M3mfjPAojtVdi7gbqyq2whgKJdedrMRHzEjj6oDjVqdhcFeEh4uEUx2Z+pifSeeWuP7DOlC4UbpkbzDHSkqMX5XtLzvcN+oOHlz0Z3ul+DnnzwOnLshfK8gexq0zLSkkDt+e2ZKFMe5OHsOVHKCHmhtMQvWiljOVTZnaj/8zMH0+Zv/HrP468+4Xf5yvw59wcXFjYoIx08w3Ifx5QcSpqTo3TRdXlN9UZn4dLHAS0QmknMeVicgHhGoAd0gcBKdFrFQna0aZmQeezblsNNkwdU1LUPi9c/OrYLzBJxYwpuDUjg839/6ZiV8jxhSnyjrSE+ai1SAxQ2/Cxto+0+r3sfL14pYTlU2h2o/9MzNburEF7hvLxE7fvJEAON+nlnHYC4iCMc/lv3JTpPtqtw1CaJlMXExq2S5NX32QTtjjYyfXXuxIic+Kk057ZWW7K7MlUr4UaLwpVETfyJ+bO69GfEbac4NX5p7gfIsgUfvVqYTMNxYUNruReyBhB5o3rdJKuEvjeLHJmXkH+0a9zmt/7hskzSJHyXix6bJis/dcDVcV7ZKtKlxfKW5+dz28KVJSs34dzdUafwt42tHrMZzRdlJ/KgofkKOsmNySsnSVaOQrUqKiRLFrMpR1OvsA2P2dtLeuG/TOtmahKT4dfuaTe6UNraVbU+LiRLxHRtMVFLh1Xs730O15caK5M1Ty+1HWhUxsYpWaqoj8KNEjh0B1Ptiohwam2bfqzE73bY9BljaK3LXxIrCoyRr8s9M+N/SW6PIWGWvr8xNJW1GelKNqVJGmnP5djU8+NmtMe0l8gzphv1qKxhr5dIceUXPuLC+fwDYPLaT8I0axaZsmay4ZcDYVpafK9+eI9t+qN1hxpAliOboL7fP4znEkeZcfkLpjfH/9SkTosK3nBuvJuoT+VSkspKtpZtWSfhLRfHr9lww0gDOUxLm63UFOStjReFRSRn5tb1TUcvdhU44TAyZe8rzZfFRovClophV8qJmwzTpKeHp3eTC+EI92ti8T7ZKxI+SrMwuvWByKIPS1RXL1yRI+FGS+HWKmu7JRksPdRySr0uLiRLxYzM3lbRMTJdPFbXqP8qcippgoEaWeqDf2l0qjpJVGydMvlQ23WRa36LcLlsZK+JHJa3ZfqidnF6a4yySr1ZUq+1WWC5sEa1RtV0oyZWty1yZkLQm/4yeBqCvKmK3NVmGT28RxRRcpSeqzFHtUmVm+KpDDk8kQ7lUtKbCx4WSjwRztoUh8QXuv32dubu7+W8263w99IW+cWSbojVkb+XFlG88/pdfnVbsyFPgDacyCQaGgel8E6+w/koYy3kUY0RTmn/UHCXbVYKD+tSJkZVbkwkGYAwMDxG62GduUxa3DE3bxuwEkbK3KHFW8zgYN2VnLoQyvMksFOQflPXl1F9WFsfxyhN99jt1o0Z5uIOkg9cVb/6XpiMtRvomBWGbi3ZJfBqsMTUUHPKeM419LXhdyduS2x6qN35QVNLPKz9dJSTArGsoVhSpwi6VxdMdyh0/MIjKaqrEBJh7Du9QbCvGm50MD5EIAps0OjozHgNK0/0Fm41r1QYQhACYNBpLaGoECwxgNTXUDxYoG/cSlPpAXl7xCcmn7y73h4GK3LwO9t7yRikXH9Ge2Z2ftxs/XZVKMDDMqj/TYD1S9WEIBpYL29P2/3jZqxVJCx11Nl8tKqyFmDf2puLmjhNN2OubY3DAGBiD+eJSl3cqbw4c3w+PsbOUu27TgXhcljgwr/HqUOraRQAAlPpSH8QUi3H6Rvl4R5BycbO2drIj+F42pT5zUV546tMQhul83pZjB5vj6mUEdelgXtVwWmVjvYBJG88VbVEWccLqZdFSAUPR2jmSmrIQAMDS3nodiykR4h797NYYSVGVhGqRJyipvNP1sikZs9FEsUIIR9eaPqomX68o6pGtU+YY36ioPBKJ013FaXnFwc0n1473PiKEgx/r1dPrn/ElBtI3aoqOa+jphxQ4gEXmlGwWTHttJtuKSs4bKYZAvktiqq1WWyjqJiu1cG9myEJ3pUyyUBAXSp3XGGEJB0Dfo8WC2cZrvdTaZBzovmtaPGIDF0AHVktbtWZXyYf5BN1fuSNvv+qypDLFoWRT/Z6CUwt3VHxUwQFTY2GevDCw+eRaAPcXPu7B/HbVnkZqa82V9aE4NdRxLK943+nw+o3Pu5d2002ORMepEp4yfqAo6WQpajoyQzBj2/7CUspqX0ZJNuTnVeM7Kj6sWsKijM2lb76T7/9h/WYO0JrynGKdUFlxUMzGzH2V+Qp5cWBzWfxCh6L8f9P6gz0HJ4qaIjSnvsIkyTPv6qhMWQgw1A1WS9upvp0HPnzbyVfmNsX2Q1SqqqacvwjIdlWeYou15qPCJZ4GQDxaMexihTw/Fz6s38xhAAPI5g/05RX1RThQVxXSogPnYv/njXjVh/mk9APeyaYCHoDmmhu1yTO6ltqzffKIZY8DAOjb2slgaerMa08fHeZyE+aLX2cdjEnd19v6bmTS/EtfAOjrjc3DofLjUi5us42yeBu3rzyTc7ZzKHM9AFjpkDR59CLXRwWl1S/e854i4il/oHvaj4RJZSkSTy2blVhcmTirH6nyBYybuJkLAGDztkkUW5J7YLsm53BHaVFzmIdnwDSM5ycCfUnOoIdA7w12VtmRLK8SNttogA9NzOPQBGWhADAcxwCAFZ5d2ZoNAEC1N3ZS/KLdYgIDAFb0tk3RDcUtXVSidKr6MJ6YD6prAxC/hO7v7g+Wytl1l3RmCGGZ+7uMwZIYAqwAwBDm7JJwAACXpPKZrQajBZY/c/1082BkXpWUiwPAQt76bUkf5DR2DqWuBwDA+Bsy7KO7zCWCYGj6ggSnDGZINyxU1ki5GAB1ofkET7Y2eWJw2GYb9d2Bs2pIVvcfY6KMRNaW863GtZs5AFRnk4aRVB6N0ZrJjgAAjh3B99zaykkvyAxnAQA3MZl77LB+EIDAVxY1L/PHWTgGgHFSknnlRRoDyOKFGdFYfls7lSLFAcw9TZpASXk0Dtd/5MHPHtUw9g9YnxZxnZo3RVGAMx2rwNg3uCRzk1V/goTF25XfjsTB3ois2mtaeu2i8f7L5LDgonEYYj08h509uSRHVZUzu0qxa9dedZlXpBKWJO/OzyOLKlSVbIw8I5MqDnMaiqenO44QfAmnvEtn2cxhDmmumwWvZxvfV+shWQD67n7g7YrEwAwAEL45L5GDA+B86crg080mEmDKG/qWszpmWt3aJSwACN+sPMDUBmLjPc7NhS+6V8U6QlmBgeM4AOCLxIVnfwrgPSK5dJNmAwkJf+lo0+OJBfbUjZO4M+P8xQN2Jc/XadmbL9iVxDmpO2QNWWebDZvzgtrrW6gYVYGYjQEAi79dHteY/4maig91KMrGXrEz48J4UTMQvumtFRzc39Fka8d5NZZSk8dfBABASPI2RjYfbdQULhG6L8Lo0YqPXKzY0JjV0GzYnBcEABCevs0+xY/zhVwoMwwC/OvM+hKJmYJjZeeujSyTLAQYaO4kea8nzbfFRveVgGlRdRxPn3sXZj/x1Kn49d4vv72SfRYeHR0D6lJe+CXHbxgx77Ycix76kgoknn/WXqbNNvrsC0HQqv+NbZQzOsZgPvfsY6PT+uTjy9dJ7cL0zy71Pv3Nt/yny9y5zpP/uTUGALdGb6dS/L+x8cC2K9+qUB88dDm2TIzPrIbxc2PYaxu++tV/kbD4zXe3vfzYqM0W8PgTDKu25+d/kz5rj67my4VvfsL/8WHH9/O5q8HRsTGAsX+M2kZtboW/mfVOYl/xG8kXQ16O4ceJU14Rc5kAv//1kJUZE/T4xFWPP/8cYb325f+O2hwmLf2XLgs3f/iz34y+RHfrAsMyYhd/XvHZtf+Tin/RPcCMeOv5UZt+bIwRFPzMRIU+9jUGjN2yjYJ58PcWa19xQnixgyZM4x9to6zRMcbTTz810Qb8AxhgtX41oYadZ2OzUuyGUOor2ufEzzs1mLlu/OMO9Cj8zbS17PMfNtzY+HaY+dNLvU+veH9pAJiHHTsCAEx2hGdHx8Zg7JZtQufRMQCY+u/ETW+NQeBzzz05brh/wNdg7B+3bLZRoC3Xqg+fuvoFSVkBAKxWiP7H32yj2NJV8XjBxU//lLKGab7ysZb5ylvLArz42e3aFJtt1PxrowWCX/pXJ32++n8UjN2yOdQCZ+1eDnzVUdlvDXrt5XH/U7/90gIwNmobtY1nII8/Hgjm3/8V4PlxP+gq1/0AlP+z3fvM9+xq8G/an91K2PTMl+8ZrYHxed9b9by/bdT22BOBMNz70y9tS0OAvnbgW++H/Lgyk5he8vMvRzx9suvG31ZF/LzLxE2MffmJDy789Ne2pQxN/5/D1y/1t42Ojo4xnp4KXP4BDKDpr2yjttFbdmP/9jsTCc8tnmzkz0SlvApgGyU9XOhs4K0xABgdtdkeX7Fj28Xc0iRRLZ//ckz8iqTECPuglzthGJ3eTWiaBqC+tEDQ889O1NSTL7yAMwbHlbT2H1wVddDBeAbxe5vN/3dDVsqQJ3AK5ot/98fRpzwU5RKcR28BjN2yhxe7r4iJwDhp8m9+bbKS1zcs/cDxQv6f/mSzMR0MHB0dA7h1y2Yb/aOHW9PDg26sCPq9zfbMrTFgMJ+aiFejt8YArGCzjYLt1hiM3RodtdnGdbWb4KD2k3Hpy8u++9Gnf4hLZfV/1G4R/GfCs84BZzp3+Qk7v4QD3L5SzM/f0fZN2N/fDxjigrO5fIcvGTjryQDaDwPw8/cPCBgX9vf3Az8/f/s/MOzxAH+34wV24Z9/dg1C17wwkz53ZGDAAj8AWOB/m5XyYsZ2ccNhYuMrT/mDD2osXve9xUC3n/ylNei1ZS/abaf+d/DPAH7+Af7jYyfPRW7ZH0q8MOWZOa1Bfz8/AL8F/gH+Ae6F/3VFSf0rOw293T3tHR8d2FT53/KKmhzMPpA/JRzgZwXwm9TZzlMCEfdg+6/+spr6JRW++aXnOCJO5bXf2p699ktMWBwR4A8Bfn7gt2Dyqon/AoAfBCYda1dNewkb8vcDP8x/op34+/sBgL+HZjPysyt9LO6Op+6S6+yMO9DJG058Y3Vm2HtVF3++81+HLv+ck/b2SwH+NoDJjgCThvj5+Qf4B/g7+8TmRwMscHEs+C/wA78FCybu6L/AD/z8FgQE2K59f8d3rvH3VzZKOTgA3Z6foIAFAQH+AQGC18RM+eXP//Ja9GeXf0lI3o4I8Ld59rMnb/zml18AkfLN55wc7v8vGPgtCAhw8fOvO/utuDDmJfvn9C96+q0MbvTLT0yKPfaY3/gwwrghL64pLmO+5NXns67BJ4TfKQEwHtUMM5Zsi3zCfu3vfmOyAsPezQN46/Z/h/OC+w77UgIfK/78N39/rNPAFu195qVnQqhTv/rjX6Db9NKq2CcDAuwV59wgx+txwXgv9vcDAJtrDXq80FmNBX4A4O8fEAABL8neu5Jq1PR0dfS0n8h/70RcyfsHVjzpXtht4QDgv8A62dkBAPz/OaUkY/n+K0cmx1An/Gzy9wNCVn1J4bpGuNehKJttNGCyKBczF0yFF7tWMFHdU8F/AQA3v/VDNyN/DtXt7+8HsGBBQIC/JysAwMWKCajp/WVcjYAFfuC3wN4TJ6sswEntp2LXi/G8j3/6l9XcK1dvRhe8+qT3Ue159ji+68IP51GeGIPgcNiun+LEIvym0USC0D6eQBv1JLBX+DYmp7vYfZMj9zoBSbYpS85/Sc+wDqZEmXKX9jOPqEuPW7dW5IXPeCypA/3tWmtg9PJQ+//oPrXOyuAu500NbzNDeZ6O2TA1FJRedD2W2Ymxry1+Y//bktufUaRHKFjIChGlhohSN25vzFlZ9Yk2Z0coh3HaNDgCS+yj5SPGYTMjiOM6dUaIxMHH1T1qyhS++iUMnuTxsIaOy0wdFSkP83ZPVjCHeVOrN4GQPa6EmaRxwqeDkh0013T0AXe119blzYHjSy4YIdnKXXfgQFiUlB555FDTpeAhXUhWERsAgBXksSNgwACrlQbAAQBGLBYP81NuGe7uu8kWb5Ry7CF8sNdondhei0WmxrG2tHXpqSZtsHRPCMBt+Jk06m8yuGEuLmURTDAPuy4B1nf2Whg8QZi9sJHuy2rq6WS54xI0qxUAwx3Wl+HsJR7XG9E3aooOd1Ne18EweHJVvruJoSHNdROEZE3sEzRq+kh4Ok0YbL9rKA8HDx0WC4/jUSc0HaDFIzYTgOHRofpOdTfo2cvf9a1JYEQwYW3TGwHsU5lkT10rFSlLnO3CKpqiaBznCBI5gsTs3MSiVYqGDsuK12b3+zAsdhCoB8mJAx3MxkGLlTGh5GWtnpZOeI8iLY+/8AwGQQTBMOsNZpjYB0RZhoC5CPdY1G3A4bIZl67rqfUTSwgoMwkswqOHPFoRFExYP3W0YoS0YATzTvcTYXxZStAbzS0XOW20+IDwId3+f9s8nBmMByIyU4NzasovxBSnPP+4WXPieIdVqEhcBDDz2Vbay2qSKeF6bT7E3KyDsVqdloXQ+rbTahDKEl/0XqrxzO5T+M7yWaZH9kDPf8ldoCfba87f0PcbBYVH3P+gEjurrOoO18FYvT4hzc2K1ApsZ2VhGpeJUaZejQWIYAJwbsYKPL/uYIdgr5gAsudwVQ8uLpm+3JUj4ONna+sodkYhDgChgjBLRW27hb/d+/oDiMhKDW46VVonOJDNY44YW/bvKDVm1JzNmc0COvp6e/dNjtz7fkhvDvSxIXl3IAAAHrch5lCe6hiEF6rGk7yXJzuClIM7dgQgQhZBT6+OyhLjQPUdb+wHeGlGHSbvxCaA1PcZ6RCO1XSx4oQWAq1my/gRRLyUJELeqLIMcFMOjucgs/QzbdAagbPSdQEsi8PGKZKkwDH/MKr7SLCyzBYAHMxXD6p6iE0Vu53Cv339jP0TS3tNbbvOxNmk2sxzW2PYkhzVqdtZBwMAVG+HAYh03rjzTe2XvmCE528WYMbWow3dhqHwXR76FwDGl4Qrq2tu0rxCDgDgYZHE0boaYMXl+LoWgpuSEfbBe0dqk0rTOVZTU8m+w9atzTmztAB0Zeu2acWqCnn0Ipw26w1GayCHCJxtKRxhNPvI+er6dK4sBIwtZWdNDEYIAAA3PVvwQZnqmOTYDhELhjrKcwu6l1Q2FgswYcYK1o4TyubwktSQhZSurkBx3Lq18eRax6JGTZ9MFeUMxmBYSZORokIZnjMScbrwiLJc1cbdk7gILL1VirzmoJILBzwtn/dsxWvZgg8drcgr6OFVNhR7OQ2NwWAANWSyjHADHVu1o9oYBtw1Us6Z4/tNzKxjfAwAgGyveP8G7418MTodY+5+m/pBAFuSW6FKoqu3JC+LiUstvs7JrTiY6tM5nma9wcyMmHhXnHtGOvZlSDNXZh8bYDDMjXkrpZkZBS32vIrWtxw+0jLg/UFF9SiLrycpd0XOMkO3B3rKYgGAiUCvsgf6oeYPhoRbN4sZmo7+WR2y5xPkuVxp5spV8gYzg6E/JluVuWZdace0XTms1HcPpkLD9rSYpVH8BHk1FacqS18EsFBYeOw7Lw9VbIiJEsVkHzIKCk8p493s7OBGR9KDJmaEgAAAwMKjeeQgyY2b0UuheRUVGXhTfiZ/qUi85Qy9UlUxq/QFAEjDAB0sENy1EOPswDfWvL5mnae99FhkZjyLYggz4ybe26c6Aj9K5NQRiJTdeSEDJWnxqzIz8i9zZSmEa0btBebKb++UUCcyYkUx65Rq3o6KohSu6VjmljNGAIAQaWqQVjPIS50aCJmdn039A9ZADnfaL5lwI3jYoNbphzUsvd2DQKzgmQ5t2i6X5X+C59bU54U7t5BhI8mwl0arW4y8jUIw9JpmM+TkI3SfWmcF2mKhAIAeqFdWm+P2lq3nmNsuWBI3hFu1mmHPDsYjhWyTycKLsQ8msQUCzGTCBPG+t0a27Idlm/G2vFUJQqmiAUupKPVlkb4L4QXlhaH60syEqPClCamFnRy5ardw9oML3K2qPdHmmhzhUlFqcZ9wUwoBVrACAJFVfnwnu3//awn8qARZBSl4t7xAgAHAQmFhVWmitSZXHBXFX1XUim8c19+hqNe+d92hKCd4qSk8y/sbEjLLpp1xOgUrseRk4RLyRGasiB+bWaQL3llZ6G33n0crglysiFRWFHh/WWJFpwlxdXFy0o4Wx7doV7XZK7J4YCXSs8b3BFh6L51v1Xgd/X5k8LP98+/TP52fM173VdhG0xjmQ5+9HzqbGvKVA7IKx+Ps3AkbGlS6SMVah7c3S8OWtP1k3LciRgx//qeVwnmyHTuTxn8kcoQkMYLQlqQpcdXHeSFeS74NnR9+YZoGlwZzv3QeaVUkHWFWfFQYic0sfPfUuEPhr36SLy6Bve7WGbTnp5WzqyZbqe3/WnetLNamHr9axJ9W0gTG2ox1PVk/qUp/cjTg71/R0KOQtkg+PCL1OjtzOwZqSuO3tHAy0nGTyQo3aWLF9tz1kSwAmhoBqmlLjjanSSXG5o+fkfD8E/71jzN2aGWNpzJnft+eNzqjdTDzC5/Sl/sB1asqbY8prvJ2Gi8A0AM1h+rorU5zFlRfl9bKTE1XFC6d3oAWEgQAOaCnQ+XBc63zI8E8aTAj+nNFqj5e3unI+aHP7LF01dd+/mxalMYAvK0iN80cl8jTK/PPdMnfFWEAALTumtYaGCn2ttppqLuT5KVLWAA2ABynmlu0vJQSfHraeacMqPssjLDt8l1ZLrkRhi80nm8io3fGAE2D/1yewIB4iKBJ9eGSRkg57tt0waPGIzWL9BAy1Kw8TG886Gke3Q5t6a1RyI+YIpOcYjqt7Zkh0FP9vSa2kPugPvoeeSwNW0TC7PepVFWJj0cEzUP0tftVH7RevabWYsmbPJzWyN24U9Bf3UwCQK9KtvqdTy1gVR/IUTR7Gmk3NDRaJJtWTJRm6Wo18Fby9fUf9M7xsclkr2YQOHGup18CAICxo40Sp4R2n2gwze1NEQ8LmtL4ZdLCvuDd5Ts8nrD3aIPGYB5gRrSHdjcGbVMGUyTpsgRi1Pb3r/70JyNJkvrr7a2dWosVmOnJDr/82KuSKRoHLQDqAzmFW8t/+Nozbm6gv64novPn39mECN9gZp3s8r7U+gGAWJEV039l+LOhzJISjzsxcNGeA/r80mqearOi/tP8GQalza0n2jk7Tk2t5AhcxA0BTa1WvHHzHD4nyE9y5YfVJACjVp5tKan7tstvTzI54Rz95TpyxWbxLHYPIh4hBIVXf1E456ekPkygdTAPrDB1VbGuqJX0de0hM+P4pSK+2/jsSQ1jjUxO7rrkvJhgnnoDCSNhSndBjSUnhfh7FybP5RZ8kVVZaJ+QepAMRMJIGAmjdTAPCXi86iddKg9f3lHaTuuqC88TivVkh1Wi8Hp0CgIxf8DDpUkAMw1nGLWQVV7obj0NAoF4wEAZDGIaVovRaOhSneBkqgrcH4+BQDyocJLWoh+WQSAeDlAGg5gGHl9yIf5+K4FAIBAIhDfQXiQEAoFAIBAPHiiDQSAQCAQC8eDh94+/37zfOiAQCAQCgUDMjgC3O1bm574pJIyEkTASRsJIGAkjYTtoFgmBQCAQCMSDB8pgEAgEAoFAPHigDAaBQCAQCMSDB8pgEAgEAoFAPHigDAaBQCAQCMSDB8pgEAgEAoFAPHigDAaBQCAQCMSDB8pgEAgEAoFAPHigDAaBQCAQCMSDB8pgEAgEAoFAPHigDAaBQCAQCMSDB8pgEAgE4p5B9dYoNq1Li4lNU2ruty73CF1DQe66NatjYhUX6bt/N4q6BzdBzBMC7rcCCDeMaM4crO8ZAcxKAVeWv11MYPdbJQQCMRfgkTmqAioz8xSTx77futwjwrPK3h3dnPz9m2GhdzGQUWajobf5g8qzsP1TVTKKmI8GATbbqNsvPH2OhO+2MN13WPZd07feK8tkY2DuLNwk3zP6fmk8fo/VcIZqfitFxSz76feW33HJlsY3098LLv/0uxEAYPx4764ffWrCpCcuFQjuroF/cTRhTkuep8LG/37j9bZXP/ifNzj3Wg1Lx/fzi1u+gPjST78f5+VRMm9dd5eFLb/SDkPwK4ufHLXZ5loN8pP8N+tY3zmxJwafQVh/eNWmftnZkzLCt5JnpYYL9I0+PTDjv/m8bdQ2s/RtqNGr+o9KE7GYYeox0ctHbaO2iV8vprrL3vjBnze9V5ZKTAp7KNmdQ+Z3Q0LCEOD2V63n5+9o+yZsachO3q9z/ZbIqL5UFH4P1XDPiF5HscMXYV6EyTNHPyJ5JekvPh4AAM9JsiUVGw7VZL+666U7VcPUXm/iyuIX+azziLalHeKkPBzAf4Ef+C1YEBDg77s3RrQtn46K0l9+0vnjZ1bsPv5NnB0Q4A9gaKn91JpUoVZELwy465UyacKcl+z2KwfvzXHJPgoHLADwWxAQ4B/gg/BcqkFeNXvbuAAAIABJREFU+e8WS6TyoiqJ6T19mU9x4x4K07/qMVjxGMGLDlUzR2qY6pSHTZKKH77y5MwlB/j5gd+CAP8Ah/Zxt7zxq8+1NxmhUaE+yrsrmRporT19CZKU3xbh04Ujv3P6FAB0FX961eTn72DUU6+8XfKzDduUF5adXLvITckOUXGaQ+Z7Q0LCD+s6GFxc3PqTC45/9XnhM19296E0J453e52lNV9v11tZxFToZxFMIHva9Xd8b31LedVl4ywuoNSnDp3WWG73fpT61KH6PjeXs7jhSwh7EKIoisHhhS18CId879B7DzKUZQSYS7je0pdHGv11LcXgCkLm3D8jrceOG6Pz5eHzzfNGjW4YgiPD8ZlFp0NbehsP5W5XNlnjdpa7pi8+gC2R7xAaj5V1UG6+nHVURMwvHs4MBhjMRQTh+Meyt3uabFflrkkQLYuJi1kly63pMwMAgLFGxs+uvViREx+VptS6FkZ2V+ZKJfwoUfjSqIk/ET82t8E8a70WrUwcaW4Z8iJBGkgrMBhTIQjDGQDDRtI579GWxkflNqhrc7NlGauS4lfJlR0TD0tzT3W+bFV8HD9KEr8ut6yDBADQlK7Mft9EXc6LksibLQD0UMch+bq0mCgRPzZzy/c/GXBNqywNW5J3d9zUH9nAX1XaCwAADLC0V+S+Fh8XHiVZk3/mxkRAGOo4Kl+XxF8aFR6VtGb70S7z1OWGoxsnL3coWRRf0gd0W25sXqPFqi5OdpYh67JF8QU9UxqR52RRSUVqGoAeaC7dJE3iR4mWxb8mKz43roN6X0xU7oXJAKXZF+/4XwfsJqyJFXkx4bW3KrvME2oUO6pxRhaVVKShHb23LP71TSUtXr13oKZAElNwdVzEWJuxNGpNhcn+P1q9JyZ2Tzs9XmsrY0VOteYArd4XH5VTN/Ux3VUg4WefGwKgjS0H3nw9PioqfKkofp2iTjvNchf/9O2f8g+lqyuWr0mQ8KMk8esU1eqpVlSeL4uPEr0siItZJS9qNrjJu93qrCmNz37fZP3i8DpRTH6b01W0oaFALsvOya3XGdW1hW/tlGfnbCppMXpL6emB5n2bpJJlgmh+bFJGvr11AYClt0aRsUrCXxrFj83cVNJmpMFry5lHGDV9JATxBEwA2th6tKhAsWl7rXYOdCRb63twcboEt7dVWfX4k5luz5eERynax29BVq8TZdSY7P+xGs8VZSfxo6L4CTnKyVbnvlVYGraI1qha6ran8aP2tAMAWLpqFLJVSTFRophVOYp63Yh7xagbmkFgvsTjAADZVVNalC+Xq3o8CDteZ2qv2SffcagLTympVBWkhrNuzzF4dJaYoa5vcw3YrlERwNkhB64OT2ji3iEXtojWqNoulOTK1mWuWrl6Tf6ZaaEAcXd5SDMY99A3jmxTtGKbKy/+rLuzuTSROpWnaCQBgIFhYDrfZN1af+V0Ac/pmhFNaf7RwUWyXSXKwjRukDi3+GBpycHyElV5Ydpt9CdWSr6gs6ze5LGdU5TL84cBAGC1UlaXjzHr9epmZsHJ+rM/aT2VYW0qOdpFA4CpeoeimkopPdvZ93lTVQZ2sSCvXA8gKGxWLmcwVlR83l6VyqQ15TnFfYS8ovXzru6PCnmGw/Liq84BhZl1siaHzeDmnu77SWGkXTX1mYvE1hOX2tR1W1maYwebSQAA8lxRwXl6perSzz7X/EQltZ7fXdxinrg85Nu1k5e7giUe+WlFJpMhVF50liGSMyOo7vPtU+nFJwOsxEwhNtKhlJf0Lcqr6f6867OzBTx9+bbiaVHJK3YTTn16xYsJa6wf7S5uMQORnBpGdbT1TlSVsbVlgBWfKcAcvffZ2d08/SGv3tuTIeaD7toAAACYNT1mdjClG0+dB7r76fA4ATZeawc/6pqstSPOo26YIEWCG1onnzF0T1O3lZcZvwgMlfmlHYHZp658rvtZU4mAPJx/qMvXMEo25OdVUytKPmzv+7zplIzRkJ9bbQQAul21p5FKqbrS9XNNS6OCPaDad9r1RdWDzoLCq3VvsBmLd37Y1V2e6DgYYG4+0Ss+cDAJOlTbFB3B7/z4cFVdIU9Tmltl8Kig8YOikn6O4vRnmp7uj1RpdEuR6ioNMNJamldFRiobu3/xecf7r+MdyqKz5GTL6ZjWcpzKvJ1Eyhlzm3J7rtz7X0mbaxI6jv1xHiYi6IHG8gZrYhrXote0aYYByLai7XJZdm652nSjfl/u9txN2TmKRsPMT/rxgq+36xmR4jAAAIIvIAa7dPYH7S+7tEw2Yeiyz62br/cagyKFbAAAq6mhflCibOz+6QWVkGosPqGmwXOrYDAYYGk9b0yt6LhSLAHQ/zg/r5mRWd7Y/XlXa+kKqiZvd7M7o+l+tc7KCIvg0qYLJe+TgtU82tTb0elt5MPcf0Gl2FRQO8TZWHHyQH5SyEIfneAejCfmY9rOLpfY6hwVpzvk7PdOdnl1CDCAbP5An3Sg/sPGn5zdHao9tv+sh2pH3B0epQyGvt7YPByaky/l4gDA4m3cvjJQc7bTPiJipUPS5NGLcNw52lFa/eI975UVZKYki5k0FSaVpSQnJSaL4yWC29wfxJEdyDYfylNd9TFiWt1+igEAUyJLsS+p4QjCWNSg0QKgP9+gD0pTrOexAAAPzdyaRgy2NrssC6La61uomG8XiNkLATAW/83/fMXa8Yna3aCFkyac9ILMcBaGLeQmJnPBqB8EACBSKn7SWJETzsIAY4WnrQyh9f13OCrLEqdLoKeh1R5/yfZWA7EyZQlQ6sZOSrB1t5jAADDW8m2boml1i2tUumMTUhMX201giVMi6c4mjb2eTO2XBomV6UtcvRexXR7n3XsLBcu5Zp3GCABUb7chVPZ6qPFaLwUAJo3GwhPzF07U2hLHWmvpdyoF46clMQdax5sr3X1ZDdFZYiZAyPa6po++v5qDA2BMUWo0QRn0PkZR/fk6LXuzYq39vpzUHRu4gxeaDQDWEcoKDBzHAQBfJC48+9P6zRzXa2fW2QlLry4oTRyo15qASN9bFM8CAAhk4VaTps/jqCRloQAwHMcAMFZ4dmXr1bJ4DGBhUnHzT6p2CpgYwEJOSjIPBjQGmGg5Z9tcWo4Tt5NIucBKLK48UuX9ryiRcHst3a/RWRlctrmq9CKxtSA1iCaBEKaL2VR71WVekWoDfr0mP+80vlFVeeRU2QpSpTis8S1SGA1GYHM59rAUIhIw9WodDQD6a714dLaQoVUbAIDW9WhxvoRrv4YhzNkl4eAYRkhS+Ux60GTx0ioAAChi9eYk9kIcA+irbxmMzCm0h9OFvPXbkvDexk43Vanv0VLAZUOT6jyWU5jFhSErk5exOtSte8ieuuLcN/Z9YhXnV1W+my1mz8mMGMYJ48CgfubA5OwQ63hQ9eIQCE/fJsABAPAI4WRIQdwrHs7d1NSlvPBLjh8whMqLVTGkkQok2FOBheAQcMlgBOAAMFhBhJsZVlwkW2tf+Uxr2nqZYTu99CeyTVly/kt6zM/Pbwb96GGtrkhuLj5xIOEF1xtirlrQAMBg4AzXQhhMYnIQaEIr2jhsZgRxp0wMDiUYp8lhGhyXAVlI0krp8wROLlpMmgG8zjHjBMECsAHY38ZgPK5ajR1HD5+9biQpKwDQN60421spvoBHZ61kypvbhjLXLyI7W/UhWWUhAIYB0soSBk2+jS3kBBHWHuNs3nnsJoBXE8bom1acAwDAiksTHtrffJ0WRmPGzovGYGlpCIBp1t5jRUu45e06y8ZnBtRatlDBh+YTaj0ks/u7jCESIZPWeqq1JY7NbUnqCqKxpZ1cn01Q6uYeiCkW4gAAlL6l9HiLzmShrABgpaxBI+7TXldocpC09h9cFXXQ4UMGQQKEJOftaN1emhRby494OTZhZdJK/iKXgQyPLW2Jhy7CTFbuAuhTam7iwujxpxdt0JoAuAyPvYr3ekFSX9EbyRdDXhZFxktS4yVcJgAAbek9dai6w2BvdEBbQWilATB7y/n48tA6mUPLccTSqwtK2xOoL55IpGyjDolUoL7m/S4TZTQOs1Lz92aG39mrvztMfTcosHafqMR3FBAMAFxUVCMCsP1NfR5WbCZMlSYrLs4vSWVjAIDjOAz3qgdBEAIAYDbcsIYscZ8Z2bM9Jos54TlxGBy4NgDxT/Vdp3j/mRRjqTylM0PIkLqfISgcH2hmEJzJ0vDxWvDcKoIAACeI8a0AZhNpsfYVJ4QXO8gxB80ALnsFhnT9JAB55vBCeeFOBgAWnn+y3pN3mkr2VVvXl5ZsWP6cr0s7fQJn4kCZZ3zbcXaIPeZ6dwjGYjo1EjSLdG95ODMYhrjgbC7f8QOchQMN07IARxHPYRQAALQdPcBNmb6RZwoisbgyceZl1bSpofhYqLywQMh0s4WMWEwAkA5nMtFWK0AQh8AAZrHfbAKPjzJCVn1JMZ7WzGopuAsjrcptKjKp7HiVmMAAzI3ylVW3V5IjWGTmCiL7fINxvbSjxchbn+whars3j/ZstjtcTPjDh2+u/i/7N7gwlQ/FLb10NKu5xchNT5oYh5j0nm+uIyIFQcfVOur5vht42AaCTfOwBrVhhOrUExEFBIDr0isP6nNTpJwPmjrI7NT+CxqGpDR6IQCQ5xTba+n1ZfWVkSwMwFibsa5lBnUc/cNYvv/KEem03Avjrq+6kmLU9Hx2pftqVV5lVVzJ+weSvU2b+uZyfU+vhcGLCcPsqbD+mpYCdriX9Q2ERFnfkWu49lN152fnldnHquUVNTkhWpV8dzd//7FGKQcHoNvzExQTikdmriCyLzQYZR5ajrdE6v8aS+vg21XKEIw8I5MqDhJNJcI5XhRr1vabYHHOyXeXaI8WravlKeuPJDEBALDlBUp/MB7tJRk8OX/8rkaD0QoMgBHNmcOt/fqOTjzvYlWqT2tZMV6cgKrVGC1P9QyGpoUt5FlC9Z29FJ/UUbxNYTNY5b5VUABTL0sAABCYdKxdJfReFq3VGIC5+tB7q/5wrER26oOC96uypu/vH4edVdkk0V4+8YPt//31+A3ydNE8OQnLi0MQ95WHcxYJYxAcDtvhj2DhACxiEX6TNE2+s9NGPQnsEI+9yQndxe6bHF7IzIIzQLUfKDVmFhcIme6/Z/ElXDBbhidTGNJIAjE56jsDGCeYsDoOlg4PkFYW4TISG0QQDLPeMLWChLIM3W5n1Gt0NDdl8/iZe/SAzjSr7MEj3PQs7nD72ZYLzcOCjDgWAEBQKIdhNg5OLgsYMQ6bGUEcAgADBlitEy4bsVhm9SLkYoJeNzhpwsKYdCGjr7Vbd7FjmJeauAjg9rwXKuTjumsdfdcpXjQHIDQmjNL0tXfocGFcqIdaYxLB04I3W7Iy2NjaeUN9WYPHpwkwAKD117QQ9q3/jGBhAAAj+j7j9Apw9g814R+MCCasg1r9lLdGyPGvaIoaAZwjSJS9vffUR6pkurNhcqm4/VpfdXZiSHPdBCHC8R3m9I3mHhJfvlnmpVvRIxSNsUKEa94oLq8/q2AP1H+iheEuzU22eKOUYy9nsNfRZm56RohLy5mGQyIFMJVIPWG1kt06EuzrSP58Q+NhRoBsU26Xb9ri9a+4xe2SEG23AQi+RBAiyfl2MuvPmg4DANVVcdS+2njcP4LxR6VR00fC00uEwQsF64uLdqV5D1U4EweLebKWcL6IO9zb3dNtCBbycMDDItk6dUdPFxkmEXjLgby0CidYbA7zplFvmrLNTI64kTP0aq24IDGGHZGteD2Uut6uo4DWVas8rWDDWLwUxY8qD8qY+gqFvKC23Tjb2OSu91MWCnDWbe2F8tUhiPvBw5nBeCAiMzV4oKb8gpECALPmxPEOqzAz0duwyiTay2qSGcq9rR7giL62DjZu8xZB2Gm5q1ma8032Z4P5akMHiHO3LvF8gRPclKxwS9ORM3oKAKiBxqNN5OKsjBAAAAwD67DRSI3QmDBjBUtzQtlsGAEASlf/3Tcy889Nm8BmAFjNpmEzRXvpriyCaSWv95IAQN1oVJ424gyKNFPjl1tMf/B+uWeI5MwIsvFQIxWdJba7CxdmrMA1tQc7SBqAJq8drprYeUGELAJTr44CAKD6jjd6WY0xswn/Y5o0AQCLSBNCV82xdktEmtiedLp4r7+uQDaz98LjeHTPqY+H7U9NjBcdajpfrYHImBCAqVobcKi1jLVunuucpJRQfcvh+j5cvDoSAwDAmEEs62B3nwWANmtqi5otLKAsZmeXO/un6twvxz/npmcLLE2qY11m+war0hxpTpmGBtCVrUvOUfUMUQBAm/UGozVwERHoVKbPOjtg6VUbACjSTAMApTu+/xIjrfRdKQsALO0VpeXTdmCZmxVJ0qIGvYUGAMrUq7EAEUwAziGA1PcZaQDKdLHkhBYCrWbLxBORWLn2ZeeW44qnRIojq7p0ci0HACiT0RLI4Qa5t4NILK6sOnXS658yxd24oaFXf5MpiAsFsD9omQQTyLYmSxgPAwCqt8MARBhv/EpT+6UvGOEbNwt8G4fghHDApJ9aXscUitnaxlpNYEQkAQBsAQ/rrTmvZ0dHet+C4LFVuMDPSAk2niqt01oAYMTYUvRGVk79tLVExutaC0MgtieLVhqeZhH4SPf5AS7fuxYLuYmby45U5IWY65XygkMXtD4fTGAFeloSTxv7jRDMnZ4CTkVFzwX66hDEfeCRymCwJbkVqiS6ekvyspi41OLrnNyKg6kexkKcMesNZmaEff3+nTDQagjNiPY+ub5Q+G6NMqzrQI48X5Fb/AlLUaVK8klJAABgZ5erNuMtO9bE8aPS5Gex7Moj9jWYmCA9jW06+FpyTpVhobCwqjTRWpMrjoriryq6hGdXlK6dlsmxpZkR0JonXlXU7vktiJNZuJNrOigV8WNzDptW7C3fkcy6XiRVXDSzpZkR0Jbv/XIvsMTpEuwmLk6PnAjgC4WFVUX8oYoNMVGiVzYdNgoKTynjFwIAkbI7L2SgJC1+VWZG/mWuLIVwGHKYERcT9vxw24QJAICJUuNBd90iSJFMRFxH7y1bs7cV3ziz97AwCc9iGgwWjS/6C4skBk0UXzL+cBqvNfkq0WSt5bDd6UokpvEGNTpmUurEwibexr2yIM07KfyotE31kK08sC0GLuanOW0hdvHP+tUT/iGyyo/vZPfvfy2BH5UgqyAjlRUFAgwgvKC8MFRfmpkQ9bIgMbWwkyNX7XadT/FZ50loXbvOyoyJpqvy5NtzdvwXveFkTcn4YKTlRsf51mnH57BS3z2YCg3b014RRPMT5NVUnKosfREwk/PyJdSJjFhRzDqlmrejoiiFazqWueWMPe1nxb/m0nKc8ZJIjWNs/EAvKCxIuuM3Fheo4SE6ODnV/jgPz5KvwDpK5RXDabnxOADQfWqdFWiLhQIAeqBeWW2O21u23rdBYgA8QsK19nZM5RCLBBFM0yCEL7dPloUKwijTICGOnumdzVOrcIX7VnlFBt6Un8lfKhJvOUOvVFXkTEthLcMUsUJqX7FFpGzPIG5U5BZponf6FngxIjqrSFWlSME6DsnzSxs0pIdubajekrlmVdLuViuDcf2gNHONNKfc4WentB39NC9u+lkyjlHRsxa+OgRx7/Gz/fPv0z+dn6fv3VdhG01jmA+NdoaSaadi5pOB80+YPCeTnpd8OG0XzD1WAwnPlbBmX/yWzsjyiyoxNl2YVu+T6zee8pAEzU6N/z27MeMjTy0H6Ku5r+7Whr8uAQMJ1pGxF7N2viV1GF6l9bV5FYyd5eun/4jP3XXdL1TxW1o4Gem4yWSFmzSxYnvueofxEkvDlrSLqRdPpeIeD9FuVSSpGCUXDkhw55Lnf9vwRZg2dTX3YUlrI92cyeu1ZOqqQqqki5qOiD267m7pjITvsvDDuZL3LuBT+nLPinnooc2608XHhsTFmb6+gSLmOwPqfgsjTOj+5ZVSNw+GyjzM2swG2qyr3VfpreXoOrVUYGTmjmJ3iRSYrx6ugW1l60MxQ5eGKRL4Pvx5pwyo+yyMsO3yXVm3eXAbLEzasa0+p7xKJ1TMu2N55wCMLcpkz/4y+kbVMTVna72HKUXEA80jNYuEeDAYqMgUvJp3Ad9aURQ/99tZEfcBQ92WtJz6QbD2H87OrXNzLAcuKasp4N3pY9fecj4O3Oyl5XhLpGhTg6qTkxmNkbobrefb7+nhZMO9mkHgxAlnSF+8L5RnZ5ft4nQoyzRom8w4I5ryog72bqXPk3GIBwo0i4SEkTASfkSEDXVbFMe1w5Q1kMkO21x+JJvjJDxQkZl5anL/0dOZJ1uLBfdEZ7Llrc2HuodvWhlPs7kpJXXfdlm5T2vPlZ29plf3DLEiIsMT/6Mw+aV57WckjITvkbDfP/5+08crEQgEAoFAIOYJAW5zn/mZbSFhJIyEkTASRsJIGAnbeajXwdCmCzUtc/jL6bT23AX9zGJuGWg+emEWvx2HQCAQCATCGw/xXiTyQqFSk6qSzlmBVHv9dVCsvb2LQ2PCqvOVC8sPTB4rArShufJ/rn7xL5LMxUbjTauuzyzemkVf15LDN0yMrD27RLe7JcEbxhblkfO9WpOFs6P55FrHO5g7aqtb+4a4KclgIClLr565QR5m1PSbTYNk+FZV5p2fR4xAIBAIxJzx0GYwxnplNb61Xjx3myHNnRchruS2swpW/F55p6zwDPfkevuJUiPdbeb41zid+Y3G9JqcEOjojyk5Iaw7spmw/H/23j6sqSvdG77ntJN9nV5u3s4k1zNDvPpI3nNKcCRBTIgEonwVCMqXCKINSOXjiIggjCgzIo4UOtC0UpxqsSrWKmoBrSItiJ0AcwhxSsKMIX0lcZyEGQkeJmEcNpx0b4K+fyRACAkEtVZpflf+IOFe977X/bXWXp916QlXld9ND4YWWVxOyllThLm5z2SvaZa7JgUh0Uc6Yj8tS6NoIDGp4npVbUG2i7Q8vEo2kODu0OHFTjjhhBOOAFddqb4gUiKzX+H+/NcfJx745XeSAJ1YXFiks0i61soaInbbPKffLoxlWwfCfyKGLv4psdjFD9rMGx1d2CkC1ztyPStN4I4AaNVaSlBKLBUAV3Wr3Zjf3eY/ZY+SIDHZbjN/dY1JDdBKe2nxGcEUAFxzS+uZvI3lAjCgVOE0t+clmcjLAzmZdXauVHHiRQB2JYvnVyx5QdjOCelT80ZceTFzHY/BEZx63Hnqp432Ag4vpw0AQF0jYCWeeYrT8SaMdLXqg+Jo2tZ6NSMrNWV3NCKqOjHgn5KWm+E3+sXVZ6yHH2hi0del8wJLZTDDytOmf/6xOHswA9cvSulx81yEtjBom9uWxPg94ZlIbjGCZeKaJvMdOigKih4l3ZeJAIC+u2uQ7u8JAHhvazclgEfFH+8+oXmhlvZqYZkP06ouiAs6KO8FJtMNAKD3ppLq6UMBAK24TesTtArmlUZ6KHAlxy9v5oVtmk/jOalnn+m5GgCgEdW2z7qo6FlgRNk78GwXO/UJYxgh5Rbnp4O6RsBYKThl2eDIywNXxlRY34D9TDEib7oif+xDSnDl9c87bbYuWkldi+rZqtzCu+hbq07mBz+N3r30wikxurn+9zVpjt3hugjgwk5JoqpsvsLJNMvsv8J9b9G9GEEOLvjIxl0QLw4WZQ9GK2pR0fxXPc1hA/UNMTXMzjUrCwCFzaUpb0ydlKWU3aEyWBQAwHu71e48BgIAfS09FD8uqfFEs8N3mS0E+lvSfiAzPGbfO4cpunUMHgMAQC3vBQaXBgC6nmY1I5ihOFermL+dIC0B8eGSlu9E7gVA2VRZfeOpvzI6Akx64qOuZ9qeeoRzqXpJW+/UD/rurn4SqV/UNd1t7GuT6alcPvNZymUFTHz68LlZ1x45DEXt4U/FtvrBA+ITFY3Ptgdj6V0o1Yvp/jTyDE5gBMnN0wNdhEfp2gWKQq/tVzgpea3dV7jvL7oXJSh0hhf1BT6teDH2YHBFt3IJjW7ZRGO3agq2JQsExU196taKvJydu9IFWYcdP3Ozr1FGi+ZOZRed+HBmemp8erlIrbpSWpCZlSlILjjlyDmYVHcaquo2X9SOabRL/PluAADaQYweajqOk8J0p2ib6iAswtbltk8KvFfcS5CYvkwAwGRnSw/lZGUWXx8EAFCrMHYoEwEAfEAD/kGeAACoK5MO4tMKejRr/uSKcHdkUqXCw3aucsT7Gsu3xfJZHB5rTYyg+NItDEB7QcCZGjDARXnBDE6ByJy5tKcSefE1GruPw3rPFmdGhQSzOMGBiQWnxHoAAGl5ePKnGuxGLic4s3Fmk4mrzu7LFCQKCuo1I9r2in0FBXmp8ck5FWI9rm2v3JeTk5UaFZtaZtLGY2FpeNhIY9N8L4i4WnyhKD0hkBMcGJuaI2ztm1YXPiA+U5AsiIpNSHxzd0mLZv62mR7qTx7sap+8lw6TiJTLYqLd+9p6JscsNOKufjI71AMAQN9ZU7A1ar0fh+e3LrWgtnfEBketSJgTFcJjrOSwQhJ2vt8xWR19Z02BYB1/Vll8oO1wZmKMH4e3OnDzttKmPmuh9XXpEXvbRpVHkljryrsBAIAE+rbf7Y5aw2NwgqPyLtwya0DfXVMQvy6YtZLDWpOwrbRVjQPg7QVrdlzT3z+XzvPb127Ju69GEF2mILrKgyZdiAR6UVXOhsCAmWwBVzaVZAnC1/BYHH5U1mGRjfsB9XXpvChh09msGBZnvwgAsN664tTwNTzGSp7futSiehUOALKKGd5lOYukk5zKMz0iODAxp2LWPdsmQWyEAGjr0iMKOwjiehGLI6i0mj2xKcacJssUmoYo9FfSeVHCpvrfZMXHxviticms7R0Qn8lJFkSF8AMTDzVPCjjQ9mFmIp+1ksPg8DfsOmZ7rGuqAhaa3LDrg0lNtudw+EX1TQWxPFZ6kxUDU7ZM3F4xO1v2SVU2X+Gl2IYPAAAgAElEQVTIXF/br3CzontEfqHwrQ1+HB6Lw49KL7e939NCh2ui0u3o0KKO6qaS9IRADsebHRCYWHB2cuxQXSNgJZ9prkoN5MSUyAFALxJmhq8xmbJJfD6dFfth3ywtWfjbtJZWb//CWs242YgsDs9vnSCnRqabfOjqtz4V1R/almg23JWp7pvNBGiBkcYcVkj5LfM3WUkIh5F+yfxcrCmTE1PWOz2L5ABm1LezNnWqviPyCwXJMfNY4TuCcdww+/OtYdTm7y8GsUIY4R13XGXxX1V11sHOYYUwYgWDs1koGTZ8a9C3/yrAK+Vcv0Ocb5ZllMmmfhntLMuuVoyKCn0Zy9dmnFY8MI4bhq9le/lmXxueV+bbx+NYscdvP0kFh9uF6RkZc392n+uxzUdWFrKCkXj+nnGwuexX1e2yq3mhLK+8L8ae3CiSQp5vfvvo7dObWbz85mET8e1jsd5bTvcbjOOG4dZ8nndkYevdsXHD2KCoLI7Fyb56f/yWcD0r+dI947jhW8MfitdGRqwPK5YYjOMG42B9undkmcJK/oM875Tzg4ZvDXfOp3B52edkgwbj+NCdS/khk0Yfu5bh5Z3fPkvm/k+yC1uH7hyPW+4dEJFdIxs2GMcNkoMBy9dGJmYLJYMG47hB8V7k8rUHJE+gjTufZGR9ctumPk3Ew635Ieuzj7d+rVB0NryTwlvBWL42u6HfYBwfan8nLmRz2TXVkHHc8K2hX3I8u/DS3flkeND+K+7yDSdNnjx8LZuzvkymEEb4Zl8bNhjHDcb+c4ne3Lz2B8Zxg+K9OK/1+XV/HjSOG4ZlNelruemz+N+/lOG1NrtB9cA4bhhW1e9+g5t+6d5U2QbFkFXZMcnBEN+44tbbw+OGf/39D8LN3CnrW3xuCddPuf1QQwbLa23c7nM3748+GFbUJPuyEj+5axbeO65Mcm9s3DCsOpe11vy7sb9mk3domcxG9dt/xfXKqB+2YJt3/ut7D/SWbI2DV7PWcpPf6+wfNRhH77YejPQKPSgbtbLgUEMGi7N2S/G128PDD4zjDyQHA5aHFrb2DxnHH/RfKwxZEVYmM3xrGJ3hXRKzN5rimpNSY/JGxflsnnfku3+29g07IWAwjj+4ksXyym+ebVx7YsxhsrxQk8lMCsk49We9cdxw/1o2ZwU3Ir++f9xgHL97ejOL96tOk3ske3OTj399f9QwNvj1sa1cTkb9/XGDcbw5z5uV1WowjhvuHI/ziqu+M0uTzQemNCnK82Xx4grPK+4Njz6YUYXJbLl39exsOdSQvUVoCnBVTXqGORv3X8pOyysVXrplM4hm6H+wPt2Xtan0q/ujBuPo3Wu/CvMKPSgZnUuHf72yz6RDa86yKVPeEq5n8bLr7wwbvn3Q3/5OnNfawvZRg3Hc0P/JFi/fsPR3RP3DQ2Pjhv7zKV7eW4SyIeP4kOJSfsxq7nJbWrLwt2kt/eOB3kpI2TthXmuzTfF1X1ad7MtKPn/X9NDl3gHpn5i0ca8hg+WVfXV43GAcv2szAc7wjf5ziVNNoUIYGxoZsdacFsZa8zlrC3//oP98Cot3sHOGlS1Mb/n567mtlvWN9Z2qb326LyvxHZGlFTofPKNewWIcg8FGMUBRi4ExtVTjlcAilAotvJ5Wku2DAgCCogghvynHYUR+qaK0vCAr1d6oDC77Qk2PnD7nW6nA/AI8tKo+jMTOPZhMRwDABV2CYDLx5FKDEXWvnW4oiqKg0z7RrSUu/tnVx47M/SnfaHtqc6BXoYVldKS9pHo0Zn8KD8Uw1D0+ctVTG7xG3JJLMpa2Vb4rtqojJq7vwNgZe4OoCABC4e7YxsXFTZ2YO49NVop7cQBQ3uxGucn+JLlYBQB4r0SOsoLtLQtQfn5W7pZWsNGLAgAoLXpnEr3/SqPKDjUA6LuVrjF+0NfbDxTuvpItXigA4DhBAOGWtD/bdAkwThCAE0/yBkETlCXrDucK2+04gL6lXp90TJgWxPCgs2ILqmsr17thHQfSCypLc99WRladzI+gmXyX7JOaxxRf7J5HGsQniLtE8wexDgBweVsviR3gRQ/wQWUiKQ4AOmlHH8KNYCMAsnON/T6phdF0FABcmFt28NHu+g6rESMcGwVkiQuKAIALLbL82o3qaPJU2Vjrspiotgnzy94X5OYCgFBWZWUGEG1fWBt/Fgha3J6NnhQEcaGHRdBBrewHABd+ceOX1bvZZATAhRYZwYQ+6RwGtc12XwLDiq2u7bIYidydy1qKACDU4NwUH117vdRGcYy6Po3v5oIiAIhPQX3bZ4XBVBQAWcqP9CHr+5T2Z8GUl+uUrjEFW0ze6JGQEUPtb2lSWLG3EwJzVMghMaxMJvxSVB09uQeTGRlNRwCAQvekAskrIXIpAADVg74E0w7qAIAaWfVlfVUqg4IAQmFEh72OKxX25misNBm0K3lKkwgQqN+WTXSyi9XdtZPZUjk6O1uisZU1eaYAp22pPrbRtNtxabTw6Du786Ld501KA9cvi0mh27N9KQgAQo3I2crUttZJrQJmhg6p4evnMSW4Z5292lgeSUMBEDIvmkvFVMrJdoHA3WMyuUtRFAF993UF4r81i4kCoB7R+QI6YVNLlv42pSXUSkt4T33joEdqnim+KMyUrPAl0obJ2CStSoo3aYPsxV4GapUWAJSX50+AVFYwrb+zVw8AA9IeHXtzLFUlVgIA9IkVwAywfcuqbeilrd9Y1jdpsr4mK+zI4VpaoUH2jIZhFuNuahwngESysA0t4WAa4KJqBUGNY5sXiGFqtcmJZR8Ie3wqyyIoWGdxQu4+18azW2ZuG8al1wZ90iw6BMyUUibo6suV4L538upatVKFAYmEgPJaxaU//U3cgm36rDbNxmI0EgkAiLmvZ/vugMmlKgCiXngjaf9OCgDQNlZ/ttFonHiaD6GlHMhsFZQd5n920Hf618E+LUHxd53azOVCc6USErUWIoI8oexmHwT+RNaDMf+L76c/drpXB+4DYgWJXWhv8QY+2K8lFO+u47xr8SOJqgWwtyqNHFuSDyArkRNk/0ieuYPb3y0fRf3WTy7G1EilgyTWDtsP1baWlF5WzzTdo0ePfvSjH80WTt5blKkrrqkIm7UFXSVHQndbzA8uDTpYXaBPKOuoafDc++UWjxk5herD1F/RgM+cqzsRdgAbSkRd2KZolUhK+BR5AkAwA4raFHiQe3dbD7CL2QiATjOgJ6TFId7Fllrp1wFYCrk0emdSS0HuOr4bk8ULCggN4a36+StTZRnWZfVaLYEpc9nXLSV6XasDmHNuHaVSJ5ePkEgkAFO6w/Xdpw+falNpMQIAACfAn8ABHE+zJrbGmWzVSg2h7UlaedGSkq3XA1gftYBSqdOq0MvOCj8VybV6ggAAHCPmWEeEqwd1JFeLietlHlTSOe0gDl4WwtsNAZjDvg6IYWUyfniAF8X8WBQlm+2AkBDS1BcgIcik0gl124cfNPSotRgB8AgfJVC7a2jtaxIASEtptq4Wn8yWKnh9drZ8QmiVWqCG0qb4UKhL0VG1Rg/+MyfgLXT46BEQo3OZEgAwZVNFdZNcrR/B4Uc/IjDCdWQy6kkU18lFI3q1jiAzqJMPJ9M9XUk3TbVbuJYwrRpbQnWbFptKo8J1lRqABkAikyftCSQEAYLAAXCtvQT4HxY/uLHZ5FPiXjyaJRdrPPiBbPTiFbEK2CRpr54pYCFg41ZEO9BrdASZOV1fD4YrqQvAjhX+qhmGta84zPzxsRh7MAhCMhl5Rg5ViOQE6s/1MH3De8S9BInuywRCrFd0K/EICurj5w4tPXJ8y1LL0MIl1/W+O62DGuvuUgA1zsfscvpbXf2Acn3oQF+5r3jDf+e0nLAjHEEAICjpqVR04VB1ywk0qLh2G5wq3hF+enPtp9keT5xHZsNDcDDpeurbVZEXN89FZkoLCDOAjZ2RqvU/kfR7xHi6MPUeyo5ujKXtxZjbPOeSjuT79u+PxC5oFZpS0q0nMf0mezlamVRDoqcyzE9RdzQrSX5bfW3vmaeGFR8Ls/rNxnnYuKau+KhHZuE+f9tnEc3O3EsTMmJqb57TKM5VtUdUBFquDMVxBzq7KDeIBe+1yUboPd0EK4uNAAAziEUc6ejDCJEUfAqmTgFYwj8q+u3qOc/wRll5Z5uTlT2dUom45WhG1YmYyppiurms0N+KWiMFoApOXS9g2NbGAoB3CzP3drHePlofS0MBcFFeSMHj8rIGPa/lsy3zH2g0bRlVZVbRVerOqs9MwyqykpDchawedfQVZT46x8SYabJUk8msLWUbIy0lO4RafsVH1UFUBOD+Z9vXfzxnAQtNWpubZC+tYd1dCnDdMDtbPhPM0KHR2P1OeN5cptReKsg6QwiEtUdZr7408fLfz8UnNk3/18F+1xz+ZkdLczYJdv5pKwFavY56BK0iFd/swxCR0s2/iOxBdsdO9w7ooFPtGeGHwgJ6MM8pFuMsEtmVAhhmNTar7OjWk5hsc4uISb4SYz+NyAxbinBLv7xa7I8AgFY5CNRltJkeOtJ2AwsMtfZFXCGWEiiba+7Y6Nqvygm36K3B87emGIbB9KvQY2FEfDgzPXPbnJ+887aG39UKuZ7EDAqgMSP3Zq4CZU+3HkB9SXhN8yTy2ADinrU/jtRYcqR36t5QVw8aSafun1o6OqIe1JFcaVQAlMWjD3Z3SbpUy/yZKKCePm694jZJp9YzmG1XUYjrMirRL1dOj1WOaPXzDlzq5AoNyZM3yXZELumDZTyGuavR19ikRLnhfqiupbzSeizaQWCisnJ1QrG97guAJw9VzNxWjN+qquyk7Uz1+6n2elGmUGaxulbV3EX2cZv3oahf4Apc3tEiVmjpvj4oAIALO4Cuk0nbOuS4Z7DpFACKG408qlZqph+s047MriWOjeAIhc6NFeQLz547xNVfbZDhdsu6UqkknVI1vSwR0w885hzpYKd01C0oJdY8idbfrX46Q5U0uhtJ26OclgqbfxpX1yvXkngCU78BQKtS6ucSBqEtoxL9yumGcbBPS5Cpy2bmEvsh8IRizDRZqb/+qsOD+EppL06PTAsyvVvjyt7+Oer5OJoEc7ZcwvK1nS3lH8YnmheELhRUOpWkUUxP12o1amwJzW1m6C3QlLjyphw8kzJZpmGPEaXMjhuSl1JAr51aE65XqgZNhI+jJQp1KTqq1UwtYsDVSi24uc9xHghCdSgBIowAJtYrbeuQo6t8qIAwuR7Km+Kum0oa12dhm+jIrjPr26c019emFdzcfrog7o+NxdiDoS6jwqB65ooWtVimBQLT6QEAdO3C929Stwn3+ls0kFj7seukpJIUjxnlMHEbERQwqzVSSroxwHV6DABAe6X4hJqZdySH4UD3fFCtJdHotgYSHYaLf371yerTc34q37QxmTLSK1ODu7lbQACQyBQy3t1wk8xwc/zpeO/nJaWXbs2XIBHmztIEUuP7X0zaAfWPD0WlZ95t0+IAuFbyQbUEDYoLRgGA7B/kJq8/I12yyocKAG5sJtJdc1npNmeM0Tcks/VXhUc7dTgAPtBWnhqbWmHqdiAIEINqNTarecblXSqgB/hTpr4qCDeuvzlP6OW9/SR2qD9JcfY6ieeIMWdDeeYspOyw3/ECQIMFy5qFTeaAx1TNpal7e0OF5Sl5lUf2sknK2lxB3plmqUrZe6My65AyfCtvUhB14+GSGomt3UNA4YZ6YD2nGlQeQVxz5Sirgun9dTUS3eQeNwDWpuhl6tPltb16ABhRNxVt3ZRaa9XTxUTFCfydZ7q1OADgWoVskKBQychk2bNyq7KIf3woRXqipFE1AgCY4uw+QULepVm7sUgAhE4zqMPmOFYIpVFBq5SpcQBM01x6Qg5LCJ1eB6YZodEBjX5kVmmERCK0GjU2F19KUJw/SCqFrQM4AK7vrsqNTi63s11uShYyBSH6pL0jALi2vVLYgZNBp9ED2PEueuQmhv7qkQt9GABgffUfXtW+Hm+9Fm2OEFi4GNOwNlm31mQyh0ChkgltT7cWALBb9SXnNSgJ0+rsKMdKk9Lf5c2vSTBnS0JvJ1vSIg+UW2XdOWGh/6XhcT7QcfzjHh0OgGuaqy72uUUmWC3umKnDI+//wZYOLdiTXSlEv1iqB8B1sk+LGvUUwPS62e5F9gnyxLsu1ikxAKyv/nCtimRTSw75G6xKiF7WV1N5RY0BgE564qM2wj9h9hy0BehxdhPgjPqwghmDV2okOJNFAwDU04fae7aml+zHXeBxaWR2wArL+p5TmutrssJH1TJLK8Q7sHX1qeBle2sgFrQ24vkifukXXAbRcPuucbXb5H/0N8X94PqG51/ff2sHQWAoI/vEmXA3xDhhnCRoefvCj/Mrd/3ilRlP1LV9+SikhGIthvprmRZej3q9a0/adcBH0cADn77lS4UJo9EkxsNHABMT5q8zoOm7jb8e/x/Tan+Wqvv7XT3KTfT9PxNGI7yyJlnAePfk7v3MsB173BbAmdB01DeA587YFVbTBROP4NGjiWmVvrwia2+0aGfDoOtD44TRCK+sLjj6qw+EHyT57SMAdWUE7D3xyzWvGCeMAD9b6U0WnsUiff/TOGEE+E/vFSO1X1GzOT+b5jb1lIcAjyaMEwCuccKjht9+UBIboicAdfUOP3g4Z+XLRuPESytjo5cdeHdDxJWUE5/tcrfQxr2//ANYYVNs//H3AXCPDPlP89dXfTe84fbxheJDnuF5O7xfsmW++fSs/FLpvmHHK7PFtiR+bdOvN3wuzNqmwQgMltAj954p9KTAhBH+Y0v1xRWXjh2/dKkk6wTi6h3+XyXvh/9siv/fOpvqNT97ayvHxvQy1TfM/d33FMvCV07R/8x3leu7Z/rd81dPqfE/d1YefvjBkT2bj+gJIC/zi6w4vPU/Zpr+lbWFFdt/+8H+TScGRwkSeRkjYO/hrF8YjRPmsnkJH8ws+8rqgg/LPnrv45yg0mEg/Zzul3w4P3aW4V6LjPO++mFukGjtb68VPXwEjx4+nFTdxMNH8OjRQ6Px1dCduzsPHYtfc5REfj3ov4reD72y85dH49Mefno8IJp7pqw4Ivzq3s+Ob7Acs/jF+vWMlk+TQprif3eR8QgePXxoqo7ROMV2Al4NOVT9rfDwifg1JQSQyIy1u47sXvvv0/adFmOyOLy0ZlfhG4WHdwTVklA33+0HSw5J9qV/nLrh5aOfv2XhXX5mbzQaX9sirDD89lhmxFGMIKFuq978XWXqrLCyHwITAACPHlqH4Rxi7PKcz2TYw0cAU3o2PnwE8MhorrVJO0bjxGsb9u7qLq2I5b1NcmVE7Sh5L6R6W3FR7J6J2nWPAB5NTBiNYHxols1oV5MPHz4yEdtII+Zs6X5zT9qN2dkS/v21Fa/ZyD/2MtLM6I747ZF/lb3/dtSaYYK0xI0RWn4kd4VV5Frr8G2TDqNm6HA6sRh/kfTrLcqyvAgW/JTKTdxfXKI9tLMsL+bhe5czZ6a412L3779deiQ55APSzxlhWZmRmkLJArQ0s4Ivr8iqLH9YcSQ94m0MSOTXg7IrC9a9ajROTEw8AoCph05My/AzmwlwFudXVvkuO3D4TmDG8peME0Z4zXsV6YMLEL/WHPgTjwAePjQaJ6atDA+nTG8J2sai/arp+m6frq/JCoeiaqetwESeUdP2I+O4jZmw5/MebceJB+ozExpD68+aF7cD1poTUiSP/qi9iGWLM95XW1JH3lnMp+qkEh2bO/VCoGssqECLf7vmlZli6OvSI97GdjZ+ljK7G2s0Trz88n/ncE542VrJO1CbmtAW13gykvJkFXQSP6fEOI4jiL23j+dUZiexk/g7JDZny8u1Sa9bE+tFNWdEvRraNmEac0bQfN8yO0yM4zAZ7j0l/Iy/ZVyfeV3uMxLjmRFPGKfqe6uUn6qxW99nJvNinEUCWBqdwddfrJs8GwqXS+TEEp8gT5vEI+Kjx7ShMbTRPrnsaqPl/LFW1LYkYvZNAphMJAcqe9XCLy1Q1dXrg7eFPi93DDnx1GG/++KEEz9E2M+WuLhJzUzxB1W35vvam/lEGGkp8Fuzo1KqxwFGlBeOd4xOz+EuRmDX91nW96O256K+i7MHAwgrK9NNVN2qA+gWCsLzbuiBEJelFjTOmv7E2osKL7bV7k1KTErYuuMDrev01KO2o5Mc5m+9sPdQ1LoSMQG6lqL40vbZixLU1z4o2ndRCYNXhPtLai1XZYKu5YSItnO3v7ONc8IJJxY/LLNl4jsdVtkSYcYl0WXNcnf+k9439/3AhV/4roAs3hfDXskJymqCyJJ3Bd/FMerPC9DwvTPqG136PNR3cc4iAQAA1i0sOEsvPhJtQ8uOcFbXFtTRS/exkacjs/ZSzr47m44V8lAHiBfE2UnsJHYSO4lfQGJdY058W2RjeQAyc/DyeZbZSfxcES/SMRgAANSnoGwTqB7/FlO3uKSFnFk4N9Ry2FQ5o/vihBNOOPEDhr6zRcUMZylr5z142gknbGMxnmg3DTIvOvCxC9P8uU9PEqDxNy583YwTTjjhxGLFkqV0d5CekQelpDmn1p14LCzuHowTTjjhhBPPJxCf3CM+37cQTrzQWMSzSE444YQTTjjhxKKFswfjhBNOOOHEwoDLLzUq5ydzwonvFM4ejBNOOOGEEwsCJqrtmXW3txNOPGs418GYgPfVVx5r0wOCY0CNydwZS3fuGnLCCScWNXDVleoLIiUSnPC6Wj1K9Mr+sTYt0fhnuXbwloa0aX8+z96BZbqOZgg4NM9xZlh37YmrYg05OpKiHDT8q7fn3yJ3BA1KpXq1pp+2rdTqHF4nnHgMOMdgAAD6anZkNi7JqhQeqTxStY10Kmv/Fe38pX5gaC/g8HLaFlqqI2eqFCarTOazVvK21du9Vu3pQVK0hpfZ8oPbo6lu3B+1hsMIKe9+po9ddNqWlgdyMut08xO+0BjpatUHxdG0rfVqRlZqyu5opO3DkwP+KWm5GTys6ar9SSJdWwfC587zkqfr6CTF8Smq+kYiODcl9b988cbKeiIsLTc7jaG9cl01d+lnhGlDT+U3/ZV0XmCpzGEW0/TqGgEr8Yx63hKPCX3dPIJJitbwdl5fRGHoABZhD2ZE3nRF7sCd71PAWo+dVtGit3ggAAAuzLhYys0PqiXzO4Kut05YIFgXzFrJYXCCw5MLKlpUC3nw8w+8r+VS5xPl8VV5Jz/KYwMAjIjPnFO67fvy96cTnKPPDmHBngyqKzU3iPAq8ZeFDm/xkBSs4eW0PUbWe3LfeI5B31p1Mj/4ez8y/TuGCzsliaqS61lpAncEQKvWkgO2xlIBcFW32o1p9/gHbXPbkph5D9JFA9KiiW4lwk+NXAoA/SotLS4tiAyA3ZIO0hhuT7Uqj4sXydDk4IKPqlLd5yd8LvCM8sPi68Fg4tOHz0kX8JaPSzukGIlCnWpWXalkkl7cIZ+7mLYpJzGtQkwKzhHWfl7XeFa4g42LilO3vt8z+6qBFxaKc8JPxU80HIXSmAwaCgBAYARQ3OlU59Cxg1iwJwNgGEaiMT1dFqBjEkoiuZAewyhP7hvPMVCqF9P9xWjXngQoCr09SrovEwEAfXfXIN1vBQDgva3dlAAeFcdt9mzVN8TUMJ95XQZBXTCVXOvuwwAAUPd+AwxPGgBgElGvZzAbtc38GeOFMjSFzvCivijLG755Nvnh34zGidkfALD5+3NPPHQhLWJv26jySBIr4p2bxgnj2L0bFbuiQngsDo8bIdh1svv+LM5/u6vBgPTjl6dYvfzyjwH06r/cn0OMoctvH25bEnv0dEnKGyv/87XXXvuPlZE7K88cfIOqV/1lbMJonDDeF3+cKwjj8Vic4MBNu3771T1zwTReVEXL5ZJdb25KWBe+Piq39ptJ+sO5gkAOj7GSx43Y/uvPb4+ZnvXPW2eKtkeFBK/2Cw3ctOfjPwxNynDvRsX2MB6PxeFv3Ft74+Q2VszvvjFOGP/wGy5nVyM2KfMffxPI2XX5nzNYsTjBlqzUn2xlJZ2+8dlv3tokiArhB276zeW/TBjHRHt4O67qB8+l87h7RWNG85Xryt9tZkS83zOtituHY3hRlbftGKVjF4e366uJbyoF4WU9hPZiKif4rc+Gpmn+2bKLx9v++dCUnv/5xR4ub0/TP+3a7puKaNamWu2kUb6pTGBtqv2b9aMfPnwEP/6X9EyuIJDDWR244a1K8f1JfV4o2hbGM+l5268/uz02LcaDaTE+38UyiWEc6ji5580IPpfD40Zs2/PprX/actG/ffW77Zv4rJUcBocfteN3HfdtaAPrvbgnKZrL4TA4wWFJvz7zpwem38e+aTy0w+Qq/Kgd79/42/8ajUP12yNnePKMz/9+8/k7b8XwWRweixf9ZlGDHAPjWMsuXm69nhAXR8wq8qDn5J63kgRvFjV+85cW4S93b9+x7c0d79/424TR+MqPlyz58Ssmnr95KyaYtZLD4vE35pqrYDsGZ/mGSdu1v9wayOGweNHT2ranvT+984bf7gt/OL0rSbAxgh8Ysf3QV0M2HjRpLG92wLSx5ggWC6Pc/+qd7WmCjWnvd9x/0PPpb3bt3bM9SfDW3oZvxh5889lvduXueWtTdNSOWjlmq4J/fCeQs/3C/TkD1vi/d754f3sMn7WSx43Yfujzu2PGCaNRtIvD//VnjXtieKu3f3HfftBZ+WHxJdVkFcxuz1jJYYUkbK8Q/W2WJtdEpU9rck5VmLRx/w/vb0/btjHtnRt/uX25ZM/2HdvfTNrz8R8fGI0T33ytcl2x8lXjhHHs1tfq1/08EaNx4psvZWRfzkuff/zF/9hw42+uSJet57w0pWf7zMf+vy61+2rvlyaMxge9skF33+VG48TYH9vl7mtX/U/t0a8ezJnMF5T5bf3rb7VvcgQf/8VsrBu5wQzOnjbcRHzv44rDOEYAACAASURBVE28jSfvWhjanN+MxomHjwAePpzN2V6Mm+gBwPgQ4NHDmWLcO5PECywSj82Qil8sw43GoZsn92yMMEVcwlslLXfGzKERyNllGRpl7XqTA1xI4wWWdNs3+sOHj4A0+idT0psZhnZVZ7tSYy27OMF7Pms8lCbYGBMdGJKw6+QtzKwNO2L/8Z1Azp4zX7yzkcfbWH2xMHCnRX54XAs6QAzGccPsz7eGUZu/vwjEt4TrWbHHbxvHDcbxB7J3wrzWZjcohozjhvuy6mRfVvL5u1acFe9FLl8RUCyZZtWaz1q+Iu64yr4Yw/Xp3qzk8/fsi3H7eByLk1IjGzQYx4cU57N53pFChcE4PtSQwfLy3VImGTKOG74d+iJvLSvxk7vG8Qet+VxOSo1i2GAcH+pvPRjraxLg7vkULi/7nGzQ8K1h8M6l/BBvs2D3z6d4eW8RyoaM4w/628sSfVnL1wvvjBuM7YUc74y6oUmZJYU874yG4RmsjONDlqz+emrzcu+A9E9ujY0bjOP3GjJYXtlXh8cNxv6aRO+wMpmpas153qysVsO3d08megcUSh6Y+SuEEd7TupqljS+yvFlZrZMCh5bJrGketP8qwGvzuX6z6oauZXM5+c1j9m2neCfMK67mr5NGUbwX6RVX02/NVlToy+Cszz4uuTs8OnS7bidvRViZwmAcfyA5GLA8tLC1f8g4/qD/WmHIClMFh1qzuV4Z9cNmMe41ZLA4+c3D4wbFe3Fe6/NNYgzLatLXctMv3bU2d/+5ZG9u8vGv748axga/Pp7C5WTU37cW6eu332DFvvf1/VGDcfSe5L0tHJM2Bq9mreUmv9fZP2owjt5tPRjpFXpQNmr41tBj4ckzPsOt+TzvyMLWu2PjhrFBUVkcyyfr8/vjBuN4Z/FaVvqlIesiquqsg53DCmHECgZns7BzaNSs9pRz/eMP7qtu3R81GFXVsd6Rxe0mnl+fzgjg5TePzRGDM3zDrO1jnXeGR4fuXMqe1LZ97cnKglewQvLr+0cNxnHDneNbvNYWto9a+8aUsb416C2MZS9YLIwyKirMrr4z2pznzeCs3VLcends3GAcPJe8ghUSl1F46fbYuME4ejXLm5F0rt9G7SQHed4p5wfnCFjDcHthiHdccevt4dGhO9cKQ7zDiiUPjOOiPF8WL67wvOLePx7o7QedtR8Grwg1KfP+pQyvtdkNqgfGccOwqj4vlJt+6Z6VJv/x9clJTc6jCuO44dsHfyjLrlaMigp9GcvXZpxWPDCOG4avZXv5Zl8bHmrI3iJUmJykJj3jnCms+i9lp+eXCS+ZEoK1G5dlmKP4W8OocbTTPnND/ycZ6efvmp0/Me/aoClj1KRn5Je9d/XOU878sz+3hOtZyZdMWbqzeG1kxPqwA52jxnGDcbA+3TuyTGFpaHN+M47fa0hh8Q52WnO2G+Nm+m8No3eOx3nFVVvV6/75FC/fad++czzOK/Tg14bR4WvZHO+4Msm9sXHDsOpc1qRfGWVlIdahsa991GAcv3feLJg9o4sKfRk+63aakp5lGNpV3d2zdirVnOXN8Fpf2DpoMI4bxmRlsd4Be3+vNxnXvtgBEdnVksGhsVFTMzGVHx7bgvMTL75ZJAvgPfWNgx6peaaNRRRmSlb4EmlDh/VNSQQBAAu7312rUhNkD7r99RzKy3VK15iCLV4UAEA9EjJiqP0tjb3m/zLidrBRAAB0lT8d1Mp+AGIEI4CEoigAoEuDChv+uzaNBqC8fFbullaw0cSHFr0zid5/pVEFgHW2KcB/cxYTBUCW+u9MY5MAmXOA0S4rAABAWEnx7ggAANmLvQzUKrvjf9TQBPaoqF5imizra+zQMuP4j39jAsKLD6MoL7eY1r9hHVelJH4CF3HQdnOCGr0zjU11QVBa2DomSa9W4wCIT0F922eFwVQUAFnKj/Qh6/uUegDUP56LSFtFpmUnOslV6ZLgaK4LyM419vukFprEcGFu2cFHu+tniUGNrPqyviqVQUEAoTBiwt1xpWLWgr5RDAMERVEEACH75NZ0fZnvBaBruyxGInfnspYiAAg1ODfFR9deL52jWpi4vgNjZ+wNoiIACIW7YxuXkHzRaX/BjFqq8UpgEUqFFl5PK8lmowCAoChCyG/KcYRCc6cgAJgeM/0KgFAYycda2isCFzS3RI3emcpydUFQWvj6SW3b1x4CAD8NFkQuRQAAaGxPCtavtp4xs2csO8FiiV4ZBIXSNIo+gkRLLS4OoiIAQBAEEKhf9oFoN/NXAgjcgdC3EbCYuOGGzj9lX5CbC4LS+PlVFRnBZAIAECBQvy2b6GQUQewHnXXV2OThPqUeAHBsFJAlLigCAC60SOGXoupospUmUcbmSU06oAqVAvML8NCq+jASO/dgMh0BABd0CYLJxHI0trImjw4AALQt1cc2mm7BXRotrK7Iz4t2n+0AuPQLNT3Sa+q7cg7msFRwpDrBxJJR8MnbEabZGvqW6mNl+3LDvvtbVtx5bLJS3IsDgFLSjXKT/UnyLhUA4L0SOcoKpi+EmUMxbgOUoEgfvOOq1DRnphFd76eGxzEBXPjFjV9W72aTEQAXWmQEE/qkKgBTaJAtQ4NsHRpzGZ0atcOc9KbDcI5KrbNXKQSAFp1iWiGEMDfH0Ie72r+BecQGr/jNPhQUeYYrBRb1bmpMq8aWUN2m76am0qhwXaUG+JkFFUJeAoCBpaEJADD5h12QAOZwDVw9qCO50qefvMyDSjqnHcTBDQAQCtllBjUAoBG5O1uyyvlrzrDZLF5QKD+ctRQBXNuvJRTvruO8a/loqhYA1FqC4u826SoI1Y1MmnPS0T4rdwAgkcmUSV4kBAGCsF87cnAC9919l0W6wFhK79U2vU9m2NK5njwfmHGbaJfrGnpT8n6ha2vtJofVshHQ2bWdw5PWJArV1fwngrggoCMIAAT0srPCT0VyrZ4gAADHCKaJhB0ZjBa0tOkj172qa2uSUwJ3+yOg0wzoCWlxCKPYUgH9OoCZVSbUbR9+0NCj1mIEAOCjBOo2Sx7utl/6Zv92U1CDJ5u9ihceyfd3cwFQKzWEtidp5UVLUrZ+juUvg31aguLvOuVCLjRXKiFRawHsZGRawsE0wEXVCoIax6YBGAEAU1v1F5ib9/FlRVsjmumreOyA4OjA4Dk66DZgS9tza49Epk7Z0l7KmzSWDid+9KMpY9kOlhlgZ5cC6OoVGvA8EO5m+m1E3tMHr2dNNsy4VCKHZfEsV5gPtgJW36cGiwBEPYIip1SxlGbmOVfQ2fHDpdE7k1oKctfx3ZgsXlAAPzzAizKHHzqgCsbWUu+XdPXlSnDfyzbbVK1UYUBa+PInvLtR67PNYjEpM6WUCU+J+dMHM8gTym72QSBF2oMxM/h++mM13+hg+YBYQWIXMhfGzJEYtwVKQIz/4bcbe3B/LqLuaFYviy13B5gAXN99+vCpNpWJH+AE+BO4KRTmCY05jE6iuNpKeo9TKRJ1KqKBTKGQsEE9DoDMJTaVTnvWVl/UPRgAkgM0VCqVBP0Wb2LYCA6AulLnaCqp7ktJF5W9WmBS7RNZYv73PIS+pfr3kWqppLNNIqrOPVYdUPppWTAAkHzf/v2RWNTqVnGH9yLiFs+eZGULjqjKDBe/zcFo7tU2fQT9hgjj7gt6wsVlbvx4z2PVX0izfna/pYcWne+xUIEWAFVlVtFV6s6qz0zDY7KSkFzzixSyKiaInNki0a3j/OG6ghqUP/miuYR/VCT0n4vpSEvJDqGWX/FRdRAVAdDVZ4ZX2yCjRVVcf+N/bkkloraOs4WbjjH2nT62EQCAntfy2RarXqDROOR4rRxYE6kQyQnUn+thLiAT9xIk8xJOE6jBJbVtOaruLomo7XJJ8tFTmVU1qQxH77y3i/m1Zx/Txlrx6sTLL/95ylg2gyXCOmDx7i4FuG1mmn/H5V0yghzGNr+tYuIWCeYWF76gF3ELuABhV/EkC+e1HXTWfngoJFdj+g/KyjvbnKzs6ZRKxC1HU6tOxFTWFNPBUpMzUoFDqsC6uxRAjfMxpyv9ra5+QLk+C607LmnRcXdYD548JebfARBmABs7I1XryWKNR7SnC1NPV7Z3Y2xtL8bc5rmgxtbBGLcF1D+aBcVN3TiX0tikpsfxaQBGvFuYubeL9fbR+lgaCoCL8kIKHK+XQ0afH9j10h3CQYcqZfb0JxL7u8CinkWiUJeio1rN1NAErlZqwc3dKgARdoAPidDqpl5J9Xo9gfoFzNVDRwNi/JfIa4+KZu4W07XtXxd+oFkHCG0ZlehXTg8yDvZpCQrVbY6YwTFsBFAaOyy54ODpz4UReEddmx6hLqMS/XLldKIc0epxAADyUgpJp9VO/gNTKwfNPRUESEBMrfMf0ZvowT6rhQNhJUW7yhubmhta8aA4/ydeHb+UH+dDtDe23rja676J7wYwp+1IJMCnhohwnVa/gBlAXa9cS+IJTM0GgFalnC6N+EQHUKStXcobV+XLYuPdAQAobjTyqFqpmWKA67Qjs7SmlPbi9Mg001QF4H29GpsiYToMR6leQRvzSo5cO7kVlV68ogYa3Y2k7VFiFlTauXdQu3rQSDp1/9SWtxH1oJ70c9rcfWllR7eexGSbs/ZI1w0x9tOIGYNn+AiGIxR3XnRKcWVtQ4FbX+0X82zHmxeOac8u7BvLZrDMKq/olhNk9mSnDfrF8lGU7Wv+iknq2kbdgsLooDhV2rSg2UkAACBTZ1gBu9V4pm7WxjG7QTeHH+LYCI5Q6NxYQb7w7LlSf/3VBhluX5MOqQJXiKUEyuaaU5+u/aqccIveGmyKXPmH8Ykf9jlQ55G2GyNBswZc7THHJZV5gsDYw7cc4PzYwNUq7RwehbJ49MHuLolY6ebPRAH1ZLkpxG2STq1nMHthacvBGLcJF784f5Kspau3uW2QGW1S4GCndNQtKCXWtFET+rvVC0hjjvn//FDKFPYrRaiV/ZN/D2r1BOrqijyZ2N8FFl8PhgRA6DSDOgzHYVVC9LK+msoragwAdNITH7UR/gmzIpASukPwurrhQh8OADAivXhF67kjM9AFAEArqio/0j446yloREEhH24UbM2pbJT0qTVqpexKVY5gn4SyJTmYAkCP3MTQXz1yoQ8DAKyv/sOr2tc3xc+xlb+3IjEiVSgZwAAA1ylVamLJUuoSoMcls/VXhUc7dTgAPtBWnhqbWiHFAcj+Qe4g/vSYVI/jmLrl8LnJNTZAdV8KGpkCAwDAZB/VK8y/22U1hy5JJMAGNPqRWRsfPaLjaMoTb7chEfEsBABAL6oqr2x73M1zaECSH1x//yM5Iy7Y3BLbtR2V7gZaiVQLAIArL56TLiSEUDIFIfqkvSMAuLa9UtiBk0GnmQx+ZiSfqmg4/GUfPXJyZQ9rU/Qy9enys3I9AIyom4q2bkqttR4Ao1DJhLanWwsA2K36knNqlIRpdVb9EPWZ9OiMt1s0IwAAWJ9chSGuNBQoQXH+IKkUtg7gALi+uyo3OrlchMFMT55RB//4UFR65t02LQ6AayUfVEvQwA3BcyZktVimBQIzddN1He8KJdRtwr0WfU9dYwE/tqhOqccBANN0S/VAXUYFAKznbGn5ldmHm9n3DQs4pD27mGGsDgtj2QkW6zor5PolPkGe5q9amVxDYgexzG8Ryp4+Ylkwf5nu2md9zFULnwZF/eMDUOmZd1s0IximbjtaVHq5D2bJYC/o7PohJipO4O88063FAQDXKrq1BIVKRmZqEtN8MalJx1ShlHRjgOv0GACA9krxCTUz70gOw6wKWuSB8hQP6zKzgYnbiOCgWXOL9phTuHmZXMp33MDJa89I5+rwk/2D3OT1Z7rRVT5UAHBjM0jdNZeVblyfBY5YOBTj9oCsivGHzpqjIv2qGLMCURoVtEqZGgfANM2lJ+SwhNDpHTs/xTGjWwKT2Yxi8pyV0raduaLGAPCBlhN1Steg8NcXIDYJcSA/PAUsvh6MW2zCKmjJDVpXJMIQr5wqIR8/lR7B4vCii3toOVXvRs+e3Ue8co9URQ9WpGdm5hXsrYXkk1XJ5gZM3339covMVveWGib87NSBIERavV+wYVN08v5TUnRTxbkTb5lm2d2SK4VpaFPmOh6LE5PZgCQfO2K9wm4GGPsqCz2U5QkhHMbKkOjCDlqmcK8/AkDdVPnRbjfF2xtCVvuFCaq0PiVV+9gIACwVlJZGQ0tWBHtNTM5196ToZeaRa2rk3lx35W/jAtclxOfdoAsiqeZVLdOsWJwQS1Z2QeHG+KPi4gj+zlkvqbSwTUwgqHGbzENV+lttl1sWdniJJRCfhEDyKMk/IWAysdi1nUvQzgNB2PE314fHCjJrlmwSuJNMi7Edek7g7v2hSOOOIE5weN6NpZllpQJPfX1qVJWpA+geG+3aK+uffE8CAPDIraqKR6/mJbBW8oLSL+DhwtmHStESCnfTNe/G8lhrUj/QhB6o3BlB6SmKLWi2jGza5sqDvrrqzKCVHAYnJrcBSS4/GEsBoISVniz00p5IWMNjrUko6l22+1hhMAozPXnG41z8C6uLWANVSX4cnl/yYTW78MTBgBkLNayh7+7qB2ooU3N4W1bm1j1fojk1tbkMyyKU6IPvRkNdVozfSg4rJPMUFiCsiFsKAJiqpaHJxrkOc/iGBRzRnl1YGGv9nq8sjAV2gmUGcK1KRw2ImfJwbf8AOSBi6s2bsT6ZDeKqoiP6xAPRDs4Fz4CLf3F1kefAkdSgNSECocqrSGgrmuwE3Sw/LNmyQl+fGlWlCS4S7iB3FCWGMFZy/JIPqxmFVTkMK02+sf2zSU3ayxszoJbKtPB6BF1SkJ6zLblIxD5Ye3LL9IoF1M2L5sCAhK6jGUJnH/42F/PHngnG9DoHGr4R+ZljbfMMJC9lryJr+oFpHoqjszwxTT81iLvQPqtDMW4XCC86EHp79OzISQWSI3LzgrET8Wt4foklYubOqqJIuuZoQvoFB1YHO2T0GbATxbSNe+1XiuSfEKAsSw3khEQLNfSC0hwWsgCxKb6O5Icnx4+M44bZv85ccjEPnMTPA7G6RhB/PazhsxTaMxJDVRmbKRfUTx2wi4sPZSpTTqe6PR7nkZaC8KqfHLny6/lPynp8mX+oxFhrTkiRPPqj9iLWY3D+pnLn1aDqYvYTi+Ek/n6Ihy5nRr6N7WycTA4W0Itqzoh6NbRtQtMtRXNw1jUWVKDFQotFb0bjxMsvP6hLj7DDHEB9Jn6n/sCX+V645sKBD79Z6kbW6wm/lN18N0TbWlJ8tAVzT2CDWLwk6+TBYKK1pEqCUBGdRv/jnzzqH4usqeBqW46e6iKh0I8xMg4kuGPiC2eV4AKDfW16/8oMl8YTlUdkaJjv/+sRvjuV68ioynNjlGdNfEuYOTuK7XNuL+AU4RWdR4K+T5kdIV58YzBOfPfAtZ3CQ/UQuXt6QAsTN/Z7sOff1mETI8pLRUIZ87+2Oth9cWJBwOUSOWExn7KwwooWOZn3HKzKdOIxgfWI5EBlr5rdw8DFTWpmij+ouudf1KEVtS2JmH2TACazx3wmmaK9F9iC7LwCllp4uFkHQA0rzuSStOCxLW+3gEtD9VdKy7X++fty8yJApqTuqK0IRJQnCk6Tkkqy9+3fSqo9XKfVNp++4RK0JS01PyvaHUHcglNDaSS3qPwDpY51X364wHsXaxQ7ezBOLBCyisDVsXulbnsrd3pNdzjQ4IqafY9z2ay+Lp3nn/wpFi08FPWYHSAn5kC3UBCed0MPhLgstaBx4dN8iOe+s2VzL7Jx4rnFSNuhDVGlYgJ0LUXxpe1WF54gzLgkuqxZ7s6f95IjbUcnOcxqpgJrfztqXYk95jNAiTx6rSKYUHWKVTgxOLWRH6F6elCovIQwGmK5ewsQEgIAt+pvqPFBce2Fsw0dOlDJlVQfP/xUIj8qfb+IEur0yQUAYSzWKF7ku6l/OKCl1spSn8mTWPva//zrp8eOvOlk5yYAADCdGO3E04VPQW3797vf0YnvDy5BBz9vL7I7RI+iWGOTnBlZiuI4zHUOmbqtZyk/zooADTxw7Y3fOCSHtrV495nRmOysoFU0VGL+ccYqGZQXxK0Xn6hUE1pk56GNrgBAAA700CRBIAKQLMgGwEcYRxr9VZ3i1nOluTpy/T6m+awTnbh9gB3o5RzBfWoIFH7d+X3L4BCcPRgnnHDCiR8m9J0tKmY0S1l7ERek8OboAbjFJc296t82zEvQ++pPXHdN6xJwEaxdhwGivHBWF5c8k59aCQkF+bEUgMmXGSY/kFJ6U44H+iCAy5tEqKdWeJFZWRhL53pB6jE9DoAgQBAE6JQKPTtw4eI58cLjpeLiotm/Pnz46N/+zdEJJiexk9hJ7CR2Er+AxC9hf+mRa/p/xN4US3tlDuKf/N/XZm92m0cMnaSy7OIf/37v7/r/E7qVM/bV1bbb/1CrJ37+k/6b8ld8fQ0XPrr8J83fBzRA9fvFz18G5H/qMzJKPq69cKGh9Y9q0uur6D+n+fBeVXxy/OpN5T058VqEP6r+qkn0J83f//J1t577VvwvfvLyqz+D7stfqR78X79IpkO33r8IRnESL4DYuRfJSewkdhI7iZ3E3ysxLilKbwquKA6mIoBpmioKLiyvqhU4tMv9xaigk/i7IX7Z3uKDBS1KcBI7iZ3ETmInsZP4MYn/9x//wn/66v/zstE4Af/+GtP9p+cNBseZvwAVdBJ/N8TOMRgnsZPYSewkdhJ/z8QDbR9+0DJKoS4hYYMDD1fv3Bft4C2BL0oFncTfBbFzJa8TTjjhhBPfM5YGZQsnz08zGidedjZNTjgA53kwTjjhhBNOOOHEiwdnD8YJJ5xwwgknnHjx4OzBOOHEYgOOfbf3wTrhhBNOPA9wTjY64cRiAa4fUPa21J44q49rOLnReVPMIgGuulJ9QaREghNeV6tHiV7ZP9amJRr/LNcO3tKQNu3P5zkt7cQPFYtwDAZXXshcx2NwBKeUz+aB2JUsnl+xZH7Cp4eB2lRW7Id9T4OVuiph9ZufOnCl+ywoD4dzUs/OurHd0efWCFiJZx7nud81tF/krEsoEWPzEg7Upq7eeMyWFdpzOLycNvslHVKdvi6dF1gqm1eMSZ5nMtMPfdBwQ9R1R28xBDMiLo9aV3Dlcc309CEtD+Rk1ukAAACTVSbzWSt52+oXfmHTM4e6RvCYkfJkGOlq1QfF0bSt9WpGVmrK7mik7cOTA/4pabkZPKzp6jPKck8PT5Y3rCEvf8Mvy+xOzxbqqoTnNIMB2EtBC284vofWbUFYhD2Y7toTYnRz/e9r0r7Tqzi1kroW1bMdrNeIatsHHru0HYGpCWUnDoY6dHQUAICm7XzH48vwvGAOTWpqD32gDire5/8k16Cx8k5+lMeen25OkIMLPqpKdXeUnJ5SffaIsCSFTZ7xs4t/XmmQ5t3iS/NbDW/N4XAY6w51zui89ZSE8DJbnp6n07dWncwPpgAAjIjPnFO67fvy96cTyPMV++HChZ2SRFXJ9aw0gTsCoFVryQFbY6kAuKpb7cac51bo5wSLI2/MADWhrKbE8cxphSdL5vPDIgUtvKkakTddkc//Cvc8YPH1YHACI0hunh7od3vN14D4REXjs+3BKL+srL7x2F1+ewIjVHcm3dVRZSmbjnz81fP62uEwlE32NDnScrRa45uXyXgy70FpTAbtiW+CpdAZXtQnv08W8crc6a8+WtHmSEoiodiNt6tkc90z/IRAqV5Md9O8B4ERQHGnO3Qc/A8YKAq9PUq6LxMBAH131yDdbwUA4L2t3ZQAHhXHn/9VT4sjb8wEQnX3emzffbJk7gCmU9DCmypMfPrwOekLMCwKi64Ho61LjyhoI4jrRSyOoFKpr0vnRQmbzmbFsDj7RQCAa0XCnKgQ3mq/AL91gpwamWn0UV0jYCV/2Fy7X5CYELiGH7WvqU/dXpGVGh/L91uXKeyytmVfjSC6TEF0lQdxBKfUAAAk0IuqcqLW8Lz9QqPyLtyabCxwZVNJliB8DY/F4UdlHRZpbTiSTnw4Mz01Pr1cpFZdKS3IzMoUJBecks5sb6Tl67ad1WA3cjnBmY0meQhtS/m2dcGslbzAxP1X1GbOuLqpJD3hDT8uYyUvMLHgrByzKfAULGaR8L7GQ9tig1krOaw1/Pi8Dzutxmal5eHJn2pGv7KQAQj1paJkPovDYYWklrRNDg1jvWeLM6NCglf7hQYmFpwSzxMMNmU2TaPMMB8mO5WX4MfhsUIEeed76vKmhjfxgbbDmYkxfhwea03CttKmvkllmGq0ms2drpGpFjM0OQVtS60EDdgQjAJoLwimdYWL8oIZnAKRma32VCIvvkZj3wqWQ7jazqqC+BAea2XwurcO1Fm82dhW3TQsZ5HMfstYyWGFJGQKF/j2hnI3BZHEta0OjLWT+TlxaGP5B1KbGQ/vayzfFstncXisNTGC4ku3MMcVNYnJWSTl77aGl/UQ2oupnGDLWSRcfChwxiwD3l3MX/3WxQEA0ElO5ZmiKTgwMafCrDTt2WReuLB3kl5f/1aAxVfL5xacbSmPX2MWyRSb6wIDZsamvi6ZF17aVLcvMz4xITyEH7/vUt8sZQy0fZiZyGet5DA4/Kgsy0ixbe4nzAN9UhWVwaIAAN7brXb380QAoK+lh+LHJTWeaH4mbc2I/EJBcowfh8fi8KPSy6dcvYDDL2psr8xLjY+NCQxJyJzd/X3KeQNXNx4SrOOxOMHhyeVXNBaanCzO4gRbFNdfSedFCVuvlOYIEhPWha+PyrswZdC5KlXfWrZra9Q6vt+6zAqx5lbtfkFiQngIPyrvkolqehZJXh7Iyanv+jQnWRC/jh+4LrOkTT8lUl1xavgaHmMlz29dalG9CgcbydyeGDkcflF9U+HGAFZ6k0Xw4p37gv32tZsroT4Tv5ITVaUxKrGxYwAAIABJREFU/6/rgN+a/SLcnIJsZf7plPXGmwemGo5J6OvSI/a2jSqPJLHWlXcDwGTrtiEwgMEJtmjd7GXdZwvjuGH251vDqM3fXwTiB9eyWV75zcZxg3F8qCGDxVm7pfja7eHhB8bxB7J3wrzWZjcohr41jN6XVSf7spLP3zWOG/o/2bLcOyzv0l3juMHYX5PozeLEHWwfNBjHHyjeifRa965i1uPaf8X1yqgfnnyK19q4vPNf3x998I8/n0z2ZSV+ctc4bjAOXs1ay01+r7N/1GAcvdt6MNIr9KBsdKbMo51l2dWKUVGhL2P52ozTigfGccPwtWwv3+xrwzOe+K8r6V7e+e3jBrPAvgGJB6/eGX4wNtgpjGNNCnNLuJ7Fy66/PTRqHL3X/k6c19rC9lErgWd87rwX6bXh2J1xg1FVHesdWdx+d2zcMDb49emMAF5+89hM4rFrGV7eeSYZjIqykBXckIyyVtXQ2Ojd1l9FLvc1Pevu+RQuL/ucbNDwrWHwzqX8EO+446pZzz0e5xVXfWcuma3MN9Saz/Vaf7B98IFx9G7zgc08XwbvYKdx3DAmORjiG1fcent43DA22CnczOXlNw9b1OhfhlHLGo1dy5jS5IzPcH26N3fv7/XGSamSL90zjhuM453FayMj1ocVSwzGcYNxsD7dO7JMYej/ZMvy1Tat0Jz1/7P39nFNXPn++EfhN3Nvl+F2N7nbMtxdkntXQq8S1IRoIMhTeRSBIoheRFeEu4guiPebSr+leEuxF8yuFFstXQXXKlVBrSItSFvAloAriVuBbUl2uwltGVxvQvkxWDpD0O8feSCBBILi4877NX9kJp8553M+T+fMOZ+Zs0yQ0zxmGB/r/U2cX8Sui73f3hr66pOSJL+VO5qHZhCdtW30v7dZYGzgjbNZfqt2nFEPG8bHhtR1+RHiTBNj0z3lumy173PrT9yYori2XaJlWWeGZnSr0Qs5yyL3Km8qX4/zW73XaKg/jH1atEqQeXHYMD421LxLsiyuoNloIS17kwSiHRduWAnqh7FP7QrKppbOPZJlm98bHPthbPTGe5v9IvYqp3JydW+Eb8xvrpu5ailYJdha228Y//KdJIFoc7VycMwwfrP3vR2SZXGy3jHD+FdH1wvCX79qvv3b46nWp+ZDuTd8cXDMjsrOwZu3Rid986/Do7a++e2Zzb7PLUva23nTMD5mGGopMDPz53eSTJ7SfyJ9mTj9nas3RsduDV59Z7NYlFVnFLh9dc8WBwzjYz8Mf+o4Dtw8s2ODzChGdXVm1om/jo0axsf6z+7I3LVXdvb6remqnPeQO1iXuVKQ+nrLjdExw+hXF1+K9IvY0z48ahhvyV/p65e0p3lwzDA+dku5N2ZxnKx36u3zGDcM6srEZeLM964PjY/dUl8oSBL7Ld703qDN7Ybxm1a33zyTJfBbucGo0B9ufpC/yhKf7TSqc3TM2CjRetnVm6OG8eG2l4KfWxmc+fsvb42PGQYvZK4U5Fy8aYqcxgim3Bu+WBCWf7p/1BjZNpgj2HDnnuDnIgqa+28axof7LxaEL47cq5wazGdkQyBJKjj+ef/Q6LC1EIYu7hBF7DE6zo33NktWx0k2m1z+akmEX9aFIasQZB35p3Qc+14Q2OsUrstWCxLf+dIwPmbdu307rB/qrbb0bg6j7jxanRPET9gcjB2Q+Oqt0Rx3DAXqWl39oE9GfiIPAwA2f3NOlJvijHl1FlueEI8DAOBLeBjNCkiSsAEA5Qo5MDg4a9oZzU3aneLLRlGMFxHDA42qHwB0refkaNzOPIEnCoDiYXmb/XVtdQrbO1W9ZECwD6HuIxFh3p50HgoA7pgbSirl3TPX6bs1L5KLoShbkBjlBYSWAADwzjl+ob40josBoCxJvBgn1Sonk+ZIPQmAYhgKgLJ90w81tZWFzDZHigRm7ArjYiiKh8ULWFS/Rg+gOne8m7NVutaPDQAYN377Rl7/+Xq140Jm4tlKfcrGDpqfliVho4Diob9O9zeTtNQ0kAE7dody3AFQtiAnO5hu/UBOzr1FGrUGODyOkcRbImSp5D0UAKg6uzBxeiDSLVcDANXT2Y0JwkxZVkvsacEC5Yn6Qf6WXTE8ForhgTuKZdLVOOVYdA5AkaOAurljKAC4c+NkH7ZUxs+SODLlcQjlLuFCv8qpaWvML7doHZwrPNBjWwgpr7tMCrNeDMVRAJQt3rZFTMkb2klrQV1xLCjn4bsueRFx6dx1Y0MUze20eE0IC1TnalUeCdINRrvySclKwPub6qfNtTgCCgDgl7zen42h6KRv4nZ9k5+0VYgBAGDilFAPbWuzjeTwuIoP6yoyfNkooGzfhChvStWrAXCkbqfigHqGOIAlllfnG8XI3VB5aK0x98IzXlZZtis/3vsBLMINXDonRyK25YrZKACKx+Ru4hPNZ5QUAKAA3PhNxsQmlL/cBxlUTX2sn467jxua1mYVFrk1xdsdAOVG7kw2J4rNfLtv0jaTQpcHmuOz3UbVKsyNik7iYwCA+gg5QPkmJHNQAGB7++NAELa+igIAK3TDak8UAIArXMImje6M+kvrWk8XhOEYAOoZHefP0veppvr5jGzQWMCGFB7LHbVRsrtwJU/Xo9AAANnVofZJW++judJFAoBWoRzihwqmbyRuhcmOY03k9JBlB5bezZ0Xae7dHEfdB4sn/21qDMc9jb9IQkO64ZzJ1Cuci8MltQaAC4BgLMs7iSiKsHFTD4EiCDK1O7Bfi/l2BEFMHYhGpaWJaxuXnrKmFOr1AFbdD39zCR90daUq8H7RnISpUalJQJAZIxPC8rDkSCAoCjRt5JJUNZRVNlzX6EdpAKBJ2mOEnpV9Iyfrd0crCzfFNPKWS4TBYfEhYbzZ8isRnGsRJ2bilyL6Cbp3X6xonw0hAeAwKXUGnifVp9cTJMI16wUwbz4H6QIA0BMETaryhJesi1xE6Kxa5L1M4h8ye4tIPQkslpmEH7oE9l7pgxC24hrJz4oO0B862qMD7wF5LyIs4APoHGvBBJ12gEQ8LTyjnLD4fwMA0NsXnSN4xm/f2CTNi43m8AWS0ODoqGA/9sx3TFM5xsKA1DkZX1DfnYVxLTmlh+Krf/1vlquDfQTNDvSwBEd3rgdOd2oIiDEL6sfKayT/P6cLaq7gxifxKw/XyfP9AqGrvhNC94RiQP1hUId48Cbd18sHR04QgxQ4nQWM4DzzXjuOfRMAECt3BjbOAr1+AMBzkpDWtL71xplrGoKkAYAapTEOgEN1dzkTB3w3lSxzuYs48GBAqAjAIyY3KmLjntjoX7VDsAoAELbFZwBFUSBp2jRgdIR7iBs6rR5wL8vdbC4HQzQz3u4BACibZdOpUw4bpdHqIRAAEEsgQABBMDezwyEIADXdjxAWPikDq+t65XHZuy3dhJ6mAYAi6enuMDMbnlyPaXcAsMVhvPKWHv1WXC3v5gRKBVB/WK6CGE5vh3ZReOBMHmEdslAEmRqy7MHoDgYAq97NcdS998y9ueDJH8FY2xPy4Gvn5Ted3uA5CxHZ1dELeJK/yS/11zv6ARP7z/Lwaq81xFlpzjE6TfZuxdJnf+QCmmPJqQ1O84qHFde05qq7OjpbWs8Vpx+syq6ozrirnFZk5WufHEjEnNuya2aeJ6unARCrU5vAjqdVXZL6OmrRlc/klz+dbJGTjUD5wULymEKjZ8m1PvFL3Pl6H9XlLlJA9JD8LUvMtc9mU7QT499ZgQnyjzemq661KzrlTQczKg4nlFcX3dPbUrMAFW5/JX5jXtHhyOoVM5AZB0oWQf24s98nwZGg5gJ25LrAg6+d6Rzhw4UONOygGIWJaXvXOhqYU06O2I2++cxUE509qWSkqXibjIgue7syFEcBdHXZUZWTTNlX932MA08QnIobU9RrJW/z7baYl2mBuxtFqstzCi/g2ytOGycOlcXheXPO3kXsRhjcX+jxtrxnhHPtOrZkI86h+GitXD1CXlZ5LC+Y5f2oeesGHUTdB4qFBsPE9AMA7F5/LIgnbgPcuW38ffsO3Llt+m14+lkPt9GBr741E3//ly8J8PrFzw0TExN34M6dCVNRt2/fgTu3zSVP3AGAiWnVGWuZmFYLANy+A3fu3DYYJn62yAsZUH7xneWu4RtfD9vh+Vb3Z1202/IVPzNev9F6vpvmxG1c9Y9TGwhgYtKW4cnTW190dsPiDZlL2SgYDBPffaHQ0HBnGsM2x20wi+7777773uXpf1sZu/H/yt499V9efTUX/ziF2EYad+7AnduT/5pOXX76c5zWXv/ie0sDv/v65i279d65bZiRZxv1/dOPf4KM/u83JgEC1XtVQ8Pt2wbDT595FtH1qW5YSv7u5tcmmZtaFLhmk02LJu5YJGlzPPUTN9Dp9War+8elYu/Bq5/J21Ve4n9/yvCPzy336vnsY/lnA4tDlj5lEruVbVgp5fYdgDsTE4anf+7BMpmcwTABlLbhSM1HXzsU3RR1T9wBMDb/1vB3t1yf/jdRXGre/xw99qpYf6G265YtseX3nTv2FP3d/46A20+emtmtjIZv/P3Uyu0vRo2cKvpd/x0E7kxMGAw/XeSF6P6q+c5M/91fCB3yrNdPJwXVobYvKFsTum0UPgAYbtuYsdXx1KoXViFdDR982ND+k+fX/vsEALj87Oc4rf3yLxaab78coFnP/szF4Op6B6ixH8zX/5fQ05Nm40DIFt80S2PSN2/focmBAYs5ffMVAR4/f8bKU7642kN5x/4y6BkXw4TB8P2frmtpuD1hcKjuWeOASSkO4sCyL2p+vTE65EW5XXXPejhJfOsvX359yyHxM7/wQDQ9f7llvvL1X/9KunE4PzFFy4lJE7I9tSh93uLG0z/3AELzjfn0xldaPQ0Ttreb7NN8u6P4bLdRXj972tIKIxsTE3cAblv3DmDsHSY7mjt34I6V6MwNvNF9nUAC1q9b/LSx/L4+PW3sWayDuZNsTDl+sXKZW3fHx1eV5JIVPzNM/GLFYrKr6+NPerCAVb8w+bJJEdaRf0rHAQB2HfCOVQ9okZ6RDbP0Zoi698tE7RIvdHV1mX4AgN3rjwWxy0KABaZ2LVwACxZa2ihMTfBSHato+OZ7ABj+vPp3l+nAddE/d3VxcVkACxa4mMgWLlwACxaaS3ZZAAAu06p76h8QevDrr8e+n5iwqQUAFi6ABQsWurq6PBu+NnDBlQPln/xtwsV1YviPB3clbZF9OjaN56/+oBwFeui7MVcXV9e/NRQf0fLzD+z0+9GUBqIo0De+/ub77yemMDx5+qOf4mz66yufDwNQw5+f2PPBEBvIoWHDFIZt2rIQjGwMf1iwOnnPua+GJ1xdXMe++eO1IcC5P5vS8Kf+AehBIw+urgsWwIKFk/+aTxevTRcO1e+vvDJsAKD+9pksKznrt58bpqrMrKYZeLZR34/8w4WgOFX9x2EX14lvmv7nuGIBwMKFrq5PrVoXwVYeef3Dr753dXEd++Lky5vWS8//zapFFIBNi576B4skbVj6Be9foV+lpcxXfroqjNNz7rgCE6z4uYur67+t8EOVx86ruQErnjWL3co2rJSycAHAAhcXV1d+arSX6ljFua+Gvx/7m/x3Ja8f+9zwlGPR2dqzi6mB339avH513ok/3jS4urpM3Pzy2g2a/S///CNbYsvv8XGABQunWOzEN19ogfPcL1xcXV2onvdfLz3/pyltN7G9YKGL+fTHgQUvButPHmkdNbbl6VXrIjDl8d9+9rcJV5eJm1ffPHwFC137/I+tBOW23K6gbA6XhQALXIw8L7QxY+vjR6vWxrhf+c1vr/zrujWLjcSL16zzHbp4sPYvYy6urt//5f236wcXpa57ztX1n372r27kn774ZsLF1dXwzYe1rXprr7cvZItvEhRM8c2FCxBE/f5bxmZ+c/73H41yAgMXWXnKM//Cogc/v3bTxdX1+z+9v/dkP4aQN74bc6juWeOASYMO4sCzK9L2JHDoBeP3GBhnPr44deLamEPin8eu9V/w6e+OfD484eI68c1HB2tVnLhkAWqKlhabmXo6/3FjUZCYo//496e/+t7V5ftvGn97rh9BwMX2dldXg/XtjuKz3UalrnjK0gqjNFxcFgAstO4dYKFNBDM2wUp05hb9mP3PKK3+4xffu7pM3PzszfLPaBbovx52tQ3mTrIx9Vga6kf/4WjDIF/C/5Gry4+WBfj0nz96DYTiRWZfNinCOvJP6TgAwJ4D/uOCBbT+65vDY4YJK+kZ2TBLz2HUvX8mapf4yc/ktQLql1shi6aqMmNWBATHF13j5lbsmy0j0hH48XF8/bsbw1PKZkglZEeWHCnwIw6nBEkEQSmFPV47DxWETZv71yiUBCyK4XVKM3O3pBe2CPfUHNnAnTZtiQpeSOBo970Qk1HpOCuWv/mVNI+u/JgVAUlbaiC9eO+2AGjMTyiUU7MyzI7fsy8eanMSApaKBOHZVWSwrCxpyrw3KkyK9+qfhQfA15W/vZPT+9oL4SsCItMqCP/iit1Cx9Owjnm2pWMlFpYkYJfznhcJYos7fDO38kzToe6BBZWlkXR1bqhIJIgtbMI2V5Su9bRq0Sqh2LpFqDDJviSx5WE8WtH2Z8sFT+FylrYf+GIfAADwES4htf14qHi25YBJgflJK2TR1PHMhMCgdXs6PbYdLIqZ8zfgsbBC2TbW5cLUcN+looD0/RrfgorcaZO3xNncxJSo2OxaHYKoDqbFpqxJLW0xz6B3t/ZS/GAJBgBAay/XnbmscWKtxT1018shoDcX4h5YUFkoGKjYGCCSBKTv1wgLjhaHGNMLTILyXXm3gpoO33XJXjQsSYjimK9w0stlW7GG7FiJQJSQfQZNP3RgKxcAUEn2rgTkZFpswprUbeW6uC1ihJp1Kcnsm6mhwdN9EwtNErYWxgdJAlIPk6EFB7JtUjG4KQU7edp9iRJBUMYb2ohXyrfHsK8VJkobdQ7UPa9xYE6gdHpnFlFGuo8datXPJDJ23L6D23FFcXyQRPB8dhUZLDu0i+80b/MZN3hZspfFuuqMwKWS+CJl4JY4HGigbW4XiMJnDzsOGuU3j1lHaMjOlyPQ+m2horCo/I88s/eWpC3R12WsqeixCeZ3xwa6JIyv12o5ElOG8hJ/vF9LCkIFU+90qquyAScxZTk05YXGFrY4th5HUfcBY4FhfGz6VYMz6QsM8fwQD9dmxrxGbq8/vXnmr2s+Sjw/NGKKAmNWvsHw1bG0zecDTlzM48wjGyNN0ijZ/7f3/OvTO5h7LPlhEpNt0sRiqvDCgVDsYbIxN2Kqq2hdHpXfVBbi/kDZ0J/PTHiDU9FWKJjvkmcmvnkuO85RHNDVZccr1neUhQDRXCi7/KPFz45/fcsnLX8dD9XJ3yqUnRvAI8MwdQudVFkeh8r3l10CHNFrCGBjgwPLS99JdWmveKuJxoDQc7cUbOXD9bpjChoDnbZd5V10SKypPlx+QOkeJfZa9PyuzEAnx9iPiSExxE8y8d/VHMwjCVLZ0g24cPnj8XHwhwmqvSg6ILW0haAASM3FqlqNR1g0Z37rcI/enu1xpbyy56F8nOn+gLpeeVDOzcoPfbAvCdwTKE1TaXEra2t2yIzvhT5BIK85EwcoVWeXbknyL3N2R1GHik5pANiBO3bHswjSa510+9Yob4zqLCvq5Wfvyi9MYmt70bTqg2tZAzXS1/SRr0h3leR6NxYd6yM7q2pGhcmbt+btWidEEOCEZURwEU6CdE/xL1cy20QyeIzAjGAeJsi219bEFstp0DUVJpe03cdPuT8JQCVS2U5eT3FqkO/SmE2/1wcWy3Lm/zUNTtrrO7mtxWWKB/5lg/uDEUV5YSvnxeINj80QmWrLFQUly/r9i0u2PjZM3xNGWl99YU2JM3EADd1z6XgSpromV+lBpzV/pxVh87w92YLEaG/bAZ/x3T1tU70aSGVtzcnjrVog1H2wRII3ZzyfsmX3YQiMe/Az/wwYzBf+Dt6mfoSBhbxy8fn/fthcPD7AfNPLatIBYI4Tj3MDvvrAh/H3peSHAXdhwcUPHzYTcwIacuDq1YdXPSvxSHvig63SPXTP+22FztizTr4/74BWkLX1BaE3u8Z6D3LzK7LokphQOF/9lg4G6bSinTzTdzzw0A3p8SwASM8AAFJXXOev6mxvbSjLKcU+3CNBTe8L6zou/21F2HzmgjBgcD/BjGAYMGDA4LGAvuXoOUiuzQ15ZuLzRhJAV3+yMWCDjw3NoIYOzi+eTKYxACcwwOu4vGckPsQdQNPUMMKHqgq3krK49EAxRrxKkMYP0dEUDXr1n/Qrwh54uxgwuEu4FBUVTr96+/adhQudXWBiiBlihpghZojvE/GI4uSeI5c133z7N0y0MRS58n5L91+++eoH9jPDnXJKEPgPzQePdX1DfKv5/mn+sp89BchwU8Fm6eGqmtpz9e2qCa8lS/6ZExDwi2/OvXnqSvc3n3/HDovEB1vOfPTHbwb/8kXnN9yUDSufQeHpZ6Dr3Mfq4X9ZGefn6eQUzKMvOob4iSdm3kViiBlihpghflKIu/enHfUqKV3LRWGE6Hx79/7bBadeWvxo88wQM8TMu0gMGDBg8HcOiiQpjMVCAQDccW8eG3G4+wIDBo8/mDwYBgwYMHhCgAbu2K1667WiazgLofWDpLDgvx7yxjUMGNxHMCMYBgwYMHhiwPLP2ONvdW4wTNsTkwGDJwXMKhIDBgwYMGDA4PEDM4JhwIABAwYMGDx+WPDD2OjD5oEBAwYMGDBgwGBucLX7FtOj+d4UQzwTMaU+X3myRYWGpSzSaEZ/uK4YCv/PddS1bmLwuhZZ9/IuieP9Th6PBjLEDDFDzBAzxAwx8zb1fYKm/uUXQsS+4aVdDknI8zmSgKLOea96pKNZH5rEJZrrNL45GZtz16AtFYcHAjdvzcuSkA0XVPNeoWMoSkNE2bW62QkfFPT1vwoOKVHee0EDNRmCxLf67r0gAAD9+UzJvHA1d1zOFUlyWx9GzQ5hJY3Z7cc5J+qeix3Oifh+gbpekRaSeVbzcLmYRNtDs5OeMgfqaJOaWdJUpAhSjz0yspoHzGt4cYBJO9efz5Q8//q1+1rbAwAzgplHqM9Xf0RFlss/LPCf8g/RWdukvq/bHbsLN2/E1d16wdY0bxSA0A6yQzcn4gCUukvD4T/IHfJ4myqO7Aq7qy1uR7obznc/Ylsq3n/dPXAszz/ydr7wLm++7zq6B/sBoPqazsofodHzHDAiL33xDGtn6dr5c1byfM699FKCu7aTB+DIeMre6uIIfB5K0rbUtA3MQzl3hXsLL49ewHzQwmRGMPMIkiQRru9i92kf5R6QHy6rv8+9IIZBzzUVbyUfBQC9onOQF7gEAKie5i52sASnqAfWCWO4H9/7rjogUn50/wmFfr4Zuic8CN09aGBcvi8Xu7t777+O7t5+AKD3hOzdjsF55ecBQV0l+wjbsivxbltuD4g7Cgjqdre337WdPAhHRnFvPx4+D3tQqhrKKz96WHM59xZeHr2A+cCF+eSNYKi++le3JIYJlooEQdHJ+W+16wAA+mQJgtSTlrGh6s31ptPu0hBR7vHWt3LT09aEh4WkvtqoUZ8vyk5OTAgJT8iu7rG30z3VV1+6JTFaIJIIghLSis5eJwGo5tygvDo93fFqnCDWZhWprzotfm8v3VEaKkqr0gAAIKBvqchdEyRZFhCxJv/kdfMYmlI1FOekRQVJBKLoNTn7Wwg7hq2T78/OzEjOLG3RqM+XSLNzstPSpVUKEgD6FGrcV8AGAKpHqV0k8UUBoK/pGjtAjNQfbpxm55T81RBRxnFi8kJXUbQg/eQAAOg6q/KNnISFpOaWtRqJiOPpktjf9prp9bXpkihZz9RyJ1cBiJpfBlsRWNHrOsvz00JEEt+lkoDY7MJ6NQX6ul/Fvdg6qjqwcYoAjROea2QNtUXZyYkJAUEJ2TU9RMe7uelpa8KjQ1JfbTQ3YaD1rezUaMFSka8oek2OSfVTMFCfGxKUUaWinBH4dN0B0ERT6ZbYMMFSSUjqy/VaynndAXmtKiclQCQRhKfkViutFEINtO7PTk0IEEkEQSlbShr6THe3SUXRhfVt5fkZyYkJIeEp2RVKk0FSRIssd024RCCSBMSm5f/+mrGtmuo0QfpbjTUvp6WmhARFr9nd0KdpK8vJSE6MDojNLpMb65xcRdJUpwnSj7XUvbol1STM8+bwYxTmCqHYSpj62swYGx05YAMUpSEi6fGm0uQgSXK11lYKpluWCcWC8JRs2bQnNqtVJEp1VpoaLRBJgtbuLJc3F4ZLcptMorE4ka8ozOREVJs0aNsF/eB7vwoO2N1mUUBfRYpv7P7rkxWoyxMlayrUdhRkUlNPbVFGVJDRODMK60wdjKY6bcUv322syAgRJRR3A4C+RZYdFWQMAg3tVksARmOIDQm2NQZ9baZkjazheE6CQPRyi22dlPL0BWLJunjOzAyPdJ+UpicEBQQLRNFrMkvPa4wlE8dtPNHiaCiCuWEsxF7V+vZqaVpsdIBIEhCbIa2xG+gsq0iOyrfvyFONxAb6rmppcqwxPqdsKWnWmB1IU/9qWqxEIAqLSi+t105+SNhiAwGJ2WWtk9txT64i9ZSFiHJr5cdy09OSY6NDYrOLW/XT7s012k/+JVvHVJRGpb+rJT/KE4Vl1+vB1pFf+PUbZt215YqiC+sapIkSQWaDzuiYdc3FOWlrYo2epe1+75W01JSo8Og1+WdNjbIjHBvMGl7M+rUb2e5OzrOC0jS9mhYbJhCFRWXub2zdv8bSR+iu2OsU7Atz+0U9mM01QCSxNdd5hWF8bPrxw9io3euPAbG6MnFZXFHbV7fGx24NXj2aFSzZ1XhrfKz39Ui/pOp+M/H1fXGmU+Xe8MWCmD2NN8bHDKPXZat9/VZtlilvGsarEHBfAAAgAElEQVTHhtoKJMs2vDc4lY2h5l2SZXEFzcYqWvYmCUQ7LtwYHzOMtxetEmytHZzOW9tLYr+suqHxMcP4zTNZAr9VSfnvXb0xOvy/nx9JXylI/f1XhvExw+CFnFXi9N+094+OGUa/at4T5xexRzlq28DR9r07KntHWwpW+j63Kuto77BhfGzo4g6/lTsuDt08s2ODrHfMMD5mUFdvzTxubGz/2R2Zu/bKzl6/ZUdoV/dG+Mb85rqpgaMtBasEmWe/NYx/+U6SQLS5Wjk4Zhi/2fveDsmyOFnvmGH8q6PrBWElV8y3f/veekH461enFtu5R7Js83uDY4bxr6pSrQks9MPNu8SizdW9Q2OG8Zv9zXsSVya9ox77YeyabLUg8Z0vp/FpFJqpvTcu7hAtFsfkn+4fN7EkeandMD5m6D+Rvkyc/s7VG6NjtwavvrNZLMqquzE+Zhj/tnaTQLKn3TA+dqO5IHxl0t7OmzMIfIq6rXQ31v/7Dc+tDE7dc+HPQ8O3BttlSQK/zNNDTujO2IrGfLHf6j1tg2OG8W+V72RJlvkaubrVuSd8ZVJR85dD42O3Bttl68WSXY3/OzZqGG/JX+nrl7SneXDMMD52S7k3ZrFREcPK1yP9Vu0403vTMD52Q1m5cYUg/b2vTBwui8w/+5VhfMzQX526TCBKMtY43Pt6nN9qWe/42A9jH+QsE+Q0m1u0LDjz90bz+PZMlsBvx4UhK2F+OzxqK8zrVjpyyIZBuTd8cXDMjsrOwZu3bOVw42yW36odZ9TDP4yNDqnr8iPEmWe/NYx/e2azSUeT9jPaXhThG77rQv/o2P//1ceyzZGixUa2bZxoqLd60on6q1OXRb52ddQwPmZQmsvpr05dFlzQOWzioVcWsyzpHbVt3LAQjw937gl+LqKguf+mYXy4/2JB+OLIvUqTrPxWRGS+3tI/dPPW+Fj/e5v9lm2QKW8axm/2nt2VuFL8XFLln62M4a/Do7bGcPNMlkC0akPRxS+HhoZtbWPsakmE33pzgHLE8GBd5kpB6ust3w6PGka/uvhSpF/Ens5RkxfYc7SxW/3Xv/xGP73q3t8k+a3eZVTckLI6c5U48+xX00Juo9lO7Jf/w5jeriPbGomNnIcu7hAtS9rb+e2t8bEh9YmcVWbFqSsTl4kz37s+ND52S33hxRfEfouNNnDVYgOGoevv7YrzM9nA2J9/E+eXVPnn8bEfrpaELxaE76rrHx0zjI/9+Z0NfqsK2kZt7OdWf4vRfrY1Tu1Tbl3M8lu2q814auvIja9YdNeSv1IgSSp4r/fbodFho2OK1suUQ2OG8eG2l4KfWxm8tar31viYYfBC5kpBzsWbjqLclK5tlvCSVTc0PvbDV8cdRLa5y3nSzr89s1kgeeXTqcHWqIjfXx8aH76hrM5cLfYz0X956AW7nYJ9Yf4wNmox1xujY7bmOvW4l1HBEzcHQ+pJABTDUACU7Zt+qKmtLGSmmUYUADzCUkLYAIB6+XERGo9I52MA4M5bwgWib+pAk5TXXSaFWS+G4igAyhZv2yKm5A3tc1mLpLlJu1N82SiK8SJieKBR9QOArvWcHI3bmSfwRAFQPCxvs7+urU5he6eqlwwI9iHUfSQizNuTzkMBwB1zQ0mlvBtLLK/O5wEAAHfDwTdf8AQAAM94WWXZrvx4b3tC8F2XvIi4dK4bAAAoRXM7LU4IZYHqXK3KI0G6wY8NAJhPSlYC3t9UP22u5e5Bj5A0IBiGAQDmGVpw5rOarbMu/vPjEngoALB5S3BAfNeu9gQAwH14biQxqAMAPK7iw7qKDF82CijbNyHKm1L1Ws9njnS/lV3U6196YLcQAycFbge+W/MiuRiKsgWJUV5A9BNOFkUpL3WM8tOyJGwAYPllZIWZ5ufJlpoGMmDH7lCOOwDKFuRkB9OtH8hJAAAUgBu/yZgUgvKX+yCDKg0F1LW6+kGfjPxEHgYAbP7m7Eg3xZnLpskMbHlCPA4AgC/hYTQrIEnCBgCUK+QAMTjtuQkAFWxMNpoHy0/oBRo14YQwAWAmNlAAAL/k9f5sDLW1PIocBdTNHUMBwJ0bJ/uwpTKeZV/Sqo/kxKJ12ZGeKKD4yvxcsfWChsWJ3HmRFieyDzwyRTjaUtdpnGboq79M8JOiHdob6i+taz1dEIZjAKhndJw/S9+nMj3T07R3QrbYE8NQ0Hdd6kUDN+XwMQDMJ37XRp5p2sBiDLg9YyDx1VujOcbmW4HUaodQLsdzRoYHLp2TIxHbcsVsFADFY3I38YnmWsVMz7Uo7s1lo9OqVp6o7/fPKDAqzp2/YVs01lV3ee7pC3N2ZPfoovoPK3cKWSiAOzcuhg99CjUAaFqbVVjk1hRvdwCUG5m7dpHpBtVHcsLLaAOAea/LjrNTPAIArLC0OOOe2lzhEjbZr9FPsR/xFPuxiymOHPrrdIvuUKCxgA3reCx3FAWjY0Yn+WEAgPoIOUD5rlnLQQGA7e2PA0Ho7zLKTQ0vWgIA8NjZndE5Oc8KkyLSvN0BZfM37I73oI12rTp3Rj23TuEuzPUu8MTtKsBfvztaWbgpppG3XCIMDosPCeM5iI8WIJiniQRFEARhYyZDR1EUYNq+aIN9BM0O9HA3n7tzPXC6U0MA8JzlEcNx82I3giAAFACARqWliWsbl56yphTq9QBW/PM3l/BBV1eqAu8XhabrGpWaBAS5qwVhbnwSv/LwmY7c5atcuuo7IXRPGAaUZlCHePAmc+S8fHDkBDFIwWySdBZYTN72ppzS6KBjQqFAEhoRHSXwnI1/DGOZZI4iKIKxzYv7CIqaJAi0pvWtN85c0xAkDQDUKI1xLLfT2lN52y/rQt9+JdAiN0cCf3oGNhCWB24OhAiKAk1TTuqO1BOjbv+KW67gPlzEOJ9PEDSpyhNesr57EaEH+DEAIGyW5RYURYGkaSAJDemGcyY1hHM84CO1BoALgGAs9uQNCBufNG7U3i5/CItl7uMmWzQpzAGSXjBVmOYWOWTDEwAQnMe1o1TP+O0bm6R5sdEc3+WSsJDoqGA/tn3dU4Reh+C4pXjech7SYPnXrhM5ACssRbxv97kWXUgiu+dCq94/O9JzBnK98rjs3ZZuQk/TAECRNN/8j5X29RodzfK15GGwfHw9kA6AmYwBMbJtr2qSJIHlY1G0fYa7VATgEVwUwAAAAGzcExvVaPUQOENjJjFZtU47oKcVReG+RdZC6tcBPONUSZNFztmRKX3X0f1VrWqjjwJFQyBNAei0esC9LKpmc7ww5GsAoIhBHeJh0TTgHjhir1iENUljZsCu/dyZkTvHugMAxJPrYVOl2TERQBDMzWzFCAJAkXB3Uc5ueJk5stmHAznP2ktMUQSX540hgwBAaQb1yLP2OgVfR2USFnM1YtJc5yP92ownbgQDeFhxTWuuuqujs6X1XHH6warsiuqMmTc3s+sTc8C8bf7Ky286vWGm2AoAQHZ19AKe5G8yA/31jn7AxP5Oj59swI5cF3iw+OyVkWULL3SgYQfFqJ2+wFH75pocPEmP8jZUfhKnUXS2t3a2VOYdqgwueXdvxEwjh9kx0lS8TUZEl71dGYqjALq67KhKy5802a3GQpdD0/5DadX5PLNX2RP4bPvIOLCWWXU3XYpW4sPTqi5Jbax0Zjbu1WRnK8wizLeCnvmRq4utMO+NDUyQf7wxXXXt0z90dDYdzKg4nFBeXeRcH3zXcA9YH4blXWjVx/A+aiHFu0NneBpXl+cUXsC3V5w2Pm4qi8PzJp93nXxS4OU3nd7wzNSvXJhn1eaZ4elw4Jg2VbtFH2yRTRO7YY7l23XkGIfJyFSXLPvFDsFrB+sSuRgA1ZIfLjX9NcU9Ht6G2laOPPU7JcgM9m5Hr3MUjqmO6ZfISyXbZIMOIptdzCDnWUABbcMD6sjHH5Udz5+4VSSgRkgKZXtL4jcXldeckXL6aj7oBgAEAYo2S53SDervVgMePlxEp+m3JL6NaAZ1iAf3noeVXB4HIa6pJlejSB1hb2mK6pUraEwoNs1H6toudNOc+E1hkyGOqM1JKLjk5LIWFpYcjCo/bGr6QM6KWMcHAEC5Xjjdr5oM24N9BM3GOSigKABNWSSnJ2aRIooAUPboKZIcAYwrjEyX7jn6viyGulxrTr67a6gUPRQvbmuo8bGY6uuxygYEhBVddKBMVhI9eiK/vIsEcF7gTsCpolgsFjI6QJibSWm7CSODHjiO6FTqybRjUj8wMyNs3BMbNU4wG8vSqAeB4z2Pr8zPKMx7Y4MiRyiUzRPH/8dO2fETJYH6C2eUdntclM3CaIKwFK/qVd112EQFG+M9uusbGs80U6FJgTOMB3Q93QQiSTMOXwAItcq+kbM82aAnLAnb+j7VoJHuruwKwzDQ661cwB7DOA9HtL2T2ZCEVkO6cTksABR14Gj2weZwWaMaldZygdIRIzMuRjkqf46OPNiuGOWEbk40veDU36WhzRx5GBdkjdBp+401oGwWRusJi29o1RqnbeAu7GceYwLMX5RTKXtnd0YbOJTzrGCzWKDvt8hb0602KcJhp+AQjs11PvGkjWB09dLoxMJalZ4CAFLbpTDNieE8DhCdXQQAAKU69Z7yrmMhFpgcgSmO7WslKACK6HyjshMLTQqb8RkJRRCa0GpIcoZZC3ZoUiB0lsuaBygASt9VkRefXtoy3X1UnV0kUDo9CQBAnC86rOHnH8i1nspjBWaX5IY4+9CGBiZFYVfKZJ3clDgf4yVe3Dpf/YUDJ/tIACD76t66QCxal+wN4IZz3cheo1FSmvpTLbN8eMMN57iRPdPpe8pSYzJknQMkAFA6lVpDu3nibgAIAK3TDupmkpNDsHEWTVzrIgCAvF5XfEKDISShswgQAQBM8nLJOqRBWtKmc1rg86Y7VBAlduuuOdxOUEARXZXH2k02iAYmR7AVh4vr1SMAQPYc352Wkn/WTsLKJJanxHv1VZef15AAoFMcfqeNDkyZcWVkjnAsTGsd3QUbZEtRSvT2Y10EBQAU0dtF0GycZT8O+gb7s/5ce7RtgAKKuFJWeXn2zgRBECAJrX5kmrZ84pO4qsOvtaIxyYKZ5kEwFhul+xQ9IwAU0VYuu0yxQKed3vGw/EOXUB2nalUkANlXt/+EyvSwajEGYmZHtq2Vw/kJpdFaZ6JMZ9gzKskfLr9dqdRRAJS2seJUHycuRYiaHNOOozmCYF28l+Zo6fFuPQCMaBoKN63LqJkhT8JR+b1zdGSMiwOhUmooAFLbWHK4G9xonV4HwA0Uc/TNVTXqEYARTcNvzvab5jt8IySsP9dWNmtIoHQ9xys/msMQwMZ+Oh3aD4oCPajRkCPUVEdWvJnvhO4cwVGUs63cifDCcsoZreFQzrPCJ1SME81V9VoKQNd9rLxeb1IELy55yZC9TmFKe0zCJKkZzHU+8aSNYNjxe/bFQ21OQsBSkSA8u4oMlpUleQK4h25/JZQ8lBodlZiWXe2WvGERAvTdjWLcAwsqCwUDFRsDRJKA9P0aYcHR4hD3GW/hx8fx9e9uDE8pmyHziR1ZcqTAjzicEiQRBKUU9njtPFQwfWCkUSgJWBTD65Rm5m5JL2wR7qk5ssE23wD15PvO5TsJvslrvWhYkhDFMV/hpJfLtmIN2bESgSgh+wyafujAVi4AoJLsXfHI6bTYhDWp28p1cVsDEasns+lAA/9zZwJychq97+7yAh9VaUq4yHdpeHzBZW627MVAFICTmLIcmvJCYwvvImpwUwp28rT7EiWCoIw3tBGvlG+PYV8rTJQ2Wjsu6ru7PMuztbiwnnBS4POnOyz6pdc24p0vJgYJns+rwjbkCBGjCboHFlSWRtLVuaEikSC2sAnbXFG6dsZJPdQvt0IWTVVlxghEkviia5xfl+9zlA97V7AIc0VIlq0wrXV0F2xgYYWybazLhanhy4TigPT9Gt+CilwHi7yoeHfZJm53cfwKyer/8z6ekSWcddWKLU4IxDpejYve3jA1L5UbuY4PNJ60jm/3TkulITtfjkDrt4WKwqLyP/LM3luStkRfl7GmYqr6uclFr4TSVenhgqCNZargnHgP8xDGZAypocEz2NUU8EKWY6rLNt/im84wO27fwe24oviF0GDB89lVZLDs0C4/FIyOac/RHMInr6IiGbuQnyJYKgnNPElFySoypvVGVkJxUP6SOToyKyYvP4w8nBwkCUgtlvO3VxTG8bQHUzJPanhZspfFuuqMwKWS+CJlwObVONBAA6CCF8u381SlyUGS0E0HifisMJbTy9dW9hOVf86R/aDCpASOdt8LMRmV6imOXNTrlO4cwFGUs4Ez4YW79kUHkW3ucp6Va37WPqkvUbFRKArbUkkmZlsehTlpvymz1ynYwCLMzN+pLeYaHySxNdf5xALD+Nj0q4/mDggMsavrcG1mzGvk9vrTm+3N1VOapsPne/q7dRH/szf8WWdLpq4Upuwa39VUNss4zFmeFaUhOdqcDyvXsR8p0THEjyMxRQGKGomHz2+JPcw91FQ021diHZSsLk/M7k6rO5rCcoLYuZJN3AEAXC+JztBmXTqylu2IeJaSv3wzOUsef+JMBmdmhu+VZ+eJqbbcoEIoaz8QOt8lPzhiKw3pzm6JPcx584M9Kx5xnh82sZXMqFZp6G4o+UwWhj6iPD9pczBPOEhlSzfgwuX2Uw0052rJpPy05bSi0+l9kChNU+neNtbWbKeGL84UOKDRkoBhd/ngwoCBBeryxKCo/AYNCUANtlSe6sbEYTMn5TsCRbTLXq2DuJ3zN1M10iQNCNpWrtBTACOqk2+3jvqEiu/hg7reW6URZM3+88ZpmPvA8FxBaXsJ2s39MXZka/shjPYTsuRhM/WIgziZFhSTXaMeAaB0ykPVSgiM4M/3xMk8YsEPY6MPmwcGToFse23Tf3+sHaUR1rOc4J1H/m/w1NiiG9SxPbC23c+fXPn+Oy/MHkypy/mhBR3Y4viXXns5xGNWcmeg+O/VWQ2094ayI/+1/DEOfQweDVCqD/b+z5FW9Y1RcPPwXrXlpZ0pvLmblbLs+V+dp7yfl75eGD9T6uFcoZe/ue9AwxW1nkZYi4RxW1/+dfC9JfST3b/dvkv9wuH/VGfdF4bnAOrS7lUvX8EEWw8e2MR7hDuwmTE/9vN3BqLtjaI3P+jpHwW3n3AEqdKXNgnnc6eLeQazivSkEV+XpRRC0fv5//4Y8cwQM8QMMUPMEDPEcyVmVpGeMOhVKr2PcIakPAYMGDBgwOBJADOCebJA9bSrvP0dfiaRAQMGDBgweELAjGCeLKiuqPAl/o/wsiUDBgwYMGAwL2BGME8GyHaZtEyu76pXsqPsbX7GgAEDBgwYPFl48vZF+vsEqSO0XTWlOu72fZPfk2DAgAEDBgyeWDAjmCcDeGJ5XeLDZoLBowJN2/Gaj7pxcRhbL1dAYIAH2dNJxe9Jv7vtPxkwYMDgkQSzisSAwZOGEeBwMT3Gj4iJ8qJ0CD860p+l19z9FnUMGDBg8CiCGcEwYPCkwZ2LaFQeEl8Ueq6QQoEnaFsUuISlnbpVEAMGDBg8zmBWkRgweKyhbaw49Unfbb8YHq3r7+uhw6QFMax+DTs4AYUBFcUL9AboGUFB00MKmRxvBgwYPEFgRjAMGDzGoOSXidAkb3muHH5ZmbFWU52WXd0TUyguKgYAcE/bkw8A4Jtffnf7CTFgwIDBowtmFYkBg8cYKD8pBVcriSUJoTgA6LR6kmR2OmPAgMHfBZgRDAMGjzMwDFV1qjjL+BgAqNu7aX4gs6cEAwYM/i7AjGAY/N2D0p6vbtDMStV9tqqVeBD8zBGaDjVwOJ4AVHdDCxq3LYoFAEApy0sadA+bNwYMGDC4f1jwwxgz58zg7wNkb/V/H+oYpVHvzFf/a6V564XB+v96RbGmrDiENdv9g/X/9ZrqP8qkAuw+MzonDNb8clM9tkrojdG015rNL/CZPSUYMGDw9wFXu7taP5r7aDtPPKI4ua+mcwRQmgReWn5OKI46Jn5EeGaI7zPx9+3lu3+/cPPWBQffOHv+i52BYSgAgKam5Og//WfN8z91tSG2W/K/JL2yNjdz70dHZDHsWYnnhWcniMkvlP3eyXWvbHjWiljTVlv/UTdvV0m0nWHZw+f5ESSmtI0HDl4gAKFImh2xTbrWz94w9dHimSFmiP/uiZ/AVSRKsT9tdyc/V3agXFZZupqQbStsJQGovoq0kMyTGuph83e/0V0aIsquu7v1A9X+KFHG8Ye8VNImFUlyW+dwg6Y6TZB6bJZlIEpZ2zrEFQp4AXEbC7MCjUNaXXN5NZ24RezuZE3s4K2B2kNHex4dIxrp7uxmeU+ZdxkBDo9NAub2kJiyi7Zck1r15zMlISVKcFJxDwLE+fzsQ9T6feWyA4cqdnI+yMt5FLiaNwzUZAgS3+qb/oeiNESUXTsPa41z9lnnQJ7PkQQUdd7t7feJqwcGh83XVKTM7DgONT4nTJpHm1QkyW8DeIR81oQnbwRD1FacI/hJCVwUAIAdsjEUmmSHrwPqk7d3K3VYWql2vvvRVKf5LhW98Fv1feP2/mKku+F896yfYtW2vnf5yf/WWc+VbvInPJ63JKNgd7y3cQAzcOmUgpeUMIevpKB+yXFo/eGWR+T7tkRbVSsaJiTPXLSxancu3SLHo3H9vfVN5PkcyfOvX7s3Fi0Q5B95O184T4XNCLLnAyfMfhKU/PAbHazENIE7AADqk5LkozpcVq+/X/w9GBCdtU2zxTrepooju8IezrIj1dd0tt2egY50N9T3PCIOdvdwLvbeJfCUvdXFEfh9Kt2Ch2kezuKJG8HorrWoaDbOsiwbsXEWEJ0tKgDgrMuLJM/sv+DkHAPVc/zMYGDUSl3z6fZH56F7DiDlR/efUMwWiFUNB3738aMzpr5PGFCp9Yg332ZjIKKlSc0NXD43D+Uu98d6G+WPRoTFQ/ILC4oK97y8xttmnZTSk5gbSdD3lrCDuKOAoPM1kYNx+b7cB5FBRMp//8bsZm+FvtZOPbBYFjvAWGyU7mpVPpZOb8aA/HBZ/WwjGAz343s/pB6q94TsXbmdUEzKj+6vUT7mw0cnY+/dAsW9/XhTUyPmHw/TPJzFEzeCIdQEDQgyqVwUQwAGNQQFAKhw/Tq893id1pmSRjpONZHiddINofBpbatVj6XrLM9PCxFJfJdKAmKzC+2FCUrTUJyZEiIS+S6VhKRKj9sbjGuq01b88t3GiowQUUJxNwBQA637s1MTAkQSQVDKlpKGPlO5VF/9q1sSw1YIxYKg6OT8t4wPLn2yBEHqScvcSV9FivUpgL42M+bF1lHVgY2C2NIuR41UlEalv6sd/ThPFJZtfuikNWcL06MFIpEgPKPY8vYN2XO8KHtNeNiKgIiQVGmV3J5zOpKMTnl8d0ZUkMRXFJ2cf6zL9OCl76qWJseGCZaKBEEpW0qa7S3w6durpWmx0QEiSUBshrSmZ8R0nWj9bU5UkEQQFJ28++z1GQPFQP2rm/5jfVplL9DX3khNS8s/ed1YEdXbpXLj8myeZHTy/dt/lZmcWdqiUZ8vkWbnZKelS6sU1urz5vPobsWjPS2HiovKdsQEcu4txqEI5oaxEIBZbb6nLFaypc6kBl1dtu/S6GKF6b/rsgRBZoNuchVpdlCqs9LUaIFIEpCYWy5vLgyX5F8y6ayvvnRLYrRAJBEEJaQVnb0+1bH0tZkxL122MntdZ1V+WlSQRCAKC0nNLbPzNhmpIYYAQVHEcsUNQYAmBu2Q9pySpicEiCQCUfSazNLzJpNtk4qiC+vbyvMzkhMTQsJTsiuUI9PuBQBK1VCcY2Qmek3O/haCAiCOp0tCijon5UmcTBNFFyoohwFBUfp8wO7jTaXJQZLkt2tygyTZVtNFI03SgCBp1dtp8Xt76Y7SUFFatdb4D000lW6JDRMslYSkvmzifHKZQH8+U7JG1lz/+s601JSo8Og1+SfN8UffIsuOCjIKvKF9huUJXVt5TkqASCQIT8k1uSpxPF0SJeuZ1I7xlGqTBm27oB88kSkJ2N1mZUumqKV+a7MlaiGgb6nIXRMk8RWFrck/adb4pHBWhKy3ipYOQPbUFmVEBUmWCYMDYjMK68wGrCgNEUlNwqzWAlCaplfTYsMEorCozP1NbW+ssayqmwOgQBRmEwDNrrFMGGx2Dadi70h9riC89LrpTFkcLvLNPGsKjWRDtqlTAAT0rW/unNJ8m1Uk2+iqmJzWsqfxSfSUxUoyz87os3NZZJzis0VRwblNFAAARbTIcteESwQiSUBsWm61cn5fkHziRjAkOSWmIQAANE3SAADAEQpZhKLTiVkYfVPNZSQ0KZAtTo50k9c0mAcHVIvs5ToyrvKT9p7PG+uknD7ZqyemzmCoD+WXtmCbj35ytecPF0qExBv5+6fP4iAoCtr3L9BZNZ+c2M0HSlGeUaTEsyuarrZ3vF/AV+3PLmobAQDNqcKSXq70xKeKzo73ZQlUQ6GszYmnQ9a6I9UZHISXe0L5YYG/IyphQX3xSgR5vuJqS2U8CwCA1tbW9IcV13V8dl4WSNYVHW6nAICozc+rIiNKTrf8oePc0TSkNj+3amqr7UimRgsA2uMF0ip69b73G+UfymLIY9kFZwcARppK8yoJ/+K6js+vtr67Hmst3nN2cEqJfRW5efVISnldx9X2ptIIsjrvxXoCAHT1xQVn6XUHG5WfXaiM76+r76cdC8Izfs+775Wn44AEFNR/WFNTvsHP2LFr1Rpgca1TXSll1RlW7oFMH9W5vMy3yJSSykOVb6fBofzixkmrQnEWi9QOOumHI/K3snNyjcf2X++0/LY+pHWP6HjIP/tAaZyHEzbvHSZ0UymM6UFkV4eaw0G75cZGaRUKvU/oXCa6KGVZflk3Z1f9Z+2thzbA0YMtegAUBYCR1uLsEqVnXnWHyUfKtxU1289ut4QAACAASURBVCqCte5I9RYvi9lrq7ZLq8i4fe+3K69eqExGG3fnlaum1DdqDBk2oz0UgNRPHYXoGgp+/TbBL6j/rF35WXUO3vna9vIuCgBQQIcaa674vVx95vyFS+XigaOlVVNrAdA1S3P2a3i7qj9uV35WnY93SjPLr1N4TPwSsrVZYXZpTVNDHzskRYg6DAgIgtC9tZc8dr/fWJORvC7UrauuzRydSPklJQSs3ritpiLeDQkoaL1ak8EBAKD1zVWK5UWnGzs+rkiAy6/JPrJtHQIIEPWnVFGv1Zyuu3S+wKf74GtnCAAYqHtZWkdHH2xUfnbiFWHnG5VaGsXsjYxpxdEP3DMqmj775Eyet0omfUPhOEqhIbLT+XzEY+OR9o6yEKvSTFHLe8cxS9Qi5Scb8ayjH38iP57FVhzcV08A2ETLT8+8OCkc+6C6KqSvKbx2n278o6K5Ltera6/0jW5juxGU7jEJM40DmlPSostYWmXr1caaXI+Lb35AAIIiYB0AlVcvWAXASdf4o6LB7BpOxV53YbAP2aMw+pGqsxv14miudJEAAJSisxtbHsYzNf8Snjml+VaYGl23v/y+0Rhm07h3mNBNpey9Tz7bavJZ6vqBbdImdOuhRuXV9vrSSPJonrRuPhMtn7gRzDRM6du4vl6g7Z190UTTUNvNikkWoAD8tS9wVedqTSGJHiFpQDAMAwDMM7TgzGc1W6cmUnjnHL9QXxrHxQBQliRejJNqlT2t0bR3QrbYE8NQIFtqGsiAHbtDOe4AKFuQkx1Mt34gJwFIPQmAYhgKgLJ90w81tdn4/LwDCczYFcbFUBQPixewqH6NHkB17ng3Z6t0rR8bADBu/PaNvP7z9VP6XTuSyeAAqBpqu1kJ2Wv92Jg723dr8d5Xkr1RAPfoovoPK3cKWSiAOzcuhg8q5ZQClSfq+/0zChJ5GAC48zdsi8a66i4PANne1Avi9I18DABlB27fGoDAzKDUfRrAed42GbvkKAlGbs1Q9ZIBwbxBdR+JCPP2pPNQAHDH3FBSKe+epHLHEaNSzIV3Fidm1zrwSvfAHZWHDhiPg2++YfltfchSHtFv0KG4N5eNOmHzKD9UAD1XVABA9cq7OYlpy3U9PToA0PW2a7zCAuayZK/6SE4sWpcd6YkCiovzc8VmFZHyusukMOvFUBwFQNnibVvElLyhfYYFPdW5WpVHgnSD0W59UrIS8P6m+h67tJTDExMGLp3rQJ/flitmowAoHpO7iU801yqMQxjgxm8yZgyg/OU+yKBq2oyirvWcHI3bmSfwRAFQPCxvs7+urU4B7NA4f+ryRdOalbblUj8eleQ3Q0BAAQD8ktf7szEURSXJkWzVuSZjRCMvX1Ag0Slie/HBd2teJBdDUbYgMcoLCK0dg/VNyjZ+KQATBPJAo+oH0Hdd6kUDN+XwMQDMJ37XRp7DhwVWaNZWIe6OYtz4rHW8oZamXkeUcwLNTdqd4stGUXdeZIyJqynCWT4pHPtA/aV1racLwnAMAPWMjvNn6ftUeoApwgRNa7MKi9ya5u0OKJu/4f+s8aCNzXUYAJ3pDhwAF4Rx+9t79AAwoLimE65PxNVyFQBAn7wX+MH+qKn5/2ftEtvmW2FadH05aZFZ+zNr3OSzfXA/fZa6Vlc/6JORb4zhbP7mnCg3xZn5TLt84vZFwtCpS+0UACAIZurk3DEWSun1JMCPZyiF6qo5p+EmyfgAAMCJSOBVVdV05hSLUcBi8rY35ZRGBx0TCgWS0IjoKIHntIBBqhrKKhu6NXqSBgCapD1G7Dk+wvLATezqCYImVXnCS9b/LyJ0APz1u6OVhZtiGr2XSfxDwuJDwnizfrnkHoDgXIvpYqbVOIroJ+jefbGifTaEBIB112tHMs+4AEX0E+DhYykTFycaf1P6rqP7q1rVhHF6jKJBTFPWj8I67YCeVhSF+xZZVcLq18GghqBZYg8zJYrjLEQ7Y6O0f+qjES7fy+YiRdmuNwLwN5fw4cbpKyrwflFoErJGpSankAECFDnZQaFL1hUXcO9PWp3vUtF9KXdG9Hx+1fbC7DaPCsV83UmFFpZPdF7HlqSEencduNxFrg3r6VSxBTvnsqMkReh1CI5b5MlbzkMa7gAADPYRNDvQwzIMded64HSnhgDg2SsIgNIM6hAPq3VCLx8cOUEMUuBrxb7btCkFGgCm6hyAUBHgEc61yrDzxEY1Wj0EAgDCZlm8EkVRIGl6SnTVqLQ0cW3j0lPWF4V6PbCDEwL3Fzf8kVoViGouN2q8Eku9AbQOAwIAIB48Cx/8pHXcc7VnerZKfXWtzV2syBqhnQGMVagBBEWBpqcP0lA2yyZ4UgCg1+holq8l5YLl4+uBdEwvHgAQT1+Lf3ngLIQk9BR42CWdEzAcN08GIAhi4sqhcBwlWumVx2XvtnQTOopesAAokuZPMo5bhKnT6gH3stgL13sRhtyAGQOgxTUEy5cFhUfZ7Q4cgCMUsqrkPVS8oFuu9YkOEWKnzsvVIEQUPXp+mgB12PxJTI+u8T+dcAUYcELjqFDM159UaMCPduCzTqfx2PVZAACS0JBuOGfSA3EuDpfUGgBPZ8ueBU/cCAZfhAMQVv0LRdMAHtw5pT2RnccvDdLk4WTRYdMVmqa151pIcQwGKG9D5SdxGkVne2tnS2Xeocrgknf3xljPuBFnpTnH6DRZzUEBGwXQHEtObbBfkW2UxNOqLkmn78CHhxXXtOaqr3wmv/zpueL0g1XZFdUZD3yjPmTla58cSMRmend/umRerS6OAAA7z7RUlyz7xQ7BawfrErkYANWSHy69Pb1It+iDLbLAKRfVLXPkndSqCfBK5E3pdVHE6NY2UY9UdPwJ8CR/k9Ppr3f0Ayb2t+4jSRpQ61iP+fDvV4bqtMGEfdy/ry8YMbvNY8sDeaWf9OhXf99L8rN82F6BnLfkKoot70UCivzmVNlcMMPqodPkmCfnJ6AgKdoyfKZpGhCu9/wPSnn5Tac3TI/dgfECeOWDLiqQXd+g4SVFmwd89gPC1PUpTnTykkOVH3Tl4gNN17jxu3zs1z3bPOU9w4kKqHlMjrYIxwl7VpfnFF7At1ec3rD46QlX18+Lw/PsTsNTQNu0A7U6MQfAKbC4xqefdLTZdQ3H8AldjhRd6SPRFhUnsJDlw/Imj/YM6KBdsyQmAANw9nUBB1KdTSHY8gDv0rYefTR5H332fpvdE7eKxBaE8UCnH7QoldAQgAvCzD3QCKmnUIw1Y48z0HRKDitfeb+2/nxt/fna98+cqn+/KBQ6TzQRAECR5AhgXGFkunTP0fdlMdTl2labwSqlutINSzZmC9goAMCISqmZPdB64DiiU6knF/VJ/YA5Z22EpFC2d+CaTUXlNWeknL6aD7oBAEGMozMjjY7QzzGazwEo7oXT/d2qSU8ZIfR28penSebMZb3xXpUlYBCdx6ub+6jBdsUoJ3RzountlP6u6TJic7isUY1KO1m+jhihAIDlyUb0hEXFpEY7OHPbNb39NObNm9IjsTzY09OmqN4OJY0JxaZORNd2oZvmxG8KszIYHUkCZnpu11w6VFaUm+s4N3xEvj87M3tLZvaWzOzMX+VsMf+2PnJrHtE8GAtmtXkAXBLqpeq8Ipdr+QFLUMD5fPR660ftPaR/4JI51YWyWRhNEJYpb1WvyqRdDx8uotP0W5bzRzSDOsRjhtkvlGtre8ZZHHxqgjM/9P+x9/1xTV3n/4+FV+7n03H9dku+6wif1eTzWQmdBtSEaCAIgfLTGCgS0EVkIqwRLQj7pNCJOBE6MK00tFKcgkWktqBWkBbEDrAV6Qq4CWwlsTZhlotzCePLRdMbQv3+kRBCSAJarWjzfuUPEp5zznOe5/0899xzzr2HhYJWZW5Rgw3hJG8+y+otQVQGlaT+2/TqEKZW4W502nwnROkMGgm7rJjmG67BTF8W+8X6I5ebL/U1tQ17C8M8ABwmBGt4RMT66tvrz7XU93nGR9Dmqc/8QPaggBbDpjqtHVDYizU9hpn3sQ1jWj1KdUeMWyEIcwntfcpSd2EcAABNXy9G4omNi4kAmFJhRw0KmQzaQXO1qr6rRkEHCdAcGuLf7rYTGnaBMAO98b7utgu96EpfKiDeXC/FZx2XPlPQub7zGwPNzq4175yfY1PzNKh+QUsUHZ0PMGYpVA903GL9ilApMKB53s2c7Bx47EYwQItOX0vpPl1vdKqmvbYN+Omp5hGlqm8QaMuMFlQ1HMiv7Jy1/0tZW3MZ5W+MplM9qFQPKpVKdfegC7aGk3trTg9AX3FCZLKscwgHAEKjUKr0bh7UGU+cImR3in6wo1sLQGi6q3IbtBTAtRrHtEL840Ip3YfzG5RjAID3VWeLRZmnhgA0DdKImNxahZYAAFzd1W2a56QyaIB1dmEAAITivePds2OSBKDXqIc1OEEAEIpT+QWnrtiYO0ZAP6xS4WMOFGTEJrK19bKDFzXGRySKkmOSi6136tmwDNXdDRiCeKa2vrTqigYfw/qqC/a+cQlHEZROBUzRoyIAcHVTweFecNNrrd5fwooXLlEdLaru1QLAmKoxd3N8co0SgOwfvgw6q8u6tQQQQ20Hj/eCQ2gVyhvAWGZ9b0pdQoVhldV2AEVn9zgQGuM2F+xM3mGVd2ZpuuWiAz6EjVMYSygAoGk5q31+E1Pf2z1sz3iL/bPKj5QfPVJ+9Ej5kUNlR6f+tvyUih3vg1G3VlZVVFZVVFaVyN+y9Tn1wF48YcTcnAcAOpuF9lVX99F8vVEA8GIv03ZUtWKsYFuLGo7ADPQlX6092j5EAIF1FpdfmOoc6h8XinZX7W/DCAAC63yjvBPlxwZb341Y0N7EvRMDOADgA3Vv1WPPxsdZWxvxT93G1jbXGVMBMdDwoYKxYWe49dDEIzyWDZ+8Xd6jIQAIdZP8vQGaQDTv3lH4sf7QWSJrGSIACG2XPEOYWGR6sRCych0XLlYebNWujOaTTUrZSQg2gAZu8oMm2cFeZmzw1HgOIZH0mFqF499t3oPsy19GXHqvVoED4AN1B44rbN9UEwCqhsNnVDgAMdR2uFbhHhzhCeBGpbvhff0qAgAIVcN7reYIJ5FIgA+ptWPW+pEA9Fr1DY0jxa2M0+/IOGB6PH6gu28MgMAulMguEGTQqG2MM7z4XCrWUtGgJgA0vVWlZ7UkY3ftJkB7oTEj96qaD+RXdtrY+4+wgpnDZyo7CW8WHQDQZb7UvurKPrIfd77X+FnZtbRz3OZGa5ugs1aifVUPMmZXioRLBipLzqhwANB0H367Te8vCrtfS0jwOI5gYLH/nsr8ZRcLkyWZ0vS8DynSctn0u9XV3d1aKptrDPOhjsa6c2rrm/Du0/XqJdFi691wPuJYBtZY2+2ZXZLjpSgShXCYy0OEORfoEtnL/jNlvZN2i927MiNZnOgtNZCYX7jND5oyo3M7HOWSxf455UVh+sp0PofDisptRpPkRes9ACjCPfuFUJsWvYbNZYVIKvBAWXGsB8Bi/vbdfLwsISI8RiypdIsXe5JAP3MUQ4sRrYTmDH5UbisOoLpQf/LC7JkOhB0rXDK4/4XI5HIHMwHU+JK3d9L6970QssovTCzHfPPl2dYsZ862jNQPAaAllsi2oi0ZUSH+MdJaRCAvWu8B5MiMzGD8cFwAzy8hv8N7uzxX4Kl+W5RywnJ21ytDLo9D6zNFrOU8fsoJIlwmT/YEAA9R3l4BNGdGsjnRGc3PbhV7kiw3plhD3acGKmPWiw0QJs9bP2AxxwMAqu6eYXg2ktEpTUnfkpjbyt5Tc2QjfUZH1b1qEoPtCQCAcresR1sb1L4RKx/k3moyijWW1SjpwqTMjB3mT1pybAyfRYfB1pMlr7VYP8Y1B1Tt1QW7pJWNTQ1VuXlVTc0ttbK91bMfnzHBhmetOQ8ADC5bP6gmrzQuwCFMrjc2iDECfe92hQ3hZhdvpvfmC1fxwjNPU5NT2VMXzcX+OeW5rCH5Jj8Ozy/xgIqdczQ/aNb7lGnr1q+Yor2Re42SKB6LEy05iSSWldraaElLLCnfqq/alpKenplbpg6VH9zhM9ujFEHRm9uo3fnCAB7reUkFHigry7IhZg+UsIIjOT7YYVEAjxUgyu1bsrMsZ2r4hfivWwN9l7VsgfkFYvYSgk2T+YqCKDjJXxRoJrm3UOCtPbYpRPTad9tQS4/L283XVySGsAI2FSsC04TuNoYwhB7ALTg5UFG4KYgTIixQM6QFO9kIAMKTZEWTToijol/41fYSjWCrP8k0JUPhRvujHXmREdsbZ448aDGildCSacpadmBpnFXrdjs0DgAStHNXKNKwjc8JXvu/H3tICgvEy7R1yevks/Z0e6fulzIx+SY2J3hLOS78zZop8k4nQBYnxCIBTofGCnaYRWjMyL1Dlxrrzilt9Qb19aep1Vpvv2UIAACNzUbUasSXP/+t/dbZ9UDhC3cxPvBc7Us80JhFfNLlsgiiIiWSxeEJ8y7T0+X7hfdzH+ciw4Ru9q8L8wSE7y5M9BYJU9Rbz5TH/vSR0fn+CWPVKQc9DhYGz8q5C1jn+yGMnfhV1GGPg02yWRfdoTqJqCG0rtqc+7S1KZH7xrY11G6xew+keGtd2nDmRyYzGr48uuHFf+z8KMcXEGSui9m9d5BQlmxOriPn1JUJbKQnTfvv9g2lysXzvG8zGCZvX7/e21DU6i/PY3ZKM4d3lm3UV6ZXe5fmzXpn7kPyIEHAlDk1p7ZEHaa9+eGeVQ+bSAtYeKxZGlFKln+Q4/sgotvCG1cKIpLVqeeOrKcsYGt8J2GLzt76+H9Df7eo4FPZ7Jx5dzXjjenZRF7Zesp8hO9B5wUhPCNmfx11+L/Lmmfnk/uuxmM4B2Mf6lpZCyrOin7gb2NekFCdbyVxvR/4exwXDghVW1VxZaeq97LCbXWkrZ57CFMjtO/Vmuce8J7WXnBnrbQ/FCAu1pwHYZI5o6naP8b5Aq9Lh2vV91n7GUA8M4syGX1FL1faessqJUj6m2X2tvPZxGI6SaVw5zER6PsMZ7M8QN3aTeWR1QvjcAllSUxAeGajCgcgsNby93pRbtDdrcv/sDCmOJUr6/GWbJ49fLkPlTdL/QK2lXRrCYAxxYm328a9+NwF/p7Wewd2QhwQKalRjgEQmp5D71wG/9DvnjM1bS04m/XYGg1gdsz2oauDv5enTRZ9oxv/Ptp5+CAUb27f3v/84dIN9B/QVfyHjM/ygjLPURNepJ0/Sy5+77fLbLpdczY7tf35w6+HIu37Nv/+Y/W4nkT+GS1w55HfBdqYScU+SHmpf8s7u/3NryhpL85pAcay0C2/Wvmg35ivObd7w96r4W8elrLuqil185vvtyuBGeZJaAeVfUTQb7MjyJ8V/oFI/30g/u6+k6zd6Yz+0t9+6Ba0VrRu2ffx3v+5QCg+LPzDkTbljXFwc/dcs+WVnSLGQtBrAUJb92Lsq30/YW3cXfTSXZ6PMe8mOt7cX9r4mVKrJ5GfZQu27nop8DG+B8Ta38h788O+wXFw+wmNlSB9ZTP7sR563C88rJj9Ya0iOYV/SMLai7JdbysAJQt+mxf57I/sCeNdMmk1I69USJ2jZkJZsf3AWLo80+Km7PvtIN5VkCxp85S9X2h13JqDmomOquMoFwrTu8SV5UKqqlL84tcvt8z7YclHx91OYaewU/gHJ/zYvQ/GCSdMIPOk5TwAADAYJu2Lob7SQqKhbwiojnfAEQolOV229WGuw6G+0sI0RXJuYUtDSdg87wwR71gRceFljBnNpwKARq3Fv/mBTLs64YQTjzmcIxgnnCDzhEFzCiHegpgHr8pcSngGRwQOUe9mTR1Fkd7OAdrK3SgAKC/26r2Tnn1g+jnhhBNOfH/4Qe3kdcKJRxuajreq0dQ8vuPHEfsq8ma8G0N1SQl0mgcA0dvYigheDCPbk3TCCSeceITgnINxwolHA4TiRJkicKfxrGEr4FrNj386NTHD3Jpv+RgA1tWrpaAtxfJOQr+k4OD6pYh5Tc1K0gknnHDiUYJzBOOEE48CsJY3GtzTpMxZL3ADINQ1fzi7fP9LFABC0d7UcaEDTZWJpp4Xwfu71J7xH+yJnxrgGAwANiWdcMIJJx4pOFeRnHBiwQPvqajB49ODZm1/IYZ6G/NTJDVua3wAAAiM5BlM12vw6Vcvj/V29pI9va1L2pB0wgknnHi04JyDccKJBQ7sTPauajW5qfu0xY96Atdi2LgeAMD9V1nGN74hdDr1ykmtVzhtqmh7RRsSzMZrG5TZQk+Lx6hmSTrhhBNOPGpwjmCccGKBgxpT1uz4MSiLx8WxXhXZd+okdqAGZeYG2Sk0U9IJJ5xw4lGDcxXJCSceExAa7Rje34XMfXbE/CWdcMIJJxYsnHMwTjjxeACrz8u9SF0WLNk+19tihuvz8uYn6YQTTjixcOEcwTjhxOMBanxZZfy8JN3nLemEE044sXDhXEVywgknnHDCCScePThHME444YQTTjjhxKOHRd/onMe8WYDAcQT9Pg4Fd8IJJxYkCMUHew6c1wBQY3fnh7s/bHWccMIJu1hkmNDN/nVhnqP9IIWJMc1w76XTx8svUPLrC9gPSw2n8GMlrGneu0U2GFNWuZXxMNVwCt+NcF9xzLYB4Xb0aEkbI7vtyHqKI+EHp4ZT2CnsFJ5b2LmKBAB4a962jMKq1ubODoz43lpVyUWrfnVMBQAAhOKEJIrH5IgrFN9b+/OFqlLMSqhSPWw1vl/gZ9J4fnmd37UWrRZhrPR+4G/tb8/0C0xvu7913h8LLCRoWwvEfhyOX3a7oyDv/rBJ7e7tvYwXHrs7Pew7Pqv1WMdOe85dss6+NdrTObz0NgDQnknhBRX0AIBKLrIlbJZ04hGChVvvd0Q8hs8ijfU2tkJgjPf814LQ4PzKYACiOb3+Ej7vUtqLlW9VNHQqsBFcT0LJ7t78Ddsy1i/9z/mWp4oKDz//pPHq1lVzuAPdUPd+qtdjtYKlbnv3q19uDvZ42HrME0bmCH755P2qkC4uPSk2/omfSYt842cl7Xm+96tyC7DSDx10/cX9qAnrrO0lR0d4LvjXxBADzY0a9nre/IcYWEtFg5ad3ySLIDvonaq3T0ui+TCZwWznmZffG1iZR94G+oyfqKLCygg3Y3q0SOk2JB9vjCn6Rv/rl888khfqTmmAlMj/Uyn/Abbx+M3B4B1HDxzv1j7oZq7IJBk1w94ZpXV/+lPHp/U1xbGkSyXbshuxedeAUD29Ge4IAAChx/Uk2jIvdMFfOO4KisbSP3786NyAPlDmkBYjQELcHkzlKJ25jH4/xr5DHYeLG5Tf3zzkvaP/uOxYx/yDDQBw7RiQfRiOhi8A+EDfINCX0R+vQFzwQOneTCsCI1RPHwYVAZgZmDYkH2/g3YfLOx+FiLQBEkoiLSY92Fh6zEYw2tqUyJfbxhWlm1hRRV0AQGCtsvR1ITwWh+cXJU6v7NHcn4aw7u5hlL89k+/pgaKLUTKdvVFWUrBTuIRk/L+msyJTHB7AY3GCgxLSi9ts5NqpVSSsNiVS2qbXn8tlccQlFqtIA3IRM+rAlekflCUxvHVyJQCM9Z6QJkb7cXgsTsS6lKIzKgIAAG+RcIKlHVPiREu65VczNJ0lmeIgDo+5nOcXJck1X7Hwvuo8ybqQYBYnOChBWtFh41pOKBoLX9ocHsBjcSLWpR1oNS+6aXqqs5PDA3hMTkRcZlWXBqC7KDzxmHr84wxOsKTBuipC1ZifIgricJjLeUEJ0upe49SX9kwKb52ssTZPEhcT7RcQLanpG+qoSk8UrwuJCErY2zRlxbHeEzm/fsG6+9Au5UTkNrSXZCbHxUQHhYgk8p4xUwltq0wSHsBjBUSL8xov1iSzYt4amKHRNHNWrSvuAgAAEmhb5enrAnhMTvC6zBNXTNNzxFDbAUlCtB+HxwoQpbz64YCt9KLpeCs9TSJO2XvGNIJDSKgbSiY5sr8ZeIuEE5xzyWwsCz/aLmteRTIasOVMQbo4QRQeErEu88SUeoSqea84KpjFCY568Y2mtgPrOMnVM1k5UCkWFvbrLxXxOeIKlckCbW/unGUBO/QDQnF235aYYNZyDisgIi7zrYsaGxbbUtBoy2LEQMNeB2UD/AKnyxLt0oBt9drh4yk8G0tCBNb2+k7rkO8uCko8ptZffSOB55fZYstjeGuBJC5m074OPaiqJDHJEnnnmLVIS2ZQoKRhepp2rCGdFSBtwgHwvtq85PAAo1+Sc+tm+bRjrx8n/Yy5aPfeoOmv2ouV0s3r1vpxeH5RydKaPlO7c/IE7LdrUTZgXZqtstraRF54QWNttiQuQRQeEhGXfcroF1WlmJVY1SRPDuJE5/caXVO0JSaCxTGGz6krlvPUmvaSNJEfh8MKEaWbNXdkDe1A3a64EB6TExyeUjQV0TbWhqZWkaxSuqWkLW4AAJhyPnM5hxUiksjah2bbbaYpuiqlcVFG7om2FLSopkLGDp8tQCirsyXiBLG0To1jF4qzpdLM5LjE9OIOLYG1l2Snp6clr4tJzm++q7H2DHiEh+FnP5qrC4Sq40RuiiiIE/z8+pR0WcvAtI+IoY4qaaJ4XYwoLiE9v1k912gIq07kBWVbDJqwU2JORG4HYZcJtq47OZcAAEVQlPSgh5uGCd3szze6cZu/PwrCV2RrWTGHvjBM6AwToz2vhvms2XGy/6ZhQnejpzxxNSvx3Wv2ar51NtVnaWBO53zUGG3PCnwudMe7PV/fsiH8xaFYFiepsmdYZ5i42f/uDt4Kgazfutqrrwl8Xii7OqEzTIye3cHyyWqybmWwMmFFYE7nqKnmv+6PXBF7SKkzDNelrGYlvNp6Y1xnGL929pUwn9A9neM6w0h9ygpuZvuUGuP1aVNfLTVvyeJykir7R3SGiZuDLXtiVseWfTFumLj2bhKXt+O4Ueerp7JCjG1NkpwRdQAAIABJREFU6K4eivWJLb86oTMM16et4W7a/8nguM4wfq1lj8AndE/PuM4w8cVRU9mbI8OfH0ri+iQdHzTac0Vmuw1nXZGtZfF21F0d0RnGv25/NdZnTU77uO4b3fDJVJbPmtSj/aOGCd2Nszs4S7mRWXWDEzrDxLWjG1i8Vy4aJkzdjy/42Lr7E62Zq5k+sXtahnWGCd2tnsLIpSazf3V8s8+KjbKem4aJm/2nsmJWc58z9miWVjGHvvhGN26YuHkyleWzJjbz3c9vjI+O9FcmrmYlvHPNMKG71bknZHVsXssXIxO6W8MX9ydweVlNI9aOO56ZVTc4fjFvDTPytSsmdg1e+eK61qb9jXae/ozUp6zg7vzTFOum/WivbNO2Fay0Fp1J7dUbCztvGiZ0hpGmzDUmtQ3K8pgV3JR3roxMjH79+ZGUtVyfFUnvDlu7pv0Vrk9q3ciEzmyBncc/s7KAXfopy6NXCPLar92a0N0a/vxoaiAvq+nWLIvJNpgsNiOslOUxDsv+SzduWdYwWJmwIqywZza1jCG/fXbIG/plkStmmdpKjZG6lBVMUzdtfG42pZntozNMfH0ylcXJahqZGO3cE/hcaE7L4E3DxOjg2ZyQpWGFPbpvdOPTsdOew1mRenJkqqrOHN7U1/7XYn3WZtX+ddgwoRvpqUxZw005dc0xT6Z0tt2uVdmvmnbb4NjE1yeTmM+tiJ2iSmtOKDPytSvf6MYH39noszos5dXWwZGbtyZ0Iy1ZvBWCnBaja1oLY1mcHfU3JnSGiaadK5ic0B2HOq+NjN+8eiorZGlgXueoPa2M1nhuBTfhlfqrI6O3hi/KNrCMicIw0ZRmIvDXJ5NYvD0Xv9GNX31NYDLdjJRulrTLjRunUn3W7DipHDVM6EaUdZmh3JRTXztI5iNnd3BWxBZ2fn1rQjeiPJ5mETI2+WxZdvCdHTktN68ein1uRWBk2pGeEZ1hQte5J/C5NYKEHbLOYaN/Bc+t2dM59zXF7ueLipS0d764ZV9gpCUrZO2OQy2f9/dfrC3YzFvKfG7NjpODOsPEzfZXY0M2FJ5V3jQ6vfPQjpxT1xyrceNUqs/qHWenuDr4zkaf0MKeCd2/mjJtM8HiumPOVzv/NG6YGL2hvHJjfNqtBsuryb1aw0r4MZuDmQnicl3DsFdyZgwDBQCKd1JauFv3yQtzjWfnA4SXK9vNxMo2R/qFiLZk7i2pa7linpBQnK5VuEdLN/pQAAD1EqVGUwebG/ruuhFqmIg93lpnuhdUNH6CecdG0GHo3OkOUui2dC4FAUCokembvbGW2u55zjTqx3A9kFAUBQDUg59z8tOaZBqA4nR1L22rdL1RZ7pw+ybG4JkGpWVJTdvpDkSQ/tJKDwQAoQZnJPlq2uu6ARSNtb3kaMl6Hwq6mMLcml+4O87xRgrPtOr6hiIBHQVAyDwhl4orFea7FG9BNAMBAApjGRVIPiKBBwAA1YvhhmPDGjB1/8Udq2d3HwGgCzcHUwAAEO+VXqRhhYoA0Ha3/A3x35zmjQKgXsKsTQz9vCxFj80WMSkIspgRFskAlWIQAG+tacT9dmTzaYsBEArrxd+s0bd92DFz95Sqo987WeChuNCh/YkXe4nxR4TqSacgNu2/db7r+vMry4zdxkYBAFCWv0ltULW1KNCwrWLPxYBQmBuyhe76edhAT4/93/XLZlrAPv1wLQ6AoCgCgFCYiWXN7cVByCyLpUkCZ1tszrKog7KWIC7XNQwzknbeY8ir+gf0P6Ez7G29Rv3Wr0a6W1qNCmg667vdgoXcxYD4Suva3s8JpqIAiEeEwJesHVDMczmy53jDoG9yjpCBAsBi743bItCuugtD8/K1vXZnlKUGZdvlmHfsVhNVuCK+u7qtxThjqCc8oyVcDxRFAO+ou4CzU1/mUxEAhMLdtoVLdDRenHIBmZ+6lU1djKB0YWo8Y6S1ud++VkYs2yQNo6MIQmGlJXOh93zHPc6K2+UGgY8D4rYYRQBgMV0g+6i1XEh2UNHiiLyGj8p3sskIwGK6INIbBrqVAPY4aQltl8I92g8G+gaBwv3f32/wQQGAIPR60NM27drhSwEAIPR60BPfZR2I/qt9iZoDGbJ2le1atM112k1lsq18pheDJfxtWU3JWhp+YXeKtKQgY59CID+SFWlaeCP7Jmd6d7zX5VAbCj82GDprm40uw1qbldRwgQ/gHac+ccAEW0AodE/KA16QfSQ3CM0XOKbC3ai06XxEpVPhnFIF8LTdMnqYJ9dQZnxxTXw+NtDd39t9+WLDweTCIi9x4euZnB+rhjUkd4s0uMSLSjqODRPAvEtvkoNF3P3Zp1s1QTGUvoZ2re+2MA+ALgUG1NDppXoK1QMdV6m14D0vvSMztjenFUUEVLHZLB4/NCKc9bQLENggpu/fH8XZbyFKomIAnuavKoVaj11OYr9nWR1bqyX0gxi4e5n7S+XGUAHAkSFxRWNxeWOvSovrAUCP693Hpi6oKEpebPwLISEklDw1CUlCEGOVmL3u+wMAiUI2ZysEQQDX6wG0ao2e7E2dKkH2YrqTzGs0DixFpU7tEyWRSMbGtRimxxUZ7HOWgs9iGgCLyVK6aA8diIt5LRg1qIBt5XMb9veYLy3mVRahTBnQCAIAQKPWAnWJ2UV0hidKGp67PRsWsG9/8QZpWM+ezZFNjJU8dmCwMCiYQXZksZ9b/OC9ITuiJ3f+Ze1ZzBTy0y9xMYf8fLaTaxRqLdC8aXYFENbaYDS7uU0bIyRr2hp7KUE7/REAAG1PtexYay+m1esBgMD184pFANCoh7T67ryQFXkWP5IHNfPkie12Z5TlrglZG+Vri2MkC/8ChUoGrRYD+AUAieJONfF5eADTU/zdzYxaTHen6jtVGAADAEgezCVT/3Gnkkk4piUAEPvWIFE9zbtYEOoSqv7CkBbgXp74ssuNSOH2Tc3SjKgImjeLxw+MCA/0cXwVJbRdRw9UtCkxXA8AQOjBX08AIN42+WwJckx+FkBPfq+e7C/wN/VrsKt3HPVbG2zqlLq7e5jE5trmA9aSX3BaNde9xJ07dxbpb/T25Uo0eZXFYbOYrOxFQndajLo9+HvKpVpR4YXKk8te/mij14zeU329tWfU4OhQepQbH06WNLQMiTZ6YBeaFZ7xxZ4ASiWmp/BsMeGBP2vpCI/1CAaA9KAbQKhe/lQv/7B4AE3zrricoqNRp7OsheZ1x28Ti/02BKMZ9W3aSMb5Nnx1Dv8+LCoijI3lfxKoujsvtnW2lmeUlQfurcwPBQDS6n1/Ko1x3AIj88Oa+GdmPrtPtAE4HK9YAzslTavSi2U1B1kUBEBVFZfQePf9eGigiivOSU0Pqth9kwF+obZthBYX6zt7hDHL/gXHCiPnl8TvuSwB+hnRgDyI0KDyf39szc5rXZc6W9tO5ycerJDIK5NRmGkxMwyGGWWD82va0pX2ylrb2f6+gu/Sr4E+JVAFDAf2RFZE88mS5k6NkNt6rp/Kz/IBAFCWpOXWU7fL3zdOu/bkh2TMsYGdsEwKbhEHW/+wahaR5va13XYtefKnP2YeOnwXHAMAIDnafmmZzmxZ++6tca+wzQ1gZVY3JSouX+zu7Gg+mCw/HF1SmedvL68RXTLJy5dY+w7WxdBRAKI1M0Q6Vb0tPs+6C1V0dmlJ3n5Td3pYT7eaxDCLqS40KUj+W7iLwRaoYXllYXN203Dr2un8ci9JTra/7cmk2e7yEKVG13x2XN1/XN4eWRxk6XmCmPN6hPiKQqmJp2tVG2PaGlXeGyPtjFHu/cJ2//BYryJRqB7oOKY2ZztCpcCA5nkfnsXD2ouzi87MjEuK9zIPwHEtIPQlVP2gYvq/wwOYnkKl3ct0GsLaJHTvbWhsOtmiD3rBGIZUBpWk7p+eUcTUKtyNTiMDCUigJ/RT/9BqtbYoRuD4GKB0dliidM/RD2SRxIWTF7QIdQlVP9irmB6HjGFaq0EJnUEjYZcV09OGuAbDwXQvZdFfrLO6ssXm/laTAorPemHZJgnLeGs0puiZ8y7EEna7bxdkdwpoMfMin3ZAMXyvsedOpZI0CuX0zDeuHbI1j6ppa+zAn40Reo51HChumyEx2/61bTNXHOz7ce6ydkAhk0E7aFZb1au0yY35wL79CRwnEIonT5iUV1JzUkobqPmwd74WI8buvaxlP40hb55euquQx1SKcRJjmUNhxFcYSOluuahoqe9dEhPnCQCg6evFSDyx8YINgCkVs42LAAn0ZpeOaaeCi0Kjk8dVCrVZkNBgYwTAfHxtv13LskdOFtvhiR7HMLNtMRUGlvPVJrh70Uka1aB5U/OYalhDcqeb5PQYZjb1MKbVo1R3xKE19NpBcxwS2CBGItMdrfA4gH1uEPgYgVAY3Bhxlqz6eIG/tv5kj/1sNHyxe5zGT4oxTQ0Ndk0nI5t8toamt19NWsZjm0ZIY72dA7CExzT1aqChUYFyI/1RTXNRyXwX+q2At/1hv0qUZ2/4ArCMh/b3zswxV+QlF+nbk/1+gp3Llch6LPakK5sukX1pc7XJiI1nDLeebDzTMMyOC6QAALh70uwwYX7XnQeEx28EQwLQa9TDGpwgYKVIuGSgsuSMCgcATffht9v0/qLZs3AmGMemxIzZBKxVXlTaPmu+nUwmqRv3Ze6qbutTabRjGkzV21KcVzVADROyABiCeKa2vvTEAA4A+EDdW/XYs/FxntaVzA9ewli64vC+NiR8/UrjGMgjPNYXLrxd3qMhAAh1k/y9AZpAxEYAodGpekVHPwEAoG2tbLR169NXnBCZLOscwgGA0CiUKr0b1d0NGLGJbG297OBFDQFADLUVJcckF88MOQo/1h86S18/P0QAENoueYYwsagVN/e36ooGH8P6qgv2vnEJRxEABAH9sEqFj82MXITsTtEPdnRrAQhNd1Vug5YCuFYz3/A2dv/QHy9bd98uyOzApcSl92oVOAA+UHfguMLmjbolc+wB8Y8LpXQfzm9QjgEA3lfzu82izFOzt1kMdPfrGYIIqrLuJO7Ltrz/s2F/D+rMp6yNfrz0t1l+nEdZO/Dic6lYS0WDmgDQ9B0radCSbNkAIZH0mFqFOzKBPfppGqRRcXm1Ci0BALi6q9u4bmVtseps8WyLaRqkETG5DsriVmVJJBLgQ2rtmLWiK0XCJYqqN+YZ8jNAKHtVQGd62r5dNsNbEEHtr5M1DjAEEcbBDkqmIPqB7r4xAAJrL5FdIMigUc8cMVA9PUDd1YcDAOA9b9f1T/2DFS9cojpaVNOnBYAxVWPu5vjkGuW8fG233ZlllfZ4QiIpTr/RhhEAhOpUxblxmh931ugN9Y8LRbur9hvFsM43yjtRfmwwCgBAAKgaDp9R4QDEUNvhWoV7cITnHNYg+qpLezQAgCuPV3aCd6jv3DNDNgPTHjfw1jxRxPaqLowAAALr78L0FCoZASAUp/ILTvVaExulUwFT9KgIAFzdVHC4F9z0Gq0GwA6frUD0XlICI9CfYv7ar6dx/U121Pb2DZLYof6kvupzJN7dbiIwQlFVA5u3sR3MjaPB4iVNskbTTQWubCpIfrkvVFaUlFlS+jKbpKjJEGdWNXUrB3pbStL2KsI380yKaNveLC6x9ZwsADVStBKrO1CHc+NNE/+o//rnbTNhXtedB4XHbwRDixGthOYMflRuK474pMtlEURFSiSLwxPmXaany/fb2tXVJROvi4kWyi4DSd+aE78uRiypMW5i1XadO93cM+v2BWFmHnl7N1tfL8uIez7S//l4cU6VippUfiyHjQAALbFEthVtlETxWJxoyUkksax03rs1Z4EeFu8NempsnHkaniLYf3A7tTtfGMBjPS+pwANlZVk+CAB4Jko3Uy9J+VGihF/v6/LfGEzWz5oyZGaX5HgpikQhHObyEGHOBbpEJvVDAKjxJW/vpPXveyGExQkRyzHffHm21bCAElZwJIc5XCEK4LECRLl9S3aW5QSj5v62ZESF+MdIaxGBvGi9BwDCjhUuGdz/QmRy+YwdweCdtFvs3pUZyeJEb6mBxPzCbX7QlBmdd2l+Q3dj93v2zeq+fROuz93N11ckhrACNhUrAtOE7rYu3ybmhK7La7V/o7/YP6e8KExfmc7ncFhRuefQRGNnreAtTPInnd+Xc4K0JSt4RvKxYf+X/a2090yUbqZ2ZvOjRHGJey38OJ+yduCdul/KxOSb2Jzg1D+Ox0iCbGZEb6HAW3tsU4io2MG+czv0owj3FAmgNi3abzmHFSKpwANlxbEesyzWjCbNthhFuGe/0FHZ5/24M8pSuNH+aEdeZMT2xpmDIcQnXV4UNnfI24C6f0DvRmfMeRCSZ4zQvbd70Fs4NTBCgnbuCkUatvE5weGZ5z0khQXiZdq65Bfe7J8uRBW8nOE5UBAdFCWKyzzPEAuoU1MyXhlyeRza8L8bWMt5/JQTRLhMnuw5L1/baXedHCzLvvC7T+zxBOXHsttyhQE8v4TDOD+nVGLjLmuxf055LmtIvsmPw/NLPKBi5xzND1oMxhs+t+DkQEXhpiBOiLBAzZAW7GQjDqxB4HoSQxBPPS0JCWaFSGoRgSzfRuzMgmVKn6mYDW6gwbmybeQLuQkhzOUcv8QDKmaOPJ0JAKC6UH/ygto6x5AjMzKD8cNxATy/hPwO7+3yXAFDfVCUcgK3w+eZGFZpgB3Bnfpdi2HAEIZ5TVXuHxdKV72Xm3feS7p99oLyfDDQrGSsXz3HqJq+cXccUbE9WZwgfuHFN1rpOTVHNnohAIhn4pG647tCPbDT+9KSJXmNemGhXGQehmn72s8023kDFoUfG4yMo/zpdXDU72XbTLC47szMV98HnOciLXxhZUmMpFdcd/iFpx4dnRee8KQBEFMsXimISFannpt55M33pMZDFCYIowUMhsnJT3P42VDwqSx4rqz6KHXwuwmPNaTzC2C3w61gC03n7yCsPZMS/QZN3p7LeqhqfJ/CWHXKwZ/J80N/9AjpDEAQt1xcf/Rg1Lj1ye93fPnro8k0G//DToljTge/P/0U24KwhvNcpEcMBHZRtrcOBDvneR/phC3g57L9AraVdGsJgDHFibfbxr343O945M0jBuyEOCBSUqMcAyA0l8sqe8A/1Nv55lkAAO3FmgMlberebiV4B/J+SO97/WFBdb6VxL23lZyHCQR5YCrjlxoHvdg2Jh0JTV9F3sEhfqpowR/gsOgb3fjD1sEJO+gpfv7FM4Tn89JXc4X3tA/YiSloO97cX9r4mVKrJ5GfZQu27nop8KE+A/gQgLW/kffmh32D4+D2ExorQfrKZvYPaxBnB4o3osTvgyCD3/c+/ttj+X4/kCGMtuHF2NIlJR//buXD1sSJhQXFmxs2VGlpgVv3/n7DXZwu+JDgXEVyCjuFncI/YOF/X6naJW/Vk8j87QVipuMNBwtFZ6ewU9gpDACP/ftgnHDCCSccAV22taxy68PWwgknnLgHOPfBOOGEE0444YQTjx6cIxgnnHj4IHpPnVHMLeaEE0444YQZzhGME048cBC44/f14a01l8H5tJkTTjjhxN3AuQ/GCSceGAjtkKKvueZwtTb25JH1T9kT01xogsAC55NB9wBC3VR6sB4DEoHrKaHbpOt9FvzTE0444cT9wg9+Dqa3KIgjqb3HE97nxlBNMivmrYF7LK09k8ILKui5rxo9imiXcnjpbQ9bi7uFokqSsveNk+dbL121PmJqJjRtF5AIO2e/PTjYZv6jRTnsTKakjNiwv0RWWibfSfswI63qAbzR/NGknxPTsO1BlVzESngQhFnweMBXve8TP/gRzHfAWG/jmV5b75/HOmublfd2itcCwnx6QbSkczjMqL0XZ5ihJz+EJ2n+ng2gbq1pn30+0cMEI6m8ulSWn8SeY3kIa2pzi36kXkNil/n3EQR2RTHHoZVEx+E3LpFjxKzFAACIlyjWS3G4uGFeR10+RiAGmk9dfChXI43yiv1Dwhc+qKLCyvxQKsDDtOEjgAVtHOcI5p6Bdxw9cNzWoRJDHYeLGx75Ecy8e0FC8fP75JbHnz4MKBpLys8/krdTqvMd1LB7OzPlIcEu8+8rBuvkcxwRN9DWqQUy2bz6hpIpiL6rzcFBxI8l+o/LjnU8lJGE9uO3axwcoLXQgVA9fRhUBOBh2vARwII2zuM3giEGGvZuiQlmLeewAiLiMt+aGjwSQ20HJAnRfhweK0CU8uqHAzbynPZipVQcFeHH4flFJUtr+qauyoSq+YAkJoK1nOcXJclvUBOgrU2JfLltXFG6iRVV1GVRheKdzcLCfv2lIj5HXGFKwHqsuWhLVDBrOS8oYdcZ0xGiQCgaC1/aHB7AY3Ei1qUdaMXmSLxYe5kkIYK1nMPkRKxLM/erPZ0TkVvXKI3hsVIaNQCE4pQ0IWKVX6BfTHpJR0tuCC/dNB0ywwJbChqnLIC1vb5zXQiPuZzDChFJZO1DAAOV4lm9sAdyRHos2lD0hu2z44mBhqItMREsDo8VEC3OO3UFB4C+4ijeljrTJVBTJ2Euj8jvNhW4Ios2dsQOTD4K8Auc9lF3UXjiMTV+PoMTLLG+Bce75NKUX28W57UM4cozBbuk2enihOT0yp4xQt0kk0oy08Uxoi3yzod1jzHQ0EMXci0GMHhXza64EN4qPy5zOcf04fBsTHfjfbV5yeEBPOZyXsC6lNw603BTVSlmJVa11u3dkiBeFxIRlLD3jKkkoWrYK47irfILDU8sOqOe+0Jvi6J2mQ8AgCvP5CWHB/BYHI5ZeRaHF34Py1LIShG9s9o2qUyNqbARICHI9CmdbiQS6LHhWclW21UpjYsy5gTRloIWUwj2FgVx0usuHUtPFMdFRQRFSfLbtFMdPyVNiGBxeH4xkuI2W2uAeEt6AM+SbGPNUr8AaRMOQGCtsvR1IbxVfoF+UeL0yh4jtQZk0ayEE+ZpwgG5yPKrGRZNW8XvdHYKWJdiYj7RLg3YVq8dPp7C88tun6kn3iWXbkkUb/79+QfFfEaUr+o9B8egmiyjaq/ITo4KCvQLEW/Jfssy0RGqluLM5HUxonUJyely+3OoFlT3i0o2U/07edC8iuTIhgCAXZRL40J4rOXB4Ym7aqemHsd6T0gTo/04PBYnYl1K0VRWt8rG1skZ8L7qPMm6kOBVfqFBCdKKDu3M2jhMTnB44q5qYyvde4M46RXNB7b/evO6qIigmPSSDvMR3yaOsTg8S46pKsWrfn3MQeyzOMFWsW+76WkPTRsn4HcXCADQdFZkisMDeCxOcFBCerHto62/RxgmdLM/3+jGbf7+CAgry2NWCPLar92a0N0a/vxoaiAvq+nWhO5W556Q1bF5LV+MTOhuDV/cn8DlZTWNTOgMPXt4K5LeHdYZJnT9r8X6rM062X/TMKEb6alMWcNNOXXNMKH715+yQ1bE5rV8MTJ+8+rZnJAVYXmdo4aJK7K1rJhDX8xWo/0Vrk9q3ciEzjChG3xn43OrAxP21F8dGb01fFEWyzL9a7g+bQ130/5PBsd1hvFrLXsEPqF7esatOvX1ySQWb89Fw4TOMHh80wpu4qHPb4zrbg1/fiiJy0mtuzGhM0y0Zq5m8WJz3u3/emR81DB+MS+UGZJV/9Xo+K3BVllSGGcpK61FZ5hlAdkGkwVunEr1WbP9pHLUMKEbUdZlhnJTTn1tmNBZ9sKuU8br01aEFfbc7HlV4LO2cEr/i3lrWClnRw0Tun81ZfJWCHJajO5oLYxlcXbU35gY7XwlkJPVdGtCZ5i4eXYHN3JtWMxrV77RjRsmvjgUy0p459rMRpsyV5h6YfbRN7pxSx/dOpvqsyKrfTYx+mUpr37+r89385ayeLFZxm7eatnhszQwJinraP9Nw4TO0JnDWyqQKW2y7ot3s1JTUu1+tqakpOwobBlxwMwrsrXM5zYcv2Gbz58Xphb2TH8d7T+UFJm05+ip+jO1BQmhqbJT9WfP1re0NLUrb84sONq5J/C50JyWwZuGidGvzmSHLA0r7Jmi3IrAlHeu3DJSKJXls6N+xBQa3JR3r/xLN35LWZ8Ty/VZamK+bcrZpaht5hsmrlWnCBJeKT95tv7sodSQDXtOnq0/e7appaW137qV+UX3SGte0p72EXvC145uYD63YkfLdNR8nhfKfC608POZwiNnd3BWxBZ2fn1rQjeiPJ62ZopgPYUhS1nBme8PjusME7qrhzb6rMlpH9cZxj83BtHguM4wcuXdLIHPVBBZqDHa/kqgz4bjg6avN8/u4HKymm5NjPa8GuazZoeRojd6yhNXsxLfvWaY0PW/GuYTWzklr+t/TWD51VTzVPwOjuus4tcyO/3r8yNm5hsGKxNWmFw/m/kjPXvmz/x5OWWmB2/1yFKy6gcdiA3WpayJzXm39fO/Xm5/d0/CauZzKwQ5LV8bJnSDZ7MiQ5Nk7dduTegME7rB9sK0PU03bKgxg+qDZ3PMVP9uHtRdfU3gE1t+1b4Nv9GN978m8AnNOtv/9a2Ra+2vxvqs3tEyojMM16WsZiW82npjXGcYv3b2lTCf0D0XR8ets7H112vvJnF5O473DOu+0Q1fPZUVsiL2kFJnmPi8MJQV89rnN8Z1hvGvO1/byAkt7JnQGYy+21H3lW7cMDF69Z2NPqt3nB3WGSw4ZpjQWXJsztgfmdBZxv43us9sNz3DgybjmPMzJ6myZ1hnmLjZ/+4O3gqBrP+eovs+CT92czC4FgdAUBQBQCjMxLLm9uIgBPDWmkbcb0c2n7YYAKGwXvzNGn3bhx0zd28cbxj0Tc6JYaAAsNh747YItKvuwhDgHac+1vgnZfNpixGUHpElL04NJt/V2eHMrRlhdBRBKKyY8CWAqTEATdvpDkSQ/tJKDwQAoQZnJPlq2uu67ddBFZQ0vCdPZlIQQCjM6HBPQtFvHF4joEf9NsYzyIsRBBTnO7Bn4yVhVAQQKjdBeWsSAAAgAElEQVQznTu1vcLaAmmSQKMFCHwcSG6LUQQAFtMFso9ay+/6FEnUJz0vHk7nlvZZ3QV2nPoEZ6e+zKciAAiFu20Ll+hovIgj3nwW9H02AABEf0cvLUa8UtPXpwEATf9F1ZJgP3tnFtnzkV0MdGv9hUxCOagF98hdeTF0BAAIggBAvLbkJDJQACBwvR4AbLuUFl9cWl5m93PwzTfKS7KC57GJxfYMVfeHKobAZ/q7shdJOnokJ1EYFkGDMVpYojAsMiIsmB/Eo1u1gfhK69rezwmmogAINXytL1k7YN44grA2xXkiAABkH/YSUCkxAFVbiwIN2yryRAEQetjOOE/HCt81RVWX9etLavKTYiLCvJFxCn9DTERYZERQMJ/rdW+PWaHc7F3L6jN31fY6WrEi7H4xYXFEXsNH5TvZZARgMV0Q6Q0D3UoAAAQAyPyNaz0QAAA6exkFH1RpARTnO7Al8ZIwDwQA9YyXCGwdb4fw4sIoitPNxiDEL9R3kyJEXIS4XNcw7JWcaaQoxTspLdyt+6Qjis7AVPx6WMfvDOajzA3zZL5eob5X5s8LiPeO3RGX92VWXbQzhTxQ10iSlhaIuN4MT54op/JYHh8drM+W5Mr3Skr1W4+UZ/ob13HAwz8rjXq+2sZbkWZQ3SNCME317+TB+eDy8YZh7y1ZkQwyglJ56YUy6VoqAUPnTneQQrelcykIAEKNTN/sjbWc7CHAKhtbJ+fT1b20rdL1PhQAQOnC7ZsYg2calADjOA4IarxokX0zKi99lDWVE9yCxQIqAABCF8b6Ep1NfQQ45hhppYPYX2wd+w6atgXF6VqFe7R0o7ELXqLUaOpgc8PDXEl87J6m9t6QHdGTuzmyibGSxw4MFgYFM8gAWgzT44oM9jlL0Wcxy/lTjXpIq+/OC2HmWfxIHtSAVqkGCs98siLqxRcAAMDwPDUikd2pU3mIhCCg1xMAKoVaj11OYr9nKcnWasHuW0H0qgtlb57+iwrD9QBAjOtRmrkFD7rpfFEC02pIVKp5AMBYySA1AoADC0QKt4ubpBlRETRvFo8fGBEe6EO5+00ZCHNnrqA1rahMWJnJMP86rMT0FJ67+SmbxXR3qr5ThQHC5nprTnSrwEffeQVdJuJ7dpVe6MZjQvs6FRTWTnv5xq6PwN4l0ku8xwvwxrK/AW1DtOksZqL3klJPDhL5m7wy0NGPk1f60u6603cDm1cJoqsB891iMZJAmPFi05+K9s+Avs7RpV/bUy071tqLafX6O3dAP673nvoPiUw2+9BMOVytBeoSMzUodBpKUjuo3j5F7YAuEP98EgAAsNZmjC6xcebtFIgrldKSDmLRokUOFDACV11u3j48WvrWb1Y8OfM/KGrNUz0AAIlk/TOh7Tp6oKJNaQwdIPTgryeMlz8SmWoOuKliBDasIblTzaanulNJYAPesfH007Un+7ZKmZq2li5yWA0bAQ2mwt2otOkhOJVOhXNKlX2KztDUXvzaZ76HnaqMzG8q74clCffEfHVtdlGTw81Od+7cWbRoEQCu6j2doRqWV+fMOtkbH1CTIyXTOQ2hC2Rl2uTEg/VHh/3z62Nm3qp4sckV3RgwZt3AWFAdAAh8murfyYNzQjM4hJM8zA0gtGAhDQC6FBhQQ+lmnlGoHuj4V+oRWAOW2dion0VyHsT0/fujOPst/03FAIK2SrmSgnj+yWVs9kpeuCDCn7Z46t90szFQMgXRqzAt4HY5Rr/r2F9tt2lbIFTDGpK7hX+WeFFJx7FhAh7amd+P3QgGqMH5NW3pyq5Lna1tp/MTD1ZI5JXJKABQxRXnpEyj0PTpUL2WZd0iDrbK/K0qVP8Z9HZuoecJO9HDyPywJv6Z+Z1oNdacv/11LLL47XI+FQHQ1EnCyy1bmFeAWlrAAqz0dxo3X7tysbuzo/lgsvxwdEllnv88ZhVmAmFv3y3clJF3OPIY14GY6UqOrvRnFLX2aSPwftw71YuyxJ/21iUl8XRHP8kvz9FNwJSPrM73cugeZU+/nsznepm+Dnb1jqDs1VNfe+ovDZP9H8ZeWqKzWcPdZnu4pjzXrqVvW2K/sLIkLbeeul3+/kYfChgMXa+GZ1pslLHJB6tR1DwobZuic+3h1XS2KmiRDAcGRXySS49snvs4t7GOA7kNoQW563/xn5Oz/ol60H4C3TihN1+69Ho9kOieMy+ARJdM8vIl1r6DdTF0FIBozQyRztGBeYIWEbesrPzDrnTqUPNlujDLyKh7u1bOA9PZad4n4Sm7evXkwNX3xHxafHF5vMPaDYZJV9fbVyrzK/yyCpJZNq98yKwBJcLYsC3ixLaGka7Kqi5+lq9lptHrCRvmm0F1gJ78kIzvb8++/u5Tv1U2tvxKWr3vT6UxqLUH6ULZOT52pbuzte1CdU58GTP7aNl6B/NGDjl2d7F/t007rPYhwNVgmJ0aAADs/b7ghQkcB/Sp/1kd9T+rozb95lTK2j+e/cvmnU//jKQZUNww/NI0Lse1/wAyFQWY/BbgzqRh0kB5hkYe7/3immEVzShCaIb1qDuKPEWlkTRfqf5t+CUKAID3nv1AQV0rYk3euQN3vp2creHktwB3vp00TBoAJifvwJ07xr/B4uvPn11Cau5R4PFU1Fgc12BAoaLWNd0B+PZbg2Hy75/36T0Tfx3wtIth0gDE366o9fDMpGHSAN9+ewfuTJrUcPnxj1H9365fnwQaGAyT8Pe+AT0wJicNhp/OtgBmtIDJYBzB/3AECcnNv43dU9v121WBlr2w6xTDt3fgzreTkwYDADy5evvL4b/K3lX2M2+SUaWfetJINdOmA/xLTEP62ZKfThoMT68OXFJ2seMTXM0UPOdiQJcuI9W2f0zpxdm/eW6WSb+9A3BnctLw1AwfGQyTUz4Cw+Qdkx9n00J9qVvrxlw9VS3W1aUmMZOWuxgmDQDEpbOt2E/4a31cvjz5u0tL83/lOaODoK773f5zji/ZJE/xnp18u7fYk3fumCw5s2bAP275f4E7n7atc0fHsHv4L+yGJ2h6r2Akv6z4pU9NGgwAmHJAqyd9O2kwTNqj3FPPuEOH6rph8mkAg2FSc02t1ZMmDUbfTWtrppx9itplvrGDmk9beslLXnrKqmYbmCO61e9Ja5/Z9XoMFaxNZ8Qv16x0O3n1q39MGozTfpqhr3ESc81ydIbw1592jdMCNwl+/qTBMAnw1Z+/0gPtW4Nh0sVw5w7cma7ZcOcO3PnWMGkKon9OGv4TAAC+VKj0QDORfIYaTz8fw5a/8cFHP8d6n12f83ODYRKe+pm727j62teGVe4AYDDc/vILDJaEPGOYxF1J8M03t01+If45pNXPjC+DuenrkwYaAMB0/D5lnZ1u3fjayPyZMWhlwEtdWjem39L5M39up8zEPz7YW/bt1gO/9kRs0hieXLryTs1fb69hIeaa8UuvF19Z/dLGwaMn3kvf+fSR1zYwTGkP7/hIRVv/tMEqUqypPmCmOnw3Dxq+BbjzrcEwabBnQ8oSd/K0N4FQN5/4DAnbwPiFO6m178tb8U8bR2fYV1/hbjTaTwyGQctsDFbJ+afPUPXnr/z9tmDKGjimJVHJCACuwUmUp5cGxCwNiHkpoeyFLe998GVM+uS3oMe+uj4JPwWDYdJIb/ennzLM5BgAYebY5OQdAHAc+wBgjn0A+PeNURtN0yyMMGUcAHD5+TNU/fkvvpwUmG6Ev/5iSE/2+7mL48vEPHDPwk+4urrM/gCAzd8XvvDoRzlr4/acvjY66eriqrv+l8sjQKX/3PXJNfGhlJ4jr3507bari6vu7zW/27xBeuafri6uLk8ALHJxdXF19U0QLlFXyU78fdTV1eX29abfJ29Iff+aq+tT/uvXoD3Vr398/bbu9vVPy/f84cxVl//j6vqfixbptf+4OaozTM5U48n/IOmH//EP3e3JSRcXl0WwyFi/i6vr9Nefhaz3X/RZ6evn/znp4jo5+peDWbFbZJ/orDv1xCKAJ55wdXV5+r/I+uG/XL7p4up6+28fFJ4YREn4jX/rXFxdn3hiESxymSqynO9Lvnrq2KcYAZM3P3/98CfjYPyvtQVO7DJa4PYn+Rui0o/95abB1dVl8uYXl2/oKf/1f3/k6mLZC1fdX08UyRuvz3bKE4tg0RPm1n/sn/NyoPbEkbZxY6NP+a9/Hu2pfv3Tf066ukze/PzNw5+h/PXP/9jF1dXlWQ5rcX/1u/00zoqnXF1dlnKYmkvVbcOskFVPznLuE4tMvZj2EQBY+MjF9cn/AP2Nf1y/fXvS2oajf/kbRlpqrvb23/+sAE/eqqeMX6//5W9aMjdk+eRn7/35fwKem9XB/9m4/9A7FXY/Rw6VvfP2b0N/5oiZExMAi55wsa759mefTISE/NRmkX/++VMl6dlf/sJ+tT+m/F9Er/zL32+7ukze/LT09U/0ZND+Y9SSY1aUezaAS9N+/M7713CA29ebXj89SCJNi82mnH2K2mb+lOluf3b+b0Bn/+K7Rvft84f/zNsZ94x94R+t+U0aW3vug89vu7q4uhq+/OgjJWNDZtRPZwo/9d8egF396/VJF1fd9fNFlf2L3PQj/x51dXF1XbQIFlkIL1oEi55wdXFdHs4jXz11+E/XdS6To38/ceRjrYl+s9T4MT/RH84deLvPe33oM8Yf2QnRSxRV8sbrtwFg9K+Vf7yg94+PeMbV5efP0WD4z3+56eLq6jJ5re5Ej97IihnWmIrff066zIzfGdkJV39oyXwExoevj96eNNhi/jI+C5kn8+fhlJkeJC6/8yE1LeW5H9mXeSZm/X+8V/rJTQMAuLqO/u2DvM1F/976xu9/k11auuVZfY98s6TgxKd///LaXxtLct68tXHz0llqzKT6myWfmqn+XT34BMCiJxzYEGBpQsQSRZX89LXR27p/fnak8NWqvxqedHkmar3vok/+eOSvo5MurpPXzx+sVdAEcSzEOhtbfV26PpE90nCg/LNRAwDxz09lqXGpr//V4Hr9eKow9Q8fX7/t6uLqevvLv1/FEff/fsp4bRq/VHW8FwdX19G/VL/fh3JDVj1pyTFXVxdLjrm4LAIAB7F/29XFMvZBfcx205ZOnDIOThCuS9fFM0fOHqz9Uufi6nr7yw/ebhh+NiH+ubuP7vsm/Ljt5KUI9+wXQm1atN9yDitEUoEHyopjPQAW++eUF4XpK9P5HA4rKvccmigvWm+1hOyVIZfHofWZItZyHj/lBBEukyd7AgDql1ueu2yoNJkfECKWKX1yZdlsBIAWI1oJzRn8qFyr5wm9hQJv7bFNIaJiBzucKGEFR3KYwxWiAB4rQJTbt2RnWY6DDaF0Uc5LnoP7Y3isgOQ31KG7S7ZHUi7nxkibrB6FRLjZxZvpvfkv+AeGZ56mJqeyp+YUrSzQjCbJi9Z7ABqcK5OQP8lNCGEu5/glHlAxc+TpTOte4Mrmk43zeSXAYn5WHh+0UwZB/V4uz2UNyTf5cXh+iQdU7Jyj+UGm2WYG15cYVJNX+ho3qjG53sODGCPQ1+H6ldlHq9iBlj5C2LHRNPX+FyKTy5VWRYbUwyh3rXmFHlNoEfba4KmVBi/hBj6qrMgp6uLnbL3X/X62gZ1KjxGFR0lqNSSS4qA4SvTCr4qnqaK50AShwbZnbghFt9KNZZ7ttwUkaOeuUKRhG58THJ553v03+wrEy7R1yevk9jnHSJXt4moqk9ewA4V5Pf5bBFTQO5oGtktRu8wHAABlrwK8/Jd911cM452t+rDIOTxCSywp36qv2paSnp6ZW6YOlR/c4WO9JkKOzMgMxg/HBfD8EvI7vLfLcwUM9UFRygm7KxEI6+WS7QxFUVwAj7/5ICZMDSYDEDYXExBfURAFJ/mLAqc8ifiky2URREVK5Cq/QGHeZXq6fL+QDACL+dt38/GyhIjwGLGk0i1e7EkCvbX5p+JXuIpnFb+W2en5F983Mx8o3Gh/tCMvMmJ7o9XG3iH1MOov8HtwzO8/j/nFOlzzBUCYmbtCVfKMzb/evC4m/W0FV/a+LIYOAKhvRmXDwe3BqPJ43rbktAOtpCR5cZCNgJhJdQ9J4dxUvwsPAoADGyI+UrksgqhOifYPiM+95L7tYF4kBYAi2H9wO7U7XxjAYz0vqcADZWVZ3nMvQ1PjS97eSevf90LIKr8wsRzzzZdnsxGgb5DnczXlEv5yDpMTnXESSSzaE2M0BGlZvBCO/nqtHyc6o8N9U0lOJAqWHGNxeJYcs4up2PdfzpsR+7QEu03PMk5U+kdDQEsskW1FGyVRPBYnWnISSSwrvc9p8y6xyDChm/3rvNdZncILUJggAHExCmtObYk6TC9rzmN//2o4hR0JaxqkxWiejG9nvEYQt1xcf7TAdJ6vMEEAMnc6n7Nmy2oWVgctMNYsjSglyz/Imb2b5F5rtui3nfhdMNa4PTn55Dxc/aDVeEyFe4uCUtRpH5XHPvXo6Py9Cz9uczA/eChLYgLCMxtVxjdrlb/Xi3KDZ2/edeIhA2ttc4t0cJIAMs/rwoLEfdJ94ZtgTHEqV9bjLdl8/7aBP1rx+0jT1InHAY/fs0g/cHimFedpCw5vDs8fBzcqIzC7LIvnzDILDdiFi+QwmdMvjzC0tSnR+3rJbLFMJrT3+qJ7gCl+xSH5uDN+nXBiLjhXkZzCTuHvW/j/s3f+cU2d9+L/qOyc17318O2W3O8dYb0muyvYqwExmAoEIUEgIAIiiBSRiXgXwYGwIWxFnAj9gulErD/orFiLaAtqBWlB3AA7kU7ATqArifMmdBKcS5iXg03PIcj3j/wOCT+sq+ie9yt/kMPnPM/n+Tyfz+d5zjlPzqOozqlxL8r1nmpomms6I2EkjISR8FwTRk+REIhvHXbMpimnLwgEAoGYFvQUCYH4tuH4TfXSPwQCgUDMBHQPBoFAIBAIxLMHmsEgEAgEAoF49kAzGAQCgUAgEM8eaAaDQCAQCATi2eOffgbTUxLIl9SopxecEk1NqiCwqPuJaGRisDqFF324/8kWikAgEAjEc8E//QzmGzDS03CxR78xDEOUc8ywTck3RNVR0ySf9X7uCAQCgUD8k+HkaFfrb2dr7KcvPP4IYGJcZ29v+mlKJj85caCK+0rEf/0rALz4n//1olHsm+is+v1vStvWBa/+zwUWe6PrHAjPqmQkjISRMBJGwkj4eRJ2svsuvLn59r2ZCVP99SWllVd7lKNAfI/jHbHz9R0CJgBQg61H9lVc7VFoKNyFG5yUlxu5GAdYMB9g3gKnBU5OAKC5Vlly7FyvQj0KTDe/xKzdiVxnAJ3uq7/8tqK0orlTOYqzloolebmRRF1q1L4uGq4mv3ohouLjbYrUqKPs8rZ83u13EjdeDZFGKqvOydVqDcn02VmyJ5oDAJSiqST/0NV+NTA9InYmwtHcvthzx5P/w9zA/srExEO3abi92veDtA+qxQvmwbyxv/5W+uah5h4VTbit2lm6J5qDAwCQvVXSIzXtchUJBIeXlJG31Y8xyRp/aSw6UqfBMGpIpcE4kdtyE3lMAFA1ZKQe7iJHKe9tu1nypq7uwe+nHiqP5QCAuqOs+FQXCRRJs3yDOaqOdtkAK+UNUfuvjnWRJO22672E+1WtX/79z7dUmGdi3i5fTV3FhR6VskcJ7lv2SOPc9K9pG+k6u6+yg8Lxkb+pxpx5m3LSwzg4AAzW50gqulVqGgBYccfORV6NTXpfBQCwMKy07lf+9r3xyfkGEkbCSBgJI+HnR/i5e4qkeD+/qI+Tc/r6H29c/1AaRTXkS9soAKqrLKWgmyUpb7px7fqHeR7yg5KCthHrU/vLMzLrsbiy2us3rjWVBJOVmbvqVQBAXt8vKehmZVa0/qGxOsOlvSiztGvhhncqU9iYe8bp7o/zVlgUgmMYLTtbQydUfFB96XfVOxlX9h1qHgEAxfs5BVeJxIrWG43VGS515Q0qwDDMSoHFKdXlkQsx37zWG9X6LctpTfOJruUFHzRe/215JHyyT3plBABAVZOVeYIMLvqgpftG3clErCYr44Rikinaj+87d3WQnXzoaOW5IzFUReaWcjkAACvi0MeV21k03X623Tt7kzut7Lh6Sw1AdZem5jQx0ivfqTj3zma8/kiXR3ZRig+H+H50aW1lCosk+04cUvr9LLeorPJQKFlXkJlY3LE4s1h6tLp6C9FeXFKj0lesqisva+rCwwql77x7fLd7d/7m/EY1AIBrpPTSx42ViYuAXiSKdMPdQ0Qchii/svX3TUVC9I5aBAKBQMyC524GQ2pIAJwgcACcyU062tRWGogD2VLdQPruyBWynQFwJu8n/72Kbv2onbQ8s/t0/cCKlLxodwIAnD0StouJztqrg0C2n/+t2i85V8h2xgmOOLu8dJuIQU+lA87bFKu/G8Hw9F4ECrkKQNHaLCNCtia6OQPO9EjIjXShpyzDCHdrZgiHwHEmb23IIlApVQAgu1DVw96as96TCQAEJzJ9k/vAxXq57al+2ceOlB/Sr85h+oi4tPJ6h3GeQxAEABG4QcgQFNZ9cvlgNBOg90qjEjjebjgAENwVHLqn/ioemZclZAAAQSwEAM/YGHccAIDFYWGg4YQmryAAAJgsFxxUMsMMhhVVeOzYO1kiAgDwxUIek+xo6TVbxzOzOI07cDr3yMXKw7JQaVGkmzOavSAQCARiljx3uwp4bMwVd+dvDmt0Xy7wDhBFBorcGQAalYomZZnely1FX1ZZ/gRJrRzU0F0FQdwCi4OMATVo5EpgCtjGQZZYLIwAAIAhRypgDAbTKI3hONA0BUAqNcBaZNrEluPuRmAOS7AoyoVFGP7GMUxfFKUaUNF9+8P5+y0lWSoAm6XEDE937GLl3tIuOQnEiBKAQZrXCGNg1IcgiHEAAAzDgaZoGgAHoCg7y4kZDBYOMA4AOADAQibTpBxgQIPxFGeOm2trQ2nW1VuDlDM+rAaggDKcBADA3lqa1Rlfurt+c+1FNzR7QSAQCMRj8NzNYIAlKqxuzZB3Xu9oab1QmHTkhKS8MoUAAFbiics5XL2Q+Vlaj+W5C8VHWqR+NgUq/wA0wKx+HoRNPkQBbXUctyc0s6IAALCV+353KJqw/089I+0lKVkNEFkkfWcPB6ca04J2qaasymPjVu+Gg/UN/cIIQnahSekiLozgWNfqbKUYjpu1s5yHKGvSJKUyt51lxb/8rxed7pSvjb9gaz+CzWJgmPLK6fbkIr8pm4FAIBAIhD2eu6dIQI2QFM50E0QmF5RVn8th91d/1AMuLBamlsnN91xIzSBpfR6TzWGMKmRKc0Fq1QgFAAwWG1MrBoyLZshb9adqujSzVYvJYIBmwKSAokeumdFTJDvgrEUseqBHZp4UjKg0k2ZYytpDF2TMmN35gRwcwHBzBUB2vqzJNJGxmR6NDoLPVuHQ6YLCg61E3JFKqZABs0GvA9V6/OD10RWZxUkeDAAAQ8Wj18pPdRoENY1FR+ic09JQqq6gsPGbvowHgUAgEP+MPG8zGHV9jjg6v0amoQCAVHZ26Z/d4H6xwcyu44X18hEAIHurf7k5Luv8oNWpvA2RixQnS6p6NAAwomjI37whpVoOQPitX0V0ndrfpBwhSUXrkfyiC/2wEAADoNXKITVp73nLJBYLfViq5hP1SgpA3XOqrF6D2bu9gmMYrVIqyCkLdY9J8tbUSY9cU1MA1GBrSUp0SmmX7V0OBgMDUqMhAQAoRXOTAgOaJtW3ZRoAoIEGAJs5lEajUirAzTt0TZjvUlfQDFoVSQPQI8YzKKABKMpUAEXRhjIBZzAIoNVq/SSPvFbfrQaapjUKmZICANBck+YcpDfv8mOL8vPEcHVfgbEjyJtVRQcuTl6SjEAgEAjEJJ63p0jMyD37FSUH06JKNTRg3+N4h0hLY1wBwC+vouRIaUWGsGgYcBd3n6TyXetdrc9dnFleDmUHs+IOamhgLPKLlOpfUkf45lfkS0sPpQjzRnHWUlG+NNcbB2BHxy2vK88Utgbs/zhves08tu3PGdpXvsm7CGN7x2RJAnsKlHakIiM8Lr+3Kagh7mjTVodlsTaUHaOKyvatC1JTQLCWhxWW7/S2WU/CiC6UaqSnjiYl1rizmayAnUfzsKzDhdURuTtvZkQf7lJhGBxPDL+wOFF6OP4lAABYKuJqMqWFdaYysO95S6TlKYyW3Mxj14cwDGrT4m4l7Iz/8ujB1gHAoC43qkectxMO72saoDBoKYpa25pVXZheXkgfrM1Ze53t/v3vekZLy/HC/IoSYkvBisqUwJNykqJp/KN2KlDUdaVdA1RXWVzQ+yxx9vvx/9N0roElzI62fnaFQCAQCMRk5unGtJOPzs1ffj/zwhQFuGGeQbXmCHNhb2tJ8AtzRefBWkliNbvoaPoKFoEDUGplZ/2B/ENDUR/WZnFsheeIzkgYCSNhJIyE/2mFn7enSHMX1dlE/zBJtXwEgFJ3H63sBr9g7hz6HQ7V09pHCGMELEKvFM5kC1KSBQyNSvl0FUMgEAgEwg5oBvNtwUrYXxpB1UqEy/i+615vZyaXvx7CfNpKWYCviPQh6w/XyEwrnDW3Ko+34AFR3k9TLQQCgUAg7PK8rYOZy7gKs08Ksy2PTL0Z07cMUyytJs4ek2bWwUICA4ocxd3XlL+3fgX6sTMCgUAg5h5oBoMw4+qXUOSX8LS1QCAQCARietBTJAQCgUAgEM8e877Wjj5tHRAIBAKBQCBmh5PdXzHNzd9NIWEkjISRMBJGwkgYCetBT5EQCAQCgUA8e6AZDAKBQCAQiGcPNINBIBAIBALx7IFmMAgEAoFAIJ490AwGgUAgEAjEsweawSAQCAQCgXj2QDMYBAKBQCAQzx5oBoNAIBAIBOLZA81gEAgEAoFAPHugGQwCgUAgEIhnDzSDQSAQCAQC8eyBZjAIBAKBQCCePdAMBoFAIBAIxLPHvPoP76kAACAASURBVK+1o09bBwQCgUAgEIjZ4WR3V+u5uY82EkbCSBgJI2EkjISRsB70FAmBQCAQCMSzB5rBIOYCmppUweo3bj7GmYrKRF78KQUA9JQE8iU16ietGuKbMze7RnYglJ9SrXraajzjmAPwKdJl4WBkd1mSmLdMsKVW83SVmg1tOXxBRuvT1UFzMVUQWNT9dJWYLc/hDOZagYibdHZQ/0XVUdMkpwAAOnL8BRmt1NPUzD5Uf9P5a3MtuX/bMEQ5xw78+OWnUDPVnMHnS+pJq4Nkg2SZQNI0B71lEpSysSjF3zsgw1pbStFcmBrny+dz+eLYrFOd/+wOZuIfEG49B0Ln4PzssSB7P7rYQ04vN9dw31z+TraICQAw0n7qtIyd+/HvTsYxnrZaiH84z+EMxpLB9uOl9foZDEZgmDOGP22NJtN3Wvpe+z/9hSDTnevBIp62Fs8aioaMdZLTtAsHsz5OdZemF7Yzko9dbGz9YE8YeUqSd37w6ag41/gHhBvBIAAj5mBqmTVk+7sHT3c9Q7cujBAsTw83JgAA0CQNTDd31vPQH4hpeZ5nMP2ViZHFffT1EiE/8YSCwAkCIwAARnrO5v14nS+fz+WLQpNer7J3zUHJGgrTEkP9BTy+eN1PD7aojBe4ZG9NQUqov4C7TOAbnpJfKzf8Q91RlpUYyBd4eQf4hkvy6+UUqKqSBIG5HeZLY9X5RL44v93iWpm6muO/vU4zdDpV4JvbRgGAuuNElr5eUWB8RmmrvVxrrIu7TGCsy6BbVYFkbZCIxxetfi33RLspE2muVeYkhot9+QLf8JSc6t6RyWX2lATyM2raT2UkJcaGiwPDJYWtGgAAslnCF+W0mxRuzvIN1n9VVCbykg43Vr+eGB8X6C9em9vQr2grTUuJjRb7hktKTbVbaBUYn2PUSlOTKlgrbahKi+LxX2+xeopEKZoOSKLFvGUC33BJYb2SMhxtKEyNC+TzucsEgfE51b2OrhTtmH2z7xors88SS2dYm3bA6AxtGXxxwfmPcqIFvNQGtcOW2qDprMyJDRfxlvF5/nFbipoV+sK6SgL5OVVNJbH+gthKJQBQso/sVWoNCSter65+PZhlfXik9f0m0mdnfoQni8Hk+Gx9PZnT836NzPZsdfsBSWpKbGpJi0J+sShHkiZJTMo50TXtJbiqKkkQWGBp4bOJfHF+F+Wwddbnhkp7TdaoMX+lBlsPSOKjfPkCnn/clqKGfsO5qhZpxrrQAO4yPi8oTiJte/ypGNVmG24AlPLD/CQxj8/nBaUUmsPNTshQ7XtX+6ZWmSOS6iwQ85LODuIYjuM4AXqXyK9tmK1LtEgl4YEBPP+oxIKGa9UpvOjD/foKHDhenu+a/Pq2sqyU2OiowKA4SXm3MaId2HCSdw22HpbEi3nL+Fy+eG3a4WtqANDUpIb94uqo7NAmXnhJpwMjGHtEEuoveDVwTWzu+VsOJjwOA9ZR+jJBNqcbkwyA/i6pyCLnnGqp3bslPnFtkDgwfu9FhamBkho19JcnhhbfpFXvp/BFW2o1QKlapBlrgwQ8vsA3PDGjsttwp8zGID0lgfyMqtbDGUmJa4NEgfF7GxXyiwWS+PXrAoOiJJWTE6ZN+gIge2t/lWpnXHCUVwEo2fmceDGPL/CNlpS2asxGcKSzAyVjo6PsKtlfHscNP9BvPtBbGs5fWy637H0v3zXG3rc+VxrFiz87aFEUL/6syqC2XZ+EkZ6zOUlRplHVcX5+0ujGtJM/X2tH7R5/JoTbfuHzysbKAePfnttqh8e0urEH9+S37o1qdWM3ioN5Ufs/vTeq1Y3e7XgzgR9c3G1T2lBd2iqfpDevDYxqdaN3GndHeAbv6R7V6sYedOwJeCU4r3ngvm7swcClvKAlIcXdWt3Yg+ZsH35yZd+w9mvt0EDznuiVMW/LtffOb/NcuePSsKHYgXcTPK3r+lo7qhuojPfSF6LVjX3xdgyPn1zZPaTVjd3vO7ND4BUh7bNpoLku3dh9U126sTtnkn0EO07rz/2iJivIS39c2/dmjOea7HN993Vj2uHuytRVPqnn79iarrs4aAkvKLt2YFSrG9PefjvBc1Ve26hWN1yX6uWT1WYUHq3bbvw68G7CK14hWfqiBirjvXj8mD1tQ1rd2IO+NyI810j7xrRfa29banX7fLZRq/vntvH4qxIKLn0xPPxAN3b3TDJPsPsT3Zh2uC0vyCumoPmL4dH7ty/lBXmFFHQ80I3dkq7hCXbU3h7W6kbvtr0R47kqt82gaoxnTMXtMa2ue4/AK/nMkD2zry6y7eIxc4vSvLip5+9bWWO4NnUJL/XSg8nO0LzH5AwtWSt5gnW5Z/ruDo8+sLG/RUut7Dx8aQffK6a44+7DMe2w/HTaKl78u3d0Y1pdd3HQkoCwHRUdQ/cfjmp1Q3Xb7Vdq99O404uXptd2TKsb03a/EeK58fSAWeBa3iqeqY0GRxq9Vryjom+0JW8l95VV2072PdCNaYcv7bA0naMYvHcm2XNlXptRn9tvx3gG7+ke0/7tYrqD1hm6Rjd25+RGXtAbN4wl3z1j/PqwY0/QypiC5i+Gx7QPh65JN/oIshuHx7T3zm/zXLWj5guNbkw7LK/NCvZJPX/38fOGZbj1FQct8RGlFjXL7z8cvdP8i4hXjI1yEDI39q3mhr15y+g5LXmreKnn7+rG7t7uuzM8ZnSJmDy9Szh2fqvPwJlkT6+E/TeGdGP3+85nR6/0eUXvz44db+erXM+YPc1DWt2Y9mF3cdgSQ5awa8O/GaLbwrsGTid5+SS9fePeqPbh0I23k33422rvjWl1Y7f2h/Oi3/5Cr5ijvHHvfLKnV8Lb3fe/1mrutRXHr+QZFLb6OApYR+nL4jNct9U656RZ5ZyA1HdvPRzT6sbuntvG89xR9zftqK7D5GDae2eSjWn2QfcbIZ6rduibcK+7Imklb9Pp23bCrbs4aAkvbE/jvTGtbvSWdA3Xc1WytPv+19rR4bY8gVeCvmSLj036etCxJ+CV1bmTxgWto7z69YNPC4K5Qdl1A6Na3fCtM9kRnkt4ac3T6mxHSX3ONClpdn55RbR5ZNHquosN7mfR+//7l08tev/uuWSeYM813Zi2740Qz5hKUwLpezPCM6byf7Sjjn3yRnEwL/rNG6ZRdcUUKXdWATud8PN8D8YanMlxY+IAMEqSgBMLCRwAZ6zIrLz+cbantai69UI7HrEzk+eKA+As4U+TVqjbarsAAF+RU9v6QZ6IRQDgruKIFQxNv0wDQI+QNGAEQQAA4SrMO/f76q0cYApjRNBR06SfdKtamuSs0AhPW8UskF2okblE5SR4MgGAWBy3LYo10FTfay1kvy6QXajqYW/NWa8/l7M2bZP7wMV6OUD36fqBFSl50e4EADh7JGwXE521V20vZHEAYIgSI1xxAACO91ImOaCY9nYysTwqkgUAwFrqTtAM3xgBEwBwjjcbVEMqAJB9aKVVZLpRKwAAkrVmq5jtbHX/nWw/d0Xtl5wrZDvjBEecXV66TcSgAdzSqurqSyI4BADOEET6sMjbMgfPAuyYPSR8KrMDtBcEcZfx9R8vbx+uf6HpCtDGGUSZyUZnABxowid+gzvDGcdt7W/dUhPO4oL6jyt2ejNwAGdORJgH9HfJjfYHz9iNK5gEjoO69cJ1bI3dSmcCqSaBSTDNBwgGAWq1dXfK+kjfgMUqeT+JeWfuSXLHAcCZWIiT3e09AADQczg2/vCkGzcAAExhxArqal2X/vJL2XJ5gBUa4wlAhObbb90MVG6pbiB9d+QK2c4AOJOXJgmgWz9qJ4EiRwFfSCzEAcCZEyH9uKUi8gmub8D8frxTxCFwnCWK5DEovc87Chlu7PqXVZcv3AIAAKqr+RrtEyVkADA47ixnANC7hG+C0SWmcn4jms7Lfbjf5p9wCQBicWT2Jnda/48pHA8D4ERu1i/7wD2WL8aGZApqChvaeBewIso/ri1P4TJxwJncqFA3StY3aSmuIyOQ15r6wG/zJg8CAGf6pW/1xWxPBXAcsA7S18zBeZti3XAAAIan9yJQyB0+EqRu1tYPLU7J0jeB6ZGcFrqw+/zVQZhkEBwAXERxgUwAwBd5cjCaFZzkQQCAs/tSDqj67dVhkb7wFTm1V87smjQuOM6r8t+2qxZtkIS44gCE2wZJBGdGOs9GSU5AGEfTctkwfNyqv6p2jxBzbHp/qYPet49jn9SPqoRpVP39pZ1Tp9wnhdO3Usucwmdrjs9PihKEF5Z6ey8XhEaI/djO1hIKmZJW3dy07H3Lg94aDQADNN1V0vdaelQamgYAiqQ9AACIsMz0prQSsf8p3nIv/6BQcSjPFQcgfDaEMiT1zYNxCa6qq00ytw2lblNoRimG1JiLu/mRwKLFLOy0aogCrsUgb67L25snEAbr66JUAyq6b384f79FgRhLBWrNoIbuKgjiFlj8gzGgBnC1qR5jsEyD3sweImMEw3wGjjFZhqEFxzAcaACghhxoBS4AQLBYtjqApl8BTD+2sX5isTBC/xcpayitaOhRaEgaAGiSdhmhHag1yeyxxVOZHQA8Mk4UCQ2rcHTj405fXcvffFz/1bEzAADGYrvojzi0P1hXTWk6Tx440SpXkTQAAEWDH03p7Y2x3Dm4udKhm5uWfTCp0ic3eHskF3mAurZEBm67vBnGeuUkYIbVYpyI3SUMd7vnMgOi/A7sq79J+fngiquNikXRJW7G1pXbb900aFQqmpRlel+2PPiySg1hkembmnKyIzvYHjyBMEAcGuDJtClPeSJ+w0H9VMs9vf6DgCuvbXhLbvqaPNX4aO5AAMK4Sk6tdBQySyLWefzmndr2LE8/6KzvAOEeke3aLcyVY3QJh85v6RIahZpmcE2rNhiLuS7YdYDpHI/JMHkCjuNA0rRDGxpd1eRdALSi9fDBczcV+n6iRmmCbWsZh0YYUqhoph8LB9ABAOAsFgNT2p4NDgPWfvqaORiDYep/DMeBph0+HiZVCnIhi23OpywOC5puK/Spz8ogABjhas5eGMYkDB2L4zgA2Es1VulL032m9FRr35D1uGDQeHJepVRDaszFfJzlwsJmovOslGSLI92OVl+5lcP1hO66Vo2HJMQVwLL3qQmYR9vrfQc49kmfrTk+kqINwnOGUTX41Ze+O8NCvxn/hDMY4ERKP/a/+/kf/9DSerUqb8NRbu7Jo+tt05x7VtMHCXoHtXiFjrwsLb+OlV7+gf42SXdhUKZ+9oq7J1T8LkLR1fHJ7663VWQerQgoeq84jImviAtmJV2oUSREtzYoPBLCbBYsTIP9IdpU17XWjhZjXSIAwFbu+92haMJaZ/V5gIXiIy1Sv1lV/eSw0MoCEsD+yOYMNMCkpKQ6n5N2ik6UVh/hMXEAxan18Q2Oq7Q1e+h0ZieYbA7HOIPRjTtpv7DS18IZbMEsLkDtt9QSqlMq2XWdt+9IbTSHAKBasoJyHMm6ZTbVJNqvdDoIJgE9GotJqkajASZz8uyH7LzeB6yYFQb7aG5dHwDCZ4V+2kKwPQnQ6cbt1uAXyYOChk7Kh1nfoHCPEXMAgOr6dfquT2fWOgOUZU+zEk9czuFOkuFlVTUmfN716R//0N50JKX8eFRZZYGfpZXZcWU1In1BOIMDRNybZ4PHFxi/Ph72Q0bHXL3B7+i+cx0jHlB3HRcd8bHjwrNziSmZwvEcMNmGOt043LGSGWkq3C5ViUuPVQhZOIC6VhJaYbcwu0aQt8xED8cBazd9hTGnLs4Su7d8vrHorGT1mPteXpaWX++yvfyDRJtx4TGYUo/ZKekausaj/L2mnuzF9JUWenmumAHWvb9AN/7gw3QHve8ABz7JiZReFqpudXUYRtWlu04ei33c6JsF/zxPkcyMqEmKcPEUrs8qPHTpnc1E1/sXrd2N487GVDdl5qVIpFpFAgCoe3tUmCBRP30BUMllGsMkgyLJESA43iGJP9t98kNpGHW1Rr9iyz1mg/tQy7mGi/VD3rEBU8cpzlnEogdkZmWG+lU0k8W2yZKmupJy9pjqwlmLWPRAj8w8IoyoNBQAMNkcxqhCpjSfrlaNzHxVKwYY0JTpOkej0Ti682G3RS4OtHIIg8XB1IoB46o08lb9qZouDSX7tAeWbpLw9JdfI7Ju5dRqzMbsU+PQGaxxaH8rhq51jbKFydGG2dJAp8J+MzjubEz12bSVOtTZ2w1X3jSvUJd136IWreBOGkipvvYumvD2MSQadVtdD82O3CwiNC2VB/KzMk70OOwrZ98YP6y76XpvY+uQR6T+2m7oeve0rcNxAIoyHdeoDP7kwmJhapncvKaQ1Azq9afIEQpnuq+MTsyWVp0u8tPUneu2UcuZxeZw2BwOm8MiAICw/jprpgoZQhQbgHV91NT0UTsjeIOH/QIMTZ2R8zNcmaBRmdZpa/plQ3qLzNDxLHBsQ2tkXb2Ue8RWof7GD9Xfay+YHBqB4crE1GaFSYVyaPLpUwSs3fRldfI3yzkWTWC5EqMqpenhCqWQqYD98pMfVtW9PSrMN2Hj5HHBETjzewStUZm6Sik3xMqT1ZkZGOWtabnc3VnfRnvH6Kf9M+p9DAOKNvWY2hilU/jkiJqkCJZ5VO3+4OK38o6g53wGg2MYrVIqSNJ8rac4lRKeUnxZOQIAQPb3yEnchWOd6JjCGD/oKJM2D1IAlKbrrazIpJIWEoBgMHG6v6t3BIBStZVJr1IMUCs1AL2l8WEp0o5BEgAotUyuoBe6shYCAAArLG65qvZALemzQWgvn2IYBuSgUjNCUeAesYGrqTt0tp8EALK/9nCd6uUNsTZPQBzU5R6T5K2pkx65pqYAKFVbaUp0SmkXBcDbELlIcbKkqkcDACOKhvzNG1KqZ7g6AQBnc1i0rL2PAgDQtFQ2zM4t3ddZajXYWmLUyhGEX2wA0XVqf5NyhCQVrUfyiy70w0Kc4cKkB9q7NACUuutUfr2GAaRGPUU5k8xOdlcVHXiMoLJxhs7yTIMz2LY0ZgYtJTgsUMm6FRQAqWwsOt4DC2m1ZvKbRJjCGF/4dPpKSY1arVGrRkkAWv+3mgIAZ9/NUYyOg0UNt1SkWtFRVnRB450QNTkLyjo6SaDUGhIAQHWx4LjCI+tQBhfaGxQeyX4g75xinogvj/KDa5VHWjTLo4T6uzsEe/rWLWRxFpK9fQoKAChF/fsthn/jfrHBzK7jhfXyEQAge6tyE+Oyzg8C2VIQJ04/1aWiAIBS9XWqaCaL8fi/lLUMN4dMFTK4X0wY0VEq7eDERSyeuq4ZOT9jhXApdf39czISgOyvPXBaZrjOnqnjmbFvw8lLOJgsBq262akCAPJWbeFpBYGRKjUJABgArVYOqUmKcmgEhl/oUmh/72iXhgJqsPXI6R57qjgM2ClSpelkNsflG+QcM8vjIhf1V5ZdVJAAoO46fqyV9l0f/Hj3NaeCYDBxWtbdN2lccMzSYAHjdk1Fs4IESt1bVXHFKP1kdWaIIn3I9uPH2kEU66NfLGHZ+z3niyx63wzLnQ2qjk4VAAAle/90lyEPOPRJxamU8JR9TRajKvZ9zmPfepwNz/kMxiMywkPz3qaguFLTcljOxvJCH81v0oXL+Fx+VOY5PKlkT7TNRTozpOidPE/V8Th/Ac8/rqBv0c6jeSICAA/c+XowXr9dyBeFZl1xlRQXJS7V1KasLYfcsrzFspK4IL6Xd0hk3lWORLrLz5BmmcIYET5KCGNW2M27TJ8oP6K9IEyc3jAI7KQy6VaiQRIu4PGjJOfwpKOHJi1z45rq4i4LsqiLtaHs2E523751QTx+0Oa3hlYUlud64wCwOLO8PJaoy4rjLRMIU89SodLylGnWhVjglpSzmXU9RxgeF5u0t9MvQcigqVlcErlYapVYrjJp5Qhnv4KK/KWDh1KE/kGJUrlnvjTXGweP5N2JLp1ZYTx+1JZqSCoslvhAY1bUFL+RtjU7KW861/A4LwKxdob8XqMz2MKaQUsZYZlZIvJ4rL/AN76w3SO9PD/CXXkkLvWsbY5mhhS+vWvaSq9J44Srw4Thhddpur04Wrg6TJh6vB8AcG7u0SIReWp7dFDo5pIuVvqx0ojJN6IUXd0qeDnMvSMnNWNLUn6L957qdxI4OOAeMZvcuxt73MS+UyQhXBAZCL03Nd4RIkPRjNAdO6drHS6QZEdhZxPDo9a9ll6mjtjqh+lvyTj75VWUhNCVGUI+nxee30Qkl5esdwVClC/dzrha8FoIdxnfN+mAgptXnjH5SdOMsQo3h0wZMtwNsYtoWBoVyp6ushk5Pye2YLeQPrklhOe/qVQWkBbpYpzCzNDxzNi14eQnqJy4vJ3uyv3RAp5/ykFl8O6y9DDmzfzonEY1e+16L2jKFIbnt5AOjeAaV1AUCU1ZYSt9YzKbXt6a6IZRpG0cOgxYNwfpyxK3136WZJlzRLPLOSZwz4xyqZg6kRrG4wsiC25yMspL1v4DXnOnHxca0ieNC72OT1m+qyzdXVYS6y8Qbj6iitwmYuifqT5hnZ391nhrbvZAYJTR8Sx7/5BytUXvW5wlTN8tJI/Gi0OjEyWVCzckumFAU+DYJzkbywt91BUS06j62hu7bUfVfwzzdGPayUfn5h5Oz6qw6nxi9AXRB3aW3M9dnZ8DYQuzPzM6f6vCmprUsH2k/bWu6vqM2NaI+pKABQucXphDOs8FYV1nwYZMKqupNNB5euGZlUxRugWGTXZvFYlTlNsuv7N+ivw/l6yBhJHw0xR2crBSz9EKPoeFImG7wpS6r3r3kcHA/JiXxnW6p6bGP5vwZLPPfZ2/bWGy83c94LJ+2Uu68UmOqfmkUc6NWPanqjNUwmY/mDM6P31h6vZH+wtbvvfjd/3/1Y7dHqdk8nJu+F5N3FulP+ExaNn7R1tH3ZNffXG6wueGNZAwEn7Kwk525z5zc7b1zAn3l8fFndSwhdvKd4u+a+9XX3NQ5+dAeLLZ577O37LwV78vSiy4oqQBay7YOJZVmW9zO+H/vLTYbd5npz8XJifjMEd0fvrCVNtP/XddJ5ZG7Sv+7x9Nf8oMS/7uml9I/1xS9suYkxoaY7y8IrJIuvkHU/9GdE5YAwkj4TkgjJ4iIWEkjISRMBJGwkj42RN+zlfyIhAIBAKBeC5BMxgEAoFAIBDPHmgGg0AgEAgE4tkDzWAQCAQCgUA8e6AZDAKBQCAQiGcPNIP55mgupgoCi7ptD3eVBPIlNZPfGP80UFQm8uJPfSv7VNilLYcvyGh9atU7wKyVojzuidjnadt5rqBu37s23Ootn9Z05PsL0i/PfHeuJ0Vbxqz8sMdRCDsI+emZyYmzDxaHes6UkfaSteE5Fx/jjdXfFoPVKbzow/1PvFzZgVB+StUcbviM+MYO8NjFOuyX7tKZqaS5mCpY/cbNx9YRzWBsoPqbzl97Iq7gvrn8nWzRNG9WVrZUt03xdnPEtwMrrriyMHh2G4fPhpGehos9s9ia8dtA1VHTJJ/tJIJStZWlirnLpsxN6ubCgpuerxfMZsPhbwde1jvHsryfthZzD2e/rCKhcn+BnU2UbOnaG7iM75vVbNX/ilOx088DHiO1frP06NDDUdb9ZswkdbjNZPh7AqAZjA19p6XvPc7uOZMhWJ4ebtP0oOzjsoor6JL9qYOz3DzdWY+/X+A0kO0nD5zumnKnt2+dwfbjpfWzm8GoW/fGJh1RsdgENoUU1VlxpJ2zeafft7Kx2+wgOB7cb2fDuWcN3FOS7qc4Im2bwTwbWwjtBwqbZuvPn886tcoavkl6dOjh36xYxIxSB+Ey/fD3JHj+ZjBUf/3eLdEi3jI+z18cm3XYOOun+utLtkSLeXwBzz9q868+vKUP1a6SQH5OVVNJrL8g9jc1Of7b6zRDp1MFvrltFACQvVUFknWhwTy+KDA+50S7MWjJ7hNpcb58AS8oLqOy234om58iaS6mCtZKmy8WZSTGx4UGiddmne2nALpKwrdUKckrmXyRpF4DACM9Z3OSonz5Ah5fvDa15KLCnpNQqhZpxtogAY8v8A1PzKjs1rdPUZnISzrVWJ4SyI8q7AGAoRapJNRfwPMXx+aev2WpItlbVSBZGySybpSmJlWwVtpQlRbF47/eYlurprMyJzZcxFvGfzVw45aiZoNqPSWB/Iya9lMZSYmx4eLAcElhq6EmSnY+J178qm+Ab7SktFVj1931OrfU7t0Sn7g2SLz6tX3mvaPVHSeyEkP9BTy+KDA+o7RVZaPkq767WwyGbagpkMRGR/n6R0mqewfbT2UkJa4NEgfG7200pktV21FJvJi3jM/li9emHZ58IWh6itRZIPby9uEu45s+idWGqq9V5iSGi335At/wlJzq3hHDqY7tbDRdTWrYrtZR2aFNr64t7XTcg9aoWn+9c22QgLuMzwuKk0j1l4yqqiRBqLTXXLLpa29pID+jqvVwRlLi2iBRYPzeRoX8YoEkNjoqMChKUmnS1kB/ZWJkcR99vUTITzyhAJvoSCw4f8veQEZSbllVp6Wx7KkmMOTVqsukX2KIIXmpO8qyEgP5Au4ygW+4JN8i8WGjn1VlJQby+Tz/qC3lHcYwtWcc1dnNvptPGHyDaskScfk5LYaCVCfiBbGVSktfWhe6JjB+r719yE1Pkcwhufm1jeaQtNugrlMZ0WLeMoFvdMah65M72BwaPP84c2gAkLIP81OjfPl8nr+pB60YrM8I9E85IbNXsbqtLC3Ol8/nBcVlmJ2NGmw9IImP8vcN4PnHbSlqsKOzvcAZqc/gBZXcMkh0FwbxuannDQYnGyT6jEH4bBBi18/+dvq7JLjPdgmrS3qg1f5sx54vUW15gemTU+ukLGRBV0lo0nuW6RGAVjWVbAkX8ZYJAuNfN6VHSvlRYWpcIJ/PXSYIjM+p6iHBjocb6S6dVCzQivP5SWIen88LSilsNWYNsrf6V2lTsS3yjAAAIABJREFUaQhW7u2/Ns3s3g5bRymaDkiixa96B/iGSwrrlZSxHLvpTu+l9W/stBo49OXU700MF/D4otCkkotKR77bW1OQEuqvj76U/FqDeqZgSX1tsz5VGoNl+mLtGdZev5ifIk0aWWYyes4c3Zh28udr7ajd48+AsLwi2iuioO3OwzHtw6EbJ7cFCLIbH45ph5uzBV4Rec364y371vH4O+rujWl13cVBSwLCdlR0DN1/OKrVDVTGe4UUd+vLvHMm2Uew4/SNv4zqxu7fPp8d5BXztlyrG7vfnO3juWZP25BWN3a3++1tAi+uYM81W5079gi8ks8MaXVj989t43muTCjuuK8b0+qGG7NW8eLfvaMb0/7vxVRPr+w2vfxQbepKXvwbLfdGtbrRO5d+EeIZvKdj1KaBD7rfCPFcteNc333dmPZed0XSSl7SmTu6Me3AuwmeK0NS32gZGL7/cEx7t2azp1fC2933dWMP7rUVx6/kvRJTcduiUd1DWlOjjn4xqleSvyqh4NIXw8MPbGw7fGkH3yumuOPuwzHt376oSjPqr+suDlrCC8quHRjV6sa0t99O8FyV1zaq1Y3eKAjmBmXX/c+DUd3wrTPZEZ5LeGnNtl028G7CK14Bqe/eejim1Y3drUnlee6oGx7T6sa+eDuGx0+u1CvZd2aHwCtC2qe1VPJv9zUGw67adrLvgW5Me+/SDv4Sn7Ds2oExrW7szsmNPMEvrunGtLqB05u8fJLevnFvVPtw6MbbyT78bbX3xrS6scYsL4NWt9+M8DTYx9SDD26/m8xftePSgFY3pu17M8ZzTbbe7MPdlamrfFLP39FNZWfLzy3pGl70219M3YOWn3vnt3muSj8nf6Ab0w7La7OCfVLP39U3KuiNG0axu2eMX7++URS0hBe2p/HemFY3eku6huu5KlnafV83ph1uyxN4JZwZso2Utl/4eG6rHdb3r3V0FMcYo8NuDHabHNtODD5sy+Z7bTs3rD/yoDnbh59c2Tes1Y3dH2jeE71SH0EteSu5K8LT3+64Mzx6//b5HYIlIcV9WsfGubU/nJd0/q5uTKsbu1awKiJsTUhBhzFqvCKK+6x86WvtwLltJl+y/DSmGXrcHJJfa0ctQ9K2pUt8BMnFbQP3Hw7fad4T4flq+qVhrW7s7rlknj7kLUNjWH7aHBpDddtX+SS9fW1g+P69vtNpq3jRb96yPPFec17QyhhDTrCyc2OWF5cfvMNonOygJQEFHQ90Y9qHHXuCVsYUNH/xN+3ow6Fr0o0+guzGYasesRM4+/84qhs4HW/IXVpdnzQ6OCJs1Y5Lw1rdmPZhczZfH7Nj2odt2Su8Uo195+DTkSdYmd02+sXJjTxB1kcGC8sror0STg5M5Utf33lncmq1zEIG9Sys8fDSNlN6HHg34ZWVAfF76m4PP3g4dE0awzN676394TzBjtrbw1rd6N22N2I8jc2x9HArF7UoVtdXHLTEJ2hbcbP8/sPRO82/iHhlpf70O2eSfQRpVY40nOze/9O42+jeDls33JYX5BVT0PzF3x4M3b6UF+QVUtDxYOp057kyYd+1IZuBQyeviPbyST1za3hM+1Belxfj47nEEJIWjvSgY0/AK8F5zQP3dWMPBi7lBS0x2N8ULP+rHdWN3TUHi+NiLUu2NKyjfvn62m7L4c9iZLE3eu7+ZCqXszvQGz/P3T0YUkMC4ASBA+BMbtLRprbSQBzI9tqrpPe2XUIWDoAzfSTJK6n2hmskAA4A4Bm7cQWTwG2eIsguVPWwt+as92ACAMGJTN/kPnCxXg5Ud+P1UY/EbQImADA8U7ZNveW9AW7Mdm8CAIDg+bmDQjZg8//ByxfaseDtGT5MHABnhWVs9lA113RZz4Kpm7X1Q4tTsqLdCQBgeiSnhS7sOndVf3lHU25REh9XgsCBvN78Ofht3uRBAOBMv/StvsbLZmOjPC0ademS3GA81pqtYrYzYfs4xVlcUP9xxU5vBg5AsMPDPKC/Sw6gtx5DlBjhigMAcLyXMskBhQZAdqVdtWiDJISFAxBuGyQRk3c/NoDzNsW64QAADC5vESjkKgCQXaiRuUTlJOiVXBy3LYo10FTfa6kkYVLSIyLKHQcApvtSFmCecRGuAACsxe4LSdWQGgBYEWX175encJk44ExuVKgbJeub9h7ySHtZRrkmqrQgjAUA3afrB1ak5OnN7uyRsF1MdNZeHZzCzo6YsgfNUuQoYAv1HeHMiZB+3FIRyZiqWAwAXERxgUwAwBd5cjCaFZzkQQCAs/tSDqj6p7p7bxsd27f4GKJj9qhkSorlttgQEfQISQNGEAQAEK7CvHO/N+/Qzlq7fas3yxknOKFrPDCNQkE5No6bL+97svZeCgBkHZ2ET5If1tMuBwCqt6OH4IncAcDKlzy9jb40BdOFJAAAYIIt6QIWgRMskWQjd/TTRuuQtAwNZ06EKTQGW9+/DqvTUniuBMF0X19QWrDVb6HpzJGew5KCvhUlh3K97ecOhnCbwTiR2za4D7c09QGQLdUNpO+OXCGbAMCZvDRJAN36UbtlN9kNnIY+YPFEnIFrvRoAGOy6qfbeGM2St8sAAPrb+8AjYAUOAIBzlnJgQDaT5ys4O6lwG6vt4P52Gy+ZmS/Zy0IX6+XT1crdmhnCIXCcyYsOXQQqpQoAwO0n716oL4ngEAA4QxDpwyLlstktA8D8UrJFHALHWaJIHoPSZ7ALVT3sLT9bN6WGVu7NCsw1uLfD1pHt566o/ZJzhWwCJzji7PLSbSIGPXW6A26MhGfrpYrWZhkRsjXOzRkA54TsjHWz1y58RU5t6wd5IhYBgLuKI1YwNP0y4y0Pe8Eys2InY7dfrDCPLI83ejpm6h3EnkE8NuaKu/M3hzW6Lxd4B4giA0XuDIChfhXN9HMxbV9HsF1Y9KcKvaUxljvHzhIISjWgovv2h/P3WxzEWCogNSpyIYdlGlFYiznYpMcutuBMhtXmeZPuz6lkKmAFmxVhslyJUYVSA34WC0xJlYJcyGKbj7A4LLgsVwBwADCmC8vgDUNKFc0UmBZ24CwWA1M6bpTLEMAPAIBgsVztak9pOk8eONEqV5H0xATMo2nwoyn9BAZjsExPO431UaohNeZiPs5yYTkY2TEGg2nSEsOApikASjGkxlzcza1ctJiFnVYNUcA2KWnauZcgjIbFMRwjGMZ4wHDcaGVacfXoWxc+U6hIGgCoUZpg29fGhKphV16za06lYYBRKwc1dFdBELfAQoYxoHZsZ4c47kFLy7tGpic25mSGi9kePIEwQBwa4Mm046JWYISrwSVxDMMwJmGwBI7jAEBPcaZtdDhzXFh0h0IF4D5NnZMZ0YyCuROIsMz0prQSsf8pb2+eQBgsDuW5GtqBMV1cwKihMw5qmp7COF6BS6Hk034IZHbdJD22iX01R0/2qsFtsL0P887zAFBb+xKG43pfmgJ9SJq3gLYrbZkcmCzWQnpApTE7OliFBgAAZQgNlUwFLkGmljC9Q8IAADQAQCvfz0y/qhYe2+3naFaKuXIXGf92YTEwUqWhQKNS0aQs0/uypeTLKounPo4Dx9Pbm3GivZeK5PW0KxeLA72J9y+2y8Eb6+rVeCTyDO0hGASMqmc4c+Ukv/7fzZuLD4g/2CMwH3XsS/9ioaej1ApTDZkYw5TfrPqXlH/06+Mf9yg0JA0ANEm7jEzl7ZPLZXFMFiMw3ELDNyN93pxKQyv39lkVtCZ8hSs+ReuwfgUw/di4weuIxcIIAKCapkp3OJNhNcRTAABqpQZYi8zexWETdvOOprtK+l5Lj0pD0wBAkbSHSR99sOgALIxJzrBYaxz1iyXmkeWxRs8pcHK0q/Uc3Ed7ZsL/vqrgvStp8q6OT9vaLhQmHXnnv8uO/xibmICJR48sS6MAJnTjOpiYgIlHunGdPpPpHk3AxKPxcZ0OdOMTgL269/LBSOtJok714QSAXgYAAMbHvwawKNzwx/gjgIlx3bhON/7IqvbxRxMwMWH6OjGuG9cZxB/p/wYAgEePJmBi3EpnnW7iOwAT5qphfHwCJibGdePj4xPwne84GU4fB31hxnP1het04w4bpSMfTcDEdx7ZMzjVVSrZ1bF871vvR7IJAKr1ZyF5jx7pdOMLdDbWM34dn9C3y2AN3aMJALBQ20L571g0GfRt0Z9uLha04xMGC1sqqf9qtrzu0YS+T3VmK+t043+/vDf910PiN44cDnTBAdTn09b8Rm/nRxNGY+pM9gEAsu//7Sz5n4DSD9a9ZCx5YgIWhh66UuJrbRid/HeO7Gzd0IkJmHg0PnUPWp3yL8sy3m14TfbZ9e5PrzceTik/Hvnm8dd9H1k7klZr8XUCvjNuarvRLAtMZrE2vk43buFv47bRoZugLCxp6xJmx57kKQazm914wX9uOHw5TNH96fW2T1uPZR49tmrvyX1i5qNHE5Yl6119fArj4NxVvJGqP/z5PvOa0j3ilX/9r7+593/y6d+XqXpIbvIrC/T+b+FL9q0KJj+0CknD14lJzj/+CGDCab5Jn0cAhpA0Ot5XjkJj/BHQAJMUGH80QZO9soWBXtB04Ej88Qx382TIZI0JgO+Mm5xqfHwCAB7pdOPjE+CScPzjny21Mbmu19gjdgMHQKcb/9EqL+xX1z//+3d+J1vkk/fij158mTzV8+U9+L1iSSj/X00RBJNcZVIHmw3rnpCf2LytsCz8g9ceGfOAQ18CgOlTq1WuM6cR3aRcYe5f1Yd5P62iE0pPlS9n4gDK9+Jf+1jvupMyqrFki2Jhigw2nYZg496/yXr7N6v2ntwndHiu8oUJeuKR1uR1lvo4THePHhmFzV46/oi2atr415YhaSxZfmh7fj1r+4HqjR5MALhZHJqleDSuswgWvbB5EJmyWFPJloZ11C8AYDX8mUaWrybsjJ7fYFYw38lpweQPANg9/iwI677S6l74/isB67bsKa8+l8OWnW38k9MPXvkhphn4y1dGYVI5pMFcfvgfC5yc5s2DefPN5cyfB/PmL1jg5LTghZfYLPrLvjs6kxpf3X8w7rTA6d+ZTGx06K8PDKeM/+XzIRrmz7fVecF8gHkLnBY4OS2YPw/mzTebev48mDdvvnGDTYPMS6+wsIE/fTlu1OT+lwOjC3/4n/9m1cDvu/6AGB36y1+NB3Vf/nkIOO4/clqwYME8mGcoysnp/7owMc29v44bvn715ZdD9Lz5lo0yFfvV/QcUwGQlLT73O26OskU/jvnRi05OCwAGbg6Y2mtjPcPXF/6dSdDDf31gtMbdPytpmLfAtmRrnRcAgP7rCz9is+gvb//FrMDtIZr5gx++YKEkGHUGs87z5wHMMxU+fx7Mm+fktODPn/XRbuGpq3/wgtMCJyfdnz8foGH+ApO8Xqv5APP05Txo+lXuJTz90G6/75pU/T7nh4xR5Z//YtJ8/MFfvxqfys42n3nzYN78aXrQ6pTxr0gK//4Sv5jNP3vzdHWRn6b+wz+OO/3Lv8wDeszUd3+/N0ybrDEPzJZcMNksFsbXm27BfIB5ejvYRsdXf7lnjA57MWjh2JNj8Lv/RsDo301FjWu/+srpxZdfFSfn/urdi9Iw+pPzv3/g5DR//jywKHn+/Hkwb8GCKYwDxHL/xUM3/3CjQ84WeL3o9F0PPqfv09/f6BhaGvTqiza+BAA2rjXZFJMdad7kjlswH+ih23eNXx/cU41iri/9m4XjWYWGk9NdU2i89AoLU35uCucHf7x46uM/feW0YP48jCHe89b+N4vEo9U5hz7T2qQvvZL00F/vm5z/r8M04er6gtMPXnLFNLf//MAkrH3wV61Vj9gNHAZr0QtOC15YFugx+vlnv/99L8F79T8WvODlu1j+h09v/EHO8V35faO89u8kLPy3F+30rIVNLOyMu6Xnx+ANRW/96aExDzj0Jb2L2qRWU7GG1Grtok4L5pk8zaZDTV/H7/yhF5Ykpa34/gsLnJwWfPXnz5S0IQlYeLh1yRbFOsxgL7FZ9Je9csqRhpPd+51zpXr3dty6//uS0TgA4OT01ecfn77wxwfTpjuTb5i89N9/6AJDf/mrsfwHX36poc3Ob3TXP/UOYYJNicv1/Xv/z3INPW++lfUMqcD4dYpiLUu2NKyjfrEc2qxGFruj5zeYFTxv62DU9Tni6PwamYYCAFLZ2aW/LUb4xQYTXaf2t6ooAErVceg3nxLCGDtP4DAMA3JQqRmhKHCPSfLW1EmPtKspAGqwtSQlOqW0iwKcF+a3sKf6+DUVBZSqs+LUtVndtLQEx4EeUijIEQpcQ2NWwNVjFd1qCoBSNpa/38+OiPO2eXawPC5yUX9l2UUFCQDqruPHWmm/uJBJj34YfiFLoP29o10aCqjB1iOne4z/MTbqmkWj3uye+nY7wWGBStatoABIZdMbJ3pgIa3WTPWbBW6wgHG7pqJZQQKl7q2quDK7BefuERu4mrpDZ/tJACD7aw/XqV7eMNOHsrYwWQx66LNOFQCQt2oLTysIjFQ5uFVO9VfmFPct3V2asNjK8LwNkYsUJ0uqejQAMKJoyN+8IaVaPpWdrcAAaLVySE1S1Ix6kGwpiAvPeK9TRQEAperrVNFMFgOHhSzOQrK3T0EBAKWof7/lG7y4CMcwWqVUkCRF2UbHwYoOu9FBqTVqtWZQQwHQpEajVmsmm5HlzsZV8n7D8d7S+LAUaccgCQCUWiZX0AtdWQsdKzWFcRh+QnZP7alOYvkKFgCwvT3wzsoLMrbPin/cTzZpABhtrz57iwQATefJC70LV4ZZhaRVaDQWHTeFhqswxhs+OXioY5Ak1bKG0oKyiwrc8GwFAwBC8HrRBqwhp6htch9SAIr64xcVJAA12Hq8RuYiErsB4H6xwcyu44X1chIAyN6q3MS4rPNWK6jsBU7sejcAAJwn4g5drOygPHgcACCWrmD1VlX2Mnx9TGvUKEWfAha5cwAAqJ7zhUXnb033a3vcI70oDquTNhiXPjj2JQyfnFqv2aRW29LN6dGhAgwXBj3Q3qUBoNRdp/LrNUwgNWoKrDx81sXqNaz/9bEpNbR2b7nRvR22jvCLDSC6Tu1vUpIkqWg9kl90oR8WPka64/j5sDXNJ6rlIwAjiobSc0ps8mN6gsHE6f6u3hH9a5ykVykGqJVTZeIZFTuFYWfCExw9AeD5+zU1M3LP/kioSYvyXcbnBUlOkAHS0hhXAGe/vIp83mD5Jl++wDfpgIK362RhoLOd832i/Ij2gjBxesMgsDaUHdvJ7iuODeHxgxLLVSsKy3O9cQAi7PXiTayOXdH+vNWZJ4iENG+MfqxuwHnrotjK/evCUirkwIzYfySd1VUY6S/grZacIAOkR7M9bRc/4J4Z5VIxdSI1jMcXRBbc5GSU77e3xpO1fndRJDRlhXnzozKbXt6a6IZRJAUAxkbtWxdkatTPeVOvsWCEZWaJyOOx/gLf+MLr3O3l+RHuyiNxqWcdrvnDebvK0t1lJRuFAcLNR1SR20QMgFn4OzupTLqVaJCEC3j8KMk5POnooa0OFwNPAycu76duA/ujBTz/lIPK4N1l6WHMm/nRdt8YK6871zeq+WRXuPnX1Ly0hhGAxZnl5bFEXVYcb5lAmHqWCpWWp7jBVHa2ak503HJoygxeW9BCzqQHCVG+VML4JD8+iLuM75t0QMHNK8/gAuACSXYUdjYxPGpt/PYydcRWP4yiHjMBeERGeGje2xQUV9o7KTq88+xFh/xoaphwdZg46yMN3XcwPky4OixS2mEjhHsEeON97YZcz80ty1ssK4kL4nOXBUXmXeVIpLv8pnC2qYzj6r2coRwAD5/FAACw2HspqRxgCX3sr9x6MlCALd8USR9LEvvyozLbGYm/3mU9sbMKjXaPdHNoMCNK3trO6SmJ8w8KTT2lFhZVZFqPSTg3t2yba2thfr31wkeKBlgoSgmQFW8K5AdFFindc4p2euOgT2IlIXRlxmpfH154fhORXF6y3rr5dgInha3/F7HCj61Uajx8l+IAAGxvb1ypxFcIzVr1tPbR3AABAQBAKa/WnruqmN65cM+MvChimDRKOvQl5srJqdUyC+XaXq0B7h1jTo+O8Eh+PcGlMyuMx4/aUg1JhcXbfaExKyq/nbL08FkXC6wNZccyptHQyr3X/fITo3s7bJ2zX0FF/tLBQymrhSGJUrlnvjTXG3+cdOe+Tfq6j7oyxW+ZILKg229LBAto27VueODO14Px+u1Cvig064qrpLgocammNmVtea/9MmdYrHXqmD12Rs/HzWEAAPN0Y9rJR3W6cSfDjaDpQcJIGAkjYaOwrrMgKlO1o/6diKlvjswlnZEwANmWE1349S8uvLX6xaepBhJGwrMRft7uwSAQiKcKviIj21tx/KDt72wRcxnqVsWRds62jED0xmLEswSawSAQiCcKM6SgcHlncYnjnR0Rc4uRrrL8VvauwoTHfVSLQDwdnrv3wSAQiKcN02/P5Y+fthKIGePsnXfpYwCAqX5HjUDMPdA9GAQCgUAgEM8eaAaDQCAQCATi2QPNYBAIBAKBQDx7oBkMAoFAIBCIZ4/nbwbTlsMXZLQ+bS2+Ec9BE6ZAU5MqCCzqfpJF9pQE8iU1c/SXL+TFNIFvge2b32aM5uITN9eTgbpVnhiYet7mrYaD1Sm86MP9T0elJ4Ujm7fl+QbMscBsy/g2c4U50Npy+IKstm9UmKIykRd/aiY7YT8NOvL9BemXH+Ols3rmYA7/ByTeOcDzN4N5ilD9Tefb5+g4OndgiHKO6V9oC6BsqW4bnEZ+LjBrPUd6Gi72PPMvRBnpaajvtd+KkfaSXecYO0vWcwBA1VHTJH/sZI+YAVR/0/lrdnILL+udY1ne374+zwKzd8vnImwduYpl4n1+QDOYJ0jfael714eethZzHqY711O/Hbusoaziyly9CLNg1nqS7ScPnO6a3WZQcw+y/eSB6m67rZCfkF4htmRHMwEABtuPl9ajGcw/lL7T0vfaVZOPExwPLge9hc4es3fL5yNsP3fgKhaJ9zlivk43PvkD+s3NZ/aZY8KPJgwbxI/r/n7rbP6WEIGAu0zgE7bllx988VAv/Ic3VvvmnvrojfUCwfp37uh0X93+6FevhYl4fFHI1l83/PbXa/lbTn1pKOFU/k/WhQbz+KLADT//zSf39XX9/bPqn2+K9OHzuXxRyKZfnvrsge5hy88F2+s0Q2d+EuCzq+WhhWKfl8Vxw379ufnIrf8Xxl9b9oVON65qO/qTDWLeMj6XL167/a2r98atm3D31CZBSOktYwM1Zy2+Pvy8fu/2xBCBgMcXr93+6ytffqXTjet0X33+4a9+HCV61duHJxCvzzSVafX58rdvWdbbrtabruWnfPEvP6j/eZSAt7X+nrH5a4NEls2f1Cl3r5T+RK/G+l3VV97Zwot663PduO7vTT/hi/KuG4UfNv2UL/r5J+M63f2zWwWBhZ26P7wRkvSekrySyRf95MP7Ot04JfvIXotsPnevlv38/7P39mFNpOf++L2rV+bX/hyu05Nc31OGb4/J1bPgdoWIg5FAkLcFAvJm5EWKaEU8RbSwcBalXRa6KBaMlcWuinXFV3QVdBXZBXEXsAWxAm4F+pNgbcJWEw9NkDJh40wG/f2RF/I2AV13V20+V/7IJPc8z/3yue958syTeVaGi5b6RUSu/tWpL8ZpeoqeemTeyZ2+3/X7PEMjYSEpv/jNZ3eNOt/v2p2XHiIwkOHnv/rYRAY7G20NtNXzq798vONnCWJcIMJF8Wt+/fGNBzYajp5aH72lXSvbsxqP3nGNnnr0GFiP/nG56hcrQoK9BWFxeXXmUxiCaEX+R48BHj0ytHztw7dXRofhiwS4KPlnZS23J5+Qz/TolQ/fXhO3XCgQCaPXvX3s5gOT0+ycY7Ri+IO1BissbZz808kLyjdWxvyIpqf+8mF6fPkgdbUiVJBeq4CpqcfwmPz7Jzt+Fh2GLxKFpPzq3F+/cmhsu5K0j6+DzKKnnHLDyAd8UZiZDwBgakeEC8Rx63eYdGh7WyD+1cdtu/PWrUyIDwlP/nlVD2Hw84Oe329MFgpEeHjyLz7sGZ32ueXrEcxUW25/mI6vPtxUtS5EEF8+ADQ9aswOUfxPixuvHDNlhx3xaq9qZqwtJ7JEhtpiQdG2XwhEv/iMKYg2VXTmBDcJMzBtOtEePQYAgMk//Dpkml1TNP3VtWIxvrruSxvX3e+p+1VWpEjkLRCvzDt8zVCUHgE8NjnZOm2lHSrnfLDk0opfvG9fKyxp+fu/TpnTdmlAMC6K/2lxw0xp++jRY2Bpvzialx4iEOCi+J9Vdd032fjlZ7/9eUq8UCDCRck/K2v8y6T91WqGyxAA0H/aESJ4ezZpC8SgfR1mokpRyCZLqlgbKAop6zGz9PLpX2f9dE1cuDgk5dfn/urgMmHzes4u9KZDWq+zfz3UaR1+/iIIN+f74jmtOlo/3l0a/HpEUevIKK0fH7lYFP5GZHmfjtbr6L7ysDeCozfXdKtGJ7U6ergm0VeYdeTmmH78fl9t1nIh33ftSZWO1t85uVYo2nzi+t+1tH709tmCcF/JgWEdrb9eHoEn7rp+X6ujtXe7d6UJIsr79Dp6pDbVN3LbdTudh2sSfU1d63V0X7mxnZETq32FGQeu39fqJlXXD6wVCjbU37cy4c7hVXj4jusmA0dOmg9VF3KWCTN2dY5odbT2TmtpLD+itM9oS2xJx51/6rSTquuHNwSLCponbfQZOZFh3e+SrNP39Tpa35bvj4skRScH745px83m96l0lubbBOX+ybV83zRp3yitHx/pKE/1x19fLr2t19FjF7J8hW99bhLWXsjxFeZ36Gj93ZNrcVFpJ63XTV7cwPct6DAIqC5sdGiRtfKDu2L5EQUXB+/+c/R2xw4J339z65iO7isVGUN264AEF6ytNej1gG4VAAAgAElEQVQ8eHKzyDdWOqh7qNO0FggFa2sHx3S0fnSktTTR3xBKBzbuu2UbQUs9x1oLRL6xRa13JvW6SVXbthW4YPOF+7ZsvCldjiceuEXrdbR+tGEDzl8myT95/e64ZmywNsMfTz1yx1kQrfh8t8HkrrGLmwW+kvLuu5N63djwiZxlpnZmy2fd4C4Jf3nBmT+raL1urK82a5kw6+wdWj/O4Jyb0uV4wv5B+1zr2xHJX1U7Yjrs+KWQv6F+TK97qNOOHEl73T84tfTC7bHxSVWnVIIbvnJg7Jvv2sWXIbOYuWHmw+TYHTMfHv79dJY/nrqj7b5WR2vvXPxlJD+itFtrYLg3X1LaqtLRet1kX3n0G7E7/6yl9aOtBUL+8tIOlY7W3+07sEHk623wufWr+a2ZasvIkTS+f2TWjraRsdF/6rQj09kxOni2INFf+Lqk5rbeAfHCZlFbzDXEIgebc0wqMQTRUnjmBDeQn5lp5kRrzvfFNzZraf318gjv6F03TWneVrQMzzp719pvtw6vFYpyjvepRsdU1w+sFfLXnhjR624fkPCN3nCctk74YMml5ncd1wozLS3T9p867aSqrVwyY9q2Ffl7L4nZdKD7zph29PbZzaI3IssHdbReN9ldGu4vKWm9NabXTao6pauEooLmMdur1QyXoYc6Ld1XHj67y9DxNQ7qMJNzHt750JIqFq/pwjtyJO113+CsIzf/qdPS+rsNG3D+5gtj38jl+BsXfonvIiFLCuvbTxeFYSgA4iGOXcLWDMk0AAAIAAA/adUSDoogIG9vlaGR69M93QDh+KRtjXc3bjQtO3e8n7u+cKUPBwBQXvym1V4j5xuHAbQEAQiKoggAwl6SV3v10wK+E0V4wdE8Tdsl4z6eNxuvqL1ixTwALLaq8aPqTG8OAgjHOyHKk5QNzvJWhbr9XBcS+1Ye7oEAIFhY3tol6o76XgBCQwAgBtU43hn7WjoqQ2y3fMViqz+tt+yXGjb2iwCFBqSleLHdEMRsPt/WfEsQne2DELgqxwcFQDwCN633YwHyNBOV6vZzV1nLHVhkhb4TjSqfdQXRXmwEdRfllksLl2OW08Syc2dk7gmFaQadFyRvSMBGWhoHAKgJggIWiqIAgHqEFjX8sW49DxzaePGikx1ria76K4Tfhi2hGAKAcITZa/3JrqbOmW6dUzzJ1mRvDoK4eUVGe4FcNgJOgsgAN3FJ46c1b/mxEQA3Xmy0Dwz1DgPMms/Qd6JxZElmUbwXCgBuPmkbxWhP/ZV7TM5hdoJcrkF4XOZNob3X50XyUATh4IlR80GpUDoy1k/zBztjHWcWMzcs+YCZ+aBs/biLFbExV8hBABAsOneNj7L1TC9pcBUvfk0YBwAA8Vm8gKWSKUgg+5qvan3SN4g4AMDmZ24Im4HCzLUFgCI9E7KFHiiKgKbn0iASuCbHBwVAF8QXrPYybcJrR7x0z6eqLdOYVRBnTHAD+RmZ5gDeKUmvKS+duwkAAGRvayclTAi13mtd1nSmnx3/3yv4HNSN472+rPzdJE+romSXtvHuhrRl5IMll0J/keE8cezTduM64WzSFovbuN4Pc0NQXtRyH5ZGLicBiLa6JiJg89ZQrhsAwsFzsoOp9k+YNwF7BpehkwPzHdXhp6aKQS98tTEKbL7ffJAPO7rv9ALgpd5VQNN3XHqsrV+poSgAIAnKx/wVy92LZ0witUID2HzM9A3PyxNlqQCAVI4oqcGdMYKdFk2yMCVAyPpCYfb2lNCGhX5+i0VRseJArpszPbjieM99dZdvFnrzoe9Cu8YnO9IDAICSX9n3u3NfyJUEBQCklkK5s7RMLlNQyhurF31k+aGfRgOBq7aK+4rXRDd7+oqWhITFh4R5se3OpuTtH7zfcMOi3/802+fBcze8Yzb/xxYfqORKihPINdUjBOOyWU+VCnKZglLdWL3otK1FYKG/WnGPYHlgpk8Qblg8FwDA1CMpV6lZ7l7mWML8BRjrhFJFwk+i8za15FSIg476+eGi0AhxFO6BMNjorgJ4nUFN1ZCS4gS6m8ONct0x6ppcCeDlzDoUwzgANAAAi8UCIE0mOwwi2IfMYJ6m5/DuQ+3DhrgBSUEgRRoq4Sz4DGrFPQ3VWxLuW2LRJntEDahD5zCDIAhgO+CVESy2u/luOwtBgKLI2RordJhZjNxg4MO1YRVgkTyzCRzMA9XKFRoIBAAWh23uEUEQAIoCQqMk5vHM7QC2gMdqc+IAcFZbWByz+Rq5mmJ7YyZF2Au83VlXAZiSy+MpaosZswziTAluIL8TptmBFy/xqTlY35XPD4Sexm4ILbUZ/5HKESW4e5oZiQkTMQAA80XfPm09MVadUkVCJCMfnihxLNLWsGuCG88do7pnSlsWx93oK0AQNwTUFAWgUSopQpbnd8lS8jWlGuBHDM04uwxhs7sM/eVZXIasbWOzOYipJJmS9EXESzyCGa7KKb6Abao+bRja95WF5zmc4SCBAmBNHyMWByz/bZ/vif2e7d7fvHjppVDlzd7utvYrx4tS9nlvPbxvpZNfrR5Ry32qj7X0FyygLrdRi7eK2QAw0VK26bfK6Mr9NaEYAqCuz46qcW6RNcm88ltOp9n/Dg4rq2vPHb72x64rfzhXlrH3UHZ1baa3ZemZaCnbKFWKmfplWbiC5b/t8z2J1vXIcCfyG4FnXsuZdOZf9gAAQMGTZBplfod4pdV8Hivv7e5s726rydtXE7z9WHkYOLDxSQ2kZhZhBkMQHYHskWZvuYpv21ufyEMByLb88EKHck74DPPEe9t+s9RuL3tHzonmPLk5RrAcf2xtLE3bqcGQWQAM3FA/KR8YYB/CGRp1WltYLGfDv2kxK+KZvfGktcUMhwx3EESnCU7TU7NnmhGcyJTAvdsauid84MJVJGyv0KH5T5Im07KMfLDgkkMiPUEfTw4s/dClQm+bDxm2lHoml6Gl2z7/XaLdvKBD5zCNo+zAkKQvGl7eu0jqgX4lS5Ru4A2AclimcUxaDpsNmhHzv8/k/cMGQQSbj1Ej/bLpYjah1BgOJtQEiWL80JX5ZXsufrgG7f3ovPPbP5yQBD9N26W+nsYOyk8SaPgjTu8A5RmzPtTwE40cGlDY6YcgACRp/lijNJnA8+KylDdk01OXhFppOCAnCBLheAbGrSmpqmso5A7VfdJv3aisd4D0inXa7wzmW4DtwWGplUrT54RcpjK2xgIWUKR50KXRMLgfLCz6wpFFFuBwPdhapcI85aJorj3VZjHlg/DmY9SIbDoWqiElxcG4CABJEBOA8vwiMwpLD38sjSavnGnXzM5GS7gv4LHU8pEJs5YKlZrlzsOcncME5iA6hKqzV8sNXZto/OfJSI/8yfgMHC6PrZXLFGZJUq2cIAEYnMOsCYqioNE82V82Zmmsw8xi5AYDHzBPd5ZiUG4OpFIhJ+bxuIyTRsBms1nae0qTRaSiX+mUrLOtLWwPDmims0MzZMoOe+IRT11bTHjCIDpJ8NkyzQQ0LCmY1ftJS8snXeyIFB/brw0dTfNO2X28tnXIIs3s03bYlLbMfJh94oB92k7Inzpt3TGMpZYNT/9bmdDcc9L5c3UZehnx8o5gUDYHoYZ6ByYASGVHlfQKyQa1wkFKLwgVYsrWQ40KEkDdf7SqUWP8leIlyfDTXJDu7VKTAOS99orMxMzKXhLkRzNjMre1KCYAAIih/mECceehhvsDhFKhmSDtL4LssHgh0XVwfxeEJQkNc30cjE2pvuhRAgBxs77shBxlEUq1VTLMw3jziAFDLSblF0+3mQjOCZUEQneVtPUeCUBqeqrz4jMq2ghQNxaKE4vPyDQkABCKnl6rmUkw96u8Yd2vSm2fhCbzO23Mt7YrMNQTuo7t69WQJCFv2X1iwPQNwuVhlOzqX0gAAE1bbZOD5EIQoFRyOTFBAidUEgDX7C2yxsJk8fyh2qozMg1BqDpryrYdvkFa/pbwik3x1lzYc2qIAABiqP6DC8rXUpI8AQYrU6Mzpd33CAAg1bJhOTXPA5vn0MZdfXbhm9YTDUyKQHuP7mxXkgCksnvP76+hoRK7ZRMsAEqtUKkJB1SYDgRDEBmA8jBQyvrkJAChaN5+sB/mUWqN/XMfGPkMeEr8fPnhiroBDQBMyJuK16Rk1g0DDDh2DrAAKI3ivp0VKI/HJuUK8wNyEBaLUirkhDNr7Y1dsW6nrbEMmcXMjWk+TBBKMx+wyBVL4Mr+mj41CUAqmqs/GuLGJvsxz4wgeHTgvP66g51KEkhlT83Rzhku2bOsLewloQvJqx+dkREAxFD97hMyE1ntiJeVlDVjbbnnuLYYwBREZjCSf7ZMm/ZfoCQa7a6UdvOSYxc46Cg2xVvT+MGxm2piQjlwfPt7718lUMRWwDJtG1WvpSR5OuGDJZd6f5fvMHEsaGmbtu/XdD9t2iKBSRGc3oNljcMTAEAMHN+anpx/lvFhUc/iMvRTfMxBHWakCjITVV4qvLwjGCTkrXcikMaNoYKwqPzLHtnl29MXauoz46oHbCV9Nuws9FZWr/YThK2rIRKzQ0zExlKq9r/FHSxPisQF4enVyiVl1Vv9EOCtqi4TqmuyQxcJvAUJeQ1IRkVpIgeAI0wIRK++Fyve1GRPaLfA5X6aG/0QkmCqpLzkol94juxMFOFBme8rIt6t2hTNuVGcWNg8XSoQUXZBAutUekxCXOrGPZrl6wNZxikZTuT2D4v4yoPJQSI8KLl4YP5b+4rCUODEl+6MhzM5Ccv8hHh49iEiWFopsZl75yUXveWlsOw3iv2Fdb9W5m9bEW5lvjU80rdvj4eWnGi/oITcS56r4+ebirRnRuEarHtraExyUsZ7PYFpYWyKtL4wIH6SBK5i54rozJph4ESWHdhib5FNUPmF1VIxeTwrYVnoquKr7hv3lljPk3MzqqTr0absGBEuSMhuQDL27VnPA4CFW6uKFsgqksMF3ovC44uu8LKlWwIRhza+jdvaaKmnW2BRTTF+r3p1gEAUkLFbjm85XBZid/uZm5i8GFryQmOKmUckjEFkADs6Lz+MOJgUJApILevy2VRdHOul2Jucdcp2aMjIZ1iQV12dhDa+vQpfJArNOkVGSaszPQG8GZzDTUxeDK359lYsCF2Myq6YH97oEx/rozm2Ojx51+ATGJu7Z4utsYyZxcSNaT4EBqVM84GzfOfeTVhvWXyQCH8z+xARLN1XwHd2aweNfqd8Nda9JTEIfzPvEJqW48einAxiZl1beEkl74ZShzLC8aDVlbLgnHh3U3bYEs+vtGrG2tJVEu2wtgAAcxCdgIn8s2aaRe8pSfMpWJgQxXX0LTejSrpu3md5MeGBiYVnkNjqipUedgKWafvT31Wt5znjgyWXSgYdJ46ZlpUDYE7bZQHBARm75X5FT522boFFNRWRVG1uqECAxxS3oGvtzLEAA1VW/M4uVZgvQ8m79jqow4zO8Z+JKi8VXqH1OvtPn+jO4ssgTJKAGLOdbC8M3Qrb/ygNQxiEnxOdn0theW160qXIhtNred+pGv/qwt84n4erEjO74k80ZHKfmc4vq7BFLG5uF2cqNlz6cKX96pTnS+cnFiZ7SlLyyPyWSvthwbepxgsuzJC2z7XO37XwyzsHM3soT6UHRWfXDU8AkOq+fbV9EBjhM6vFeC648Pzh2+Cz5/rCCKJu93nXHhpOMdFSGBC0sapXQwJMyE7tb9cuCBU+/Qrp5xSkvKWirJ29Pptx+OLCzHBdhp4KL/F/kWYNLG1npaq4OjtUqgX033l+a6vfiXzpqowL/zL4VvjsFliwU5ydV3SW/+Gs/inzrwk3cdFOWcX7WxNqNRSL/dqS+O07059q1fdzC7IjN2hLF7owoWy702cIuTATXJehp4LrLpJL2CXsEnYJu4Rdwi7hF0/YdRfJBRdccMEFF1x48eAawbjgggsuuOCCCy8eXOtgXHDh5QcpO1ssvawG8Egq+fWb//Fdq+OCCy648AzwykOd9rvWwQUXXPhGMShduUkWtxE9Ut3hteXygRWuFYIuuODCS4C5DlfQPJ9rdr4R4f6KkCxFzqc1KcxFnaFlxZms7DPe0ro8q12HnlCN8abc2J0c6dUy4RPoPKuWn4lwR66gGCo794R+t2p8HeHu4qDCfxS1Hlj+/e9Uja8n3FsRkuOMpTO03Nt8acQ9YZGPh1gSFB/FAXjuDJy98EyuYG65o1BQTFqT+evpTJzPiXaSvN+J66YfyGSqbJJ/e84i+G0IOyhcAACgObc+YQ+vuqMYt3ly1ROp4fDc59gbL7Ow6y7SU4ObUrG5bUVxZeCJEj/GB6kCgLo+O7T8hqNvFr/XXvF8L0TC8z/cDy/enyTJoZYmtd9K0Usz1eC1pvpDrcfTmiPvH9CwuHxv7zA/bwCgv7m9Ob8FfD1XPCna8kV57Y6ezuu1qfG05FtS4ruBoq1O4ZUeMrttR583vKCF65vGCx1Tx3CNYL4GOLFb151Kkp5LOb3WwW4gZqn48pZAwxYVw/uztvQE7KzN9AQAAOTfULj8bSj61EB5PrZbsL4IGDwhPYZWvUQjGBTj222YN2sQQwMjwIvkvRxPx/parnhiBJZdaCFIAADlubysc+6lx4qWvgoAwEI9AG5+e4p865A1VdWotr6oV7sXtHB9w3ixY+oYz/cUwBNDeTxDFFLSPb2llfJUukBc3EsCaHpqC5NiwvBFAjwoOWvHZbntvlfK4xmiKKl5ZxPNmelD8l777uzUhACBCA9KXre9ybyxKi9e4iM/dabXqVII2wPDPDDMA2OjAIBg5kPDNYUFmrbq3LggkbcgLC7/1E3TlhykrKksJz0qSIQLxHE5u9uNe9x2FArExY0dVfmZSYkJIeHJ2dV9E9YdTjTmLo2qNJXXvrJwgXfWWePTU4mmbEFCWb+VUUtDVlkaZYGOXIEotx0ANOezRHHS1vPbc9f8dFVUuDgu/5RJnpS37M5OFOOLRAEx2WWNCtJ4ori4vqloZTCe1aQGAGLgeEl2XHgYLggLSS081GXe22w6LktDVq3b3mqKi7JNmhsXLvJeJMDDk7OlHaY9PjSdtYXpMeKggOCAmMzCugEb24HsKAzaeEGjOpElCtjaYWiMpf3ieH56iECAByWsq+5WWzcVIBA5bgoAet8LEeQeatmdnZEeFyMOScytMmuu7j6Unx4TEowLwkJScyvblQbP4+EVTJ7fFLCirJ+5396KEEHh8ZaKpCBRUq3CWo2KEEH2GbVVINJTk60DYQ+ibXt2UuLqbV0UyI9mJ2ZmV3fb2zhUnYxnfHC+tjA9NTkuXByVUdGsnNan7lKlWZ+J/lOFGQkBAhEuEMdlVZw3pxDRdyg/OUAgWhq1Jreu70y+KKCkGwDktel4xtHm6swQO8rhQclZOz4ZchprU3cCb0FYzM/ePd5PWLpiqDrZO2b30LQdA5UxgrjqYQAgZZ9YJk6b0spBhhMtBh/DVYkiw4n2QFC2ZbaibHfjIcc47cqQvOS99t2bfrrCvmJYgBxqfG9doqEiiVP/Z1+nGkxO+6C57p301OSQIHHc1qYheUdlTmZSojggJrvSRD9S3lSWlRwiEHgvEoWkFhqdwwSG7LMLkAm9FVEZxxTE5TxBWHajBuxqkcmlVwxpXpgowrOa1IbSVN9alpMeF2PQVnGz7h0DUVf8z8dGvqi7q/LTQwQi70WigJjs4sZhO99o6n8eHCdtOp6TgAveaQMAYuBMSWZUkOGUzOJ64ykG6jYe2WpL3enCBUD0HcpJDhCI8PDk3No+u4dIK49niEK2Wl4yzqYLxMVdNkop26TZUUEiPEictPXsTcudGU2+XRoQYV3ZlJ3VhUnhInxRWFTGO2em2Vt4vKUiNSTYkFMMjrUyOSguy2wyo/cY1WCM6UT/qaKfrXCQzpZgUuP5Aa3X2b8e6rQOP3/+he+fXMv3L+rQGj+8fUDCjyjt0+vGLm4W+ErKu+9O6nVjwyc2LsNTj9yh9Tq6r1Tku/akSkfr7xxehYfvuG5q8O5J0+E/O98N95eUtN4a0+smVZ3SVUJRQfOYUcxw1s3Z6Xy9PMLbWljVsAHnL5Pkn7x+Xzs+Nlib4W9STHUhZ5kwY1fniFZHa++0lsby33y3T6uj9W35/t58SWmrSkfrdZN95dFvxEoHrTsaOZHiKzkwrKP1OnpQmhgRG71s88UxHa3XTbYWCJYVdWh1k92lZqP++fc/WBtlfjXn+OI5rTpaP9qwAef7p5V3jz7Uaemx5nyTA8c6isJ9JSWtt8a0o7cvFoX7RpZ0j9P6tnx/XCQpOv7nkTHtOK2/c3KtULT5RJ9KR+tHb58tCDepZxmXf9w6nmNq9v7ZDfxlmxuGx2m9bmy4Pj9CmHX2Lq3XDe6S8JcXNAyOPtRpx/pqs5YJs87esfXzSG2qb2R5n+Gwrcjfe0nMpgPdd8a0o7fPbha9EVk+qLNsitbrLJuyimBfqegNXLS5fkSvo/Xjt4+k8f03X1TpaP2tAxJcsLb2+t+1tH508ORmkW+sdFBHj5xIZfb8kmVbO7SM/dJ95eFvBEdvrulWjU5qrdXoNrN0OhC0XmcOhDPWjdVn+XobSeWIorcPSF5/Q5hx4OakXkfr7zRsFvJX1Y6Y9cnZZ9CHVtVn+eOpO9rua3W09s7FX0byI0q7tTpaP9paIOQvL+1QjT8cv91amiby9xaVdtJ63ciRNL5/ZNaOtpGx0Um9FeUmVZ07U42UY4j19fIIPHHX9ftaHa2927lzlSCivM/SFcM1idNR1tF95UZSqS5stEmciNI+rY7WN+cbyDxSm+obXNQ9bvTGn3dGm0Pm5DVSm/qGcMvnlq4bZUpeg6XvNg86qhim13BNom9sScedSb1uUnX9UFawqKB5Uq8bOZL2um9kvoESI7WpvrhAUtqh0tH68cEdsfzl0kG97qHuhnQ5Ltpcf3tMR2vvduyQ8JcZi97tAxK+pOa2RWV7qLvNlH02AbLkxuTFDXzfgg6Dqva1KKK0T6t7qPvMkOYnB++OaQ1Z7y1YJe0b09H68Y5fBr/uH5x15NakXkerLqxfiudcHKX1460FQsHa2sExHa0fHWktTfS3d/7omSxcsCyt5OKtsbFxWj/eXRr8ekRR68gorR8fuVgU/oYx7gbqrt5/w5a6FoXLRE4drb/bd2CDyNdITrOj7p/dwPc3JqnRJwamWXjj/tm1fN+0A32jtH78fkd5qj/+usHJFpXtoU5l6dvBXbH8iIKLg3cnx+507JDw/Te3jk3neOffVZNaRsfamPy381tNJjN5j1ENy5d1TOuz/PGU7Z/ZpbPli0mNmV/f2qjgJZuDAU5o7BLyyoVew0hR0XZpBIuS8AHcxCWNn9a85cdGANx4sVELYajX8a8uOxDtJz8lAjZvDeW6ASAcPCc7mGr/pMv4mwfj8Vhq+bCDn++zBsWTbE325iCIm1dktBfIZSMAoG4/14XEvpWHeyAACBaWt9ZP84f6XgAABIAXvyaMAwCA+CxewFLJbIbPGB7CHekc0ADAvd4bar9VidhwlwwAYKhrEHyClyBEW12ThVGLrY1igLdko2HFD4oHGvUkuhouqwPXbg3luiEoT1xQXbkhjE0BAAIUGpCW7MV2QxCQnTvez11fuJLPAQCUF79ptdfI+cZhsI4Lyo2J9jHGhSS0gMxzQxEAcOPFSj9tq4lnA/SdaBxZklmU6IUCgJtP2kYx2lN/ZcYtWLG4jev9MDcE5UUt92Fp5HLySZqaF5Ye6wEAgPDiJUvI7uYBEmTnzsjcEwrTfDgAgC5I3pCAjbQ0DgCGh/GYPb9w2RKEuV8EAICftGoJB0Wc3/FxEAhmyAeHqH/neTl9mD0Lz0j3RAAAsOgkIWLYdxoBAPBemWrQ596lc12siI25Qg4CgGDRuWt8lK1nekkg+5qvUj7pG0QcBBD3sLw1SywapkjPhGyhB4oiYEM5/Of/vcxAOYZYawkCEBRFEQCE7feLD69+WsC31JkXHM3TtF0yTprebLyi9ooV80Ddfu4qa7ll4ixRd9RbzpJikcl+2rZ643SUrOkPSh+J+GnXTDhKXqOlb4c4rBgmEBoCADHYx/FO/90nHZUhxrCjixPiMQAAbKEXSrEDJCIOACA8Py4oVUoAAM+c4xcaK2J5KADCFsULMWJYpmRQUfYxU/ZZB4gR9rXI7FJDmqcY0txQmsQSPgoAyAI/LpDeCUlcBAA4njgGSqUGgJogKGChKAoAqEdoUcMf6xxuR0Bgy9eLuW4oAoAsKaxvP10UhqEAiIc4dglbMyQzzTGw8PQ0O+qaQfY1X9X6pG8QcQCAzc/cEGq3ZJETKgmD7jMthgaVbS3DWFSsFdOA6GwZhMA1q31QAIQTuGl9gGmLccbK1neiUeWzriDai42gmCi3XFq4HCOnc9yPgyKIE8damYxFLTeZzOA95gLLBEM6/3yzv206W4FJjecIL906GE5wQuDubY03yEAhIr/SLJ+fWOEJAEBqeg7vPtQ+rCQoAHhMUhBImRjlHBqliiKG8/wuWX74mlINgAIAcFAU5AQB8NS7mqEYZlqwwWKxAEgAALlMQSlvrF70kaWkn8bAHhaHzTZ9hiAIEBRlbQrXD//3I10DZDze36VYIA7xQz863zUMfqzeAY1POo6ARqmkCBmjUQ6BcNhuALT5mAQAzZAcOIFcU9/ogtBY09csD567UVA5oqQGd8YIdlq0xsKUAJ6WcXn8GF6hjHHxiN+0uqUwL0bM9cFFocHiqGA+BwG14p6G6i0J9y6xaIg9ogZwemeXxXF3N3vLDQE1RTlpyvZhKSyMZ776o2wOQsmVGpJUqVnuFqOC+Qsw1gmligRvPz/2ISbPr1qMqD93ZgIL85rFchVDIKbhdGJXLVNogOvDdSbDwuZjpm4RjjubGpYbiYZ5mWKrlCkBi5jWjoN5oFq5QgM8jZJg8TATIVFPHy6rx9wyx7/EB9YAACAASURBVB0zMoqRctEOYw3C9YXC7O0poQ0L/fwWC9+MXr7sx9YpxhXHe+6ru3yz0JsPfRfaNT7ZkR4APTIFpbqxetFpS1FT4hjADksW7tx6rk0dksgZaOzQLNkY+dQrAxwlr9FSf+fJ5bNqq7iveE10s9dikV9wcExQxBv/x9gQyjav4EIQFsfkW4TFQsC4rJiQNVXWNPXLNQQFABRBuU84WnAMAKSKOfusAsQI57XInOaGQ7apNLGAxULncYyEYSEAJAEAaHTeppacCnHQUT8/XBQaIY7CPRxRHsWw6aBo+o5Lj7X1KzUUBQAkQZmXQjmmrtl9hEZJzJsmJ2CeXFa7bU/ClCh2dmPrveQ0D+WVFplnSqWntYRKrqQ4gdP9YBibpQBwUtnUmnsEy8PcL8INi+cCAGjMOT4FzhzLtjT58WOgtAaTHXvPWYFlAGM6B1r/1HGsxnOEl24EA2hgPA4lTT2kkNPYJPcy/Loie6TZW67i2/bWJ/JQAPJyXnjRDO2QltcFLP3QpcJvfWmYV37L6TRzGj/RX868Qhaz3rs2RCBtMm5gMXsB25M4PHBPDZ3yhdEBKIAGLIx6opZt4AYU4yWUxbJ477/t8z2JtrXSKi40/dUfCiMLDd+geP7x5gzZjc7e7q6WvZnVBxOqaku8AGCeeG+bNPBr6WyCsSkb0I5EZ8L01WNB6GJWiWPPRwpRJ/1+QxgaGAYs1usJFjVTAMCaUcpKnmUxfraeP2KxLA8t88gigo5iHYjy4qWXQpU3e7vb2q+c/NWxAz5bD++z2kXSI2q5T/Wxlv6CBdTlNmrxVrHpguGZ13Im3cmgxC1gVRiad6FdE+11uZ3wL7L/Yf61gaUf+iT/J04pioWV1bXnDvdc7W5rP1e+bu+R7OrazNkVGeXHhTlHqXRp3V6cgwDIjyalNjmTd5x9hq9Ys/gVZ1uLDKBpYwvMpzloG/FKq/k8Vt7b3dne3VaTt68mePux8mh7fk6fOlyVU3wB21R9Oo3PAYC+svA8uePu7KhrP6pzUKuQJckRWMa5M/K0xPYmuU9a9BNtvmnyrVVFUp8FyvkvCxMcOdbGZJru2RGVbzDZoffCmNT4umBU4/nBy3YXCQDcAiSBrL6WqwPN7SqfeMOvK1Vnr5YbujaRZ0jikV6FPbURBIAkzZ9rlBrDe3fMnaWWDU/PTRKaexYTwmqCAMOs3jMFz4vLUt6QTXdEqJXO7/FYAVm4zIcY6G2/0o8uXoIB4iNcILvWdfWajCdcwgEAdwxzZtSswcZ4LLV8xHQTjbjZePRMr+00I4LNx6iRftl0Rk8oNSSAfVx65Cb/k8QEiXC8hInpBdLjJ7YHai409JEcLo+tlcsU5nZItXLi6ZaWzb4pSik3z8+rlfcIFoaxEd58jBqRTWezakhJcTAuAoB4BzN53o/zJP0+GyjlMi3La6HzmySUckRuXj+uVClZbB7bVgbzwliKwenblUqFnJjH47KBzWaztNPkJAd6HCQXOKOcw1gDTKgJEsX4oSvzy/Z8fCAD7f3ovE355IQk+GnaLvX1NHZQfpJAFMCYOF/MkDgIvjrevb+xqbmhlQpZEfiMs3eWyUVOECTC8RTFry2pqvvof+YP1X3Sby/lCOTwtX5YuDobN8xwTMj65AwTMACAuDNl32zxNWuRDUiCmACU5xeZUVh6+GNpNHnlTLvTGxPqgX4lS5RuGL4AKIdlmmlrZ6Aum81mae8pTe2TigGVw//GS1K8VG0NTecbVX5JwXajKbYHh6VWTi+ylSuMrTBWNg7Xg61VKkyFg1Q0155qs7vNx+hYZpMdeo+5wDKCMZ0t4dTzzwlewhEMIIsTAqGzdm+bZnFCqCEkKA8DpaxPTgIQiubtBwdgHqXWWK9Ln4fx5hEDhqCS8saP2oxfI4Er3+T0HixrHJ4AAGLg+Nb05PyzpgUTSrmc4vDmuwEAKNuqK/Z0qJ6JEZxQSSB0V0lb75EApKanOm/Fup1ts68byOIwb9X52m7SB+cBALpwCTZwvHaAHSDkGYxKirAwatDaqNkDDUwKRnuP7mxRTBCEvH1v8fZzQzDPVspLkuGnuSDd26kmAch77RWZiZmVvaRNXFp2HOo3xoVoK0kWbzraoyQBgFQO9igpDsZGAE+Jny8/XHG8XwMAE/Km4jUpmXV2t3tZLBYQ9xSaCdJJFs+uKQAAbVft0ZsEAGh6Dn/UjwrD/BDwik3x1lzYc0pGAAAxVP/BBeVrKUmeAAAI7tTzs+/3WYAc7pcDz9tzplucA2dqug1/GTtR2w0+EUvsqrhHlGQJXNlf06cmAUhFc/VHQ9zYZD8EEDzMD3rqDvaoAUhFc/mxHgftgx3lBup+tSY5/+w9pljLj2bGZG5rUUwAABCywWECcefZDjXYYfFCouvg/i4ISxIabOSESgLgmmXixGdU2CfOgngJT3ZwWzsStXIxAmBI3qp2prUkTwSjpeUXHVYMI9SNheLE4jMyDQkAhKK3TwPY/Fn++EfY7hxqpKtXA0Cqe48WN2o4QGjUDGz3WsGQfc77QIBSyeXEBOmgFjl06ewwUJkanSntvkcAAKmWDcupeR6YXcWwBMrmINRQ78AEAKnsqJJeIdmgVpgHPQMNv7/GSF0Ejw6c1193sFNJAqnsqTl61bHdWHTyYmX97npCmOJgQo4dGLUQuo7t69WQQN5r33vCPNJkrGwLk8Xzh2qrzsg0E4Sys6Zs2+EbpN1cFaNjrU3e89s/mExm8B6jGtawiKkhnQ/8/oZtOjN73kKN5wgv4wgGEFF8CAzc0PjFhhnZzI7Oyw8jDiYFiQJSy7p8Nu3+1XIvxd7krFNyy7OyCxJYp9JjEuJSN1apY9cHsgxTMmjAlpqKSKo2N1QgwGOKW9C11RUrjfN+6u422bzAUMPtRk3PpXMtfc8owJzI7R8W8ZUHk4NEeFBy8cD83D1bwp7gxyK6JJCrUGh8AhYiAABcPz9EoUCWGFUFt8Ais1FL4961MupJ4BZYUlO88N6ezNCg8HTpML9YutXPfuoYS6na/xZ3cNuKcFwQnl6tXFJWvdUPsYnLVe+N1cWxXoq9yVlNvGLpRvaV4tRw70WCgIzdcu+i6lxvAFiQV12dhF7IT17qFxyadYqMklZn2t3r5QgTAtGukmjxpiYnYzJzU/giEWNTAMBamBIPhzLEAYKEvC731VVF0SgAcDOqpOvRpk1xwbggIbsBydi3x7QgcQbPz7bfZwLF4BA1j+fl7lyKxYtMwJqyY8Lw8LwzSKy0zBETOLE7927Cesvig0T4m9mHiGDpvgI+AgDsxOLtCeiVvDcFS+O3d3lvWO/l+LaCJeXwmOJLaEZ1xUoPQMMcxpq3qrpMqK7JDl0k8BYk5J9FMipKE+3GVW6By/00N/ohJMHMOk5k2YEtlonz1r4iB4nDi0zxAQqTJBnv22h6Lp1rsZs+fDoYLT2S76BimMCJL90ZD2dyEgIWCfDw7MNEsLRSMtsE9M54N929Jz8aFySsq4OMsvKNAdCcn2D3H2AD3BmyzxkQP0kCV7FzRXRmzbB9LXLs0tmpvrWqaIGsIjlc4L0oPL7oCi9buiXQqTJIyFvvRCCNG0MFYVH5lz2yy7enL9TUZ8ZVDwAAixcZ7/4JM3XR6HfKV2PdWxKD8DfzDqFpP8dZlKN5BE6oJAzRoqGSJY508Ugu2R4PLfnRfoKEvJbX1qd7skjDY4KmK9vSgEgL3yL8wmqpmDyelRAYlFJ81X3j3hIHd8qYHGttsvt/bzOZDAzeY1LD2pFWMY3duXcT1rfNLp0ZPW+hxgA8N3iF1uvsP30+nx/8HArLa9OTLgnrTm9eMAvhb04Nl/A3JTzTphPPo84WmGjMDd0O71qvgbARdv549VmqQZKAIAbhvx9KXX0+4MTFPO7T6fxtCQ9XJWb3p9cfXPFvz3MEXcJOYKDuR3WrX/v6LSvPpieeCztt9ceo79xAl/CMwi/lHMy3BXVTZZ02OtfZA3ldcOG7gKazbndVu6K/dxh8gkXPfqGqJcjOEnFAakWbkgQg5I0Hz8jdw8Tcb7TLrwtS2Sl9rx5i34q3W+/jwr8eSPXAoZK990I3JLs2InjR8PL9F+lbg+JM0QfqeGn1s14H6IILXxeyo9ukH0G8O9WPRBdGfsObKyCiQulb2yvKUoM0BAvlLhSXSXO8vtkuvxZ6K0KyzlFeEVuqNvER0x9qXPhXxVB1cvJhDTd0Q3VxyFM/EcOF7wqvPNRpv2sdXHDBhWcKYrD2V+93UCx2cE7ZTxe6htguuODCSwnXOhiXsEvYJewSdgm7hF3CL56wax2MCy644IILLrjw4sE1gnHBBRdccMEFF148uEYwLrjgggsuuODCiwfXCMYFF1xwwQUXXHjx4BrBPFPIdscEZB1/Jo8mf1aQ7Y4SZDpSSXMmSxSyvQ8A5EfW4KlHn27Lrnt1mXjiB0NPq528Nv2pu36x0VsRIsg+o55Z0IWZwUjyFwcDlc8xH4jzOaKAku6nPb2jUCDK73iG+nx9TFe/rwN5dfKzKF8duQJRru2W2bPpaOYTod9cZzoKZxR+AeF6Hsy/LNhhhfu9UO5Tnatoq1N4pYc8xS4EzxGU3Wf62QliT7vHiCva6v7+jVvntab6Q63HN/yolm8NE/1NbRAc+5PvP9FZ6t6jZSUH21mr6s9vnuGxkIpjSUn7ZQ6+YImrOqVPtJnwvyYY2c4IQ0wTfV7sP+MzWPF1qt80sOTyWvG8r80+PP/D/eD0YXqWHVlYNPOJLz1cczD/uuB4efOxpypPsqaqmssv+sTJva6DlY3DDjaSkX36bViHYnwfz5dlAEN0Hd594sk2FSJ6f5eVVNLnxp3dU3G5K2o+Pd/y6fmWT89vC50HXmtOGA8vvBvwVCr/i4GR7Yx4ipg+h2C04umrnwUQzJPvhc1+UMgAlOfjbbdrKVNHlhbNfOJLj5dtBEO2FOKLBN4WLzy/lQQAIO+1785OTQgQiPCg5KwdnwwZsrm3IkRQeLylIilIlFSrAICJ/lOFGQkBAhEuEMdlVZyXO856k5jAWxAWlfHO8f7prVop+dniDDEuEODhmWWm3W5JeVNZVnKIQOC9SBSSWmiS15zJEsVJm47nJOCCd9oAADSdtYXpMeIAgSggJrOwbmDCmbkDlTGidfXG/FTXZ3svEpf1Gr+7KU3As5rUjCo5nkclZU1lOelRQSJcII7L2d2mtDO/rzIq45iCuJwnCMtuNHRNKVsq1sWE4YtEIanvTHuMGKj7dU5ceBguCAtJLTzUNUM1VHbsy04V44sE3gJxXM4HncYZ9Y5cgbi4vqkwUWQwh5SdLUwVLw0IDkjMrepqLQ4X5bYYerQK8brtTcYQg7L9t2/FhYu8Fwnw8ORsacc9gKHa9PjyQepqRagg/ZDlaKW3ImbdcUvrGBxi1KpoZTCe1aSGjkKBuLi+tSwnPS5GHBCTXdmluFn3TnpqclS4OC7/rAMS9VrO7oqLGzuq8jOTEhNCwpOzq/tMQSflLbuzE8X4IlFATHZZo4J05BBGPxMDZ0oyo4JE3otEATGZxfWmC5j6WlV+eojA8Hl2sfnCRgwcL8l20I6627G8EZozWdFb2rWyPauXxlX2AACpbJPmxoWLcIEoICY9t7bP0b0RgsBW1Hy8Z73fPMf7QNoC5WCYB4Z5YBiHBcBimw7ZbqYLiJnkS6OyzHnHaJQVyKHGinWJYlwgwoMS0kvO3jRkZ39FiCD3TNfR3Iz0pBhxSEx2eYf5dIY8tfBVUFyOna8MUHZWFyaFi/BFYVEZ75zpt9vlWd19KN9AubCQ1NxKky3mmuMbEGFZc2bMWTu2M9g7jemY4jEVhs3GWaBpq86NCxJ5C8Li8k+ZTmFKOiZoemoLk2LC8EUCPCh53fZWueM6TMpb3kuPCcMFYVFZu5vbd8eZ7xI+AUsdWGFhoOkeem06nnG0rf69danpceHikNT3zjv4+UIONb63LtGgtjgp31idzDd3yJbCpX7CGa87DP4x3wzSnM8SxUlbz2/PNZWOUwZ5U0c2FlneRTI6dqmf0Mqx9pZ0vRdidcuV7CkR4xmnnGyC+1yD1uvsXw91Woefv1jCk33lib6RRR2jtF432V0a7i8pab01ptdNqjp3pgpFBc1jeh3dVx7+RnD05ppu1eikVker6rP88dQdbfe1Olp75+IvI/kRpZ3j9mpcL4/AE3ddv6/V0dq73bvSBBHlfXodPVge9oYwfEN56/DopPZO6y9jX/cv6tDqaP1N6XJctLn+9piO1t7t2CHhLyvq0Ooe6lQNG3DBsrSSi7fGxsZpvW5wl4S/vKBhcJTW68b6arOWCbPO3mH2xnj3L4MFBc2Teh2tH724WRi9PDJx101ar3uoGzwgwVOP3KEHy8Mdq3T35FpcVNpJ63W39kv4kprbeh2tupCzTJixq3NEq6O1d1pLY/kRpX1aWz9PXtzA9y3o0OtovW7kSNrr/sGppRduj41PqjqlEpy/oX5Mr6P1d06uFYpyjvepdLR+9PbZgnBfyYFh26jdPmDqeuTEal9hxoHr97W6SdX1A2uFgg319/U6Wt+W74+LJEUnB++OacdpbWdJhHd4wYW/jWsnR9qkayMFb+A5rTr7EEtXGUN8/+wG/rJNDcPjtF43NlyfHyHMOnuX1us6fik0qWr1+uf5LLN1zA4xanX8zyNj2nFa35bv7y1YJe0b09H68Y5fBr/uH5x15NakXkerLmT54zkXR20j2F0q8l17UmVoypsvKW1VGUkb/UasdFD3UKcd6ygK95WUtN4a047evlgU7htZ0j1u6xBGP493lwa/HlHUOjJK68dHLhaFvxFZ3qej9ePN+ULB2trBMR2tHx1pLU30N8jfOblWKNp8wqadhzpNa4FDecvXTelyPPHArYc6La0f79sRyV+22cDh+301Gf54xsk7TAl7+4CEv1w6+CTZ3VEgfH1V7YilgDXJm7eaSe7YKJuWx1oLRL6xRa13JvW6SVVbuQQXbL5w31gc8PCC+hGtgatp/GVbO7Q65jwdt/TV35rfdeQr3eCuWH5EwcXBu5Njdzp2SPj+m1vHdA+vv2viw60DElywttag8+DJzSLfWOmgVc15OD4yXXNmylmD6yzZzmivlZ+NMaX1Olo/2rAB5y+T5J+8fl87PjZYm+GPpx6581CnZUo6a5Ob833xjc1aWq8bu7hZ4Csp7747qdeNDZ/IWYanHrlD29Xhh7f2JfoKs47cHNOP3++rzVou5Bud4yCg+25pbTxvwVJLKywNnK5+I0fSXvcNzjpyc1Kvo/V3Gzbg/M0Xxmy8MVyT6Btb0mHw2PXDG4JFBc2Tet3tXbHG8mUh7OS6Y/aPdTFvzvE1FLHRhg043z+tvHuU1uvoseb8ZUY/W3RkaZH5xGnH/lOntXasuc405xuFr5dHeEcbLxNaWttWtAw3lMTZ5+DzI/yyzcFMQ91amN+EZEvfDUQBiLa6JiJg89ZQrhsAwsF//t/LqPZPuggABACAn7RqCQdFELh36VwXK2JjrpCDACBYdO4aH2VrQ5/9aFZLEICgKIoAIOwlebVXPy3gG79iBWYWhPFQBMHC4nE2OSLXAIBnzvELjRWxPBQAYYvihRgxLDP/SsSWrxdz3VAEoO9E48iSzKJELxQA3HzSNorRnvorzKNjxCcUh4FrQwBADnb1cxPTF6sHBtQAoP5Lp3x+WADGrJIjn7Wf60Ji38rDPRAABAvLW7tE3VHf61jYAt7r8yJ5KIJw8MSo+aBUKAFAdu54P3fd/6zgcwAA5cVvWu01cr5xmLENLLaq8aPqTG8OAgjHOyHKk5QNGn4LIUChAWkpXmw3BAHZ5S7laynZkRgCCCbMzxWa5lBtQ5yTHWwIMUlogTXPDUUAwI0XK/20rWbW+/k5cYhBq2SDVgAIAE8s4aMAgCzw4wLpnZDERQCA47kEA6XS2fwTAsCLXxPGAQBAfBYvYKlkchKA6Gq4rA5cuzWU64agPHFBdeWGMDZl5xAmPyNLCuvbTxeFYSgA4iGOXcLWDMk0ABRBUMBCURQAUI/QooY/1q3nGeO1vnClXTvUhEN5JpA36htVCzLzDRzm+KzNiZrX2+CEw88K0yQPjfM1kpzRKEsQXfVXCL8NW0IxBADhCDeuE5JdTZ3G4sAOS4/1QAAAeH4L2YQhd5jy1MpXWMhWR77qO9Go8llXEO3FRlBMlFsuLVyOWRYY2bkzMveEwjSDzguSNyRgIy2NA0w158lzltlep6B4kq3J3hwEcfOKjPYCuWzESdIxwU1c0vhpzVt+bATAjRcb7QNDvcMAtnVY3vGZDI1cn+7pBgjHJ21rvDtFGZ1jH9CLF5+cpTZA8NVJhhVCbL7ffJAP2y4KJzQEAGLwPcc7Y19LR2WI45tHTq87M/oHAMBbstEPBQBA8UCjn2cGo2MddZCS9Jry0rmbAABA9rZ2UsKE0Bd1i9OXdCUvOXwov6Lfr6Qh08BLjVJJEbI8v0uWQq8pDbPbLMyLZ2SjUqYELIJn5iYH80C1f1OMwU+a171ZaSgL7KT9HcXC9YXC7O0poQ0L/fwWi6JixYFc465gLHeeeWUXyjK3RMiaKmua+uUaggIAiqDcJyiTFIYZF42qFfc0VG9JuHeJhZrsETUA06pSxE/ooz7VKwc+1X0TXZgc6tmz50oPsXLZ4DUZB3+LByADYGEOVbKHXKaglDdWL/rI8kM/jQbAGb9ZbHfzDWUWggBFkQCkckRJDe6KF+6ylMSUAJ4MzVDyK/t+d+4LuZKgAIDUUtPr7FgePHfDO1KpUbMwzGyO12IvVhMAOAlxdPym9ObCvBgx1wcXhQaLo4L5nNneuWZ2iJVWRjewjV5iAYuFzjN1wmIBkDNcHlgcttnDCIIAQVEAmiE5cAK5Jl3RBaGxZnkLhzD7WdN3XHqsrV+poSgAIAnKBwAAjdq8sTW3Qhx01M8PF4VGiKNwD8TYzs4YwU7bdn4cnbepJcdWnhGEUk7Mw7jTqxsxHgaXhuXMHH42sCT5PMSgILNRliRUDSkpTqC7eVc/N547RnXLDRcxFhszL1YyW82Yp6ilr4TLwpfHLLH1lVpxj2B5YKZwI9yweC4A0H83fkDKVWqWu9e0/+YvwFgnlCoSIs01B1/sGxQdZ6g5T56zzPY63Y8TxcyeYLFYACQ4q6tMizNITc/h3Yfahw1ZDiQFgRRpcK1FHdYoNIDNN/uA5+WJslTAFFB3FcDrT8ZSa7DYbHNJMFcwK/is2iruK14T3ey1WOQXHBYfEublyL2zv+78iFEZhMO22mBylmuXTI69N0G98oq1Y+3Ai5f41Bys78p/Y+lUT2M3hJaGvbCLaV7KEYyms7zwECXZXxZiuVISSz90qdDb8H56bwVHf29wAE7k9o9x45ADdQcAXrz0UqjyZm93W/uV40Up+7y3Ht63knHQrzxbmHOUSpfW7cU5CID8aFJq0/S3ViybJ97bJg2cnVYAgC4O9KpoG9CIiUHCZ8MCzvxA7gddMvIHVwdZAaX8mc+3g1d+y+m0J7zYMKxkYPm/d6lK8oNZbXgx0VK26bfK6Mr9NaEYAqCuz46qsWxqVoslLENsATz3SNOaOzc7e7u7WvZmVh9MqKotmf2O4k4c4kyrr728D8ANKMYCZtm1Yz8PV+UUX8A2VZ82/JrvKwvPM85pea2q+Txe3tvd2d7dVpO3ryZ4+7HyMABg+W/7fE+itWNoegrxSqv5PNZGPpp5EfLs1rV8W3Bk1IygZhZhyFMLX33++/wDBx35iprtVclGF3PN+fzzDnPNAXi6nGXo48nBkHQOQfZIs7dcxbftrU/koQBkW354oUM5oKx4hFgc2AWUpqcA4ElZao0ZOYuFldW15w73XO1uaz9XlrH3UHZ1baaN1TNfdyx0nqVis8S0Y2N/9P25c2kmxxrBiUwJ3Lutoft/fvLowlUkbK/wGVSr7wgv4V0kef07W7rmb6nazJ8OizuGsdSy4ekVhYTmnqOfxZgXxlIMTq+BUirkxDwu998BUA8el2d4cRAAmFATJIrxQ1fml+25+OEatPcjR+u/jCBl1/ph4eps3DDSn5D1yR3WDA6Xx9bKZYrpE9XKiRmqHSYKnS/r6u7qUvgELEQA8/FBbrZfvjqoXRK40PmZ9uB5cVnKG7JpzxBq5UyTywxAsPkYNTJgsZBxQqlxYoqsd4DyjFkfalhvTw4NKBx6COGwUUqpNE/yygZlRjnmEJMEQSIcL2FieoH0+IntgZoLju4LOsQzdMiTg43xWGr5iGlVL3Gz8egZu39VMPpZPdCvZInSDcMXAOWwTGP0FEkQE4Dy/CIzCksPfyyNJq+cadcY2umXOYiXQ3lGrTmYB6o13Eg0nC2XKYHr+Z385dOJURZwX2DlZ5iQq9SWM6n2YM5TS1992FDpwFccrgfbwj+korn2VJvFTQuENx+jRmTTxUQ1pKQ4GBexqDm5v37fXHOenKJPbi9zU7Osq2ZbOnu13NC1icb/z4z0OK6DwGGzQTNiblbeP2wg7zNj6RODnCBIhOMpil9bUlXXUMgdqvuk31pCfvbdp77ufG3M1rEmoGFJwazeT1paP+1iR6T4fBMqfUt4laan7F8A4PDz51/4wZ925Eo1UaVlsf/H8tu5/iveZPcefO/jWw/oKfrBzbpfrUl6q+FLeoqmHz+Gx49Mkv8Rnuj3+Mq+fT33J6foyTtN758amr88CUdsu/vr4XUxme99cucBPUXT43/5s4xg/XD+96Zo+jEAPJqWNDY+599+yKYUf/zTKE1/df9Ph9+5oGED8Y///QoAHj2Gx48emeQXrYydL6/9zdEvRml66sFfG9/JSFl3/BZNT9H0aPvvKnd/dtfe8B/5Lp7Xf/R4/3z8J9+n6an/8n1D3Xm0Xbk4eNFc2s5Ay8OpxwCPHhlcB48f0fTUvwUlBjzurqps+XJyip4cvVaVG5fx/LNnZQAAIABJREFUm8sP7Pw8lwWU8s5fxx9MTk1NPYbHj6dM304f/jjxp7im8bf7r9z/iqa/+vKzHesS11X86Stb/R+Zuv4hm1J98acvp2h6/Mbp947/DWUR9/73wRRNP3r0GB5PmeRfD/Jj3z59qE1JwuSXXb/Z3zEBhm9tQ3x0S3rSWw1f0uOX302OyT127cuvaHpq8sv+6/co9g9/MIeemjuXRd2T//XB+OSktYEIYraO2SFGrUwUtVLS4FmTTx49MhzZ8HnqEYDBb9YGTreM+q9YhvYerfjkzoMH47c/+13x9rO3pr5nK8/k5+/9gM2ibl2/+YCemvyybXdlx0M2qP82StM3d/00dl1l15cPpmj6q/v/39DfyHnu//E9QzsXdn5g0w7AYEVKtAN5qzjOefyYUv/tnpogJ2m+JHb+UO3uc38dp+mp+3/6/b42KkAS/h+2vP2KUGvu37/7v/+ggJz43y9H798ffTA5RdNTk180vFfWcMMmKBaum3oM8NjsXltWG4SNhwxGWbeM+q94E+09WvHZ3Ul6avLLrqr93WhIYvD3HOSOKbuZ8vSmpa/Uw8OOfPW6JHL+UO3uU38ZffDg7pV975XV9n316hQAGPnw4+ikhZrz1XV/eTBF0+N/Of27C8rXVq74sWXNASDMNWfGnAXjlLOZ7d9nttfSz8aY3n/w1SQ9ZV2mph49hsePHwEgDElnE+tHjwEAgKa/P98dlEM9tyen6Ad3msp+f/PxPOof//hfuwh6hfi7K1s//PjOJD11/4vDuy9oWKzpqmIT0F19pI3nLVhqZYWlgebqx1jBLITvf/x2VOI7p/4yOklP0Q/uXOtRg/uP/sOifD34046C347NeN0x+8f60vbosbGIMfkZzB1ZW2Q+cdqxQCisHGtRZ8y90PTUnKWJUfO6d/32GlcS/V921xSHr+fqQm9+zXW4qzX9XO6jPRvhL859qqAoRW5kg/kLdPn+P5aKlv3yQMXeypr8N38zBoi7lzBjz5ak/5wLMPeVV+CVV+fOmWu4n/bDeOm+yW3S7ZJQDYnM43lHSvcX+CB2avzXT/eUPdhWs+nNd8Yo1jyMh2dUFkl+OAf++QoATLdmbtz3ZyXpt7e9HbsU/h0LTCvZVn6vJHvb2xLYdUzwCrzy6qvm9t/Ir65+ter9t1ft0VDAnh8YL92T9fpcAIDxgY7zl+i4gjf/r63lPwkQUKcvcNYs/c85cwHmLgrgqz7r8c7w/8GcuWBn4PThnDmvAJi7fuXVuXPnzP2huPwQvVN6aFXodhJYHJ/g/H0FEda3J2h66v9dujKB+86upNiL62qrOa/AK6/MmTvH0PycOebD/5v2/n5q2+4dyZFqElBscXTZnreWft/mtuXcV41d81KLftFXtispuBxx94nftP39yP1rikuTiuaclrz6CrwyZ45Rz7mBRZVrirdvXxFYgnoJ1xf+95K+CpgzZ+5c+IF1iBcErN1TmPSfc+E/35Uqt+0uTT+kJCgWe75PaNGet/hz54JvYqzP5WNroz5J3tdS4mehE74igfuuwbqGPCaHvGrQCgDmzp0+NChp8KzJJ6++ajiaO8eKz3NeBXhlztw5c+danWvZ8g+WldYUV1Tu3fDmO1oEWxhWvKto6ffngo08k5/D8ov/uEW66c1TLJQnzCnbUd5VmFmzYcX/s/+jXVt+U7VzVZSKoFgo5hm2Ubpl2ffnwvfT3t9Pb6+yaQfo/5+9e49r6koXxv/EcLKnjvHnDHmnQ5hWOD0VrYSLwZRLkFu5ioDIRQ8iI8UOogeK86PSKQWk0oOmrxbfanGsOBatFdSqpRVpC9gB6Qg4FZhK6PgGZmpwPAnHw44Td9jI+0cuJCE7Boty8fl+/EPCytrr8qy1F3vvZLnmv5v/lmR8emPPrU5adr48N7Rpxe4L70S+Wi6ZU7b3N9GlJBC8RcE55a+t/oX57Wr5uS1Re7t0P/RvjTkLwPEr+6oigvjn378+dQbccxOWGb3HuOnYLACWoXnNohoAgAbQ//gri5UyLgxNj/xsxesVBXt3vbdhxe80wHVwC8o/khf8s/GTg93Y6GYap8ZtNc/h+RALbTV32fZyyZyyvZnxb5Ng7xKQdSA/+pdsegD08fBc2rsSuvS9LTHvkxSH6yxMPbDv5X9jAzDMOfCAMattOpNoZ6qvSTvr+/RSwO7PC+eYTFPsOSxgseYAMA46U3NY2vaz+8XKV3NbC/evDXqf4C0KzizcF3UmM/f9tZlzjueZ9qDgZUnerbfeS/P+T46TV3zu5sCuwj42Q4duFRJ2du4MUWpcC0kk11DBsdnPaMoCMJnBxlrjl6uLJX8rezc7/h2lBjg/d/YKk+xOeNaOLdNPXzaedwztY3pqm8MCADbbzo7N1M6GedK0Riv1bxxrWI798yGbi8YaNntsnmGBdt7QHtR9beLCjyrmxUU9Z2fbsyTT6kRv+JFFD6un8PCY2PbEd78u3vrXXx9Jd5raYkyDxBQFBFubWHF6Y9QhZ7MlyGMqBibGxJj4kSUeoUH3QDZQjXlB22HnHyXBlp7XmEZlnkmJqbbCpOx7ORd3B89/cOJHV4wfm3gWPgczS5GXa/sXezk8OOEs17s3zj88t1ZGAlDyhoqPO7k+wTY+R4gQmhHkH6f4R2Ye7x0CoBQdByo7wC/UbeY+bjrtULK6spJG+42vBNi4fJm2ZuVnkWYlbtDbH4TavFCdvRZl7SpU7jy0IbxEBfP4LgHbD2wT49SG0GzCX7t71z8KyjODJCrg/tzZK638jbDZsgXHVKOasv1fa+G6xpbstO2C/rSGd5EwMSbGxJgYE2NiTDzzEuNdJIQQQgjNPLiCQQghhNDMgysYhCYF2VaZtzE51tc/tuTBO0nNNBRpdY90hBCaAriCQWhScJenS7b7ckjSwc1pqssyaShS0dd8fk/m6vW7Z9+yDCE0w82+FUxTtkic3TjVpfhRWgv8xZl1E9k7pb0sUJRZrXhwQguke6J8M6rMN2N9NKi+qoyIhPJe07pNvL42uHk8XRj3Xs/kZvoAyp6uAXByXfxQn5qQVaYIk48yb03x+JENhZtz/7Oqoa61RW6ld37MiHskXQ+gPJshDtzZMdnZ2qgpT9cgyuopLcZ0ngknPjx/TGOSZ7PEvoWtD/Ve29lSQsudIitPfNDYHwvp6TdRTKXZ92lqYe4H78OU7MLyo1A9dbUKrzXih/vIoMuG8g9UjtP944ZUT8Ub71Npx3MWEQBDnbUNEBDnNmM3RR2P6mqRari+wmkaffLW6k772IhFNn8inxtcUrmCHhn5MvfcZSu7uUx0xOlC3XuB7W+ZoeyD8953Gdti/TGbfjOhPgIf6tsPprYxbWFLCY06xag1+ImllRHzHmZnqoelnX6jX5j7GI/5SMy+azBcZzeB88w7LXYfk3zY8tAXQrh8d7dF030BI6/ddVwVkRfvDABAthzZc2zcPoUzm/RqJ8lx8Xq4CfqRu9lyaNf53km/3DHxEffjQn1G4bkI3PlTNRlNu5nwR0bglDamTWwo4VinGLcGwV/k7sJ/jPPG7Jl+Z98KxnCZTnk2Q7xKUn92Z3ZKcmJ4SMSq3BM9+tFDSj8pyIj1FYmE/omZkqabANprgKsktVVZsULRGw0AAMrmyryUqAh/3wDfqPS84136hxmVbZV5CVHBQg+R0D9x4856/V7W8gZJ9urwAIGHSBhiyHYsH1+R2DQfPaopz3/zOeXAsQyx7/YmbWYc8mpVbkqgSCT0j91Y3qqwntXYXaSmbFFEQU1t/poAYUat2W2loc4TeamxviKRQBQcnvpGVefYH9Ya2emC1AihSCQMSS9p1J1eKFltSUZioEgk8BAHJucZ0ssqU4SpRy+UpweKYks6AYC62bgnMznWVyQW+idu3FnbY2mW6qn5uNM5PtWNAFBWZ0S+1qiS7lsvjCpr09f3+G83jKuvpZzJ+mx/8ZZPx4bfUF2er3/eBQuXCTTyurKNUcEvegUEJr9xVt9PNxvfy0yOEHqIBKKIVVnvNSsAQF6VKg4sbB0ruPxEiiiioJ2ysXYAIGvvkIODm5c9ACWre69ge97GrKPXLCZWdFRtTw/3FwtEEQm5R9vG3f4b6jyR/+vVviKxUBSxKqPMUHKmHqSkn5VkpYT7i4WiiFVZexrG3fTpqUyJKe3WXC4LEqVU9gFQ8gZJ9qoQsVAk9o1Kya7seLg7kABgPOLO/yaAacTpGIW6/+8uWQ11k2bPePszi83OFKIAAJqBszv1jbzd0GtUz/myjXERQpFY6B+bUni6kwTbe5+xGNLTeckRQpHYNy5zV6Nh+2uj2wqK1r25KYEiscBD7BuVWWA4kesjwdN3pSESeiSxwuQT+tkDesoT9T9SPed3bIwLftHLR+gfkZCrDV2mzI1uWDB0t3YgN9Ts2JicsiokIjB5x/k+y31sYByBUb9+09Dg+tfNI9ZA+ocNhgg8rLsFohueQg+x8fCkpLWl/7FhXDCPNea4+ceYrqbjJmHggLKhPHt1YIBAFLwq98Q1XcEZJvP2skBR3vGLuxL8xQmVfdpSWR9iJt3dWRYoyq5uOZqdmpIQFREYlVmi2yhb1ylmrWF8F8nS7GQJWZ/tL848bz4N1plNgxZiY2z6fXHVrjYAILuqC9PD/bVp0gtqeikAqmVHoCjd6OkCqr14pTD1xE19EAo9RCZBOFXoYfX4f/fUKouvz4TEF7I8hVn1anr49qlNQnfvdaWtt+lhNT14IXeFMPkPN+hhNT1wbvMKn9SDzf2Dt291H8taIYx755o2vWjFusJPrw8O3qGH1d3vxLuv3Haq+/Y9tWqwozJjhU/G6Rv0sHrw060iz/jS1h/uDqsHe49l6bO9dXqT+4qt1deV9LB6sLcmN9Qn4/QPxvnQw2rjfEwq2F+Z7BlW2qGtS0O+t0C0cuvB1huDqtvfn94qXhpW2q2+p1YxZtVaJPZM+2hATQ835HoLxfH5Vd/2D6rumDbRldJQYdw7V26p1LTqh9Z31olCSzuG1XR3afBSn5BNpfW9t++qbtS/Hr3EO79JpaaHr0lWCsVba74fVNOqH5rejndfkd+kUt9Tq/r/sM7dOyzj7Yb+wdt3h9V3W4tCvOML668PDqvvDjRL1vqIt10YNO/BG0fihSFvX9P/eE2yUhh38LpxfQ80f29cX5ox5ztNrwe4J1f167K6/elWH9G2C3dN46H/D+uWeAckF537fvDO//z9a0m80H1TzeCwmu4/lurpk3rwyi2V+u7AlYNpPqJNNbeG1bc+SnP31lWQHlZ/fzDePbSow2rtTCt4+9Qm4ZIV+a2qO90fFZWevtZ6cJ3IM/5g7/gQvX4kzUe89VjHwO3BgSsH03zc0471a48YX/H9sJoeqMnwFibt/PKWSk2rbnz6eph7aFGrirkHtfH8TnO/Sk2rbtQXRbuHFnWozAdI0+s+2ha4p1Z2vB3mvmKrNpBudVSkegtTP7rBNKzufrrJfWlAfivT0BsbcdUZDCPO+J8+1O+pVUyhPr7rdyebNLtxFFkK0f5TaUJ37+jcj67dUt251V2Z4S2IfOcaPawerN8m9ozOr79xd1h9d6ChNF64POsT497X5szU+5aLobpSGCoI2XauX6WmB699tC3afakwq159T93/UZpQXNRMD9+p3+YjSqvsHlTTw7f764vivLWBMRYJ//X3bwyR0P12mHt8pT681d3vROt+7K2I84wubLrxP2rV3YErRzYFiLdduMuYua5frHR3/x/WLfEMyPjDtbvDanr4h1ObhO5Zn4xrZMY5pHn3Wn0E1mR4C5PfbhgXsSaBZIhAs+F5d6B5bHgOnMta4bN+99fjgvkHfWOqzeYf49OEdhI+1XvHdBK+fWqT0H1FfO5HV364oxzsrkz11kUm02ROd5SGLA2IzDrQOnD7rkpXKutDzKi7tW8Xhmyr6Vdpw2mdNjKNOsWkNb5/J1o39i3NTj+oVfTwD6f0mesnijtNrwe4rz1mNg3+j8lJkyk2dNPvPbWKHr7TWhSwJDS/vv82PXyn/9P8kKXaM9GV0lDdqKGH1bSq4bUVwozTPxiC8O6w2igImU7HNv37MYnn2LKBtfV/0yyxyU7l4Br3isdcmh6hn/LwWQT/97qMpkf+9tWJy/DSbzZ4PP3U3AXPxf3u7YJfe8/V7iBPOkT9+qVn5j5lR9NtH57v90rLi35uLgDMfSHplbB5bdWNf6NH5r70xpnz+7d6LGDTI3OfiQxzhZ4rPTQ98s87JHB+yp1H0PTI3Gci//P8F+9FLTDOh6ZHjPMxreD9URi9r9v6/P79UXCIzkzzeHoue+4zIZECjvL//vWfAFcZszLaQv1fRjVc76REF/u5bDvTJhr6nyHg/HTuU+wRmr3Ac8uhr8/nLKVHaHoUgOOblrPimbls9tMrVnraU303/jFC08+9cuTMJzsjn3lqhGYv8I7y5pO93/19BABGRkY11PPRGaKnn5rLpu98UVU75JP1W/9n5tIj7AUer2xaQTXWfv3fZhWUXbsJi174laE8o6Mwet+kvulCB+P60ow523mvDrXv/eSzv47Q9Aj9341n2zjh8SK2aTyMjIzCqOuvt4Q885QdwVsWHboQbsr+To/Qv4jcc/7jPRteWMAeYS94YWXo85S086/0yAL/KC/q0tk//RMAaPrGF3X9/NDYpVZrZ1LBu51XOjWcRc/+48B/fv50+m+jfvHPH0YdfFaveGZciP7l0+pO+5iMuKUL5s5d8EJa4VtvrP43Nj1C3wcYvU/TI3/7/HQL56XfbPVewB6h2U+HZqUK5PUn//RPph689dXpy5yV/7HF42n2CM1+esWWVC9F08k/mQ+QkfsAo/dH6BGg/nzy3IBLWo42kBa8sP43ofPaa3QxaWFYjYwCgD44x/8bG3EAlkfcuPSj90e0rWE51Md3/W9eMWl2/T/GEL0/qtEsjPuP1c8tYNsteC7p16E/72tp+Z6+83X1JVL48m/9n2bTI+wFolc2eGtaP/v6v8d6n6ZHrPS+5WJ8V98sX7hmU8jT7BH6qefiN0U5AYyOjADAyCjA/fs0rb4zpBn9l5/OfWqEpuc+7Z/3ceOHac+YRAKX52qIhBFtC43rOPqOYgjgX+bOJQDYC15Yt++zL0v92UyZ6/vFSnePjIwCZ9m6uOfY9AhNL1i6bCH0ff93a9OsSQR6/ccH2gjURuwrWaJxEWsSSGMVMR2e7AUehuF566vTLZyV2f+xbHww6xtzxHT+MTlNaCfhnz5lZzoJj9wfBY3T6t+ufoFHEHOfCwnTRybTZE6zR0cBBGuSPRfMZbN1pbI+xIy6W/v2nweujXyaPULTI894LrUntZOqvlNMW8Mw9i3OTn0AutOZNnNdYjvv1aH20jNm0yBhctJkig3d9AsANG3nmfvxF8fzVvxiLk3bPf1SlNBeef36bZp+IT7+eXndqav0CE2P3P3TxcuUd7T/AkMQsukRoyCclHP3wyS2s/htvvS0/P5g2xKb7FRO8P7Xz4x3Kh+eY2fH/sf3A+Dw0jP67dR/+WJENAAAOYcFXEfHZ7XpFX8bUGrad4R57jA6hv3f/9uO/Sx1589Vew439spJDQAApQE/esSO/ezqreu/yNsWs9LJTSgOCogID3DnEdbyMa6g3RwWsObotj6fM4fF+V+/+pX+V0/9fwQoRkZA0c+YFXtsC/U5LI7jc78CgHFN57fpNZ/MnetCz7h6eS0Th0dH+DnNBwA7FnAc/vUZ/a7rC35C6Le5v3Pjwq6K2k6ZktQAgIbUONwdYQOMsNksDo//zM+0DXjnH7c0Kmmud73xsZ7/xx223c+MKkj+t0rD4S2Yq9/Jnc1iAWsOW9tl2vrqyqyvr50dc86eaxKcPjn9yXev5AkUf/yynRd2/MW5Zg+lGxeSpkfmPkXA8DBtx7aDkb/98f13T12VafuPUmm4zmw7tt0vg+L83n3rs2uUr+inf2+u71sYt2uJnV2fldqBcQ/e+HOXCjSthw/O37L9mafs7LgBhUcCTIukTUzd/pscHJY8q2/wZ/3inwUAUM8BYM2xs2P/468DwA9zJvQ9+EvHX3FVsr/fsbOz3IN//75fM/DnNK+TxsfyunPHzs7epEHmALDmsO3YoBjoV81zfO5X+r6AZ57jwxd//Zsd+1kwR9MjdmwWgGYOzbaz/Nz/2IgDAOJ/WRhxJsn1oQ4wog3X8aFuret/ZpIZQ4jCHBaH+6//+qz+0M88x4cv/vYPu9vfD2h4fo76EsLP/o3P17T232bbueh6f2SFDyGztfe1qH/cUnIcnnla3z7PODpyANhsAGCzAObMsbNbsPLVLfVZu1cGVXl5CcVBoRHhQkcCjCOBpkfs9JFwR9tC+gnK0HF2nuvyI64WbIy+uMhTvDwwOCYw2MUewHLmhn4BkrG7ndksDo/39E91B5r7FAEaDa0/riUmEejzUuTKFc/NB9BG7L/p8zGK2LGHU2l6ZKwipsNTd+jhYdqOzRzMbH1jss3ea3yasDwJA1s7t//Sjk3TI3Z2Tz1F6COTYTIn7FgsDt/FidDmbMsQo2lDd7PBjsXi8H5lCIm5LJZuUtV3Cpi0hp1+7FucnQBAezrTZj6W2HNNsvMn1abTIJicNJliQzf9anOG29+ekHzY0ClXajQAQJEatzlsOzv283Hxbr8/dOZPv13mB9989g0Evhn6M7bdz/RB6LJM7BWgD0Jzj21VMPs+i2QTDdMvTB6mmhexv0HiZ9ZkVJsk87XLwrf218Q5cwGohtyQPO1vuMLcqgvr/tL+zbd/aqnbn15+KHZvZaHLWD6TwbasOByLLzvHSC4Gya+1tzY0XqrKTzog2H7kwBrGDyvIT+dlHdWkSI7vF/IIANnRhORa40MYNxU/5fDFvEeyQzRDzk4Ra5Ye/P1nbdn8m3VXnWO2Lbb8bgvtMFRXslkij9j1fkUQnwBQ1GSGV2h/w/WLEUJhbTslevp8rcwlPkLfNLbUTtHZ3QfPp39Q5N75XkHyUbeS4/siLAxsg4d7ntFiDwIALMqpq05xtDkfy/ExzRg3u+U5zmqIcmyrpb4jdL3fRvnwmHt/QlOtMcJlXcVX0bL21ubG1oaKnAMVATs/LA02KYAt+MElxxuze7/5Y8ulr8+UpO4/nFlemS6wmHmk0YP9VhtiYrFgHIEf/e7Dg276CHwYDId2yf3seNKz5u1s+tip6fwzhivMrbqQKr3a3N46NgkzTpjMk7mlUtWdXGf7EHs4zLOTRU4RCa4HKkymQdo0xQNjA6B3b1bBOf6W8pPr3HkA0FESkqN7TokXluS3/61TrUNucO4yEbTPmwAwBGHb5daGRqMgnMxmmIDZ9yTvg/Fd+Jy+vxgeNVO0nz58ftzTtTwnZ3uVTNpneIFSyIcoABhoblc5BaXF6Z7y72+T6ZdDFDlEETwX77iUbZKqYzv9lOdOdVCM+Uwcb+GPzGpIQVJcvnvQmtySfZ9+sIHb/vFZ5m8VoKTfdILr+kwhjwAAGJJ2yCyv+xz4fI5C2jv2OBepvDn+oVquPZfQDJETqrm1nPlhq5drms5drD/XtSgpwsn2TKXtXZRL9MtB2if/qZ6uPkO15vvG+3E6LrZ2X2gccIsJc7S9dkB1Xu4FvjDYa1Fw+tZI3mB7Yy8A2Vz+XvO4GhP8hXxNv9TQ8vLWqsp64+dD+S58Tl/32KOQ8j4ZOc/ZyR4YetDZxYkj/7N0rFSkQm7lw88APAdHrkreZ3hIj5JJ5eC0aDp98NamZrcaohqlvM/wdrlMDnwnR3BY7MxRyPoNg31INqDk/NKZD6Dv/brLXRPtfYJnz9Uo5YZEfb3jRwpFkkPAdfYKS80rOvKJJJK6VN2oZIwEDgcojWFaUciVhv8PkRTBW+S3akPh3uOn8px6jn/WyZD52LEntbuNI/CTg6naCLQSsRPl7OLEkV+dQDCb0U3CPiaTMGNq5sl8cktlMyuzk0WOEfHWp8EHxAYAKLo65Rxxinb5AiDvlRrCDbjBCQGc9s/q6j5rsQ9N0C3jdUEojkkzDsKp8iSuYByD4r3g63f3td4kSYW0dlfh3rMyYr55KmFSzELZkbKqTiUADMlqCzYkpR/vBeA680Eu7ZBRAGTfhZ2HOmGeRqFUANlQmBix5Wi7nAIASt7dJtfw+PYEYz6mOBwOkDf7lEOUlXP8MpuyYiI7mh6V/lZd3xAAANnT2UsSDlY+bEnYO/A0/S3tSgBK0X604LySB6RSMb54hF9CKK/9UMn53iEAILuqtqck5p6+aZ5s4WI+SLv6DRUG0Cj6BhSklQpbzZm7Yr0vXJDs7xTEB0/kixR4fHuN/GqbHADIazUlx2RcDilXaKcjYlmsH1z+w4EG5bLYIPuJ1K63Taqy9wpYDKD9o9qebw/y+nNKV7fxf5u4RCcJlOf2Hb2mIIfkXVU7d7x7meQaJXMMj18Olw7+/qqCAqD6LpR/3OMUnehFMPUgLyjeF77ZK6m/SQFQyrbynJjUsobxJ1oORyPvk5EkRXkmxizsqdx7VkYCgKL90PuNGr/EMKa/Lynt9fWHvGw0jj7UrfX8uGY//rsN45vdSohqADjSMwca5RQAJTt9uFHl4uvjDFy/hFBu+9Hd2tflre9WtHIDVwdrRwGxLNYPmiv3W+l9i8UAQajY/vvqinoZCZSiq6rii3GfUu3alRyZLmm9SQIApZD2yjTzHPnzjCOBlHcbIoHv4gTy1jY5AAAl/fhYu+6MojifFxFXUC1VUgBA9rW1K4G/kM+U+ZiJdbeWrG5PSWWr+adMTCNQ2q2LQG3Evl/RYR6xZv01FoGMx+UFxftB677//YX1YGagm4TbzCdhJkyTueVSPXCITYjF1rA2O1muQYDVaZApNoymX649j9D0tHcNAVDypr2SS5Q9KPp0IUz4xUdyW3dJWp0To10AgDEIp8yTuIIBXnTZ/9ns3FmW6B8SnnFrC89tAAAgAElEQVRUEbSzImfR+FSLc8rLE7jnchNf9AoIyjhBhUvK0xcB2Efm5AaThxL8xb7JJS1uW8oLol369idm1DoXSDbbXyr89zCBh8g3dY9MkF+eLTDOR+ghNsrHrEg+sX7clsLIiC21486OFopkLSsmzmvLS3wUFZlBHiKBKDbnFJFaVhRn5Ttk3NLeTHFoy40UimI3HofUktLNvnAhN7bwsvn0M98vv6IsTFOZHSQSCaMK6rhp5WVrxs2PfD9fB0V7q/4PTqe4xGVQlxMUVWBlIrCaM7E8MZBHcvwSAyb0RTjOifmvuvTtjhML/dPf7Qt9c++WSN7Vgri8CwoAIMQxgdD9Z6VXdLA+U5tqRw7cpBZGxrgSAACCpMxQorEss3wgNjtw3MoYAJxS90pe5tbnRIX4xeVVE9HmGfKid+/fwu94K8ZfLHwp8zAZIDmwzZ1g7kFeWMnB19zlhxL9xUL/xIKuha8eyA8etzZ1i4l2U364PiTxnW7CPbtcEkEdzogUisQxhVeds8t3x1j4i7lNkrJ6zeoYyVXgaBryk1bFpWTavmJmog/1qOzPrYS6WbNf5KZaaHbGENUAxeHHpLk1FsT4i32TD5F++ZLMRbpsC4Q3y9f7isS+qXtkXvmHigL0fUSIYwKh66qV3rdcDEL42t4tLtKyBH9x0Ib98phNwfYAJmdpwfa9+YulZYkhIoFHSEz+JedMyWt+hHEkrEjYboiE+UFb3gwiDyRHhMelZFbOS0pZxAGNBoAXU7Q7BqqzYld4+QhDMg+TAZJd8Y6MmY+Vz8buNnbzcm3NxV7zoWkagbmnDREYvXv/Fn57iXnEmnWXPgJ3dTEfmBe284N8wcBh68HMgBtcINlsf6kgOcRsEmbANJmfML82zQvb+UH+A4fYhFhsDYuzU1HC9guMn1i2Pg0yBp52+g1dVdigCXz1jVDi/OYgUXB47heOmaU7U1yVNemryrXFEiQlLNSAa2y4k64l9EHo6yEyCsIpw6KH1eNfnWYP52LiWZFYfnpj3IeLP6jebuG6xMPk/M8v8yP22Zd/kr/8Qfdgp2NrYGJMPJ0Tk7XZ26nCA2us/Hkw7cr8RCYeqsszngYnuxhUW2FSDpVbtytw7rRsjSfyGgyaEvzoV1M45yRnJmVHD1L6SYGkwy1zwwOXLwihiVI01pNewun+Nd9PvCHp6Uc5DVKyurKSRvuXMy1eS54WcAWDHhvCPVOymThaYL6z40QpqzPEKzZ+SMZIdsZM4R1YhGYtXsy+I+lOU10KZIWyOkPsl/rIpkGqKVvknyDpX16y8+Xp9JC/GbyLhIkxMSbGxJgYE2PimZcYr8EghBBCaObBFQxCCCGEZh5cwSCEEEJo5sEVDEIIIYRmnidlBSOrTBEmH52Uz/E+Aq0F/uLMuof+gE5Tnkic3TiZBZoSsj9seCR9JN0T5ZtRJX9wQotk5YnTK3LaywJFmdWM33CFrOpkar0pGEQ3j6cL497rech3K89miAN3dkxqiZDNpHvCRekPmlWY+6hj1xSO4h8XeA/BMLgmP2jttNtVj8f0+gxNPLZ9+SMqhvybmq6fx4QvImzNmZJe/FwhXO3HGwG4f38URkdGHvhGhgS6Hdtp2pbEE8r5gYkNtZicnM366MHFMGp2U32NH/W7/HsAHwDoUQC4T5u3zwNy1vvF6pJDL3F/wVyqxx3Pz63fc5DkL5iS7p75iUfuA4yOmAYDTY8wDaLJL4ZRxI6MjMLo6Ig+tCaa8/1RgPv3bXnX5LezvhYwzbv70SWmR0dh9L6FQDLG3EeLNlgcxRMuhu2JLQXe5OT84MSGwcXYIA9dDDuLn2Kanp+b+jGJjbYvfyTFuPmnw+80xq9cuQRszfn6iT1VP31ndcAv2QBz5rCAxWZbfyNzMeawQPv2iZV5MhJfP7Gnirs3IeCXk5AzgEkf2VIMQ7Obv0V6Yd+hge0bgp8FADsWAMyxM2mfB+Zs+NHu2SXLbE48oZwfMvHPfrXsZ9OgGDM0MXsOAIttFAz6xBYG0aMohnHEstksYLHYdmy7h8p5DgtgzpwHvutRtLO2FhHhi346zbv70SW2Y7GANcdCIBlj7COa67DM81ePs8wWA8/ms9WPLIZhcFluEPw0tSlFR9X29HB/sUAUkZB7tG3clbqhzhP5v17tKxILRRGrMsrO6vdUHeo8kZca6ysSCUTB4alvVHXqdgWhpJ+VZKWE+4uFoohVWXsa5Oa3e3oqU2JKuzWXy4JEKZV9AJS8QZK9KkQsFIl9o1KyKzvMi0A15flvPqcc+Og3Ab7bm7TZccirVbkpgSKR0D92Y7lhTzVlc2VeSlSEr0jsvyoj7/i4PbTNkF3Vhenh/mJPrwDfqPSCGt13x8kqU4SpRy+UpweKYks6AUDZIMkM9xcL/WNTCmtbPsoYu6hIdlUVZq4KCRaKggOT8w63KM0ax9M3VNc4+locyxAbamEox7XKvI2pKRuKP+uR1e/Kzc7MSk/J2tPw4Fs5yp6aNxJCxAJRcHhG2QVt+pYdvqLss4Y9Wtp3BIqyz5MmzX7Y+DZPe1l46od95Bc5ouDM87rya2SnC1IjhCKRMCS9pFFfDobKGhu7i9RZFijKrm45mp2akhAVERiVWTK2y6u8uTwvIUQs9AgOT32jWhs57WWBoryqurIEf3FCZR8wBxIlqy3JSAwUiQQe4sDkPEPgWQ7IsbtIyrMZ4lWS+rM7szf8+9rwkIhVuSf0e1yb9G+zxYvGVH22KDivprYkIyUhLjYwJDG7Uh9dRgHsv2qDLoDlJ1LG2plqyA0WiPIadIeTH07W1pG62bgnMznWVyQW+idu3FmrL09TtiiioKY2L04szKg1HQ5Uz/kdG+OChR4ioX9EQu57zQrD62Ub4yKEIrHQP3ZD8SfXDAGgaD2cq23G4MDk7F263rTSGubI9qPZcRFCD7FvXPa+y+M73eTQKYWnr5G66lf2Wa2+onVvbkqgSCzwEPtGZRZ+av7NjZYiViOvK9sYFfyiV0Bg8huGuYiS1lqfc0wp2yrzEqK0bZi4cWe9zKjZC09/Zmh2Sno6LzlCKBL7xmXvbakvCBFn625e6+YZf98A36h0o3lGFwkCD5EwJDFT0nTTqBYv+W44bH571VLTAUBn2Uu+rzKMnbEpzvTQRizNAGdJXQznn/7MQgwbkVWmCFPfu3D8jZTkxJcCV67aXtsja9qVlZ4QF+EblblLO+rJ+kxRcF6LoR712aLg/Mu6RrAwurWdZzSrlDYNWO4czcDZnfrz0Xb9iDC6i2SlU7Sj+MXA1WajmCE8zLvbgCnwMlaFCj3ExoF3s/G9zOQIoYdIIIpYlWUYjE15oojCTy/tzU3XtnNmeYelM9FYHL4YuNYoDh8lelg9/t89tcri6zMh8fUjaT7ircc6Bm4PDlw5mObjnnasf1j9/cF49/iK74fV9EBNhrcwaeeXt1RqWnXj09fD3EOLWlVqevhKaagw7p0rt1RqWvVD6zvrRKGlHcNqeuDc5hU+qe8096vUtOpGfVG0e2hRh8r86E2v+7hvqhkcVt9TKzveDnNfsfVU9216WH2royLVW5j60Q3zAvdXJnuGvXVFW+aGfG+BaOXWg603BlW3vz+9Vbw0rLRbTQ+ru9+Jd1+5TZvVf135IGOFT8bpcVkNX8j1FGbVq+nhO61FAUtC8+v7b99TK/s/zQ9ZGlbaoaaH1f1/WOfuHZbxdkP/4O27w+r+j9LcPddJOm7Tw7e7T2+LfdFnibZxhm98pGs9NT18+/vT20I84w/2mjTOvTv9Y43TX5nsqTuEyb/eiqyi5sFuSeRSgWitpHVQTQ/faXo9QNsXTD14/f34JZ4+ya+f+37wzt2BZslaoS59U77Ic9OpQX3K1nyx56bq2yrjZjfL6u6nm9w9tzVpf+wuDV7qE7KptL739l3VjfrXo5d45zepGCtrFnXfvxOti5yO0pClwpBtNf0qNT2s/v7gOvcV+V/dUdHD6u53ot1Dt33a/cPdwRtNb8e7e2+tH9SmD4jcWtE6cPuuykogXZOsFIq31nw/qKZVPzS9He++Ir9Jpb6n/sZyQLYWiT3TPhpQ08O3T20SunuvK229fU+togcv5K4QJv/hBj2uf+O8Df1rPFIuZHkK3Ffm1w+o6WH13Y7SOM+A/KY79PAd4wD+4coBfQBfk6wUpp7+gR5W08PNhSuiI1eGFbaqae2Y8owu7Vb/T/ObId7xhfXXB4fVdweaJWt9xNsuDA6r6eGGXG+hOD7/o+4fBlV3TIrRWxHnGV3YdOPusPruwJUjmwLE2y7cHVYP1m8Te0bn12tfb3hrtVC09dytYTU9fP1gvFCUVqntte6Ptoo9oyXd1lrD5F9HkXipjzittKn/9t3BG/VF0e4vbvl00HgQmR+6NF576GuSlcL11f3M1b9Tv81HlFbZPaimh2/31xfFvqgdO5YnCu2oXOIdkFx07vvBO//z968l8ULdrwbOZVmdc+6pVfTwD6fShOKiZnpYPfjpVpFnfGnrD3eH1YO9x7LGKt6Q6y0Ur96ua3ZVc2GoIGTbuX6V+m5/gyQtTLRUV2XDPHNPrRrsqDTMM7dOb3JfsfVU7x16WD3YW5Mb6pNx+gdDLf5r3PzM0HRquqM0eNzYaVKZT3GGQ5vP/JZmgFOD+hiO2j4uhk1K1f+HdUs8w3JP36CH1fdufJDsKRTFFzUNqOnhO91vR7uvlHQPq+nBcxmePrlN+nepzmV5+rz6FfPo7i4NMZtVXtzeZH5e+OFUmtDdOzr3o2u3VHdudVdmeAsi37lGD6vvNb+pG8XMnWIYxffUAyajmDE8TLvbhsC7flt5d6B5LPD6j6V6+qQevHJLpb47cOVgmo9oU80tXSAJ3Fe/aWjnyKXaQWfa+0Zx+F/Xq4zi0DC4xoLW+N+PWRXMumsw0trqTvvYzDXuPO58nuDlktI3E0wekrh58UwLJ/Q3W715BADBj8ze4Cavr26nAFQkCQSXyyUACPvlOZWXP9/mDqBoPHOZs/LVHKEjAUDwg3PSliuaatqZC0D9ueb8wOL03DgXLgDw3NKywue1n7pkZRteLX7Mlpe9+PMJrnP4SjeOUiajADqOne9fnp6vzYorWLs5gttWYyUrYnleTePJ/GA+F4BwjIhebq/skeovQlCLYjN9HLlcApRtF7sJvw1ZblwA7uKYbSkuGn3rnanqdHo5b407DwC4zjFb1rv0nz3fy9Q4TGTtfe6JQo20Ww7Pv1yydTkXAAgul9B0ftP5gFW56/q8MGcuQfCEWek+0PlFy+Q87MbxS98W7MwlCH5wjNCe6pcprVSWAQEA9sEp0Y4EAICzlyuP7O9TAkDHsfMDbhu3RbrYE1y+OLtUkreST2nTg3vC2uU8LkFYCaRFWVXnzpdFO3MBCHtxjA+f7JXKwdY2F8Rv9uICAHCFfi4gk/bDuP5db+jfcRVyjknT7sNMuK2NdRlsbuwG6qpJAAs26AN4kdjLXtrSRQGAtLWN65Pqx+ls6QUAqqu1kysMdiEbP/qc9N26PchpPgDBE2ZlBmgaP2shtcfScH3XJbnYzydMn1kilaQ2OAAIniD1QF3TrkACyJaaS6TXpteC+AQAwfPJTPOmWmqbSQDpmWqpQ2zeOm2vLU7cFMvvrzuv397XQmtYCAbxxi1iPpfg8oMz1wpU31xoNw5K80Nv3uhDtdQ2k4vEXvbS1m7m6muGSA1wuFwuAHAdg/JPNn1ow9exC17O0Qb8srjwhSDvkwMoGs+0ENG2zznzIwrPf17xqpc9ATDfOTrSDXrae/VdrOH6JOuaXfpFi/z5pMwwRwIIvk9uto9+c2WTeWa+2zrDPEORKiDmzecSADDfOVryeUOFtU2tmZpOOxZ+bjZ2ZErGQ9v+2D0B4LQq1TyGx+Mui9V+9T7f1YWrsfeNF/MAgHD2cgL5gNXDMYxuAPNZRaOtkRmNxin+1cRFPILguax7OfznfZdbTa5bMXYK4yi2Eh4m3f0AhsATGgIP+NHln9eUpwt4BBA8QWz4IkraLTO0c/QGfTsvW8wZkI67wGIch1ynKOM4fHRsezRg5qDk/XJwWGzYJoLvE8cHADBc+JNL5cAPdTb0L4/vyFXJ+pTg5/Nynk/mzqSgU65eXsvE4dERfk7zAWTSPs3A1fUeJ42P4qVUAjCMZHJARs7jO41tVMF35sPFXhmA1S3IOTy+g+6/BDGfAIVGA4q+m0pNe2GIoNAooX2/wkpWyo4qyYcNnXIFpWGxgCI1bmMHcODrBodSptDYC/j6NrB3cXXgfAOgbT1N9+4o0W7jkvHlAIGGxhEu8/SPXKVtHCbOiUUvA9VQ0a1xWO2lm8RJmaXxbd4K/EXO+hFM8BfyNZduPvhNNuA4OBs6hMvRVpy5ss8x52PPNzyzbAghRd9NkuPI18cD4RQc4wQAoATg8F30oWYlkEhp7a6K2k6ZktQAgIbUOAxpAMDbYkCaIXj28wHGHgekYHz/LhY4cC5brg/fEHVgz+NxSLmSIkmmAF4e5Aql3/RAIK/9Kum2KcJXeeBIlwIW3Wzp5njlu4Hy6ICG7M3xumh8iOflCgAuAHAcnR1gPLe12yM6CjZEXnBZJvYKCI4JDHaxBxjokWt4fg6G+nKdHPiab2RyoGQDCo6Dy1jpFi7mc47JByhwYmgNC5U2dArw+Px5mn65cZCZH3q+swNf0yqTQ2SQK+z8pgeCGarPdcvZUpdVFuF/1MtLKA4KDQ3xePZB8yvH3jAqgUMQoNFQ2lCRX13v8bFxSmtzDqVsO7LncGOvnNQAAFAa8NPol9AcvpOu2Sm5UsHh8w1N57LMhVMLAFbmGfeYLevr8nKiIpzchOKggIjwAHeelVMjY9Npq2p57DAc+lnmw5ji8B3GxbDREXSJuPZjByc4PP1oJTgcAiyv78dKyDy6jWcVDkPxuM5Ohuma78yHi303AZ7Rv8LYKUajmAYwHsXM4QHG3W2dLvBoAKPAA9DIGt9799RVmTaSKJWG62R4B8/+5/r/EwQBpEZj3sxGcTg6CiyNcRw+KrNtBaP1cHffnGMkF4Pk19pbGxovVeUnHRBsP3JgDQDAopy66hSr6w8TDKH8cOZF7G+Q+AHY9LhT796sgnP8LeUn1y1dMGJn921JSM7Yep/DsSmSON5vfbUvjmv+sqFxvvqqydA4Vv/C7G7o1Mzz8V6s/YnqaOnScFy83X58OFPWp5yJsFTZiX14SktjW8hZDCT56byso5oUyfH9Qh4BIDuakKydwiwH5CPcZE1fB6YAJtwCvMij7TKlfUvf4hjX+W7KxdJLbaRQ3kW6bXQlQAkA/JTDF/MElt9veZLnB5ccb8zubbvc2tB4piR1/+HM8sp0C1HC0OkPEwvEBIeo9hgPqj6Ay7qKr6Jl7a3Nja0NFTkH3l+xs+rtyAfs78xQFJfcupPrbJtzqDZJ5muXhW/tr4lz5gJQDbkheSZHsKW2unnGfJLhCnOrLqRKrza3t7bU7U8vPxS7t7LQb9zswMyG7hmb4gweMAatzACP4sELG0c3A87knhC0rISHTd0NFgNvqK5ks0Qesev9iiA+AaCoyQyvsL1MJnFI0//8Oi8s78Hv+rFm210kgr+Qr+mXGs7b8taqynrjB/r4LnxOX/fYBTB5n4yc5+xkDwBDCpLi8t2D1uSW7Pv0gw3c9o/PysDZxYkj/7N07OEtUiEf+8ECnoMjV6W9JgcAAJRMKgenRQ9z4uE5OdurZNI+wwuUQj5kZTApujrlHHGK9gI7gLxXqrQ40u0deaCUGx4OVEp7B3RzNH8hX9PfKR07xpBcqf3B0DjZxe8aGsca6aU2JcdNuFR7Lhq6/EUL+fPIzDDrk7JG2W8oFiXvl3Psne0BCODo/0YAgCGlclKmKSuVnRiek6O9UY9TfRcqT4x/ZpkpkCjpN53guj5TqP3jdkjaIdN3msWAtIF5//ZIB5hO/0b3WQbkSg2X70Dw+IwBzBWKXQbaLre2SJ383LjAdV3u1NXS2Nosdw324gI48B04Cmnv2H0/UnnT6ljR5j9EUgRvkTgmrXDv8VN5Tj3HP+sEh8XOHIWs3/C0INk3oOA4OPOBcDYd4Nq/+/lOE1gYa+Q9ffr/K+RyFYfPN762YX7oIZnu0MAV+lqrPlAkOQRcZ6+w1LyiI59IwjVfVzc+zCVEZxcnjvyqzXPOQHO7yikoLU539bK/TWa5twmePVcjlxs6Vtot1Sa0Ms9Q5BBF8Fx84lK2SaqO7fRTnjvVwTxGmJuOiY1TnLUZQNPXOy6GmQ/IiAMc0FCGYyiVSn3j2DK6mWmU8j7DiJDL5MB3Mp4DGTuFeRRPMDwmQNreRblEvxykvXxL9XT1TeTvA1vjcHLNthUMuEQnCZTn9h29piCH5F1VO3e8e5nkGkW0Y3j8crh08PdXFRQA1Xeh/OMep+hELwJkR9Oj0t+q6xsCACB7OntJwsGZC7ygeF/4Zq+k/iYFQCnbynNiUssaxgUMweFo5H0ykqQoz8SYhT2Ve8/KSABQtB96v1HjlzjuzM3hcICU9ymHKCsnTWFSzELZkbKqTiUAkH2fFWxISj/OfGeRa88jND3tXUMAlPzSXsklyh4UfePnUPvlQa7U5Y+rpSQA2VOz53ivfj3uEp/qpTwn2d+soACom41l6XHpu9oppsbR1uKmpVrIWjrkoCG11zYVTbslrfyNktf8uAAgq9tTUtlq+fkWqqtqX4cCAMjeY5Wt4Ba6nAfAX+QIfW1dJAAA2fF+zdh9bqNmN82HIEAzIJOR1hZ8TJWdMNfEiIU9lXurpcohUt5cUfLWkavUuL9wmAKJsHfgafpb2pUAlKL9aMF5JQ9IpYKCvg8tt/mDmffvMSnjn2XyxqNnZSQAdbPuULXUIThiEcAykwDuOGwUwPZ+QU6dNUfbuMuW8wHAycuNaKs8I3XyWc4DAMJvzUu89kMl53uHAIDsqtqekph72voTYIrzeRFxBdVSJQUAZF9buxL4C/nA9UsI5bYf3d0opwAoeeu+33/DDYoP5hoG+IkeEgDInpr3zsmfT0pYZEu7AGivCahajp+4RgKAsu3Ima553pFexqc880O/W9GqOzTY+wUsZK5+167kyHRJ600SACiFtLePmufIn2d2fMaINcILiveD1gfOOYYCO/NBLu2QUQBk34WdhzphnkahtDC+BAHL7b+vPtJ0kwJK3rqr4pI+S5N5ZkhWq59nyIbCxIgtR9vkFABQ8u42uYbHtycYa2Gl6ZgwHdoU8wwAAPKmqnExPHGEkzNfI23ppgAAlA2VtfpFsk2jm4kGgCM9c0DbILLThxtVLr4+Jn/NMnYK4yieYHjo62dL4PHtNfKrbXIAIK/VlByTcTmkXGHr6sgkDuvePswYh5Nq1q1gwCl1r+Rlbn1OVIhfXF41EV1etsZk9cCL3r1/C7/jrRh/sfClzMNkgOTANncCwHlteYmPoiIzyEMkEMXmnCJSy4rieAC8sJKDr7nLDyX6i4X+iQVdC189kD9+TLrFRLspP1wfkvhON+GeXS6JoA5nRApF4pjCq87Z5bvHP/7G84n1417eER2xpdbKFL84p7w8gXsuN1HoIX7pNyepcEl5OvP4JAJffSOUOL85SBS88v//0jGzdGeKq7ImfVV5l1lC54TCN4M0h1NDhP7rd0kDMqMd9EOSn7T3/Vedut9aHSIUhaSUy5eXlG/3Iowbx9M33qhxfGL9uC2FkeNqoWy73A/8UEHfuxuzMlNyP+NmVx7PEWhvkN+8XFtzsXf8uNCQGo5LdBL/TGZIsDAks5qIlpSscQQAfvRrOYt6dsYGRiUm5H7hkhLNB412HBqafZdpFQmv+Finvt2rI9MrrDxKxlDZCSPc88olEVRVRqyff1LBZYfN+wst3DtgCiS3tDdTHNpyI4Wi2I3HIbWkdLMvXMiNLZSvthyQNjDr36wYB6ab9H6JAdLS9EBRSIykzyVv56teBIBJAK8uNglgR69l9n394OajvTm42MuV7OvnB/lohxjX97WKsjBNZXaQSCSMKqjjppmPvvGtElO0Owaqs2J9PUTCkMzDZIBkV7wjwHy//IoC4c3y9b4isW/qHpnwtSMlgfMB9AO8NjNKLBTFZp4iUg/ss+GBWQMKOMvWx2jeT43wFcXmtNin/O/XzIaz+aG98vWHBr7QSvUF2/fmL5aWJYaIBB4hMfmXnF7Z9ZqfeTgxRaxpo4Tt/CD/gXOOnn1kTm4weSjBX+ybXNLitqW8INqlb39ixgnzC3aEz/ZdG5w7S2JeFIfnnuGnb/LSh4VhnnnRKyAo44R+nuEGF0g2218qSA4ReIh8U/fIBPnl2QJDLdLC15rVwkrTMTGe4owObcrSDKC/XMLxXbNiXAw/hEWpeRv4l/OCohITUne0+a0LttdQGrB1dDOhOPyYNLfGghh/sW/yIdIvX5JpWjvmTjGM4hcDN5iM4omFh44tgeecmP+qS9/uOLHQP/3dvtA3926J5F0tiMu7YNMyxCQOLws2M8bhpGLRw+rxr86ALxTCxD8yMUWB/nn1qyURm/626eIHa2wZmDYVg6zPDinojHn/y3wPC4nJ2uztVOEB88PNmKabEYmN+vfazoj0vrH+1SduyhMVULua9wVNmzJj4kee2CgsFKc3Rh1yPlBX6PX4izFZiZvyRAX33r70f16aQWUen5i5UygKCEKb2GwUT3WZp0vi2XcNBj3YUF2er//mve1KCmBIeuLgJdXiIB/b/654IKqztVMzb3mQq8XfKhrrSS/hJB4OmTHr3/cbJ7l/0czUuzfOPzy3VkYCUPKGio87uT7BDE9do8eFsVNwFNtidn4WCVk3PyJ/t7Ts3e2xlUoNx/55r+iS3SlWHrebmDZJSl5NvxKgpTQ9f9Ped1b/wiwBL2bfkck6GLLErH+Xx+ycxP5FM9airF2Fyp2HUkJKSJjHdwnYfmCb+JF+1C+dELcAACAASURBVBU9GGOn4Ci2Bd5FwsSYGBNjYkyMiTHxzEuMd5EQQgghNPOw7qlVU10GhBBCCKGJsbN49WZ6Xi/CxJgYE2NiTIyJMTEm1sK7SAghhBCaeXAFgxBCCKGZZ3avYMizWWLfwtZHeoybx9OFce/1PNJjPCpUT3lKYMaJcdukI4QQQtPdLFzBDHXWnu2cnJ2uGMlbq+t6H815v6/heJP1rWQmD7E4p/Rl6lD+7x9RXRBCCKFHZfatYMiWI3uOtT/MlrC2u9lyaNf5R3PWl9burfjikW4kYcopKSeMPP3uuQnstooQQghNvVm2glFWZ0S+1qiS7lsvjCprAwAADigbyrNX+YsFouBVudo9aQGAutm4JzM51lckFvonbtxZ22NxPaJoPZybEhUYIBQFByZn72qUA0BPZUpMabfmclmQKOWwbq2hkdeVbYwKFnqIX/r3N8/q78pQ0tqSrJRwf7FQFLEqa0+Dbqd0ZXWGeJWktior9kXfNxuMD9deFp76YR/5RY4oOPO80qyQGW9/pi9kU7YooqCmNi9OLMyoVUBTniiioKa+JCtlVVSEb1Tmrpa+zo/eTElODA+JWJV7WlccReve3JRAkVjgIfaNyizQr8AIr7UJ/L9U1fRNVh8ghBBCj8EsW8HYJ31Qme7Ecck+1vF5/nIAACBbTlzgbzry5VctVZt47ft3n5cDANXxbnphBz+zvO5K8+VP8t2kezILm4bMc+s7vCXvMBlddupSx5VzFQnEhe05e6WwOP14ecw8jm9+45Xj2k1xNcr6w+3LCk9euPxleQx8/ZbkiyEAUNTnZe2RuWyr/LK544+VufzWvIy91ygA4HA4oKw7I4sp//JiQbDxAb3yz5d4czih5VcaKmLsqfa9JoXsfVdfSIIgVM2nOpbvOte4P5QHBBCDDed7Y3cd//Tzc7u9+o7lZx6ElytP1lw8uc2xfe/eRhKAapC8UUNGV3zV3PXthZo8px7JjmO65ZeTl/Dn8vbWx3XrCiGEEJoEs2wFY4HGOX57ooBHEPNdwiJdQCbtByAbP/qc9N26PchpPgDBE2ZlBmgaP2sxe3hGeqZa6hCbt86NBwDcxYmbYvn9dect7k0ueDknzJlLEDzhqrCFIO+TAygaz7QQ0a/mCB0JAIIfnJO2XNFU0657A8lf+XKEE5drZVcSsuF4rXEhf/PKCkMhCdBwfdcludjPJwgAIACcI+LduQBALPZyAkqwao0TAQC8Rcv5IJcrATRDpAY4XC4XALiOQfmn/qhbfgGAs+tC6Ot+jLeuEEIIoR9r9u/syOXz9ft5cjgcAAoAlPIBDdmb43XROOHzcgUAd+xnSjag4Di4jO2ltXAxn3NMPkCB+XauHHsHvv6NBIcDGg0FIJP2aeRX13t8bJzSS6kE4GhL5QhAWyu4Ui7XkFKmQnIcnR1MimBvr/sfcDjceTxCX2UAigQAbmTOlrqssgj/o15eQnFQaES40FG/fOJy7QlqUEGaVB8hhBCazmb/CoYJP+XwxbwJbS2vYf4Vx/LLLrl1J9c5mr+qu4piC+NCmn9xIYfhoAy5Ey7rKr6KlrW3Nje2NlTkHKgI2PlhaSRu1o4QQmhmmv13kSxx4DtwFNJeheEFUnlz3OevCeeFfE2/dOzmykCPXMPjO9m4Hb2zixNHflU6li2pkE/oM94OfP6DC2k7iiSHgOvsFZaaV3TkE0kkdam6UfeJLZJUUgSXhxdgEEIIzRyzbwXDAdAo+gYUJMX8aWfCb81LvPZDJed7hwCA7KranpKYe9r8UVaX6CSB8ty+E1ISAMiemvfOyZ9PSlgEAASHo5H3yUhrx+AFxftB615J/U0KgFK2lefEpJY1PHAJQhCgGZDJyCGK8EsINS7k8d9tsFBIW3XtSo5Ml7TeJAGAUkh7ZZp5jvx52t/JuvvBydXZ6vsRQgihaWX2rWCc4hKXQV1OUFSBleUC1/e1irIwTWV2kEgkjCqo46aVl60Zd7vHKXWv5GVu7ZZVAUJRbOYpIvXAPu3Tr24x0W7KD9eHJO6y+FyvFi9s5wf57vJDif5ioX9iQdfCVw/kBz/oOgfhFR/r1Ld7dWR6Re98v3zjQl7kploqpI0E2/fmL5aWJYaIBB4hMfmXnDMlr/lpLyf1tXcM8r18HjZnhBBCaAqw7qlVU10GNJWorl2rf9O/8dSBRP6DEyOEEELThJ3FXa2n5z7amPgRJO47sedL7rr98c+ybXyoexqUGRNjYkyMiTExJn6CP4uEAKie8pLDxKZDryyy8fFkhBBCaJrAFcyTjFicU9kEQNMjU10ShBBCaGJm35O8CCGEEJr9cAWDEEIIoZkHVzAIIYQQmnlwBYMQQgihmQdXMAghhBCaeXAFgxBCCKGZB1cwCCGEEJp5cAWDEEIIoZkHVzAIIYQQmnlwBYMQQgihmQdXMAghhBCaeVj31KqpLgNCCCGE0MTYWdzVenruo42JMTEmxsSYGBNjYkyshXeREEIIITTz4AoGIYQQQjOP3VQXYJKx7X5iW7IJ5YmJMTEmxsSY+PElHqHvTeAN6EmF12AQQgghNPPgCgYhhBBCMw+uYBBCCCE08+AKBiGEEEIzD65gEEIIITTz4AoGIYQQQjMPrmAQQgghNPPgCgYhhBBCMw+uYBBCCCE08+AKBiGEEEIzD+ueWjXVZZhMxE9+OtVFQAgh9KNQ9+5OdRHQDGBncVfr6bmP9iQmRgghNG1Nh9MEJp7+ifEuEkIIIYRmHlzBIIQQQmjmwRUMQgghhGYeXMEghBBCaObBFQxCCCGEZh5cwSCEEEJo5sEVDEIIIYRmHlzBTKLuYg+WBf+SfHKqS4YQQgjNMnZTXYBZorvYXbCjU1DUNfqtq/nvqpNYLFZpUVdn8bhfPQiLxZqc8iGE0BQZHR2d6iKg2QlXMJOi+9TZTgHTGiWpuus7d8HZU93FrhNewuDgRwjNZPhnGHp08C7SpPjL9e9g8QuM6xPXF1zgL9f/8jhLhBBCCM1quIKZFEuXvAA933Uz/br7OyksXbL0cZYIIYQQmtVwBTMpXBPi3Lp2CJKqLf2yOkmwo1MQl/AQt5AQQgghZBHrnlo11WWYTMRPfjp1Bz+ZzFlbPTzuZfeirm8n/hAvAACwWCx8DgYhNHM93CRG3bv7KAqDZhkWPawe/+r03EfblsRsu5/YmH5GwBUMQmiKLWABANx5yIno4SaxEfqejSmn1QkIEz/mxHgXCSGEEIMFLPP/IDRt4ArmcegudsfvtUMIzTBmqxZcxKBpBr8P5nFwLb42Wsz4W/y+BIQQQmiicAUz9azcJMbFDUJoytwZNbnu8rCPwiD0iOBdJIQQQgwMqxZcvqDpB1cwCCGEmOHaBU1XuIJBCCGE0MyDK5hJcTKZw3oA/CwSQgghNHlwBTMpkk9quorcAeySPh5lMHwyeapLiRBCCM0auIKZLK7F33YVLa1em2xxbySEEEIITSZcwUwi1+LfJUJ1suX9HRFCCCE0efD7YCZVUvVo0lSXASGEEHoC4DUYhBBCCM08rHtq1VSXYTIRP/npVBdhMuHe1AihqbeA9Zj3pqbu3X24w6Enip3FXa2n5z7ak5gYIYTQtDUdThOYePonxrtICCGEEJp5cAWDjHUXe7CSios97FgsFouVXA3dRv9HCCGEpg1cwSBzNWfhGD06Ovpx0ifJrPVwjB4d7SpyP/N2UfdUlwwhhBDSwxUMMpf4u2JXAIClS17Q/981IW7ptevfTXHBEEIIIQNcwSCEEEJo5sEVDEIIIYRmHlzBIIQQQmjmwRUMQgghhGYeFj2sHv/q9PzuGlsSs+1+YmP6GQG/kxchNPUe+3fyjtD3bEw5rU5AmPgxJ8ZrMAghhBCaeXAFgxBCyFxn1nOdWc9NdSkQsgZXMAghhEwY1i64iEHTGa5gEEIIjTFbteAiBk1bdjQ9YvEXTK9P88RsO9uTI4QQmo6mzzkFE0/nxPhZpGltWnwWqbvYY9n11zUnk6e4HAihx8T4uovbgRv4WSRMPD0T410kZN3J5GU7rk31Igoh9Di5Hbhh9h+EpiFcwSBG3cXuLNZa6eokd9ZUFwUh9Hjh2gVNf7iCQcxe+F3X6Oi3by6Z6nIghBBC5vDBV8TINelhHn1hsSb5is3UPwmEEEJo+sFrMAghhBCaeXAFM2mqk1k6ydUA3cUeLIOk6qku3GM0OtmmukIIIYSmI1zBTI7uYvdkaVHX6Ojo6OhJSGaxBDtcTupPwR+z1rPcirunuowIIYTQ7IErmEnRfepspyAuwRUAAJLWJMIc98I3k/S/TX7zd25dZ0/hEgYhhBCaLLiCmRR/uf4dLH7BdeyFOS7GP7m+4AJ/uf6Xx18uhBBCaJbCzyJNiqVLXoAz33UD6Jct96XGP3V/J4Wlq5dOVel+JNfibzVTXQaEEELIFF6DmRSuCXFj94mqT9fA/Wslbxke3zW5x4QQQgihHw+vwUwO1+JrJ6+zBKwdAABJJ0dHXyj2ELBYuu9TSTw52plk7e0IIYQQmhBcwUyapJOjSSfHfiz+drR4ysqCEEIIzXJ2TLtaT8N9tG1JzMYlGUIIzXDT55yCiadzYjuLu1pPz320JzHxY9Zd7C4oXfzx8MmH+ZZ+hBB6wkyH0wQmnv6J8Unex8G1+Noo8/KFxeyxlnK86iRdOdgeRfhtNgghhKYTXMFMvWn6hfrdxR4pvYXarxk+sajEM/nkg9+DEEIIPSa4gkEMXIu/Hf52h/5rhpPmSL/DyzAIIYSmDXzwdRJ1F3sIdlwb97Jd0kx/Aqa7+O3qJau7bPtCG1b7JN/8GvXCzR0RQgiZw2swk6O72J3FEpyJ67JwK+j46FrWjN3ZsbvYw44leItVeKwYv5EPIYTQ9IHXYCZF96mznYKirk6LZ/mk6q7v3AVnT3UXu868RYBr8bd0MVQnsTyTX7DtShJeMkEIIfQY4DWYSTFuZ0dTM35nR3wOBiGE0DTzpK5gDJ8TNpVU/eC3WrJ0yQvQw3yG7/5OCkuXzNSdHRFCCKHp50lbwZxM5rBYLBbrdIKlDy93vfA2i8Visf5lop8cdk2Ic+vaIbC8AKpOEuyYgTs7VieNtUP3demSuMQZVgGEEEKz2RO1gjnZDclvaka7Rke7TiZZumDiWvzt6Ojo6Ohw/JmfTGwR41p8bXT0Y9Z6Sxd23n6ha3TU8iMy01lSddcbPWu1VfC8/vq3M64CCCGEZjMWPawe/+r0/P5gWxKz7X7ClMCtuHvO2VPGr3z7bbGNmU8VFos1xd9rhxB6UnVmPed24AYAwAIW3HnIiejhJrER+p6NKafVCQgTP+bET9Bnkbp2CEa7iqa6FAghhBCaBE/QCqbIHYqg2PhhDrwtghBCCM1Qdky7Wk/DfbRtScxmXpJ9EneS5elxbmmc4ZXpfxcJIYSeQNPnnIKJp3NiO4v3n6bnHa8fmbhzRzLeRUIIoelvRpxTMPGUJ36C7iIl4V0khBBCaLZ4glYwUkiS4l0k67qLPZZdf11j2D1Av1flzN+cEiGE0CzzBK1gvj22BGCJ8SvJHFb1sP4H96KuJ/0rT04mL9txbTTJ8HN1smCHy8nRb5Oqk1nJyWuSTyZZeTNCCCH0OD1J32jnWjz277vvWO5nF181+jreuE8EbI+iJ3Xrn+5idxZrrXR1kjvL8NrJ02fdC99MAoCkN4vcPzk9we8p/n/t3U9z20aax/GnLUbjqqlKxW9hszWyKEBkXNmqOecNjGyJgGajfQM5ZY+rrETQmmiPm9O8AicRoD/WvoGct2qyGZGAqGhqZ99CplwzFY8sp/dAiaQoMKYpEGgA30/5YEFtdVOWiZ+7G/0AADBDZUowA5G3u9/4+qQ1vCfGa/tr7acbXkkzTHUz1Ppka2iOKjo71wtX1SqtxQU1aWVH9W7CvwAAuK2cCeb07Ky2WB296qw28l1B+g4sxy33ChoAIGdKtA9myNLiYrvbHX0YKeqey9JjKkjfkX6R9QgAACVQzgRjeZsN5SpHdHC9OTXyanar0/DbTEUAAGC+cq4i+e7Gvojsu4MC0narc+PKO29Xm7qAhve+DO+JAQDAAOVMMK5/od+A40/EXV1pP90JRCTYabUfr5b+GwIAMEg5V5EwEcffO5x3lXKl4uy94jAYAIBBSjUH47v3J1wbmrxlsVjeycXw5NP1ZBUzUgAAw5Qqwbj+yydH80oppdwgrkHk1XubYI6evOSeDQCAuSrjqlobWEd7ksZzb1gWc/0L1xeRwFEqJqI0fK1ZLQGATJlzT6GxyY0rsVWtzayjnWBjcQKSCgCYyYTbBI3Nb1yqVSQAAFAQpU0wvjuvYnAMDAAAeVDOBBN59fWg2gw5BqYv8uqVqxTnBDEXVb2sNS8BAEYqZ4I5PetKY9PjjNlrvvuo9auvtNZa+43939abvbTS7bZX/atsd8K3CwBgkHImmKXFqnzfTXhOIXCHFqGGZy/mrgOBsYLDoNrc7m1tdrabdvus27u8b98u4Q0AgAHKmWAs71nz3ucbCQaLwFXukbPXW4SKvPoHx785uV6Zev1v3z8aWpoxkBMMTbGc9uKLSNQ9rz1eY+YFAGCiElcV0O2ntno6crFynULejn/4XOzPtnp/MNhptZ/4J4Nbv7u1uWvvepGTg4WYyNsNqs3QEZHTszM531BP2yL3atvtk9Zko//i0Q/JDunT7x4k+wUBAAVQzjmYyNtoDXZ4JLST9+FV7eaoey4jiy9WdUFOz07vOOrZi7ya/fnDvd58THR2/pP85tn1NNKHPKUFADBIOedgejt5EzzSzl19vO4eBuI4ItbaynLrrCsymLKIuuey9Hgpuf5mIfJq9o7abl9nOMs7eeUNPq3Pu9HwaxqLKRMAQArKOQeT/E5ex99znru9nbyW92Xz3F3uP30cOPaO2n5m9BLS1ezL60mXigAAyFY5E0zyO3mvyjh/qdeVUsputSVs2VfPIh2uacOTQeRtfK62/3hzBS1whh6tOjtfXGmY/BIAJOGLRz8kvpUNmJFyJhjffdRqX7af2mrUHc/kdYKYvTW+6RWYgp3R74YTiDhB+Nn3672PPzj7N86DAYqun10IMcgFdfnqx9tXzazhNEnjucr9CdvnglJKa531KAAU3+3U8tGvP1z+/Z9FRN5T8pcp34imexN7fflywpZG3YBonHLjyriq1gbW0Z6k8ZyRW5OvdpmUtmQBALwNc+4pNDa5cTnnYHx3fj14FfeZKc+DuROl1M98ljkYAOkYnob59LsHnU/eZw6GxiY3Luc+GNe/uL1bpZFJfBGRmK0z11IfC4Dy6h+FwJkIyIVyJpg4TuA/CdZdkw//B4DZIrsgR0gwA85qQ44O7/AsUuTVbz3cdPfnmwAAwC0kmIGoez79n/VqStlHK2HMUtCXel2pwQF3hoi8+vxwtLqOX++88SIAANkjwfT5O7sdebI61T6Y6OC4YzfDTuyZKU4QNpfD4wOTIozvPmq1h7bZBK7dWvC11sNLabEXAQAwQTkTjO/O317sWQ+qzXDK0+dOz7r9yo4xjKrsGHk1pdbPHzu1wSNQ/uFxbXvLERFnq1l73ltKi70IAIARjDw+ZeZc/yLZZZGlxaocja98aFZlx+pmqF0r8urPz66uRGfneuFJb+zW4oI67kYiEndxgnN5O5+8n+x4r57nBABgSDnnYBJnra0shy3biV1pCRy71bFX1gw5ld9yXENGAgDA1Mo5ByO9Q+3ONsOOZ0VezW51RERqzXDa6j+W19ae784rdXsfTa0Zal2e0MCUCQAgBSWdgwnc9aDa/MqzJPI2ftcRx9da+wst+077VeMOytNaUxMRAICklTPB+IfPpbHpWSLS7bZfS2PVkQTOg8kta3FBnXd7z0pFZ+d6oWqNuQgAgBnKmWAGgsN9qTirjsjdzoPJOXd1pf10JxCRYKfVftx7pDz2IgAARijnPhh39fG6exiIow+fiywtLolcnwfzWTnv046/dzjvKuVKxdl75fzMRQAATKBe/vjXrMeQpF/c/+VkDa/LU9+rbbdPWlbk1e3Wgq+nPA9mVqYr6woAU/vi0Q+96kgZ1qb++8u/TdcdSqUSW9XazDraCTa+dSSM5Z1ob+I/DACYHRNuEzQ2v3Gp9sH47jwlfgAAKIJSJRjXv9D61ZOjeapGAwCQb6VKMD1Dp7aQZgAAyKcSJphht9IMOQYAgDwoeYIZ1ltj8ov/NHXgXE07zdWbUf9q5NVvz0XFXgQAIHtlTTD9u/hN8aUZiyTy6h//aTvUWmv99a+efnAVTQLXbi34Wmv/SbB+XVoh9iIAACYoW4Lx3d7Gl8O1uApGYXW36FMOlnfy6qTVqw/grDr3enUD/MPj2vaWIyLOVrP2vFdaIfYiAABGKNWZvH4k7taFuyUiIpHIrTo//VNhfPe+Ky8LvqIUebvB4uPQuip79KT37bAWF9RxNxKRuIuTlEZ6TyU80GmP0gIAFFiJEsyyt3Tv2Bu+cnLixTcV139Z6PQSefV6q61r223qZgMAcqlECSZs2TpsZj0KM1jeyaUngaM+cKuJb15mygQAMHslSjDNmjTFawzNOZR9+sFZdf7lP7rRmxsCAGCaEiWY5yu++qD+X0sr/SvjV5FKZniby2BPTOxFAACMUKJnkTot9+SPKyfPpP+rjAJn8KRVdHa+uNKwRMRdXWk/3QlEJNhptR+vujLuIgAARqhcXr6O/cS464Y3nhs/qeSwiiQiThB2a7ZS6yJScfZe+VcPVvt7h/OuUq5UnL1Xjoy/CACzZs49hcYmN1aXr36MbWFgHe1JGs9V7o9rUK+7cnouuVpFUkppzcZYALOl3hUR0S9ERL549MOn3z0Qkc4n7y///s8iIu+pqXfoT/cm9vry5YQtjboB0TjlxiXaB3PybFFkcfiKO6+CV9cf1JrhCY8WAyidXnzp/aYXYoBcKNE+GLG8wa9uV9WOH343dBzvynP7Rp0gACi+fnyJ/RAwWZkSzEDk7e43vr4+XF9ERCyv7a+1n254SWaYyKtXSlBrCQCA1JUzwZyendUWq6NXndWGnJ6dTvMFr8stjbBb7dey7xa91hKA3BpZNmIVCTlSzgSztLjYPuuOXo2657K0uDTNF3T9Zw0RsZvhzUqRzdqcNHyttdaJH30LAEnopxbiC/KlnAnG8jYb++6N9Z3Iq9mtTmNz2s28TqD13uKureqJrkMBwOyRXZBH5UwwvruxL3K9vnO14NO5cWWaRR/Xv9D+QosdwQAAzFo5E4zrX+g3mHbRx/F1uKWf2mqZuRgAAGamnAlmtiyvrcPmvd/ZauM467EAAFBMpUowvnt/wrWhyVuOYXknl2FT2u23OCsZAABMqlQJxvVfPjnqPfbsxh7SEnn13iaYoycv7/7okOWdaK11QEEhAACSVqoEI4MdMKsHsee3dDdn8uRz5NU4DwYAgASVqC7SDU6gU5wasby29sZ+VimV3lAAACiEyriq1gbW0Z6k8dxEkcx3f/EfD//nRlUBEZHAUR+rvdSPnvuZwq2EGwAlZM49hcYmN67EVrU2s452go1jRd1zkYd3+QoAgLsz4TZBY/Mbl2sfTHB1YN16cNF+at+uYtSxP9u6wwTM9UbgEeyAAQAgaeVKME6vRJHec+Zr22HMOXadaYsKRF5NKftoJe6LfqnXFQfcAXg7Xzz64YtHP2Q9CsBc5Uow15YWF9vPDxKMFNHBccduhvEByAnC5nJ4nGR/AIpKvSvqXelnF0IMME45E8zpWVceVqecbpniC1rVBTk9O02uPwCFpN4VEfnPf7yRWggxQKxyJhjXf9bY/zjB7SlLi1X5vjt2kiXqnsvS4lJi3QEooF58ATChciYY393Yl8tgPbFdt9baynLYsp3Yk34Dx2517JW1BOd8ABTYv/7vg+EPP/3uwbiWQJmVM8GMr0097WEwltfWek9txD2LtFsN77BHGEBJ6BeD3/dDDPEFGKesZ/LOhOtf8OA0gOnpF1drSfqFiDxgBwzwM8o5ByMiIpFXrwzNlMzVmzwsBCBrwzMxAH5GWRNM4Ci79dO/D45vCbf0U1vFb2QBAACGKWeCibzd/ZHjWyyvHTaX93c5eA4AgBwoZ4KJP76FU1sAAMiLciaY+ONbOLUFAIC8qIyram1gHe1JGs9N9HCV5W02Wq69LIOFpMir2a1Ow2/z0DMAZMucewqNTW5cia1qbWYd7QQbixPoqlev26p1feVebTvULfILAGTNhNsEjc1vXOLzYCzv5NLLehAAAGAa5dwHAwAA8q20CcZ359WyF4lI5NWuDrWr8yg1AAD5UNIEE7jrQbX5lWdJ5G38riOOr7X2F1q2y5F2AADkQDkTjH/4XBqbniUi3W77tTRWHRFxVhtydEhhIwAAzFfOBDMQHO5LxVl1RHrnwQAAgDwoZ4JxVx/L/mHQm4y5PsXO39ntyJNVN+vBAQCANyrp09SOv3c47yolcq+2/cyzJPLq68FjX/tO1kMDAABvVtIEI+L6F+7QlhfLO9FeZoMBgAyob5WI6A911gMBplHOVSQAKLtefBn+DZAvJBgAKJ2R1EKIQR6RYAAge+pbRYwA3goJBgAylv6CzsjeF7bCII8q46paG1hHe5LGc6Xdmgwgn+IWdNLIE/pDbexOXnPuKTQ2uXEltqq1mXW0E2wMAOiHGNOYcJugsfmNWUUCgCyxoANMhwSTmEGNa6Wc4Nan3nGpuAQgVj+1EF+AyZFgkhF5NXtHbYdaa631ntpQijLXACZGdgHeFhtfExEdHHfsrbBl9T50/Yulxbqt6t3wxLOyHRoAAEXEHEwiTs+68rA6nFUs70T7Cy277kWZjQoAgMJiDiYRS4tVOepGIjcmXBxfi6tstxouZjUwAACKiTmYRFhrK8vh5zu39+o6/p7z3LVbnQwGBQBAcZFgkmF57fCz79dvPYUk4voXYbOWyaAAACgsVpESY3lt7Y353nv/OgAAC4pJREFUzMmYzwAAgKkwBwMAAPKHBJMGTrQDACBZrCKlYfwCk4iIUibWJQHKydhihwBGMAeTPT1e1kMDyqVf5tDMeocAhlXGVbU2sI72JI3nmFQCMJWR1KK+VUWdienN+5r8fyRz7ik0NrlxJbaqtZl1tBNsPBuRV7db7VuXK87eK9/NYDwATJd+mOgvWyuljA0xJtwmaGx+Y1aRkhF5NaXso5UwZinoS72u1DLVBQCzjcy4pDABMxwmZt1XbEdswkOukWASER0cd+xm2Ikt4+gEYXM5PD4gwgCG66eWNONL7IcA3ogEk4jblR1vsKoLcnp2muaIAEylqHtfekaWjYxdRQImQYJJxNJiVb7vjp1kibrnsrS4lOaIALwNpVTKsyBZhYl+R8QX5B0JJhHW2spy2LJvFUUSEZHAsVsde2Vt7BQNgEylvx+lJ6swQXZBMZBgkmF5ba331IaKsVsNtY7fIgMga9nuRyFMAFPj+JQEuf4FpQOAO+k/XczZuAB+HnMwAEwxWM1J8WxcNrcCOUWCAWCEwfLNH25eTzHEDMcX9a6od2fdM4DpkWAAYHTqpZ9dCDGAsUgwAOKl/IDxIEP8083r6W+F+Sg+zWSl88n7nU/ez3gQgHlIMABiZPKA8WA1J8WzcQ3Xzy6EGGAECQbAqAwfML4dYjLwzY3Xq19kNQ756NcfDn9IiAGGVcZVtTawjvYkjed4PByFk375YugXV4tHGcaXMjPnnkJjkxtXYqtam1lHO8HGQF4Mr+akefD88LxLOcNTP8Rk6Jv//nZ4Gmb593/OcDBpMuE2QWPzG7OKBJjLiNWcUsYXc/RTS3niCzAhEgyAeGQXQ5BdgFgkGMBcHBcLAOOQYACjmbCao75VKRyMCwBvhQQDmC7bqZc0SxQBwORIMADGS71EEQBMiAQDAADyhwQDYLzMSxQBwBgkGCA3MtlRS4kiAGYiwQCTSrlW82jv2e2oJbsAMBAJBphIJrWaB0q8o1a9m/3p/gAMRIIB3izD0/1Lrp9dCDEARpBgkEvZLuhkoJw7aj+68TIJMQCGVcZVtTawjvYkjecqkzdHXqVfrtmEWs36Q91bPCpLfEGJmXNPobHJjSuxVa3NrKOdYOPZiLy63Wrfulxx9l75bgbjKabbCzoph5gMT8jth5iy+EYNT8PoFxkOBaky4TZBY/Mbs4qUjMirKWUfrYT6ti/1ulLLXpT1GGeiVKs5FFZMXz+1ZBhfvnj0wxePfsisewBjkGASER0cd+xm2PGsmE86QdhcDo8PihdhMnk8h3LNZZPt1Es/uxBiANOQYBJxetaVh9W4+CIiIlZ1QU7PTmc5gvTnQjJ8PMeEcs0og//8xxuphRADGIUEk4ilxap83x07yRJ1z2VpcWlm3Wd8VEkWyC4AUHIkmERYayvLYct2grhPBo7d6tgra2OnaO4mq7mQMq/mZHK6vwnKdrjcv/7vg+EPP/3uwbiWANJHgkmG5bW13lMbKsZuNdQ6fotMzpmwmpN+mMjwdP/BGLJIEpkfLpfJjtp+ask+vryn5L0y5mZgHBJMglz/IuZRJH0y2/Aymh7+cHVn7d/k+u/7nU/e73zyvkiSb4X93vtJIp1++50Oeh/Xb7Kdjpzun+KLHe60/5v0+r15uNxsv8lxhnfUpvBNHtbPLin3O2z5q/+7+h0hBrhGgimCQYi5vr/2b3L99/2rd14ZegdM7q1wkCTS7Hc4TFzfX0f6ne37/phOb3SXeL9DSaK/zzSNfoeM9JvCzXV4R+1Hv/5wtLtUbuopf5NvGOmIEAOICAkmHZFXU++4/iy70FoP7ujXN7n++37/TX9ws+lJ5K0wq377xvQ7k077p/tn9WKvpd3vNyq233RebF/K3+TM+wXwM0gwabC8th5/LG/c3hlVqpPipvRPb24yCxkf6v9NZj8VGZ7LMrKjtnT+on/uQ6Cs1OWrH29fNfP84Ekaz1XuT9g+F972yPzB3tIJZwgSeivMqt9B15NMwyT9vt9fMkvtxY50nX6/Pf1VsxS+ybf7TfnF9vVXkVLud6A335O3+DJd3Y/Xly8nbGnUDYjGKTdmDqZQ+tMD/f8u9zchLv/+z1eX+u+Ayb0VZtVvr2v9oR7Xb+ef/2EWnV51nfqLHe5av8ig3540v8kj/X763YOUX2xfVv0O/EXnLr4AM8UcTIKSr+yYWtlCAJgF5mBoPLvGlXFVrQ2soz1J47nK5M2TFHk1u9Wxm6E+ufXodOAopT4fVzUJAHCTOfcUGpvcmDmYRERe3T5aGZtRIq9mHz8O3/5gGOZgAOQaczA0nl1j9sEkIvvKjgAAlAoJJhEZV3YEAKBsSDCJyLKyIwAAJZTRxtfCsby29nx3XqnbDx3VmqHWU8cXzrUDAOA2EkyCXP8i4dIBudjGW6rtxqV6sVKy18uLBfKFVSQAAJA/JBgAAJA/JBgAAJA/JBgAAJA/JBgAAJA/JBgAAJA/JBgAAJA/JBgAAJA/6uWPf816DEn6xf1fZj0EAMCd/P3l37IeAnKgElvV2sw62gk2BgAYy4TbBI3Nb8wqEgAAyB8SDAAAyB8SDAAAyB8SDAAAyB8SDAAAyB8SDAAAyB8SDKYTeXXVt+xFWY8nJYGrVL0Erzby6pXrv103yHo0sxV5tf5PslPg1xp59XnXH7kYOFevfK7eLP6PNYqGBIMpRF7dboW17VBrrcPmctiyC3+fExEJnDK8SgkctSHPLrXWWus957lb4L/cyKvZO6r3k6z9xr5b1BDju49abX3zWuCo3/7p6rV//aunNUIMcoYEg7cXHRxH0vj6pGWJiFheO2wuy9Hh6H/visZ3N/azHkMKIm93315Zs64+dLc2C/yXGx0cd2Rts/eTLE7gO7J/WLgIEzhKrQevRq5G3u6+vfVs8NrX2k93CvfaUWgkGLw9yzu51IEzdKG6ID+ddwv9H7jI2w2qzabz5pb5Fh0cn9Ye9wOMiOW19SvfzXBIuIvAUe6+3Qy137hxPTo4juRhdfAXXV0scFRFMZFgkIDgcF/uLQy9GRZO5G18rrafedWsBzJz3W5bFqqW786XYZOTtbayLAe7V6sngeMG0lgtVkp1Aq11x4v7x6lqi0M/0FZ1IbVBAYkgweDOAscNxP5sq7j/TY+8jdZPn13Ptxda1D2Xy2D9naMnF719MOGT4yJvcrK8tv76V09tpZTqbQoJihVgxup22z/dulj0mVQUDAkGdxM4yt0Xx4//T14hRN7HLWl+VdwXOOpebfuP/WUjy9tsFHhxIXCV+ljt9dJae+W/6sWecwIKpXJ5+Tr2E+OuG954rjJ5c9zZ9RJ7gePL1frRHwv8Cm8ZWRCsVmu6dRj4bvEmJyJv91AaX13HNct79u/P7c93fK8E+36q1dq9P41eNGYt2Jx7Co1NblyJrWptZh3tBBvj7iKvZrc6BY8vItHB8/Zlp22rp4NrLVu1Gn4xlxviN0Pc3DBRHN1uW9d+M7IXpLeSUuQf6mu6fdYdvNKoey7yMNMBDZhwm6Cx+Y1ZRcI0evGl4Y/ZIVggltfWQ3xHpNYMdTHji4iIs+qo4MYDxVd7ezMb0QxVqzXVPuvevGjMPMRsWWsrlnw/tO2le9aRJ6vFn3xCgZBg8PYib+N3HbsZFvYuXmru1uby/m5/M0jk7e4Xdpu25W2uyv7H1yfVRl79n4v7YkdZ3mYj3NkYPId1UNve4p808oRtI3hr0cHz9uveWsrQ1Xu17fZJGZ7WKTzLa+uqo5TqfVjshULH1+IqVwXrIlL0FzvKCcJuze6tkPLvFzmkLl/9ePuqmStekzSeq9yfsD0AwEyvL19O2NKoGxCNU27MKhIAAMgfEgwAAMgfEgwAAMgfEgwAAMgfEgwAAMgfEgwAAMgfEgwAAMgfEgwAAMgfEgwAAMgf9fLHv2Y9hiT94v4vsx4CAOBO/v7yb1kPATnw//Rd4aIBIU1YAAAAAElFTkSuQmCC"
    }
   },
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We have a lower loss than the Ludwig model but our output is the same for all predicted titles: a seemingly random set of repetitive phrases.\n",
    "\n",
    "I have seen this form of behaviour before. One method of avoiding it was to play with the temperature of the sampling. This is explained [here](https://stats.stackexchange.com/questions/255223/the-effect-of-temperature-in-temperature-sampling) as set out below.\n",
    "\n",
    "![temperature.png](attachment:temperature.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample(preds, temperature=1.0):\n",
    "    # helper function to sample an index from a probability array\n",
    "    preds = np.asarray(preds).astype('float64')\n",
    "    preds = np.log(preds) / temperature\n",
    "    exp_preds = np.exp(preds)\n",
    "    preds = exp_preds / np.sum(exp_preds)\n",
    "    probas = np.random.multinomial(1, preds, 1)\n",
    "    return np.argmax(probas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1226, 1415, 2180, 1370, 873, 1059, 18, 414, 364, 1926, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "state = infenc.predict(X_test[1])\n",
    "# start of sequence input\n",
    "target_seq = array([1])\n",
    "# collect predictions\n",
    "output = list()\n",
    "for t in range(decoder_seq_length):\n",
    "    # predict next char\n",
    "    yhat, h, c = infdec.predict([target_seq] + state)\n",
    "    # update state\n",
    "    state = [h, c]\n",
    "    # update target sequence - this needs to be the argmax\n",
    "    next_int = sample(yhat[0, 0, :])\n",
    "    output.append(next_int)\n",
    "    # It seems like we throw a lot of information away here - can we build in the probabilities?\n",
    "    target_seq = array([next_int])\n",
    "    # Check for stopping character\n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_sequence(infenc, infdec, source, decoder_seq_length, temp=1.0):\n",
    "    # encode\n",
    "    state = infenc.predict(source)\n",
    "    # start of sequence input\n",
    "    target_seq = array([1])\n",
    "    # collect predictions\n",
    "    output = list()\n",
    "    for t in range(decoder_seq_length):\n",
    "        # predict next char\n",
    "        yhat, h, c = infdec.predict([target_seq] + state)\n",
    "        # update state\n",
    "        state = [h, c]\n",
    "        # update target sequence - this needs to be the argmax\n",
    "        next_int = sample(yhat[0, 0, :], temp)\n",
    "        output.append(next_int)\n",
    "        # It seems like we throw a lot of information away here - can we build in the probabilities?\n",
    "        target_seq = array([next_int])\n",
    "        # Check for stopping character\n",
    "        if next_int == 2:\n",
    "            break\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: character string recognition method for recognizing character string comprising steps of imaging character string on medium to obtain image data first step in which first projection data of image data\n",
      "\n",
      "Predicted title is: fidelity awareness screening using regions filtering said program . \n",
      " Test title is: character string recognition method and device  \n",
      "---\n",
      "\n",
      "Sample of claim text: device for selectively modifying transmission performance of frame data having data size and preset transmission clock rate, frame data being transmitted through transmission interface toward an image\n",
      "\n",
      "Predicted title is: dependent accessory candidate lock assignment algorithms initiated devices using manufacture . \n",
      " Test title is: modification device and method for selectively modifying transmission performance of image frame data  \n",
      "---\n",
      "\n",
      "Sample of claim text: an apparatus for use as switch, comprising ring tag including ring element with an rfid circuit, ring tag attached to rotatable on rotation axis to place ring tag into first position, wherein ring tag\n",
      "\n",
      "Predicted title is: refresh similarity coverage serving work hosted secure end diagnosis malicious cryptographic attribute claims tissue controller therefor . \n",
      " Test title is: switch using radio frequency identification  \n",
      "---\n",
      "\n",
      "Sample of claim text: computer-implemented method, comprising receiving sensor data from user device, sensor data comprising image data depicting at least portion of user of user device, image data provided by an image cap\n",
      "\n",
      "Predicted title is: tuning modified pertaining searching detecting scanner response . \n",
      " Test title is: employing device sensor data to determine user characteristics  \n",
      "---\n",
      "\n",
      "Sample of claim text: method of prioritizing feed items based on rules, method comprising receiving input data, wherein input data comprises data or feed metrics receiving user input to provide one or more rules to feed it\n",
      "\n",
      "Predicted title is: timeline abstraction matrix tests combining marks . \n",
      " Test title is: rule based prioritization of social data  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: method for providing service address space, comprising providing service with service address space attached to main processor, wherein main processor is provided with main address space, wherein serv\n",
      "\n",
      "Predicted title is: networked engine memory secured same . \n",
      " Test title is: providing service address space for diagnostics collection  \n",
      "---\n",
      "\n",
      "Sample of claim text: an image processing device comprising filter control unit configured to on basis of an prediction mode, filter processing turned on or off as to neighboring pixels that are located to current block fo\n",
      "\n",
      "Predicted title is: determination virtual rfid swap manufacturing thin session mapping advanced wireless asset sequences telematics . \n",
      " Test title is: image processing device and method  \n",
      "---\n",
      "\n",
      "Sample of claim text: processor implemented method for operating client computing device to allow user to interact with network sites over network interface, method comprising initiating via processor operation of browser \n",
      "\n",
      "Predicted title is: analysis natural alternate adaptive personal methods of applications . \n",
      " Test title is: system method apparatus and means for evaluating historical network activity  \n",
      "---\n",
      "\n",
      "Sample of claim text: method of converting enterprise resource planning data in database managed by an application and accessed through an application programming interface api and message agent api to data in java object \n",
      "\n",
      "Predicted title is: multiple preparing peer estimating insertion signatures measurement . \n",
      " Test title is: accessing a application over the internet using declarative language files  \n",
      "---\n",
      "\n",
      "Sample of claim text: method for information units, method comprises receiving, by storage system, write requests for writing information units to storage system wherein write requests are initiated by multiple accessing e\n",
      "\n",
      "Predicted title is: fuel clustering dedicated length repair names view copy in web store engine . \n",
      " Test title is: system method and a non transitory computer readable medium for a pre operation  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length, 0.5)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: method for using persistent party for comprising via computing device, global array according to hierarchical server architecture, wherein hierarchical server architecture enables user to create and h\n",
      "\n",
      "Predicted title is: a volatile dimensional dimensional more more more more more more more dimensional determine dimensional more more more dimensional dimensional more more more . \n",
      " Test title is: persistent party  \n",
      "---\n",
      "\n",
      "Sample of claim text: an input device comprising selecting section for selecting pair from among plurality of x electrodes and y electrodes disposed as being spaced apart from each other detecting section for detecting tou\n",
      "\n",
      "Predicted title is: a volatile dimensional more more more dimensional more more more more more dimensional dimensional dimensional more more more more dimensional dimensional more . \n",
      " Test title is: input device input control method program and electronic apparatus  \n",
      "---\n",
      "\n",
      "Sample of claim text: an image processing apparatus comprising designating unit adapted to as an image processing function to be applied to an image of interest, any of plurality of image processing functions including cop\n",
      "\n",
      "Predicted title is: a more more volatile dimensional more more more more more more dimensional volatile dimensional dimensional dimensional image adjust dimensional transitory image volatile . \n",
      " Test title is: image processing apparatus method and program  \n",
      "---\n",
      "\n",
      "Sample of claim text: an image processing apparatus comprising separation unit configured to separate image data into luminance signal and color difference signal decision unit configured to reference pixel, which is refer\n",
      "\n",
      "Predicted title is: be . \n",
      " Test title is: image processing apparatus  \n",
      "---\n",
      "\n",
      "Sample of claim text: method comprising identifying, by one or more computers, an image in first storage system determining, by one or more computers, whether second storage system includes an entry for image identifying r\n",
      "\n",
      "Predicted title is: a dimensional volatile dimensional more more more more more dimensional more more dimensional more more more more more dimensional more more dimensional . \n",
      " Test title is: methods and apparatus for automated object based image analysis and retrieval  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length, 0.1)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So low temperature reproduces the default results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: computer-implemented method for analyzing data representative of media material having layout, comprising identifying block segments associated with body text in media material and determining which o\n",
      "\n",
      "Predicted title is: electrode localization funds link being . \n",
      " Test title is: methods and systems for analyzing data in media material having layout  \n",
      "---\n",
      "\n",
      "Sample of claim text: computer interface system comprising at least one camera operable to create an image of by user, comprising plurality of features and b processing module operable to receive created image of and deter\n",
      "\n",
      "Predicted title is: unstructured log entity plural adapted performed . \n",
      " Test title is: for camera calibration and as a gesture based 3d interface device  \n",
      "---\n",
      "\n",
      "Sample of claim text: computer-implemented method, comprising receiving, by computing system, multiple portions of text that were input into different types of fields associated with resource selecting i first threshold va\n",
      "\n",
      "Predicted title is: preferred map merging horizontal pad refinement normal operands editing multicore health party storage communication terminal or management server memory . \n",
      " Test title is: selectively processing user input  \n",
      "---\n",
      "\n",
      "Sample of claim text: mobile terminal comprising display memory configured to store at least one image fragment first camera user input unit configured to receive input and controller configured to cause display to display\n",
      "\n",
      "Predicted title is: determining technical tomography initiating sequences behavior spatial particular electro managing pipeline assistance shared listing commerce user requesting arithmetic criteria domains insertion schema . \n",
      " Test title is: mobile terminal and controlling method thereof  \n",
      "---\n",
      "\n",
      "Sample of claim text: an information handling system comprising plurality of ports for sending data to and receiving data from one or more devices one or more processors that are communicatively coupled to plurality of por\n",
      "\n",
      "Predicted title is: mass diagram level user's development metal identification operable requests computer machine attached product . \n",
      " Test title is: reducing internal fabric in switch fabric  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length, 1.5)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {}. \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample of claim text: an id document comprising document core layer having two opposed surfaces and on at least one surface of document core layer, comprising top layer middle layer and bottom layer, wherein point of botto\n",
      "\n",
      "Predicted title is: removal human partitioning related recording platforms  \n",
      " Test title is: id documents having a multi layered structure  \n",
      "---\n",
      "\n",
      "Sample of claim text: method for presenting story content relating to and location of interest, method comprising receiving query comprising an intersection criteria, intersection criteria comprising location and of intere\n",
      "\n",
      "Predicted title is: item many step chips overlay transmitting  \n",
      " Test title is: systems and methods for collaborative in a virtual space  \n",
      "---\n",
      "\n",
      "Sample of claim text: method of forming an image using plurality of comprising receiving at least one raster of image pixels each having discrete value for each of for raster associated with defective modifying values of p\n",
      "\n",
      "Predicted title is: held appearance execution acceleration site containing reporting common remote it nand configurations  \n",
      " Test title is: replacing a  \n",
      "---\n",
      "\n",
      "Sample of claim text: an integrated circuit ic comprising digital circuit comprising derived clock circuit configured to receive root clock having frequency and single phase, wherein d is divide factor for root wherein der\n",
      "\n",
      "Predicted title is: detect compliance separation  \n",
      " Test title is: apparatus and method for reducing interference signals in an integrated circuit using  \n",
      "---\n",
      "\n",
      "Sample of claim text: method for using secure socket layer session from pool of sessions shared between method comprising receiving, by first intermediary device, information on one or more sessions of pool established by \n",
      "\n",
      "Predicted title is: different appearance interference characters via modules including web sequences  \n",
      " Test title is: systems and methods of using pools for acceleration  \n",
      "---\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Testing\n",
    "num_test_titles = len(X_test)\n",
    "indices = np.arange(num_test_titles)\n",
    "np.random.shuffle(indices)\n",
    "X_test = X_test[indices]\n",
    "Y_test = Y_test[indices]\n",
    "for i in range(0, 5):\n",
    "    pred_seq = predict_sequence(infenc, infdec, X_test[i], decoder_seq_length)\n",
    "    predicted_text = seq2text(pred_seq, y_dictionary)\n",
    "    Y_test_text = seq2text(Y_test[i], y_dictionary)\n",
    "    claim_text = seq2text(X_test[i], x_dictionary)\n",
    "    print(\"Sample of claim text: {}\\n\".format(claim_text[0:200]))\n",
    "    print(\"Predicted title is: {} \\n Test title is: {} \\n---\\n\".format(predicted_text, Y_test_text))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comments on Results\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Options for Further Investigation\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Summary\n",
    "\n",
    "In this post we have:\n",
    "* Constructed two sequence-to-sequence models.\n",
    "* Applied theses models to our patent claim and title data.\n",
    "* Looked at the performance of each model, including identifying strengths and weaknesses."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
